<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[关于线程池的面试题]]></title>
    <url>%2Fjava-threadPool.html</url>
    <content type="text"><![CDATA[问题问题： 单机上一个线程正在处理服务，如果忽然断电了怎么办（正在处理和阻塞队列里的请求怎么处理） 为什么要使用线程池，线程池用什么用 说说几种常见的线程池及使用场景 线程池有哪几种工作队列 怎么理解无界队列和有界队列 线程池中的几种重要的参数及流程 1. 为什么要使用线程池，线程池用什么用 降低资源消耗：通过重用已经创建的线程来降低线程创建和销毁的消耗 提高响应速度：任务到达时不需要等待线程创建就可以立即执行 提高线程的可管理性：线程池可以统一管理、分配、调优和监控 2. 说说几种常见的线程池及使用场景 newFixedThreadPool（固定大小的线程池） newSingleThreadExecutor（单线程线程池） newCachedThreadPool（可缓存线程的线程池） newScheduledThreadPool newFixedThreadPool12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 线程池特点： 核心线程数和最大线程数大小一样 keepAliveTime为0 阻塞队列是LinkedBlockingQueue 它是固定大小的线程池，其核心线程数和最大线程数大小一样。并且阻塞队列用的是LinkedBlockingQueue，也就是说线程最大数这个参数失效了基本，所以不会出现外包线程的存在，所以也可以认为keepAliveTime参数是一个摆设。除非allowCoreThreadTimeOut方法的调用。 该线程池的工作机制是： 线程数少于核心线程数，也就是设置的线程数时，新建线程执行任务 线程数等于核心线程数后，将任务加入阻塞队列 由于队列容量非常大(Integer.MAX_VALUE)，可以一直加加加。(当线程池中的任务比较特殊时，比如关于数据库的长时间的IO操作，可能导致OOM) 执行完任务的线程反复去队列中取任务执行 适用场景： FixedThreadPool 适用于处理CPU密集型的任务，确保CPU在长期被工作线程使用的情况下，尽可能的少的分配线程即可。一般Ncpu+1 newSingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 线程池特点： 核心线程数和最大线程数大小一样且都是1 keepAliveTime为0 阻塞队列是LinkedBlockingQueue 该线程池的工作机制是： 线程池中没有线程时，新建一个线程执行任务 有一个线程以后，将任务加入阻塞队列，不停加加加 唯一的这一个线程不停地去队列里取任务执行 适用场景： SingleThreadExecutor适用于串行执行任务的场景，每个任务必须按顺序执行，不需要并发执行。 newCachedThreadPool12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 线程池特点： 核心线程数为0，且最大线程数为Integer.MAX_VALUE 阻塞队列是SynchronousQueue SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue 锁当提交任务的速度大于处理任务的速度时，每次提交一个任务，就必然会创建一个线程。极端情况下会创建过多的线程，耗尽 CPU 和内存资源。由于空闲 60 秒的线程会被终止，长时间保持空闲的 CachedThreadPool 不会占用任何资源。 该线程池的工作机制是： 没有核心线程，直接向SynchronousQueue中提交任务 如果有空闲线程，就去取出任务执行；如果没有空闲线程，就新建一个 执行完任务的线程有60秒生存时间，如果在这个时间内可以接到新任务，就可以继续活下去，否则就拜拜 适用场景： CachedThreadPool 用于并发执行大量短期的小任务。 newScheduledThreadPool123456789101112public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125;public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, DEFAULT_KEEPALIVE_MILLIS, MILLISECONDS, new DelayedWorkQueue());&#125;private static final long DEFAULT_KEEPALIVE_MILLIS = 10L; 线程池特点： 最大线程数为Integer.MAX_VALUE 阻塞队列是DelayedWorkQueue ScheduledThreadPoolExecutor 添加任务提供了另外两个方法： scheduleAtFixedRate() ：按某种速率周期执行 scheduleWithFixedDelay()：在某个延迟后执行 两种方法的内部实现都是创建了一个ScheduledFutureTask对象封装了任务的延迟执行时间及执行周期，并调用decorateTask()方法转成RunnableScheduledFuture对象，然后添加到延迟队列中。 DelayQueue：中封装了一个优先级队列，这个队列会对队列中的ScheduledFutureTask 进行排序，两个任务的执行 time 不同时，time 小的先执行；否则比较添加到队列中的ScheduledFutureTask的顺序号 sequenceNumber ，先提交的先执行。 该线程池的工作机制是： 调用上面两个方法添加一个任务 线程池中的线程从 DelayQueue 中取任务 然后执行任务 具体执行步骤： 线程从 DelayQueue 中获取 time 大于等于当前时间的 ScheduledFutureTask DelayQueue.take() 执行完后修改这个 task 的 time 为下次被执行的时间 然后再把这个 task 放回队列中 DelayQueue.add() 适用场景： ScheduledThreadPoolExecutor用于需要多个后台线程执行周期任务，同时需要限制线程数量的场景。 3. 线程池有哪几种工作队列 ArrayBlockingQueue （有界队列）：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。 LinkedBlockingQueue （无界队列）：一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。 SynchronousQueue（同步队列）: 一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。 DelayQueue（延迟队列）：一个任务定时周期的延迟执行的队列。根据指定的执行时间从小到大排序，否则根据插入到队列的先后排序。 PriorityBlockingQueue（优先级队列）: 一个具有优先级得无限阻塞队列。 4. 怎么理解无界队列和有界队列 有界队列即长度有限，满了以后ArrayBlockingQueue会插入阻塞。 无界队列就是里面能放无数的东西而不会因为队列长度限制被阻塞，但是可能会出现OOM异常。 5. 线程池中的几种重要的参数及流程123456789101112131415161718192021public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; corePoolSize：核心池的大小，在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中 maximumPoolSize：线程池最大线程数最大线程数 keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止 unit：参数keepAliveTime的时间单位TimeUtil类的枚举类（DAYS、HOURS、MINUTES、SECONDS 等） workQueue：阻塞队列，用来存储等待执行的任务 threadFactory：线程工厂，主要用来创建线程 handler：拒绝处理任务的策略 AbortPolicy：丢弃任务并抛出 RejectedExecutionException 异常。（默认这种） DiscardPolicy：也是丢弃任务，但是不抛出异常 DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程） CallerRunsPolicy：由调用线程处理该任务 执行流程 当有任务进入时，线程池创建线程去执行任务，直到核心线程数满为止 核心线程数量满了之后，任务就会进入一个缓冲的任务队列中 当任务队列为无界队列时，任务就会一直放入缓冲的任务队列中，不会和最大线程数量进行比较 当任务队列为有界队列时，任务先放入缓冲的任务队列中，当任务队列满了之后，才会将任务放入线程池，此时会拿当前线程数与线程池允许的最大线程数进行比较，如果超出了，则默认会抛出异常。如果没超出，然后线程池才会创建线程并执行任务，当任务执行完，又会将缓冲队列中的任务放入线程池中，然后重复此操作。 6. 单机上一个线程正在处理服务，如果忽然断电了怎么办（正在处理和阻塞队列里的请求怎么处理）经过网上查阅，发现基本是没有一个明确的回答的。不过思考过后一番，我感觉实现思路和MySQL的redo，undo功能很相似，我们可以对正在处理和阻塞队列的任务做事物管理或者对阻塞队列中的任务持久化处理，并且当断电或者系统崩溃，操作无法继续下去的时候，可以通过回溯日志的方式来撤销正在处理的已经执行成功的操作。然后重新执行整个阻塞队列。 即： 阻塞队列持久化，正在处理事物控制。断电之后正在处理的回滚，日志恢复该次操作。服务器重启后阻塞队列中的数据再加载 参考 http://www.54tianzhisheng.cn/2017/07/29/ThreadPool/#%E7%BA%BF%E7%A8%8B%E6%B1%A0 http://ifeve.com/java-threadpool/ https://blog.csdn.net/qq_38283430/article/details/80193235]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal 深入剖析]]></title>
    <url>%2Fjava-threadLocal.html</url>
    <content type="text"><![CDATA[图解ThreadLocal ThreadLocalMap.Entry的弱引用12345678910111213141516171819202122static class ThreadLocalMap &#123; /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as "stale entries" in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; ...&#125; 弱引用作为Entry的key在这里的作用： 当程序中再没有对该ThreadLocal的强引用时，各线程的ThreadLocalMap中Entry的key为该ThreadLocal，他们的key值都会变成null。该ThreadLocal对象会被GC回收。算是ThreadLocalMap考虑周全，怕我们忘记删吧，我能想到的优点 …… 对ThreadLocal的理解 ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，其实意思差不多。可能很多朋友都知道ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。 该类提供了线程局部 (thread-local) 变量。这些变量不同于它们的普通对应物，因为访问某个变量（通过其 get 或 set 方法）的每个线程都有自己的局部变量，它独立于变量的初始化副本。ThreadLocal 实例通常是类中的 private static 字段，它们希望将状态与某一个线程（例如，用户 ID 或事务 ID）相关联。 这句话从字面上看起来很容易理解，但是真正理解并不是那么容易。 我们还是先来看一个例子： 12345678910111213141516class ConnectionManager &#123; private static Connection connect = null; public static Connection openConnection() &#123; if(connect == null)&#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public static void closeConnection() &#123; if(connect!=null) connect.close(); &#125;&#125; 假设有这样一个数据库链接管理类，这段代码在单线程中使用是没有任何问题的，但是如果在多线程中使用呢？很显然，在多线程中使用会存在线程安全问题：第一，这里面的2个方法都没有进行同步，很可能在openConnection方法中会多次创建connect；第二，由于connect是共享变量，那么必然在调用connect的地方需要使用到同步来保障线程安全，因为很可能一个线程在使用connect进行数据库操作，而另外一个线程调用closeConnection关闭链接。 所以出于线程安全的考虑，必须将这段代码的两个方法进行同步处理，并且在调用connect的地方需要进行同步处理。 这样将会大大影响程序执行效率，因为一个线程在使用connect进行数据库操作的时候，其他线程只有等待。 那么大家来仔细分析一下这个问题，这地方到底需不需要将connect变量进行共享? 事实上，是不需要的。假如每个线程中都有一个connect变量，各个线程之间对connect变量的访问实际上是没有依赖关系的，即一个线程不需要关心其他线程是否对这个connect进行了修改的。 到这里，可能会有朋友想到，既然不需要在线程之间共享这个变量，可以直接这样处理，在每个需要使用数据库连接的方法中具体使用时才创建数据库链接，然后在方法调用完毕再释放这个连接。比如下面这样：12345678910111213141516171819202122232425262728class ConnectionManager &#123; private Connection connect = null; public Connection openConnection() &#123; if(connect == null)&#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public void closeConnection() &#123; if(connect!=null) connect.close(); &#125;&#125; class Dao&#123; public void insert() &#123; ConnectionManager connectionManager = new ConnectionManager(); Connection connection = connectionManager.openConnection(); //使用connection进行操作 connectionManager.closeConnection(); &#125;&#125; 这样处理确实也没有任何问题，由于每次都是在方法内部创建的连接，那么线程之间自然不存在线程安全问题。但是这样会有一个致命的影响：导致服务器压力非常大，并且严重影响程序执行性能。由于在方法中需要频繁地开启和关闭数据库连接，这样不尽严重影响程序执行效率，还可能导致服务器压力巨大。 那么这种情况下使用ThreadLocal是再适合不过的了，因为ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。 但是要注意，虽然ThreadLocal能够解决上面说的问题，但是由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。 深入解析ThreadLocal类 在上面谈到了对ThreadLocal的一些理解，那我们下面来看一下具体ThreadLocal是如何实现的。 先了解一下ThreadLocal类提供的几个方法：1234public T get() &#123; &#125;public void set(T value) &#123; &#125;public void remove() &#123; &#125;protected T initialValue() &#123; &#125; get()方法是用来获取ThreadLocal在当前线程中保存的变量副本，set()用来设置当前线程中变量的副本，remove()用来移除当前线程中变量的副本，initialValue()是一个protected方法，一般是用来在使用时进行重写的，它是一个延迟加载方法，下面会详细说明。 首先我们来看一下ThreadLocal类是如何为每个线程创建一个变量的副本的。 先看下get方法的实现：12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 第一句是取得当前线程，然后通过getMap(t)方法获取到一个map，map的类型为ThreadLocalMap。然后接着下面获取到&lt;key,value&gt;键值对，注意这里获取键值对传进去的是 this，而不是当前线程t。 如果获取成功，则返回value值。 如果map为空，则调用setInitialValue方法返回value。 我们上面的每一句来仔细分析： 首先看一下getMap方法中做了什么：123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 可能大家没有想到的是，在getMap中，是调用当期线程t，返回当前线程t中的一个成员变量threadLocals。 那么我们继续取Thread类中取看一下成员变量threadLocals是什么：123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 实际上就是一个ThreadLocalMap，这个类型是ThreadLocal类的一个内部类，我们继续取看ThreadLocalMap的实现： 关于弱引用WeakReference的学习可参考：理解Java中的弱引用（Weak Reference）12345678910111213141516171819202122static class ThreadLocalMap &#123; /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as "stale entries" in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; ····&#125; 可以看到ThreadLocalMap的Entry继承了弱引用WeakReference，而WeakReference的泛型也指向了Entry中的键值ThreadLocal。也就是说ThreadLocalMap是使用ThreadLocal的弱引用作为key的，它这么设计的原因也是为了方便它的键值ThreadLocal在外部没有强引用引用的情况下进行内存的释放。 下图是本文介绍到的一些对象之间的引用关系图，实线表示强引用，虚线表示弱引用： 然后网上就传言，ThreadLocal会引发内存泄露，他们的理由是这样的： 如上图，ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc的时候，这个ThreadLocal势必会被回收， 这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链： ThreadLocal Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value 永远无法回收，造成内存泄露。 我们来看看到底会不会出现这种情况。 其实，在JDK的ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施，下面是ThreadLocalMap的getEntry方法的源码： 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; // Entry 继承 WeakReference if (e != null &amp;&amp; e.get() == key) // e.get()拿出的是WeakReferencere的referent即 ThreadLocal return e;// 如果桶不为空 &amp; 且元素刚好是此ThreadLocal else return getEntryAfterMiss(key, i, e);&#125; getEntryAfterMiss函数的源码：12345678910111213141516 private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) // 如果从桶中取出的Entry的 key==null expungeStaleEntry(i); else i = nextIndex(i, len); // 类似HsahMap中取桶中的链表的下一元素 e = tab[i]; &#125; return null;&#125; expungeStaleEntry函数的源码：12345678910111213141516171819202122232425262728293031323334353637// 删除陈旧条目private int expungeStaleEntry(int staleSlot) &#123;Entry[] tab = table;int len = tab.length;// expunge entry at staleSlottab[staleSlot].value = null;tab[staleSlot] = null;size--;// 接着处理此table之后 的桶中key为null的Entry// Rehash until we encounter nullEntry e;int i;for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125;&#125;return i;&#125; 整理一下ThreadLocalMap的getEntry函数的流程： 首先从ThreadLocal的直接索引位置(通过ThreadLocal.threadLocalHashCode &amp; (len-1)运算得到)获取Entry e，如果e不为null并且key相同则返回e； 如果散列到的Entry为null或者key不一致则向table数组的下一个位置查询。如果下一个位置的key和当前需要查询的key相等，则返回对应的Entry。如果不等，如果key值为null，则擦除该位置的Entry，然后继续向table后续的位置查询该Entry，直到table到头。 在这个过程中遇到的key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，自然会被回收。 仔细研究代码可以发现，set操作也有类似的思想，将key为null的这些Entry都删除，防止内存泄露。 需要注意的是： 虽然ThreadLocalMap内部有对这样的 Key为null的Entry的处理机制，但是光这样还是不够的，上面的设计思路依赖一个前提条件：要调用ThreadLocalMap的genEntry函数或者set函数。 这当然是不可能任何情况都成立的，所以很多情况下需要使用者手动调用ThreadLocal的remove函数，手动删除当前线程不再需要的ThreadLocal，防止内存泄露。 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; 当前线程调用一下ThreadLocal的remove函数即可删除该线程的ThreadLocalMap中的该不用的ThreadLocal变量了。 所以JDK建议将ThreadLocal变量定义成private static的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，就不会出现key为null的Entry了。也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，当我们某个线程不需要该ThreadLocal变量的时候也可以手动的remove它，方便可控且防止内存泄露(针对Value)。 参考：ThreadLocal和synchronized的区别? 然后再继续看setInitialValue方法的具体实现：12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 很容易了解，就是如果map不为空，就设置键值对，为空，再创建Map，看一下createMap的实现：123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 至此，可能大部分朋友已经明白了ThreadLocal是如何为每个线程创建变量的副本的： 首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。 初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。 然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。 下面通过一个例子来证明通过ThreadLocal能达到在每个线程中创建变量副本的效果：1234567891011121314151617181920212223242526272829303132333435363738394041public class Test &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;(); ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;(); public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final Test test = new Test(); test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread()&#123; public void run() &#123; test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;; &#125;; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;&#125; 这段代码的输出结果为：1234561main8Thread-01main 从这段代码的输出结果可以看出，在main线程中和thread1线程中，longLocal保存的副本值和stringLocal保存的副本值都不一样。最后一次在main线程再次打印副本值是为了证明在main线程中和thread1线程中的副本值确实是不同的。 总结一下 实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的； 为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像上面代码中的longLocal和stringLocal； 在进行get之前，必须先set，否则通过ThreadLoca的get函数取出的值为null(默认initValue()函数的结果)。 如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。 因为在上面的代码分析过程中，我们发现如果没有先set的话，即在map中查找不到对应的存储，则会通过调用setInitialValue方法返回i，而在setInitialValue方法中，有一个语句是T value = initialValue()， 而默认情况下，initialValue方法返回的是null。 123456789101112131415161718192021222324public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 看下面这个例子：12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;(); ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;(); public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final Test test = new Test(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread()&#123; public void run() &#123; test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;; &#125;; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125; &#125; 在main线程中，没有先set，直接get的话，运行时会报空指针异常。 但是如果改成下面这段代码，即重写了initialValue方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Test &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;()&#123; protected Long initialValue() &#123; return Thread.currentThread().getId(); &#125;; &#125;; ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;()&#123;; protected String initialValue() &#123; return Thread.currentThread().getName(); &#125;; &#125;; public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final Test test = new Test(); test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread()&#123; public void run() &#123; test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;; &#125;; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;&#125; 就可以直接不用先set而直接调用get了。 ThreadLocal的应用场景 最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。 如：123456789private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() &#123; public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL); &#125;&#125;; public static Connection getConnection() &#123; return connectionHolder.get();&#125; 下面这段代码摘自： 正确理解ThreadLocal 1234567891011121314private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s;&#125; 可以看出每个线程操控属于自己的一个Session。 关于ThreadLocal在exchange中的用法当某个线程被程序分配到执行某个用户的请求时，由于对于每次来请求的用户的身份未知，所以为了该线程所处理的函数间用户身份信息的传递确认，会用ThreadLocal来存储用户信息。这里ThreadLocal的作用也就是相当于方便函数间参数传递的工具 exchange项目的代码中做的处理就是每个请求过来先走PassportInterceptor来确认用户身份并且绑定到Hostholder中 这样无论程序分配的是哪个线程来处理用户的请求 函数间传递的都是该身份的用户不会出错。并且由于每个请求都走该拦截器，所以用户每次过来当前线程的ThreadLocal对应的对象都是当前用户会替换掉之前存储在其中的用户。 ThreadLocal与Synchonized的对照ThreadLocal和Synchonized都用于解决多线程并发訪问。可是ThreadLocal与synchronized有本质的差别。synchronized是利用锁的机制，使变量或代码块在某一时该仅仅能被一个线程訪问。而ThreadLocal为每个线程都提供了变量的副本，使得每个线程在某一时间訪问到的并非同一个对象，这样就隔离了多个线程对数据的数据共享。而Synchronized却正好相反，它用于在多个线程间通信时可以获得数据共享。 Synchronized用于线程间的数据共享，而ThreadLocal则用于线程间的数据隔离。 总结ThreadLocal这个类它是作为在多线程并发环境下，为每个线程划分属于自己的变量而存在的一个类。从如下的函数Api也可以很清楚的看出这一点。 ThreadLocal：123456789101112131415161718192021222324252627public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value);// 这里的this指针指的是该类中的ThreadLocal变量 else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; // 根据ThreadLocal的引用来获取其对应的Entry ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; Thread：123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 我们一般用它作用在多线程情况下的并发访问上，同一线程的职责内，不同方法间调用时，在保证各线程私有的参数的传递上时使用。如下例： Controller：123456@GetMapping("/")public ServerResponse&lt;PageInfo&gt; getConversationsWithTourists(@RequestParam(value="pageNum",defaultValue="0")IntegerpageNum, @RequestParam(value = "pageSize", defaultValue ="10") Integer pageSize) &#123; int localUserId = hostHolder.getUser().getId(); return iMessageService.getConversationWithTouristsList(localUserId, pageNum, pageSize); &#125; PassportInterceptor：12345678910111213141516171819202122232425262728@Override public boolean preHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) throws Exception &#123; String ticket = null; if (httpServletRequest.getCookies() != null) &#123; Cookie[] cookies = httpServletRequest.getCookies(); for (Cookie cookieItem : cookies) &#123;// 找T票 if (cookieItem.getName().equals("ticket")) &#123; ticket = cookieItem.getValue(); break; &#125; &#125; &#125; if (ticket != null) &#123; LoginTicket loginTicket = iLoginTicketService.getLoginTicketByTicket(ticket); if (loginTicket == null || loginTicket.getExpired().before(new DateTime().toDate()) || loginTicket.getStatus().intValue() == Const.TicketStatus.LOG_OUT) &#123;// T票无效 return true;// 放行去生成T票 &#125; // T票有效 User user = iUserService.getUserById(loginTicket.getUserId()).getData(); if (user != null) &#123; hostHolder.setUser(user);// 同一Thread重置对象 &#125; &#125; return true; &#125; 还需要注意的就是，对于成员变量(线程共享的变量)，如果存到ThreadLocal中是没有意义的，仍旧会触发多线程间并发修改的问题。因为这些变量是线程间共享变量。我们一般使用ThreadLocal来存储每个Thread实例对应的一个对象的访问，就比如上例中对于访问Controller中的User对象的存储。显然Interceptor中set到ThreadLocal中的User对象是局部变量，每个线程被Tomcat用来处理一个请求，所以每个用户是每个线程的私有变量，所以不存在并发修改的问题。并且可以根据ThreadLocal的机制保证各线程走到这里被分发到了属于自己的User对象，进而ThreadLocal会将该User与自己绑成K-V对，存储到当前分配到处理的Thread的ThreadLocalMap中。从此该User就和该Thread对象绑定。 我们一般就通过这样的方式来简化某个线程私有对象在一个线程处理职责内，被应用的函数多处调用时参数的传递问题，可以简化函数的签名，因为如果每个地方使用时该变量都需要传一下的话就太麻烦了。这样就比较简洁了。 使用ThreadLocal需要注意的点 它一般都是private static的 由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。 由于ThreadLocalMap中的Entry的key是ThreadLocal，Entry继承了WeakReference类且referent是ThreadLocal。所以很多时候可能Entry中的key，ThreadLocal会变成null值，而ThreadLocal内部虽然也对这种key为null的Entry做了处理。但也要调用ThreadLocalMap的genEntry函数或者set函数。 这当然是不可能任何情况都成立的，所以很多情况下需要使用者手动调用ThreadLocal的remove函数，手动删除不再需要的ThreadLocal，防止内存泄露。 学习时必看的另两篇文章 正确理解ThreadLocal java ThreadLocal(应用场景及使用方式及原理) Java进阶（七）正确理解Thread Local的原理与适用场景 参考参考资料： 《深入理解Java虚拟机》 《Java编程思想》 http://ifeve.com/thread-management-10/ http://www.ibm.com/developerworks/cn/java/j-threads/index3.html http://www.iteye.com/topic/103804 http://www.iteye.com/topic/777716 http://www.iteye.com/topic/757478 http://blog.csdn.net/ghsau/article/details/15732053 http://ispring.iteye.com/blog/162982 http://blog.csdn.net/imzoer/article/details/8262101 http://www.blogjava.net/wumi9527/archive/2010/09/10/331654.html http://bbs.csdn.net/topics/380049261]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于锁的面试题]]></title>
    <url>%2Fjava-lock.html</url>
    <content type="text"><![CDATA[面试问题synchronized关键字，实现原理（和Lock对比着说，说到各自的优缺点，synchronized从最初性能差到jdk高版本后的锁膨胀机制，大大提高性能，再说底层实现，Lock的乐观锁机制，通过AQS队列同步器，调用了unsafe的CAS操作，CAS函数的参数及意义；同时可以说说synchronized底层原理，jvm层的moniter监视器，对于方法级和代码块级，互斥原理的不同，+1-1可重入的原理等） synchronizedsynchronized的实现原理synchronized可以保证方法或者代码块在运行时，同一时刻只有一个线程可以执行该方法或代码块，同时它还可以保证对共享变量操作的内存可见性。 实现同步的方式synchronized实现同步的方式一般有3种，普通同步方法、静态同步方法、同步代码块，分别锁的是当前实例对象，类对象，synchronized括号中修饰的类或对象。 由于Java保证任何一个对象都有其对应的monitor，或者说管程对象存在。对于synchronized修饰的方法或代码块JVM本质上都是通过获取，释放monitor对象来对方法，同步块进行同步的。 同步代码块： 具体实现规则又有所不同，同步代码块是在代码块前插入一条monitor.enter指令，代码块的退出位置再插入一条monitor.exit指令。以及插入的一条，异常结束时供异常处理器调用的monitor.exit指令。 同步方法： 方法级的同步是隐式的，并不需要像同步代码块一样通过字节码指令来控制。它在方法调用和返回操作的时候，JVM可以从方法常量池中的方法表结构中的ACC_SYNCHRONIZED访问标志来区分一个方法是否同步方法。当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor，执行结束或异常终止则会释放monitor。 synchronized优化在Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，所以这也就是synchronized效率低下的原因。而在jdk1.6的时候Java也对该弊端进行了改进，为了减少获取锁和释放锁锁带来的性能上的损耗引入了偏向锁和轻量锁。 Java锁一共四种状态，无锁，偏向，轻量，重量。 偏向锁偏向锁的核心思想：不存在多线程竞争，并且应由一个线程多次获得锁。 获取锁当线程访问同步块时，会使用 CAS 将线程 ID 更新到锁对象头文件的 Mark Word 标志字段中，如果更新成功则获得偏向锁，并且之后该线程每次进入这个对象锁相关的同步块时都不需要再次获取锁了。 释放锁 由于线程释放锁只有竞争才会释放，所以对于偏向锁线程是不会主动释放锁的，需要等待其他线程来竞争。偏向锁的撤销需要等待全局安全点（这个时间点是上没有正在执行的代码）。暂停当前线程，判断对象是否处于被锁定的状态，撤销偏向锁，恢复到无锁态或轻量锁态。 轻量锁轻量锁的核心思想：对于绝大部分的锁，在整个生命周期内都是不会存在竞争的。没有多线程竞争的前提下，减少传统的重量级锁的使用，及操作系统互斥量产生的性能消耗。 获取锁 根据当前对象头的Mark Word标志词中的锁标记为来判断当前对象的锁状态是否处于无锁状态，若是，则JVM首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝。JVM利用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指正，如果成功表示竞争到锁，则将锁标志位变成00（表示此对象处于轻量级锁状态），执行同步操作；如果失败判断当前对象的Mark Word是否指向当前线程的栈帧，如果是则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻量级锁需要膨胀为重量级锁，锁标志位变成10，后面等待的线程将会进入阻塞状态 释放锁 轻量级锁的释放也是通过CAS操作来进行的，取出在获取轻量级锁保存在Displaced Mark Word中的数据，用CAS操作将取出的数据替换当前对象的Mark Word中，如果成功，则说明释放锁成功。如果CAS操作替换失败，说明有其他线程尝试获取该锁，则需要在释放锁的同时需要唤醒被挂起的线程。 适应性自旋锁防止线程切换的损耗，某个线程在被强占cpu时间片后进入阻塞状态并后续唤醒是十分不值得的，所以让该线程自旋等待一段时间。jdk1.6后引入了适应性自旋锁，通过每次自旋并实时的监控上传自旋的状态来决定自旋的次数。 锁消除即JVM会通过变量逃逸机制来判断，当前操作的变量是否是栈封闭的环境中运行，如果是，那么它便会大胆的对一些通过加锁机制来保证并发安全的变量进行去锁操作。比如栈封闭情况下的StringBuffer和Vector等。 锁粗化在使用同步锁的时候，需要让同步块的作用范围尽可能小—仅在共享数据的实际作用域中才进行同步，这样做的目的是为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快拿到锁。 但是如果一系列的连续加锁解锁操作，可能会导致不必要的性能损耗，所以引入锁粗话的概念。 锁粗话概念比较好理解，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁。如上面实例：vector每次add的时候都需要加锁操作，JVM检测到对同一个对象（vector）连续加锁、解锁操作，会合并一个更大范围的加锁、解锁操作，即加锁解锁操作会移到for循环之外。 12345678public void vectorTest()&#123; Vector&lt;String&gt; vector = new Vector&lt;String&gt;(); for(int i = 0 ; i &lt; 10 ; i++)&#123; vector.add(i + ""); &#125; System.out.println(vector);&#125; 对象头Java对象头和Monitor是synchronized实现同步的机制。Hotspot虚拟机的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）Klass Point是是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例，Mark Word用于存储对象自身的运行时数据，它是实现轻量级锁和偏向锁的关键。 Mark Word用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等 锁标志状态图 Monitor每一个被锁住的对象都会和一个monitor关联。在JVM层面monitor是由C++中的ObjectMonitor对象来实现的。 Monitor对象的结构图： Owner：初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该锁后保存线程唯一标识，当锁被释放时又设置为NULL； EntryQ:关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的线程。 RcThis:表示blocked或waiting在该monitor record上的所有线程的个数。 Nest:用来实现重入锁的计数。 HashCode:保存从对象头拷贝过来的HashCode值（可能还包含GC age）。 Candidate:用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下降。Candidate只有两种可能的值0表示没有需要唤醒的线程1表示要唤醒一个继任线程来竞争锁。 Lock Lock提供了比使用synchronized方法和语句更广泛的锁定操作。支持中断、超时不获取、是非阻塞的 提高了语义化，哪里加锁，哪里解锁都得写出来 Lock显式锁可以给我们带来很好的灵活性，不需要像synchronized一样锁的获取和释放要在同一个函数体或代码块内。不需要像synchronized一样反向释放锁，但同时我们必须手动释放锁 支持多个相关的 Condition 对象 允许多个读线程同时访问共享资源 AQS 为实现阻塞锁和相关同步器和其他同步组件提供的一个基础框架，它依赖于先进先出队列等待队列 并依靠单个原子int值来表示状态。 当state=0时，则说明没有任何线程占有共享资源的锁，当state=1时，则说明有线程目前正在使用共享变量，其他线程必须加入同步队列进行等待，AQS内部通过内部类Node构成FIFO的同步队列来完成线程获取锁的排队工作，同时利用内部类ConditionObject构建等待队列。所以说AQS是有两种多个等待队列的。 AQS作为基础组件，对于锁的实现存在两种不同的模式，即共享模式(如Semaphore)和独占模式(如ReetrantLock) 而相应的tryRelease方法公平锁和非公平锁则是通用的Sync类的tryRelease函数，它重写了AQS的tryRelease函数。tryRelease函数主要是对当前锁的同步队列的State的值进行更改。使其的状态值State-1。同时release函数在tryRelease函数返回值为true的时候，当队列中还有元素的时候，选择去唤醒头元素的后继元素。12345678//标识线程已处于结束状态 static final int CANCELLED = 1; //等待被唤醒状态 static final int SIGNAL = -1; //条件状态， static final int CONDITION = -2; //在共享模式中使用表示获得的同步状态会被传播 static final int PROPAGATE = -3; 参考： Java并发编程札记-(四)JUC锁-03AQS 深入剖析基于并发AQS的(独占锁)重入锁(ReetrantLock)及其Condition实现原理 ReentrantLockReentrantLock底层是依赖CAS方法和volatile变量来实现同步的，并且还依赖于一些LockSupport类的方法。 重入锁的静态内部类Sync实现自抽象类AQS，依赖于AQS的同步队列及int类型的值来保证同步。Sync内部类又分为公平的和不公平的，公平是指，等待时间最长的线程优先获得锁。保证公平会影响性能，线程会严格按照先进先出的方式来获取锁。一般也不需要，所以默认不保证，而不公平则是保证每次调用lock函数获取锁的时候，都会尝试先通过CAS的方式获取一次锁(修改一次该独占锁的State数值，及设置该独占锁的Owner线程)，获取不到才去同步队列中等待。synchronized锁也是不保证公平的。 公平锁和非公平锁都重写了AQS的lock和tryAcquire函数。区别是，lock函数非公平锁比公平锁多通过CAS尝试获取一次锁，获取不到才会调用AQS类的acquire函数来处理。而公平锁不同的测试会在调用tryAccquire函数中通过调用hasQueuedPredecessors函数来检测当前队列中有节点，且头节点的后继节点非该线程节点的话那么获取失败。 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h);// 释放当前节点,并唤醒他的后继节点 return true; &#125; return false; &#125; AQS类的acquire函数的处理逻辑是，先通过tryAcquire通过CAS的方式获取锁，如果获取到直接返回，否则调用addWaiter函数将该线程封装成同步队列中的等待节点，并插入到同步队列中。然后调用acquireQueued自旋的方式获得锁，获取不到的话，就中断当前线程。 LockSuport的函数基本上全依赖Unsafe类来实现。 获取锁的执行流程： CAS12345678910111213141516public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable&#123; protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; // ....&#125;public final class Unsafe &#123; public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); // ....&#125; var1:操作对象 var2:对象的属性地址偏移量 var4:期望值 var5:修改值 synchronized和Lock用哪个首先两者最大的区别就是一个是隐式锁，一个是显示锁。 jdk1.6之后对synchronized进行了大量的优化操作，导致在Java1.6上synchronize的性能并不比Lock差。官方也表示，他们也更支持synchronize，在未来的版本中还有优化余地。所以两者在使用的时候，Synchronized锁用起来比较简单。Lock锁还得顾忌到它的特性。 所以我们绝大部分时候还是会使用Synchronized锁，用到了Lock锁提及的特性，带来的灵活性才会考虑使用Lock显式锁。]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java IO源码分析 - InputStream，OutputStream系列]]></title>
    <url>%2Fjava-io-sourcecode-InputStreamOutputStream.html</url>
    <content type="text"><![CDATA[说明整个系列的文章全部参考或直接照搬下面两位作者的文章，这里只是根据自己需要对原作者的文章梳理的总结，仅给自己日后复习时提供思路，如有读者看到学习时建议移步原作。再次重申并非我所写 潘威威：Java8 I/O源码-目录 skywang12345：Java I/O系列 IntputStream，OutputStream 简介 所有字节输入流的类的父类 IntputStream。 所有字节输出流的类的父类 OutputStream。 助于理解无论是输入流还是输出流，都是相对于内存的，即内存数据的输入还是输出，所以InputStream就是往内存输入数据的输入流。对于内存的动作就是read读取。相对的OutputStream就是从内存中往外输出数据，对于内存的动作的就是write操作。 12345public abstract class InputStream implements Closeable &#123;&#125;public abstract class OutputStream implements Closeable, Flushable &#123;&#125; 所有字节输入流的父类 InputStream 有这样一个抽象方法：1public abstract int read() throws IOException; 所以字节输入流必须提供返回下一个输入字节的read()方法。 ByteArrayInputStream ByteArrayInputStream 支持 mark/reset。 ByteArrayInputStream的close方法无效，无法关闭此输入流。 123456789101112public void mark(int readAheadLimit) &#123; // 设置流中的当前标记位置 mark = pos;&#125;public synchronized void reset() &#123; // 将缓冲区的位置重置为标记位置 pos = mark;&#125;public void close() throws IOException &#123;&#125; 实现了父类InputStream的read方法。1234567/* * 返回一个 0 到 255 范围内的 int 字节值。 * 负数用补码进行计算 */public synchronized int read() &#123; return (pos &lt; count) ? (buf[pos++] &amp; 0xff) : -1;&#125; 需要注意的是，如果buf数组中有负数的话，负数在取出时&amp;与运算用负数的补码(除符号位全部取反并+1)进行计算。 ByteArrayOutputStream头123456789101112131415161718192021222324252627public class ByteArrayOutputStream extends OutputStream &#123;/** * The buffer where data is stored. * 存储数据的缓冲区 */protected byte buf[];/** * The number of valid bytes in the buffer. * 缓冲区中的有效字节数 */protected int count;&#125;// 缓冲区容量初始化为32，如有必要可扩容。通过ensureCapacitypublic ByteArrayOutputStream() &#123; this(32);&#125;public ByteArrayOutputStream(int size) &#123; if (size &lt; 0) &#123; throw new IllegalArgumentException("Negative initial size: " + size); &#125; buf = new byte[size];&#125; ensureCapacity，grow，hugeCapacity1234567891011121314151617181920212223242526272829303132333435// 确保缓冲区可以存放多少元素，必要时扩容private void ensureCapacity(int minCapacity) &#123; // overflow-conscious code if (minCapacity - buf.length &gt; 0) grow(minCapacity);&#125;// 增加缓冲区容量，使其至少可以存放minCapacity个元素// minCapacity : 期望最小容量private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = buf.length; // 扩容2倍 int newCapacity = oldCapacity &lt;&lt; 1; if (newCapacity - minCapacity &lt; 0) // 如果扩容两倍还是小，那么容量赋值成该期望容量 newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) // 如果还是不够，那么最大提升到 Integer.MAX_VALUE 舍弃到了头信息 newCapacity = hugeCapacity(minCapacity); buf = Arrays.copyOf(buf, newCapacity);&#125;// 计算允许分配给byte数组的最大容量private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125;// 一些虚拟机会存一些头信息到数组中，如数组的地址类型等，提升性能// JVM默认规定数组最大容量就是Integer.MAX_VALUE，再打会内存溢出private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; write，writeTo12345678910111213141516171819202122232425// 将指定的字节写入输出流public synchronized void write(int b) &#123; ensureCapacity(count + 1); buf[count] = (byte) b; count += 1;&#125;implement了父类OutputStream抽象类的write方法public abstract void write(int b) throws IOException;// 将指定byte数组中从偏移量off开始的len个字节写入输出流public synchronized void write(byte b[], int off, int len) &#123; if ((off &lt; 0) || (off &gt; b.length) || (len &lt; 0) || ((off + len) - b.length &gt; 0)) &#123; throw new IndexOutOfBoundsException(); &#125; ensureCapacity(count + len); System.arraycopy(b, off, buf, count, len); count += len;&#125;// 将此byte数组输出流的全部内容写入到指定的输出流参数out中public synchronized void writeTo(OutputStream out) throws IOException &#123; out.write(buf, 0, count);&#125; 重要函数123456789101112// 将输出流的count字段重置为零，从而丢弃输出流中目前已累积的所有输出public synchronized void reset() &#123; count = 0;&#125;// 使用指定的charsetName，通过解码字节将缓冲区内容转换为字符串并返回public synchronized String toString(String charsetName) throws UnsupportedEncodingException &#123; return new String(buf, 0, count, charsetName);&#125;public void close() throws IOException &#123;&#125; 总结 ByteArrayOutputStream中的数据被写入到一个byte数组里。byte数组会随着被写入其中的数据的增长而增长。 表示字节输出流的类必须提供至少一种可写入一个输出字节的方法。ByteArrayOutputStream提供了两种。加上继承自父类OuputStream类的write方法是3种 ByteArrayOutputStream可以将缓冲区中的数据转化为byte数组或字符串并返回。 ByteArrayOutputStream可以通过writeTo( OutputStream out)实现输出流之间数据的复制 ByteArrayOutputStream 的close方法无效，无法关闭此输出流。 PipedInputStream，PipedOutputStreamPipedInputStream与PipedOutputStream分别为管道输入流和管道输出流。管道输入流通过连接到管道输出流实现了类似管道的功能，用于线程之间的通信。 通常，由某个线程向管道输出流中写入数据。根据管道的特性，这些数据会自动发送到与管道输出流对应的管道输入流中。这时其他线程就可以从管道输入流中读取数据，这样就实现了线程之间的通信。 1public class PipedInputStream extends InputStream initPipe，connect，12345678910111213141516171819202122/** * 初始化PipedInputStream的缓冲区大小 * * @param pipeSize 管道缓冲区容量 */private void initPipe(int pipeSize) &#123; if (pipeSize &lt;= 0) &#123; throw new IllegalArgumentException("Pipe Size &lt;= 0"); &#125; buffer = new byte[pipeSize];&#125;/** * 将PipedInputStream连接到指定的PipedOutputStream。 * * 如果 PipedInputStream 已经被连接到了其他 PipedOutputStream， * 或者PipedOutputStream 已经被连接到其他PipedInputStream * 抛出IOException。 */public void connect(PipedOutputStream src) throws IOException &#123; src.connect(this);&#125; receive，awaitSpace，checkStateForReceive1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889// 接收一个数据字节，将其插入到缓冲区。如果没有可用的输入，方法会阻塞protected synchronized void receive(int b) throws IOException &#123; // 接受前的状态检查 checkStateForReceive(); // 设置负责向管道缓冲区输入数据的线程是当前线程 writeSide = Thread.currentThread(); // 如果缓冲区被塞满的时候 if (in == out) // 缓冲区被写入线程塞满的时候,唤醒读取线程，并阻塞当前写入线程 awaitSpace(); // 初次接受前初始化 if (in &lt; 0) &#123; in = 0; out = 0; &#125; buffer[in++] = (byte) (b &amp; 0xFF); // 从头复入 if (in &gt;= buffer.length) &#123; in = 0; &#125;&#125;// 检查PipedInputStream是否可以接收数据private void checkStateForReceive() throws IOException &#123; if (!connected) &#123; throw new IOException("Pipe not connected"); &#125; else if (closedByWriter || closedByReader) &#123;// 输入输出流都不能被关闭 throw new IOException("Pipe closed"); &#125; else if (readSide != null &amp;&amp; !readSide.isAlive()) &#123;// switSpace 需要用到读线程,读线程不能为空且不alive throw new IOException("Read end dead"); &#125;&#125;// 等待可用缓冲区private void awaitSpace() throws IOException &#123; while (in == out) &#123; checkStateForReceive(); /* full: kick any waiting readers */ notifyAll(); try &#123; wait(1000); &#125; catch (InterruptedException ex) &#123; throw new java.io.InterruptedIOException(); &#125; &#125;&#125;// 接受指定字节数组的数据synchronized void receive(byte b[], int off, int len) throws IOException &#123; // 检查接受状态 checkStateForReceive(); // 身份 writeSide = Thread.currentThread(); // 写入总量 int bytesToTransfer = len; while (bytesToTransfer &gt; 0) &#123; // 判断缓冲区满没满 if (in == out) awaitSpace(); // 下次插入量 int nextTransferAmount = 0; if (out &lt; in) &#123; nextTransferAmount = buffer.length - in; &#125; else if (in &lt; out) &#123; // 初次写入 if (in == -1) &#123; in = out = 0; nextTransferAmount = buffer.length - in; &#125; else &#123; // 再次写入 nextTransferAmount = out - in; &#125; &#125; // 如果 可插入的量 &gt; 要插入的量，那么一次插入结束，此次插入的量就是写入线程要插入数据的总量， // 否则off记录偏移量，in记录存入位，bytesToTransfer记录剩余插入量，while循环批次执行。 if (nextTransferAmount &gt; bytesToTransfer) nextTransferAmount = bytesToTransfer; assert (nextTransferAmount &gt; 0); // 写入 System.arraycopy(b, off, buffer, in, nextTransferAmount); bytesToTransfer -= nextTransferAmount; off += nextTransferAmount; in += nextTransferAmount; if (in &gt;= buffer.length) &#123; in = 0; &#125; &#125;&#125; receivedLast123456// 管道输出流关闭时（PipedOutputStream.close()中会调用此方法），通知其已经关闭。synchronized void receivedLast() &#123; // 状态设置 closedByWriter = true; notifyAll();&#125; read123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public synchronized int read() throws IOException &#123; // 状态检测 if (!connected) &#123;// 输入输出流是否连接上 throw new IOException("Pipe not connected"); &#125; else if (closedByReader) &#123;// 管道输入流被关闭 throw new IOException("Pipe closed"); &#125; else if (writeSide != null &amp;&amp; !writeSide.isAlive() // 写线程存在但不alive，管道输出流没关 且现在管道中没数据 &amp;&amp; !closedByWriter &amp;&amp; (in &lt; 0)) &#123; throw new IOException("Write end dead"); &#125; // 状态设置，当前线程为读取线程 readSide = Thread.currentThread(); // 尝试次数 int trials = 2; // 管道中没数据 while (in &lt; 0) &#123; // 如果管道输出流关闭，且此时in&lt;0 管道缓冲区没机会再写入内容了，read 返回 return -1 if (closedByWriter) &#123; /* closed by writer, return EOF */ return -1; &#125; // 如果写入数据的线程不为null且不活跃且trials&lt;=0，说明管道损坏，抛出异常 if ((writeSide != null) &amp;&amp; (!writeSide.isAlive()) &amp;&amp; (--trials &lt; 0)) &#123; throw new IOException("Pipe broken"); &#125; /* might be a writer waiting */ // 唤醒写入 notifyAll(); try &#123; wait(1000); &#125; catch (InterruptedException ex) &#123; throw new java.io.InterruptedIOException(); &#125; &#125; int ret = buffer[out++] &amp; 0xFF; // 读完一轮，复位 if (out &gt;= buffer.length) &#123; out = 0; &#125; // 管道缓冲区为空，读完 if (in == out) &#123; /* now empty */ in = -1; &#125; return ret;&#125;public synchronized int read(byte b[], int off, int len) throws IOException &#123; if (b == null) &#123; throw new NullPointerException(); &#125; else if (off &lt; 0 || len &lt; 0 || len &gt; b.length - off) &#123; throw new IndexOutOfBoundsException(); &#125; else if (len == 0) &#123; return 0; &#125; /* possibly wait on the first character */ // 尝试读一个字节，看缓冲区情况 int c = read(); if (c &lt; 0) &#123; return -1; &#125; b[off] = (byte) c; // readLength int rlen = 1; while ((in &gt;= 0) &amp;&amp; (len &gt; 1)) &#123; int available; if (in &gt; out) &#123; // 可读数 available = Math.min((buffer.length - out), (in - out)); &#125; else &#123; available = buffer.length - out; &#125; // A byte is read beforehand outside the loop // 可读数 &gt; 要读数 if (available &gt; (len - 1)) &#123; available = len - 1; &#125; System.arraycopy(buffer, out, b, off + rlen, available); // 一次读取影响到的变量统一变更 out += available; rlen += available; len -= available; // 继续从头读 if (out &gt;= buffer.length) &#123; out = 0; &#125; // 缓冲区读完 if (in == out) &#123; /* now empty */ in = -1; &#125; &#125; return rlen;&#125; available，close123456789101112131415161718192021public synchronized int available() throws IOException &#123; if (in &lt; 0) return 0; else if (in == out)// 读完被置为-1 所以这里肯定是满了 return buffer.length; else if (in &gt; out) return in - out; else return in + buffer.length - out;&#125;/** * 关闭此管道输入流，并释放与该流相关的所有系统资源。 */public void close() throws IOException &#123; // 状态设置 closedByReader = true; synchronized (this) &#123; in = -1;// &#125;&#125; PipedOutputStream1234567891011121314public class PipedOutputStream extends OutputStream &#123; private PipedInputStream sink; // 与PipedOutputStream相连接的管道输入流 // 创建连接到指定输入流的管道输出流 public PipedOutputStream(PipedInputStream snk) throws IOException &#123; connect(snk); &#125; // 创建没有连接到输入流的管道输出流。 // 在使用前，它必须连接到管道输入流。 public PipedOutputStream() &#123; &#125;&#125; connect，write123456789101112131415161718192021222324252627282930313233343536public synchronized void connect(PipedInputStream snk) throws IOException &#123; if (snk == null) &#123; throw new NullPointerException(); &#125; else if (sink != null || snk.connected) &#123;// 此管道输出流已经与某管道输入流连接 或 该管道输入流已经被连接 throw new IOException("Already connected"); &#125; sink = snk; snk.in = -1; snk.out = 0; snk.connected = true;&#125;// 将指定数据字节写入管道输出流public void write(int b) throws IOException &#123; if (sink == null) &#123; throw new IOException("Pipe not connected"); &#125; sink.receive(b);&#125;// 将指定字节数组的数组写入到管道缓冲区中public void write(byte b[], int off, int len) throws IOException &#123; // 数据校验 if (sink == null) &#123; throw new IOException("Pipe not connected"); &#125; else if (b == null) &#123; throw new NullPointerException(); &#125; else if ((off &lt; 0) || (off &gt; b.length) || (len &lt; 0) || ((off + len) &gt; b.length) || ((off + len) &lt; 0)) &#123; throw new IndexOutOfBoundsException(); &#125; else if (len == 0) &#123; return; &#125; // 调用管道输入流的receive函数处理 sink.receive(b, off, len);&#125; close，receivedLast，flush123456789101112131415161718192021222324public void close() throws IOException &#123; if (sink != null) &#123; sink.receivedLast(); &#125;&#125;// PipedInputStream类的receivedLast函数synchronized void receivedLast() &#123; // 状态设置，负责缓冲区数据写入的流被关闭了。 closedByWriter = true; notifyAll();&#125;/** * 刷新此输出流并强制写出所有缓冲的输出字节。 * 这将通知所有读取数据的线程，告知它们管道中的字符处于读取等待中。 */public synchronized void flush() throws IOException &#123; if (sink != null) &#123; synchronized (sink) &#123; sink.notifyAll(); &#125; &#125;&#125; 总结首先在看PipedInputStream和PipedOutputStream的时候，我刚开始没搞懂为什么PipedInputStream技能read又能recieve。后来看了PipedOutputStream的源码的时候才知道，原来PipedInputStream类中的recieve函数是给PipedOutputStream类中的write函数调用的，后来才串明白，这是一个“管道”的输入输出流，用一个容量默认为1024的byte数组来做管道的缓冲容量，最终的输入输出实现都落实到了PipedInputStream类中，这样状态都由一个类来控制才能做到，某个线程通过管道输出流向管道中写入数据，另一端管道输入流能立马从管道中取出对应存储到的数据。 PipedInputStream与PipedOutputStream分别为管道输入流和管道输出流。管道输入流通过连接到管道输出流实现了类似管道的功能，用于线程之间的通信。 通常，由某个线程向管道输出流中写入数据。根据管道的特性，这些数据会自动发送到与管道输出流对应的管道输入流中。这时其他线程就可以从管道输入流中读取数据，这样就实现了线程之间的通信。 不建议对这两个流对象尝试使用单个线程，因为这样可能死锁线程。 PipedOutputStream是数据的发送者；PipedInputStream是数据的接收者。 PipedInputStream缓冲区大小默认为1024，写入数据时写入到这个缓冲区的，读取数据也是从这个缓冲区中读取的。 PipedInputStream通过read方法读取数据。PipedOutputStream通过write方法写入数据，write方法其实是调用PipedInputStream中的receive方法来实现将数据写入缓冲区的的，因为缓冲区是在PipedInputStream中的。 PipedOutputStream和PipedInputStream之间通过connect()方法连接。 使用后要关闭输入输出流 FilterInputStream，FilterOutputStreamFilterInputStream、FilterOutputStream是过滤器字节输入输出流。它们的主要用途在于封装其他的输入输出流，为它们提供一些额外的功能。 - 装饰者模式 123456789101112131415161718192021222324252627282930313233343536373839404142434445package java.io;public class FilterInputStream extends InputStream &#123; protected volatile InputStream in; protected FilterInputStream(InputStream in) &#123; this.in = in; &#125; public int read() throws IOException &#123; return in.read(); &#125; public int read(byte b[]) throws IOException &#123; return read(b, 0, b.length); &#125; public int read(byte b[], int off, int len) throws IOException &#123; return in.read(b, off, len); &#125; public long skip(long n) throws IOException &#123; return in.skip(n); &#125; public int available() throws IOException &#123; return in.available(); &#125; public void close() throws IOException &#123; in.close(); &#125; public synchronized void mark(int readlimit) &#123; in.mark(readlimit); &#125; public synchronized void reset() throws IOException &#123; in.reset(); &#125; public boolean markSupported() &#123; return in.markSupported(); &#125;&#125; 可以从源码看出，FilterInuptStream类本身并没有对构造时传入的InputStream抽象类的实例进行装饰，只是简单的重写了父类InputStream类的所有方法。 可以看出FilterInputStream在这里做的是装饰抽象类。而InputStream做的是抽象构建。 根据装饰模式的设计思想我们可以得知，虽然FilterInutStream类并不为具体构建提供装饰功能。但其子类在装饰模式中充当的是具体装饰类，可以进一步重写这些方法中的一些方法，来提供装饰功能。它的常用子类有BufferedInputStream和DataInputStream。比如，BufferedInputStream的作用就是为它装饰的输入流提供缓冲功能。 至此： InputStream：抽象构建 *InputStream：具体构建 FilterInputStream：抽象装饰类 BufferedInputStream：具体装饰类 filterOutputStream123456789101112131415161718192021222324252627282930313233343536public class FilterOutputStream extends OutputStream &#123; protected OutputStream out; public FilterOutputStream(OutputStream out) &#123; this.out = out; &#125; public void write(int b) throws IOException &#123; out.write(b); &#125; public void write(byte b[]) throws IOException &#123; write(b, 0, b.length); &#125; public void write(byte b[], int off, int len) throws IOException &#123; if ((off | len | (b.length - (len + off)) | (off + len)) &lt; 0) throw new IndexOutOfBoundsException(); for (int i = 0 ; i &lt; len ; i++) &#123; write(b[off + i]); &#125; &#125; public void flush() throws IOException &#123; out.flush(); &#125; @SuppressWarnings("try") public void close() throws IOException &#123; try (OutputStream ostream = out) &#123; flush(); &#125; &#125;&#125; 需要注意的是看了FilterInputStream源码后不要想当然的认为FilterOutputStream也和它一样全篇方法调用装饰的OutputStream的子类的原方法。其也重写的父类的OutputStream全部方法，并有一些赋予了自己的处理逻辑。 总结 FilterInputStream、FilterOutputStream是过滤器字节输入输出流。它们的主要用途在于封装其他的输入输出流，为它们提供一些额外的功能。 FilterInputStream、FilterOutputStream并没有提供什么装饰功能。FilterInputStream、FilterOutputStream的子类可进一步重写这些方法中的一些方法，来提供装饰功能。 FilterInputStream装饰功能的实现的关键在于类中有一个InputStream字段，依赖这个字段它才可以对InputStream的子类提供装饰功能。FilterOutputStream也是如此。 BufferedInputStream，BufferedOutputStream1234567891011121314151617181920212223242526272829public class BufferedInputStream extends FilterInputStream &#123; private static int DEFAULT_BUFFER_SIZE = 8192;// 1024 &lt;&lt; 3; 缓冲区默认的默认大小 private static int MAX_BUFFER_SIZE = Integer.MAX_VALUE - 8;// 分派给arrays的最大容量 protected volatile byte buf[];// 存放数据的内部缓冲数组。，如果有必要，它可能被不同大小的数组替代 // 当前缓冲区的有效字节数。 // 注意，这里是指缓冲区的有效字节数，而不是输入流中的有效字节数。 protected int count; // 当前缓冲区的位置索引 // 注意，这里是指缓冲区的位置索引，而不是输入流中的位置索引。 protected int pos; // 当前缓冲区的标记位置 // markpos和reset()配合使用才有意义。操作步骤： // (01) 通过mark() 函数，保存pos的值到markpos中。 // (02) 通过reset() 函数，会将pos的值重置为markpos。接着通过read()读取数据时，就会从mark()保存的位置开始读取。 // 可以理解为，mark位置之后的数据是保留数据，即有效数据。mark确立了有效数据和无效数据。 protected int markpos = -1; // 相当于从输入流中一次读取数据的大小。当buffer.length小于这个值的时候就需要频繁的扩容，当大于这个值的时候就可以直接从输入流中读取数据。 protected int marklimit; // 缓存数组的原子更新器。 // 该成员变量与buf数组的volatile关键字共同组成了buf数组的原子更新功能实现， // 即，在多线程中操作BufferedInputStream对象时，buf和bufUpdater都具有原子性(不同的线程访问到的数据都是相同的) private static final AtomicReferenceFieldUpdater&lt;BufferedInputStream, byte[]&gt; bufUpdater = AtomicReferenceFieldUpdater.newUpdater (BufferedInputStream.class, byte[].class, "buf");&#125; BufferedInputStream的作用是为其它输入流提供缓冲功能。创建BufferedInputStream时，我们会通过它的构造函数指定某个输入流为参数。BufferedInputStream会将该输入流数据分批读取，每次读取一部分到缓冲中；操作完缓冲中的这部分数据之后，再从输入流中读取下一部分的数据。(即对应read时发现缓冲区数据不够时调用fill函数，fill函数内部调用read函数读取输入流中的数据再填充buf缓冲区。) 为什么需要缓冲呢？原因很简单，效率问题！缓冲中的数据实际上是保存在内存中，而原始数据可能是保存在硬盘或NandFlash等存储介质中；而我们知道，从内存中读取数据的速度比从硬盘读取数据的速度至少快10倍以上。那干嘛不干脆一次性将全部数据都读取到缓冲中呢？第一，读取全部的数据所需要的时间可能会很长。第二，内存价格很贵，容量不像硬盘那么大。 该类最关键的函数及fill()方法，其他方法都很好理解。该方法负责读取输入流的数据来填充buf缓冲区。具体解释可参考http://www.cnblogs.com/skywang12345/p/io_12.html。 BufferedOutputStream看过BufferedInputStream源码之后BufferedOutputStream就看起来很简单了，和BufferedInputStream一样，BufferedOutputStream通过字节数组来缓冲数据(1024*8)。BufferedOutputStream当缓冲区满或者用户调用flush()函数时，它就会将缓冲区的数据写入到输出流中。 总结 BufferedInputStream是缓冲输入流，作用是为另一个输入流添加一些功能，比如缓冲输入功能以及支持mark和reset方法的能力。 BufferedOutputStream是缓冲输出流，通过设置这种输出流，应用程序就可以将单个或字节数组缓冲的写入底层输出流中，而不必针对每次字节写入调用底层系统。 DataInputStream，DataOutputStreamDataInputStream DataInputStream为数据输入流，它允许应用程序以与机器无关方式从底层输入流中读取基本Java数据类型。 DataOutputStream为数据输出流，它允许应用程序以适当方式将基本 Java数据类型写入输出流中。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public final String readUTF() throws IOException &#123; return readUTF(this);&#125;public final static String readUTF(DataInput in) throws IOException &#123; int utflen = in.readUnsignedShort(); byte[] bytearr = null; char[] chararr = null; if (in instanceof DataInputStream) &#123; DataInputStream dis = (DataInputStream)in; if (dis.bytearr.length &lt; utflen)&#123; dis.bytearr = new byte[utflen*2]; dis.chararr = new char[utflen*2]; &#125; chararr = dis.chararr; bytearr = dis.bytearr; &#125; else &#123; bytearr = new byte[utflen]; chararr = new char[utflen]; &#125; int c, char2, char3; int count = 0; int chararr_count=0; in.readFully(bytearr, 0, utflen); // 由于UTF-8的单字节和ASCII相同，所以这里就将它们进行预处理，直接保存到“字符数组chararr”中。 // 对于其它的UTF-8数据，则在后面进行处理。 while (count &lt; utflen) &#123; c = (int) bytearr[count] &amp; 0xff; if (c &gt; 127) break; count++; chararr[chararr_count++]=(char)c; &#125; while (count &lt; utflen) &#123; c = (int) bytearr[count] &amp; 0xff; switch (c &gt;&gt; 4) &#123; case 0: case 1: case 2: case 3: case 4: case 5: case 6: case 7: /* 0xxxxxxx*/ count++; chararr[chararr_count++]=(char)c; break; case 12: case 13: /* 110x xxxx 10xx xxxx*/ count += 2; if (count &gt; utflen) throw new UTFDataFormatException( "malformed input: partial character at end"); char2 = (int) bytearr[count-1]; if ((char2 &amp; 0xC0) != 0x80) throw new UTFDataFormatException( "malformed input around byte " + count); chararr[chararr_count++]=(char)(((c &amp; 0x1F) &lt;&lt; 6) | (char2 &amp; 0x3F)); break; case 14: /* 1110 xxxx 10xx xxxx 10xx xxxx */ count += 3; if (count &gt; utflen) throw new UTFDataFormatException( "malformed input: partial character at end"); char2 = (int) bytearr[count-2]; char3 = (int) bytearr[count-1]; if (((char2 &amp; 0xC0) != 0x80) || ((char3 &amp; 0xC0) != 0x80)) throw new UTFDataFormatException( "malformed input around byte " + (count-1)); chararr[chararr_count++]=(char)(((c &amp; 0x0F) &lt;&lt; 12) | ((char2 &amp; 0x3F) &lt;&lt; 6) | ((char3 &amp; 0x3F) &lt;&lt; 0)); break; default: /* 10xx xxxx, 1111 xxxx */ throw new UTFDataFormatException( "malformed input around byte " + count); &#125; &#125; // The number of chars produced may be less than utflen return new String(chararr, 0, chararr_count);&#125; readUTF的执行流程相当于把UTF-8编码的输入流中的字节数据先读到了bytearr数组中，然后根据UTF-8编码的特殊性，判断数据是几个字节，根据情况又往chararr数组中转。保证了每个字符转化的正确率，最后所有的字符都正确的转化到了chararr数组中，然后返回string值。 readUnsignedShort，readBoolean，readUnsignedByte123456789101112131415161718192021222324252627// UTF-8输入流的前2个字节是数据的长度public final int readUnsignedShort() throws IOException &#123; int ch1 = in.read(); int ch2 = in.read(); if ((ch1 | ch2) &lt; 0) throw new EOFException(); return (ch1 &lt;&lt; 8) + (ch2 &lt;&lt; 0);&#125;// 此方法适用于读取用接口DataOutput的 writeBoolean方法写入的字节public final boolean readBoolean() throws IOException &#123; //从输入流中读取一个字节 int ch = in.read(); //如果达到输入流末尾，抛出异常 if (ch &lt; 0) throw new EOFException(); //如果读取的字节不是零，则返回true；如果是零，则返回false return (ch != 0);&#125;// 读取一个无符号为byte输入字节，将它数值位左侧补零转变为int类型(覆盖符号位)，并返回结果，所以结果的范围是0到255public final int readUnsignedByte() throws IOException &#123; int ch = in.read(); if (ch &lt; 0) throw new EOFException(); return ch;&#125; 最后我们落实到该类的特点，它允许应用程序以与机器无关方式从底层输入流中读取基本Java数据类型。 其实就是通过构造时传入的InputStream对象来根据要读取的数据类型来读取对应的字节数，比如readByte就调用一次in.read。然后把读取出来的数据强转成(byte)。readChar的话就调用两次，然后因为两个字节连续起来表示一个字符，那么就将先读出来的字节适当的移位并将两个字节+起来。这样就相当于一次性读出来两个字节，然后对该数据强转即可得到最真实的数据。 需要注意的是，因为我们从输入流中读出的内容返回的是int类型的，默认除了数据位，把我们原数据的符号位覆盖掉了。然后我们强转就可以就可以恢复(暂时先那么理解有符号位和无符号位的计算方式，方便记忆，虽然肯定不是这样，以后再研究。) DataOutputStreamincCount，flush，size12345678910111213141516171819202122// 到目前为止写入到输出流中的字节数 最大值为Integer.MAX_VALUEprotected int written;// 增加wirtten的值。最大值为Integer.MAX_VALUEprivate void incCount(int value) &#123; int temp = written + value; //int允许的最大值为Integer.MAX_VALUE，即2147483647，2147483647+1即为负数 if (temp &lt; 0) &#123; temp = Integer.MAX_VALUE; &#125; written = temp;&#125;// 清空此数据输出流。这迫使所有缓冲的输出字节被写出到流中。public void flush() throws IOException &#123; out.flush();&#125;// 返回written的当前值，即到目前为止写入此数据输出流的字节数。最大值为Integer.MAX_VALUE。public final int size() &#123; return written;&#125; writeShort，writeChar，writeFloat123456789101112131415161718192021public final void writeChar(int v) throws IOException &#123; out.write((v &gt;&gt;&gt; 8) &amp; 0xFF); out.write((v &gt;&gt;&gt; 0) &amp; 0xFF); incCount(2);&#125;public final void writeChars(String s) throws IOException &#123; int len = s.length(); for (int i = 0 ; i &lt; len ; i++) &#123; int v = s.charAt(i); out.write((v &gt;&gt;&gt; 8) &amp; 0xFF); out.write((v &gt;&gt;&gt; 0) &amp; 0xFF); &#125; incCount(len * 2);&#125;// 使用Float类中的floatToIntBits方法将float参数转换为一个int值public final void writeFloat(float v) throws IOException &#123; writeInt(Float.floatToIntBits(v));&#125; 可以看到DataOutputStream和DataInputStream的处理方式是一样的，要输入到输出流的数据有可能是1个字节或多个字节的，所以对应不同的数据定义了不同的函数，然后针对这些数值一个字节一个字节的进行输入就好。 总结 DataInputStream提供了一系列从二进制流中读取字节，并根据所有Java基本类型数据进行重构的readXXXX方法。同时还提供根据UTF-8编码格式的数据写入输入流的方式，即readUTF方法。 DataOutputStream提供了一系列将数据从任意Java基本类型转换为一系列字节，并将这些字节写入二进制流的writeXXXX方法。同时还提供了一个将String转换成UTF-8修改版格式并写入所得到的系列字节的工具，即writeUTF方法。 PrintStream由于学习的时候，我在学习字节流的时候跳过了PrintStream，先看的PrintWriter所以看过PrintWriter后再来看PrintStream就感觉很简单了，所以简单记录下。 PrintStream 是打印输出流，它继承于FilterOutputStream。 PrintStream 是用来装饰其它输出流。它能为其他输出流添加了功能，使它们能够方便地打印各种数据值表示形式。为底层输出流提供了缓存池(BufferedWriter)。 与其他输出流不同，PrintStream 永远不会抛出 IOException；它产生的IOException会被自身的函数所捕获并设置错误标记， 用户可以通过 checkError() 返回错误标记，从而查看PrintStream内部是否产生了IOException。 另外，PrintStream 提供了自动flush 和 字符集设置功能。所谓自动flush，就是往PrintStream写入的数据会立刻调用flush()函数。 123456789101112131415161718192021222324public class PrintStream extends FilterOutputStream implements Appendable, Closeable&#123; // 自动flush // 所谓“自动flush”，就是每次执行print(), println(), write()函数，都会调用flush()函数； // 而“不自动flush”，则需要我们手动调用flush()接口。 private final boolean autoFlush; // PrintStream是否右产生异常。当PrintStream有异常产生时，会被本身捕获，并设置trouble为true private boolean trouble = false; // 用于格式化的对象 private Formatter formatter; // BufferedWriter对象，用于实现“PrintStream支持字符集”。 // 因为PrintStream是OutputStream的子类，所以它本身不支持字符串； // 但是BufferedWriter支持字符集，因此可以通过OutputStreamWriter创建PrintStream对应的BufferedWriter对象，从而支持字符集。 private BufferedWriter textOut; private OutputStreamWriter charOut; private static &lt;T&gt; T requireNonNull(T obj, String message) &#123; if (obj == null) throw new NullPointerException(message); return obj; &#125;&#125; ==需要注意的是== ：很明显，该类和PrintWriter还有个最大的区别。继承自FilterOutputStream，也就是它做的是装饰模式中的具体装饰类。至于Appendable，Closeable接口和PrintWriter则没区别，PrintWriter其父类Writer抽象也早实现了。123public class PrintStream extends FilterOutputStream implements Appendable, Closeable&#123; PrintStream和DataOutputStream异同点相同点：都是继承与FileOutputStream，用于包装其它输出流。 不同点： PrintStream和DataOutputStream 都可以将数据格式化输出；但它们在“输出字符串”时的编码不同。 PrintStream是输出时采用的是用户指定的编码(创建PrintStream时指定的)，若没有指定，则采用系统默认的字符编码。而DataOutputStream则采用的是UTF-8。 它们的写入数据时的异常处理机制不同。 DataOutputStream在通过write()向“输出流”中写入数据时，若产生IOException，会抛出。 而PrintStream在通过write()向“输出流”中写入数据时，若产生IOException，则会在write()中进行捕获处理；并设置trouble标记(用于表示产生了异常)为true。用户可以通过checkError()返回trouble值，从而检查输出流中是否产生了异常。 构造函数不同 DataOutputStream的构造函数只有一个：DataOutputStream(OutputStream out)。即它只支持以输出流out作为“DataOutputStream的输出流”。 而PrintStream的构造函数有许多：和DataOutputStream一样，支持以输出流out作为“PrintStream输出流”的构造函数；还支持以“File对象”或者“String类型的文件名对象”的构造函数。 而且，在PrintStream的构造函数中，能“指定字符集”和“是否支持自动flush()操作”。 目的不同 DataOutputStream的作用是装饰其它的输出流，它和DataInputStream配合使用：允许应用程序以与机器无关的方式从底层输入流中读写java数据类型。 而PrintStream的作用虽然也是装饰其他输出流，但是它的目的不是以与机器无关的方式从底层读写java数据类型；而是为其它输出流提供打印各种数据值表示形式，使其它输出流能方便的通过print(),println()或printf()等输出各种格式的数据。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java IO源码分析 - Reader，Writer系列（二）]]></title>
    <url>%2Fjava-io-sourcecode-ReaderWriter2.html</url>
    <content type="text"><![CDATA[说明整个系列的文章全部参考或直接照搬下面两位作者的文章，这里只是根据自己需要对原作者的文章梳理的总结，仅给自己日后复习时提供思路，如有读者看到学习时建议移步原作。再次重申并非我所写 潘威威：Java8 I/O源码-目录 skywang12345：Java I/O系列 PipedReader，PipedWriterPipedReader与PipedInputStream极其相似，PipedWriter与PipedOutputStream也极其相似。 PipedReader与PipedWriter分别为字符管道输入流和字符管道输出流。管道输入流通过连接到管道输出流实现了类似管道的功能，用于线程之间的通信。 通常，由某个线程向管道输出流中写入数据。根据管道的特性，这些数据会自动发送到与管道输出流对应的管道输入流中。这时其他线程就可以从管道输入流中读取数据，这样就实现了线程之间的通信。 PipedReader为字符管道输入流，用于读取对应的字符管道输出流写入其内置字符缓存数组buffer中的字符、借此来实现线程之间的通信。 PipedWriter为字符管道输出流、用于将当前线程的指定字符写入到与此线程对应的管道字符输入流中。 PipedReader1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class PipedReader extends Reader &#123; //管道输出流是否关闭 boolean closedByWriter = false; //管道输入流是否关闭 boolean closedByReader = false; //管道输入流是否被连接 boolean connected = false; //从管道中读取数据的线程 Thread readSide; //向管道中写入数据的线程 Thread writeSide; /** * 管道循环输入缓冲区的默认大小。 */ private static final int DEFAULT_PIPE_SIZE = 1024; /** * 放置数据的循环缓冲区。 */ char buffer[]; /** * 缓冲区的位置，当从连接的管道输出流中接收到下一个数据字符时，会将其存储到该位置。 */ int in = -1; /** * 缓冲区的位置，此管道输入流将从该位置读取下一个数据字节。 */ int out = 0; /** * 创建PipedReader，并指定其对应的PipedWriter。 */ public PipedReader(PipedWriter src) throws IOException &#123; this(src, DEFAULT_PIPE_SIZE); &#125; /** * 创建一个PipedReader，使其连接到管道输出流src，并指定管道大小为pipeSize。 * @since 1.6 */ public PipedReader(PipedWriter src, int pipeSize) throws IOException &#123; initPipe(pipeSize); connect(src); &#125; /** * 创建尚未连接的PipedReader。 */ public PipedReader() &#123; initPipe(DEFAULT_PIPE_SIZE); &#125; /** * 创建一个尚未连接的PipedReader，并指定管道大小为pipeSize。 * @since 1.6 */ public PipedReader(int pipeSize) &#123; initPipe(pipeSize); &#125;&#125; 对于Piped系列的字符字节输入输出流，刚开始对其中的in和out两个变量还不太明白。第二遍刷类似的内容，果然一目了然 receive，123456789101112131415161718192021222324252627282930313233343536373839404142/** * 接收一个字符，将其插入到缓冲区。如果没有可用的输入，方法会阻塞。 */synchronized void receive(int c) throws IOException &#123; //检查PipedReader的状态是否正常。 if (!connected) &#123; throw new IOException("Pipe not connected"); &#125; else if (closedByWriter || closedByReader) &#123; throw new IOException("Pipe closed"); &#125; else if (readSide != null &amp;&amp; !readSide.isAlive()) &#123; throw new IOException("Read end dead"); &#125; ///获取将数据写入管道的线程，状态设置 writeSide = Thread.currentThread(); // 如果被写入管道的数据刚好被读完 或者 // 管道已经被塞满 两种情况 while (in == out) &#123; if ((readSide != null) &amp;&amp; !readSide.isAlive()) &#123; throw new IOException("Pipe broken"); &#125; /* full: kick any waiting readers */ // 不分作用线程的情况直接唤醒一个跑，能跑通的跑就行 notifyAll(); try &#123; wait(1000); &#125; catch (InterruptedException ex) &#123; throw new java.io.InterruptedIOException(); &#125; &#125; //？？？ if (in &lt; 0) &#123; in = 0; out = 0; &#125; //将数据字节写入到缓冲区中 buffer[in++] = (char) c; //如果in已经超出了缓冲区的范围，将in置为0，从头开始写 if (in &gt;= buffer.length) &#123; in = 0; &#125;&#125; 对于函数中notifyAll()函数调用的解释： 因为该输入输出流就是供多线程数据交换使用，可能此时锁外挂着一堆读写线程。全部唤醒，因为无论这两种情况的哪一种不分线程是谁哪个能跑下去让它跑就行，跑不了的全部wait 1秒。 疑问对于这种处理方式的==疑问==： 虽然程序肯定会自己调通，但是不懂的是应该这样效率很差，为什么不用ReentrantLock解决。分成两种锁控制，根据不同的条件来控制作用线程的执行？难道是因为无法判断此时缓冲池是满还是空？(自己想了想好像是无法判断) 那新问题就是为什么不新加一个volatile变量控制当前线程的前一次作用缓冲池的线程是writeSide还是readSide？ receivedLast，read，close1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 管道输出流关闭时（PipedWriter.close()中会调用此方法），通知其已经关闭。 */synchronized void receivedLast() &#123; closedByWriter = true; notifyAll();&#125;/** * 将最多len个数据字节从此管道输入流读入char数组。 * * 如果已到达数据流的末尾，或者len超出管道缓冲区大小，则读取的字符数将少于len。 * * 如果len为0，则不读取任何字节并返回0； * 否则，在至少1个输入字符可用、检测到流末尾、抛出异常前，该方法将一直阻塞。 */public synchronized int read(char cbuf[], int off, int len) throws IOException &#123; // 状态判断 if (!connected) &#123; throw new IOException("Pipe not connected"); &#125; else if (closedByReader) &#123; throw new IOException("Pipe closed"); &#125; else if (writeSide != null &amp;&amp; !writeSide.isAlive() &amp;&amp; !closedByWriter &amp;&amp; (in &lt; 0)) &#123; throw new IOException("Write end dead"); &#125; // 参数判断 if ((off &lt; 0) || (off &gt; cbuf.length) || (len &lt; 0) || ((off + len) &gt; cbuf.length) || ((off + len) &lt; 0)) &#123; throw new IndexOutOfBoundsException(); &#125; else if (len == 0) &#123; return 0; &#125; // 特殊情况判断 /* possibly wait on the first character */ int c = read(); if (c &lt; 0) &#123; return -1; &#125; cbuf[off] = (char)c; int rlen = 1; while ((in &gt;= 0) &amp;&amp; (--len &gt; 0)) &#123; cbuf[off + rlen] = buffer[out++]; rlen++; if (out &gt;= buffer.length) &#123; out = 0; &#125; if (in == out) &#123; /* now empty */ in = -1; &#125; &#125; return rlen;&#125;/** * 关闭此传送流并释放与该流相关的所有系统资源。 */public void close() throws IOException &#123; in = -1; closedByReader = true;&#125; 从close的设计可以看出，由于早期设计架构的思考，该类的开发人员明显的清楚，该类对于输入流操作的函数进入与非执行结束退出的关键判断条件是in和closedByReader变量。所以这里只要对其状态进行设置即可。 感悟写代码一定要像这些大师一样，特别有条理，1、先对该PipedReader类进行状态的判断，2、然后进行输入参数的判断，3、然后进行特殊情况的判断处理，4、进行程序优化。可见目前自己青铜 总结 PipedReader和PipedInputStream的几乎一模一样。区别在于PipedReader操作的是字符，PipedInputStream操作的是字节； PipedReader有ready方法来判断是否可以从PipedReader中读数据，而PipedInputStream则根据available()方法进行判断。 PipedWriterflush1234567891011121314/** * 刷新此输出流并强制写出所有缓冲的输出字节。 * 这将通知所有读取数据的线程，告知它们管道中的字符处于等待中。 */public synchronized void flush() throws IOException &#123; if (sink != null) &#123; if (sink.closedByReader || closed) &#123; throw new IOException("Pipe closed"); &#125; synchronized (sink) &#123; sink.notifyAll(); &#125; &#125;&#125; 我们知道sink在PipedWriter类中指的是和其连接的PipedReader对象，也即两者操作的是同一个对象。所以如果PipedReader类的当前对象在进行receive函数或者read函数被wait的时候会挂到该对象的线程等待集合中。此时缓冲池装填可能是满了，也可能空了。 所以当flush被调用时，明确的是该缓冲池中的数据要被读走了。然后唤醒该对象等待队列上的线程即可，无所谓唤醒的是读线程还是写线程，读线程一定可以正常运行下去，因为其进入wait情况的先决条件是in&lt;0很明显这时不可能，相反写线程肯定会继续卡住，因为其进入wait条件的先决条件是in==out很明显这很有可能。 总结 PipedWriter和PipedOutputStream的几乎一模一样。区别在于PipedReader操作的是字符，PipedInputStream操作的是字节。 InputStreamReader，OutputStreamWriterInputStreamReader和OutputStreamWriter 是字节流通向字符流的桥梁：它使用指定的 charset 读写字节并将其解码为字符。 InputStreamReader 的作用是将“字节输入流”转换成“字符输入流”。它继承于Reader。 OutputStreamWriter 的作用是将“字节输出流”转换成“字符输出流”。它继承于Writer。 InputStreamReader由于InputStreamReader类的函数全是依赖其内部声明的StreamDecoder对象来作用的。所以这里我们大概了解一下该类的各个函数的返回结果即可。1234567891011121314151617181920212223242526272829303132333435363738394041// 将“字节输入流”转换成“字符输入流”public class InputStreamReader extends Reader &#123; // InputStreamReader的功能是依赖StreamDecoder完成的 private final StreamDecoder sd; // 根据in创建InputStreamReader，使用默认的编码 public InputStreamReader(InputStream in) &#123; super(in); try &#123; sd = StreamDecoder.forInputStreamReader(in, this, (String)null); // ## check lock object &#125; catch (UnsupportedEncodingException e) &#123; // The default encoding should always be available throw new Error(e); &#125; &#125; // 获取解码器 public String getEncoding() &#123; return sd.getEncoding(); &#125; // 读取并返回一个字符 public int read() throws IOException &#123; return sd.read(); &#125; // 将InputStreamReader中的数据写入cbuf中，从cbuf的offset位置开始写入，写入长度是length public int read(char cbuf[], int offset, int length) throws IOException &#123; return sd.read(cbuf, offset, length); &#125; // 能否从InputStreamReader中读取数据 public boolean ready() throws IOException &#123; return sd.ready(); &#125; // 关闭InputStreamReader public void close() throws IOException &#123; sd.close(); &#125;&#125; 感觉像是给InutStream穿了个外衣。将字节流通过流解码器StreamDecoder，解码成了字符流。 OutputStreamWriterOutputStreamWriter 作用和原理都与InputStreamReader一模一样。作用就是将“字节输出流”转换成“字符输出流”。它的原理是，我们创建“字符输出流”对象时，会指定“字节输出流”以及“字符编码”。 演示程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/** * InputStreamReader 和 OutputStreamWriter 测试程序 * * @author skywang */public class StreamConverter &#123; private static final String FileName = "file.txt"; private static final String CharsetName = "utf-8"; //private static final String CharsetName = "gb2312"; public static void main(String[] args) &#123; testWrite(); testRead(); &#125; /** * OutputStreamWriter 演示函数 * */ private static void testWrite() &#123; try &#123; // 创建文件“file.txt”对应File对象 File file = new File(FileName); // 创建FileOutputStream对应OutputStreamWriter：将字节流转换为字符流，即写入out1的数据会自动由字节转换为字符。 OutputStreamWriter out1 = new OutputStreamWriter(new FileOutputStream(file), CharsetName); // 写入10个汉字 out1.write("字节流转为字符流示例"); // 向“文件中”写入"0123456789"+换行符 out1.write("0123456789\n"); out1.close(); &#125; catch(IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * InputStreamReader 演示程序 */ private static void testRead() &#123; try &#123; // 方法1：新建FileInputStream对象 // 新建文件“file.txt”对应File对象 File file = new File(FileName); InputStreamReader in1 = new InputStreamReader(new FileInputStream(file), CharsetName); // 测试read()，从中读取一个字符 char c1 = (char)in1.read(); System.out.println("c1="+c1); // 测试skip(long byteCount)，跳过4个字符 in1.skip(6); // 测试read(char[] cbuf, int off, int len) char[] buf = new char[10]; in1.read(buf, 0, buf.length); System.out.println("buf="+(new String(buf))); in1.close(); &#125; catch(IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果：12c1=字buf=流示例0123456 问题1，char为什么能表示中文呢看了下面这篇文章很好理解这篇博文。 答：因为java是用unicode字符编码表来对应字符的，”字”这个中文字符的unicode就是2个字节(且所有收录的中文都是2个字节的，本人粗略算了一下2万多个收录了)。且如果其给定的int值范围超过0-65535的范围，如果强制转换（char c = (char)i;）其会自动mod 65536(此处只针对大于)。java会根据该规则自动转换到0-65535区间中的一个。而“字”这个字的unicode编码其实是23383。 问题2，UTF-8方式存储的数据，StreamDecoder类怎么精准算出原数据占几个字节，并还原原始数据看了下面这篇阮一峰老师的文章很好理解字符编码笔记：ASCII，Unicode 和 UTF-8 答：也就是因为UTF-8方式读取字符的时候可以精准的找到整个字符所占的所有字节呀！这也就是为什么它的中文占3甚至4个字节的原因，因为UTF-8编码方式的每个字节都有标识位，需要耗费一些空间。还是挺好理解的 重点3一定要搞懂一件事： Unicode 是「字符集」UTF-8 是「编码规则」 其中： 字符集：为每一个「字符」分配一个唯一的 ID（学名为码位 / 码点 / Code Point） 编码规则：将「码位」转换为字节序列的规则（编码/解码 可以理解为 加密/解密 的过程） 参考：邱昊宇的回答 总结 InputStreamReader，字节流通向字符流的桥梁：它使用指定的charset读取字节并将其解码为字符。 每次调用InputStreamReader中的read方法都会导致从底层输入流读取一个或多个字节，然后调用编码转换器将字节转化为字符。为避免频繁调用转换器(StreamDecoder类内部底层调用)，实现从字节到字符的高效转换，可以提前从底层流读取更多的字节。为了达到最高效率，可要考虑在BufferedReader内包装InputStreamReader。 InputStreamReader的功能是依赖于StreamDecoder完成的。 OutputStreamWriter，字符流通向字节流的桥梁：它使用指定的charset将要写入流中的字符编码成字节。 每次调用write()方法都会导致在给定字符（或字符集）上调用编码转换器(StreamEncoder类内部底层调用)。为避免频繁调用转换器，在写入底层输出流之前，可以将得到的这些字节积累在缓冲区。例如，可考虑将OutputStreamWriter包装到BufferedWriter中。 OutputStreamWriter的功能是依赖于StreamEncoder完成的。 FileReader，FileWriter FileReader 是用于读取字符流的类，它继承于InputStreamReader。要读取原始字节流，请考虑使用 FileInputStream。 FileWriter 是用于写入字符流的类，它继承于OutputStreamWriter。要写入原始字节流，请考虑使用 FileOutputStream。 需要注意的是该类并非直接继承自Reader，Writer类，而是继承其子类并在其子类基础上进行扩展。 大致看了一下源码，我们可以看出FileReader是基于InputStreamReader实现的。相对的FileWriter是基于OutputStreamWriter实现的。 12345678910111213public class FileWriter extends OutputStreamWriter &#123; public FileWriter(String fileName) throws IOException &#123; super(new FileOutputStream(fileName)); &#125;&#125;public class FileReader extends InputStreamReader &#123; public FileReader(String fileName) throws FileNotFoundException &#123; super(new FileInputStream(fileName)); &#125;&#125; 都是如此。只是几个构造函数参数不同 演示程序FileWriter12345678// 创建文件“file.txt”对应File对象File file = new File(FileName);// 创建FileOutputStream对应FileWriter：将字节流转换为字符流，即写入out1的数据会自动由字节转换为字符。FileWriter out1 = new FileWriter(file);// 写入10个汉字out1.write("字节流转为字符流示例");// 向“文件中”写入"0123456789"+换行符out1.write("0123456789\n"); FileReader12345678910// 新建文件“file.txt”对应File对象File file = new File(FileName);FileReader in1 = new FileReader(file);// 测试read()，从中读取一个字符char c1 = (char)in1.read();System.out.println("c1="+c1);// 测试skip(long byteCount)，跳过4个字符in1.skip(6); BufferedReader，BufferedWriter==注意：== 其实看过其他类的源码后，真正理解了字节，字符输入输出流的作用机制后，就很清楚了，其实BufferedReader比起其他输入流没任何优势，只是他的缓冲池大，所以它缓冲的数据是其他输入流的n倍。也就为其他输入流提供了缓冲作用 BufferedReaderBufferedReader，字符缓冲输入流，作用是为其他输入流提供缓冲功能。BufferedReader从其他字符输入流中读取数据内容，缓冲各个字符，从而实现字符、数组和行的高效读取。当通过其read函数读取不到BufferedRead流中的数据时会调用fill()函数读取源输入流的数据来填充BufferedReader缓冲池的数据。 通常，Reader所作的每个读取请求都会导致对底层字符或字节流进行相应的读取请求。因此，建议用BufferedReader包装所有其read()操作可能开销很高的Reader（如FileReader和InputStreamReader）。例如，BufferedReader in = new BufferedReader(new FileReader(“foo.in”));将缓冲指定文件的输入。如果没有缓冲，则每次调用read()或readLine()都会导致从文件中读取字节，并将其转换为字符后返回，而这是极其低效的。而BufferedReader就可以一次性帮我们读更多，从而减少了读的次数，也就减少了字符转化的次数。 123456// BufferedInputStreamprivate void fill() throws IOException &#123; // ... int n = getInIfOpen().read(buffer, pos, buffer.length - pos); // ...&#125; 问题：提供缓冲为什么能实现字符、数组和行的高效读取？ 是提高了读取的效率 是减少了打开存储介质的连接次数。缓冲中的数据实际上是保存在内存中，而原始数据可能是保存在硬盘中。从内存中读取数据的速度比从硬盘读取数据的速度至少快10倍以上。 问题：为什么不一次性将Reader中全部数据都读取到缓冲中呢？ 读取全部的数据所需要的时间可能会很长。 内存价格很贵，容量远没有硬盘那么大。我们能做的就是在效率和成本之间找到平衡点。大多数情况下，默认值就足够大了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class BufferedReader extends Reader &#123; // 底层字符输入流,BufferedReader实际操作的字符输入流 private Reader in; // 字符缓冲区 private char cb[]; // nChars是cb字符缓冲区中字符的总的个数 // nextChar是下一个要读取的字符在cb缓冲区中的位置 private int nChars, nextChar; // 表示标记无效。设置了标记，但是被标记位置由于某种原因导致标记无效 private static final int INVALIDATED = -2; //表示没有标记 private static final int UNMARKED = -1; //标记位置初始化为UNMARKED private int markedChar = UNMARKED; //在仍保留该标记的情况下，对可读取字符数量的限制。 //在读取达到或超过此限制的字符后，尝试重置流可能会失败。 //限制值大于输入缓冲区的大小将导致分配一个新缓冲区，其大小不小于该限制值。因此应该小心使用较大的值。 private int readAheadLimit = 0; /* Valid only when markedChar &gt; 0 */ //表示是否跳过换行符。（skipLF ，skip line feed） private boolean skipLF = false; //表示当做了标记时，是否忽略换行符。 private boolean markedSkipLF = false; //字符缓冲区默认大小 private static int defaultCharBufferSize = 8192; //每行默认的字符个数 private static int defaultExpectedLineLength = 80; /** * 创建指定底层字符输入流in和指定字符缓冲区大小sz的BufferedReader */ public BufferedReader(Reader in, int sz) &#123; super(in); if (sz &lt;= 0) throw new IllegalArgumentException("Buffer size &lt;= 0"); this.in = in; cb = new char[sz]; nextChar = nChars = 0; &#125; /** * 创建指定底层字符输入流in和默认字符缓冲区大小defaultCharBufferSize的BufferedReader */ public BufferedReader(Reader in) &#123; this(in, defaultCharBufferSize); &#125;&#125; fill，read123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141/** * 填充缓冲区。 * 如果标记有效，要考虑标记。 */ private void fill() throws IOException &#123; //cb中填充数据的起始位置，记录了此次填充时是从缓冲池的什么位置开始填充数据的 int dst; //如果没有标记，从缓冲区索引为0的位置开始填充 //这个if的处理逻辑是填充缓冲池前的原数据加载行为， //即找到缓冲池中原本标记的有效数据，读取readAheadLimit个后，舍弃其他数据。 if (markedChar &lt;= UNMARKED) &#123; dst = 0; &#125; else &#123;//如果有标记 //delta为标记位置与下个读取字符之间的距离 int delta = nextChar - markedChar; //如果delta超出readAheadLimit，标记即为无效。 if (delta &gt;= readAheadLimit) &#123; markedChar = INVALIDATED; readAheadLimit = 0; dst = 0; &#125; else &#123; //如果delta没有超出readAheadLimit，即标记有效 //且readAheadLimit小于等于缓冲区长度 //将markedChar与nextChar之间的字符写入到缓冲区中 if (readAheadLimit &lt;= cb.length) &#123; /* Shuffle in the current buffer */ System.arraycopy(cb, markedChar, cb, 0, delta); markedChar = 0; dst = delta; &#125; else &#123; //如果delta没有超出readAheadLimit，即标记有效 //且readAheadLimit大于缓冲区长度 //将重新设置缓冲区大小，markedChar与nextChar之间的字符写入到缓冲区中 char ncb[] = new char[readAheadLimit]; //这里触发的条件是缓冲区已经标记，且标记后读取的规定的字符数要超过计算的个数(nextChar - markedChar)， //且要读取的个数超过了缓冲区总长度。 System.arraycopy(cb, markedChar, ncb, 0, delta); cb = ncb; markedChar = 0; dst = delta; &#125; nextChar = nChars = delta; &#125; &#125; int n; //从底层输入流中读取数据，并存储到缓冲区cb中 //如果没有读取到数据，就继续读(可能有数据为空的情况)，直到读到数据或者到达流末尾为止(只要不返回-1，就说明没结束) do &#123; n = in.read(cb, dst, cb.length - dst); &#125; while (n == 0); //如果读到了数据 if (n &gt; 0) &#123; nChars = dst + n; nextChar = dst; &#125;&#125;/** * 读取单个字符。 * * @return 作为一个整数（其范围从0到65535( 0x00-0xffff)）返回，如果已到达流末尾，则返回 -1 */public int read() throws IOException &#123; synchronized (lock) &#123; //确认BufferedReader是否处于开启状态 ensureOpen(); //？？？什么意义？ for (;;) &#123; //如果缓冲区数据已被读完，填充缓冲区。如果填充缓冲区后缓冲区依然是空的，说明已到达流末尾，返回-1。 if (nextChar &gt;= nChars) &#123; fill(); if (nextChar &gt;= nChars) return -1; &#125; //如果skipLF为true，说明要跳过换行符 if (skipLF) &#123; //说明只作用一次 skipLF = false; //如果缓冲区内下个字符为换行符，跳过它。 if (cb[nextChar] == '\n') &#123; nextChar++; continue; &#125; &#125; //返回缓冲区中下个字符，然后nextChar+1 return cb[nextChar++]; &#125; &#125;&#125;/** * 从缓冲区中读取数据，写入到cbuf中。off为开始存储字符处的偏移量。len为要读取的最大字符数。 * 如有必要，从底层输入流中读取数据。 * * 该方法在read(char cbuf[], int off, int len)中被调用 * * @param b 目标字符数组 * @param off 开始存储字符处的偏移量 * @param len 要读取的最大字符数 * @return 实际读入cbuf的总字节数，如果由于已到达流末尾而不再有数据，则返回-1。 */private int read1(char[] cbuf, int off, int len) throws IOException &#123; //如果缓冲区已被读完 if (nextChar &gt;= nChars) &#123; //如果要读取的长度大于等于缓冲区大小，且没有标记，且不跳过换行符 if (len &gt;= cb.length &amp;&amp; markedChar &lt;= UNMARKED &amp;&amp; !skipLF) &#123; //直接从底层输入流中读取数据到cbuf中， //？？？这里有个搞不懂的地方，那这样的话那么缓冲区的暂存数据还未被读走不是选择性[跳]着读了吗？ return in.read(cbuf, off, len); &#125; //填充缓冲区 fill(); &#125; //如果以上步骤执行完后，缓冲区还是没有可读数据，说明已经到达流末尾，返回-1 if (nextChar &gt;= nChars) return -1; //如果跳过换行符 if (skipLF) &#123; //说明换行符只不被读一次 skipLF = false; //如果下个字符是换行符 if (cb[nextChar] == '\n') &#123; //跳过它 nextChar++; //如果缓冲区已被读完，填充缓冲区 if (nextChar &gt;= nChars) fill(); //如果填充缓冲区后，缓冲区依然是空的。说明已经到达流末尾，返回-1 if (nextChar &gt;= nChars) return -1; &#125; &#125; // 如果缓冲池中还有数据的话也就不填了，该次读取仅读有的这些 // 所以说，如果一个数组过来读没读满的话，不能说明原数据没数据了。 int n = Math.min(len, nChars - nextChar); //读取 System.arraycopy(cb, nextChar, cbuf, off, n); //缓冲区当前位置+n nextChar += n; return n;&#125; ==注意== ： 这里带上read1函数的一个主要原因是源码中的设计有个地方不太明白。注释中已经说明 其他地方无论readLine读行还是skip跳字符等，都和之前研究过的BufferedInputStream一样，不一样的只是多了关于换行符的判断。 BufferedWriterBufferedWriter，字符缓冲输出流，作用是为其他输出流提供缓冲功能。BufferedWriter将文本写入其他字符输出流，缓冲各个字符，从而提供单个字符、数组和字符串的高效写入。 通常Writer将其输出立即发送到底层字符或字节流。除非要求提示输出，否则建议用BufferedWriter包装所有其write()操作可能开销很高的 Writer（如FileWriters和OutputStreamWriters）。例如，PrintWriter out = new PrintWriter(new BufferedWriter(new FileWriter(“foo.out”))); 将缓冲PrintWriter对文件的输出。如果没有缓冲，则每次调用print()方法会导致将字符转换为字节，然后立即写入到文件，而这是极其低效的。 1234567// BufferedOutputStreamprivate void flushBuffer() throws IOException &#123; if (count &gt; 0) &#123; out.write(buf, 0, count);// 一次性向OutPutStream输出更多数据 count = 0; &#125;&#125; BufferedWriter是如何为其他输出流提供缓冲功能的创建BufferedWriter时，我们会通过它的构造函数指定某个底层字符输出流Writer为参数。当程序中每次将单个字符、数组和字符串写入到BufferedWriter中时、都会检查BufferedWriter中的缓存区是否存满，如果没有存满则将字符写入到缓存区中；如果存满，则调用底层的writer(char[] b, int off, int len)将缓存区中的所有字符一次性写入到底层Writer中。 提供缓冲为什么能实现单个字符、数组和字符串的高效写入如果没有缓冲，使用底层字符输出流向目的文件中写入单个字符、数组和字符串时，每写入一次就要打开一次到目的文件的连接。这样频繁的访问效率非常底下。比如，将一个非常大的数据写入到目的文件中，如果每写入一个字符就要打开一次到目的文件的连接，可以想象效率是如何低下。 有了缓冲，当使用底层字符输出流向目的文件中写入单个字符、数组和字符串时，将单个字符、数组和字符串先写入到BufferedWriter的内置缓存空间中，然后当达到一定数量时一次性写入Writer流中。此时，Writer就可以打开一次通道，将这个数据块写入到文件中。这样虽然不能达到一次访问就将所有数据写入磁盘中的效果，但也大大提高了效率和减少了对磁盘的访问量。 write，newLine1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 写入字符数组的某一部分。 * 将字符数组的cbuf中从下标off开始的len个字符写入缓冲区cb中 */public void write(char cbuf[], int off, int len) throws IOException &#123; synchronized (lock) &#123; ensureOpen(); //检查参数是否合法 if ((off &lt; 0) || (off &gt; cbuf.length) || (len &lt; 0) || ((off + len) &gt; cbuf.length) || ((off + len) &lt; 0)) &#123; throw new IndexOutOfBoundsException(); &#125; else if (len == 0) &#123; return; &#125; //如果cbuf的数据的长度大于等于缓冲区长度 if (len &gt;= nChars) &#123; //刷新缓冲区，将要写入的数据直接写入到底层输出流中 flushBuffer(); //Writer抽象类的不同子类实现不同，因为该函数在Writer抽象类中声明的是抽象方法，也就是准备给子类各自去不同实现的 //CharArrayWriter的实现方式是如果缓冲池大小小于len则扩容成(缓冲池大小1倍，len大小)两者较大的量。 //PipedWriter的实现方式是迭代len次的调用write(int a)，逐个写入 out.write(cbuf, off, len); return; &#125; //如果cbuf的数据的长度小于缓冲区长度，将数据写入缓冲区中。 int b = off, t = off + len; while (b &lt; t) &#123; int d = min(nChars - nextChar, t - b); System.arraycopy(cbuf, b, cb, nextChar, d); b += d; nextChar += d; //如果写入过程中缓冲区满了，刷新缓冲区，继续将数据写入缓冲区。 if (nextChar &gt;= nChars) flushBuffer(); &#125; &#125; /** * 写入一个行分隔符。 * 行分隔符字符串由系统属性line.separator定义，并且不一定是单个新行('\n')符。 */ public void newLine() throws IOException &#123; // 这里写入一个行分隔符，所以当你再写数据的时候，如果操作的是文件 // 新数据就会出现在文件另一行。 write(lineSeparator); &#125;&#125; 这里写上write函数的原因是方法中out.write(cbuf, off, len);这句曾困扰我一会儿，突然想不通当len &gt;= nChars时具体他会怎么操作了。 后来想明白了，还操作个啥，BufferedWriter才不会管，让实际操作的*Writer输入流自己去处理去，因为本身该方法在抽象父类Writer中就是抽象函数，也就是任意Writer的非抽象子类都必须重写。所以它根本必须要管，也没权利管。 总结 BufferedReader，字符缓冲输入流，作用是为其他输入流提供缓冲功能。BufferedReader从其他字符输入流中读取文本，缓冲各个字符，从而实现字符、数组和行的高效读取。 BufferedReader支持标记功能。 BufferedWriter，字符缓冲输出流，作用是为其他输出流提供缓冲功能。BufferedWriter将文本写入其他字符输出流，缓冲各个字符，从而提供单个字符、数组和字符串的高效写入。 PrintWriterPrintWriter 是字符类型的打印输出流，它继承于Writer。 PrintStream 用于向文本输出流打印对象的格式化表示形式。它实现在 PrintStream 中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。 ==需要注意的是==，该类和其对应的字节输出流的自动刷新功能不同，它只有在调用printf，及println函数的时候才会自动刷新。这一点下面的源码注释中我有写。 PrintWriter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public class PrintWriter extends Writer &#123; /** * PrintWriter的底层字符输出流 */ protected Writer out; //是否自动刷新。 //如果为true，每次执行printf()[format函数的原因], // println()[newLine函数的原因]函数，都会调用flush()函数。 private final boolean autoFlush; //是否有异常 //当PrintWriter有异常产生时，会被本身捕获，并设置trouble为true private boolean trouble = false; //用于格式化字符串的对象 private Formatter formatter; //字节打印流 //用于checkError方法 private PrintStream psOut = null; /** * 行分隔符 * 在PrintWriter被创建时line.separator属性的值。 */ private final String lineSeparator; /** * 返回csn(字符集名字)对应的Chaset * csn为null或是不支持的字符集，抛出异常 */ private static Charset toCharset(String csn) throws UnsupportedEncodingException &#123; Objects.requireNonNull(csn, "charsetName"); try &#123; return Charset.forName(csn); &#125; catch (IllegalCharsetNameException|UnsupportedCharsetException unused) &#123; // UnsupportedEncodingException should be thrown throw new UnsupportedEncodingException(csn); &#125; &#125; /** * 创建新的PrintWriter。 * 指定底层输出流，默认不会自动flush，采用默认字符集 */ public PrintWriter (Writer out) &#123; this(out, false); &#125; /** * 创建新的PrintWriter。 * 指定底层输出流，指定是否自动flush，采用默认字符集 */ public PrintWriter(Writer out, boolean autoFlush) &#123; super(out); this.out = out; this.autoFlush = autoFlush; //line.separator属性的值 lineSeparator = java.security.AccessController.doPrivileged( new sun.security.action.GetPropertyAction("line.separator")); &#125; /** * 创建新的PrintWriter。 * 指定底层输出流，不自动flush，采用默认字符集 */ public PrintWriter(OutputStream out) &#123; this(out, false); &#125; /** * 创建新的PrintWriter。 * 指定底层输出流，指定是否自动flush，采用默认字符集 */ public PrintWriter(OutputStream out, boolean autoFlush) &#123; this(new BufferedWriter(new OutputStreamWriter(out)), autoFlush); // save print stream for error propagation if (out instanceof java.io.PrintStream) &#123; psOut = (PrintStream) out; &#125; &#125; /** * 创建新的PrintWriter。 * 指定文件名，默认不自动flush，采用默认字符集 */ public PrintWriter(String fileName) throws FileNotFoundException &#123; this(new BufferedWriter(new OutputStreamWriter(new FileOutputStream(fileName))), false); &#125; /** * 私有构造方法。创建新的PrintWriter。 * 指定文件名，默认不自动flush，采用指定字符集 */ private PrintWriter(Charset charset, File file) throws FileNotFoundException &#123; this(new BufferedWriter(new OutputStreamWriter(new FileOutputStream(file), charset)), false); &#125; /** * 创建新的PrintWriter。 * 指定文件名，默认不自动flush，采用指定字符集 */ public PrintWriter(String fileName, String csn) throws FileNotFoundException, UnsupportedEncodingException &#123; this(toCharset(csn), new File(fileName)); &#125; /** * 创建新的PrintWriter。 * 指定文件名，默认不自动flush，采用默认字符集 */ public PrintWriter(File file) throws FileNotFoundException &#123; this(new BufferedWriter(new OutputStreamWriter(new FileOutputStream(file))), false); &#125; /** * 创建新的PrintWriter。 * 指定文件名，默认不自动flush，采用指定字符集 */ public PrintWriter(File file, String csn) throws FileNotFoundException, UnsupportedEncodingException &#123; this(toCharset(csn), file); &#125;&#125; 光构造函数就有9个，其实底层用的就只有一个。1234567public PrintWriter(Writer out,boolean autoFlush) &#123; super(out); this.out = out; this.autoFlush = autoFlush; lineSeparator = java.security.AccessController.doPrivileged( new sun.security.action.GetPropertyAction("line.separator"));&#125; checkError，setError，clearError该类除构造函数会抛出异常外，其余所有的函数调用均不会抛出异常。在调用时如果抛出异常会被catch掉，然后设置trouble变量为true，并不会显示抛出。123456789101112131415161718192021222324252627282930313233/** * 如果流没有关闭，则刷新流且检查其错误状态。 */public boolean checkError() &#123; //如果流没有关闭，则刷新流 if (out != null) &#123; flush(); &#125; //检查错误状态 if (out instanceof java.io.PrintWriter) &#123; PrintWriter pw = (PrintWriter) out; return pw.checkError(); &#125; else if (psOut != null) &#123; return psOut.checkError(); &#125; //如果抛出了异常，返回true return trouble;&#125;/** * 指示已发生错误。 * 在调用clearError()之前，此方法将导致checkError()的后续调用返回 true。 */protected void setError() &#123; trouble = true;&#125;/** * 清除此流的错误状态。 */protected void clearError() &#123; trouble = false;&#125; write1234567/** * 写入字符数组。 * 此方法不能从Writer类继承，因为它必须取消I/O异常。 */public void write(char buf[]) &#123; write(buf, 0, buf.length);&#125; 很多时候我们不得不重新自己定义一些函数。因为我们有些原因不能重写父类的函数 其实大多数函数都是直接底层调用，除了会有字符输入输出流特有的安全检查机制ensureOpen对于底层实际操作的输入输出流的null判断外。大部分都是直接调用，然后区别只是catch到异常的时候不再往外抛，而是设置trouble变量为true。如下：1234567891011121314151617/** * 写入字符串的某一部分。 */public void write(String s, int off, int len) &#123; try &#123; synchronized (lock) &#123; ensureOpen(); out.write(s, off, len); &#125; &#125; catch (InterruptedIOException x) &#123; Thread.currentThread().interrupt(); &#125; catch (IOException x) &#123; trouble = true; &#125;&#125; printf1234// 其实底层调用的就是Formatter类的format方法public PrintWriter printf(String format, Object ... args) &#123; return format(format, args);&#125; 总结 从构造方法中可以看到，BufferedWriter包装了底层输出流，为其提供了缓冲功能。 此类中的方法不会抛出I/O异常，尽管其某些构造方法可能抛出异常。客户端可能会查询调用checkError()是否出现错误。 print方法可以打印boolean、char 、char[]、double 、float、int、 long、Object、String这些类型。都是按照平台的默认字符串编码将String.valueOf() 方法生成的字符串转换为字节，并完全以write(int)方法的方式向输出流中写入这些字节。 println(type param)方法可以打印boolean、char 、char[]、double 、float、int、 long、Object、String这些类型。都是先调用print方法打印，再调用println()方法换行。 printf方法和format方法的效果是相同的。因为printf方法是依赖于调用format方法实现的。 append方法其实是依赖于out.write方法实现的。 RandomAccessFile RandomAccessFile 是随机访问文件 (包括读/写)的类。它支持对文件随机访问的读取和写入，即我们可以从指定的位置读取/写入文件数据。 需要注意的是，RandomAccessFile 虽然属于java.io包，但它不是InputStream或者OutputStream的子类；它也不同于FileInputStream和FileOutputStream。 FileInputStream 只能对文件进行读操作，而FileOutputStream 只能对文件进行写操作；但是，RandomAccessFile 同时支持文件的读和写，并且它支持随机访问。 RandomAccessFile 模式说明RandomAccessFile共有4种模式：”r”, “rw”, “rws”和”rwd”。1234"r" 以只读方式打开。调用结果对象的任何 write 方法都将导致抛出 IOException。 "rw" 打开以便读取和写入。"rws" 打开以便读取和写入。相对于 "rw"，"rws" 还要求对“文件的内容”或“元数据”的每个更新都同步写入到基础存储设备。 这里的s是synchronized的意思"rwd" 打开以便读取和写入，相对于 "rw"，"rwd" 还要求对“文件的内容”的每个更新都同步写入到基础存储设备。 和rws的区别是不包含原数据 ==说明：== 什么是“元数据”，即metadata？ metadata是“关于数据的数据”。在文件系统中，数据被包含在文件和文件夹中；metadata信息包括：“数据是一个文件，一个目录还是一个链接”，“数据的创建时间(简称ctime)”，“最后一次修改时间(简称mtime)”，“数据拥有者”，“数据拥有群组”，“访问权限”等等。也就是数据的修饰信息，状态信息。而非具体的数据内容 “rw”, “rws”, “rwd” 的区别？ 当操作的文件是存储在本地的基础存储设备上时(如硬盘, NandFlash等)，”rws” 或 “rwd”, “rw” 才有区别。 当模式是 “rws” 并且 操作的是基础存储设备上的文件；那么，每次“更改文件内容[如write()写入数据]” 或 “修改文件元数据(如文件的mtime)”时，都会将这些改变同步到基础存储设备上 当模式是 “rwd” 并且 操作的是基础存储设备上的文件；那么，每次“更改文件内容[如write()写入数据]”时，都会将这些改变同步到基础存储设备上。 当模式是 “rw” 并且 操作的是基础存储设备上的文件；那么，关闭文件时，会将“文件内容的修改”同步到基础存储设备上。至于，“更改文件内容”时，是否会立即同步，取决于系统底层实现。 作者的演示程序还是很好理解的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114 /** * RandomAccessFile 测试程序 * * 运行结果(输出如下)： * c1=a * c2=b * buf=9876543210 * * 此外, * (01) 在源文件所在目录生成了file.txt。 * (02) 注意RandomAccessFile写入boolean, byte, char, int,所占的字符个数。 * * @author skywang */public class RandomAccessFileTest &#123; private static final String FileName = "file.txt"; public static void main(String[] args) &#123; // 若文件“file.txt”存在，则删除该文件。 File file = new File(FileName); if (file.exists()) file.delete(); testCreateWrite(); testAppendWrite(); testRead(); &#125; /** * 若“file.txt”不存在的话，则新建文件，并向文件中写入内容 */ private static void testCreateWrite() &#123; try &#123; // 创建文件“file.txt”对应File对象 File file = new File(FileName); // 创建文件“file.txt”对应的RandomAccessFile对象 RandomAccessFile raf = new RandomAccessFile(file, "rw"); // 向“文件中”写入26个字母+回车 raf.writeChars("abcdefghijklmnopqrstuvwxyz\n"); // 向“文件中”写入"9876543210"+回车 raf.writeChars("9876543210\n"); raf.close(); &#125; catch(IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 向文件末尾追加内容 */ private static void testAppendWrite() &#123; try &#123; // 创建文件“file.txt”对应File对象 File file = new File(FileName); // 创建文件“file.txt”对应的RandomAccessFile对象 RandomAccessFile raf = new RandomAccessFile(file, "rw"); // 获取文件长度 long fileLen = raf.length(); // 将位置定位到“文件末尾” raf.seek(fileLen); // 以下向raf文件中写数据 raf.writeBoolean(true); // 占1个字节 raf.writeByte(0x41); // 占1个字节 raf.writeChar('a'); // 占2个字节 raf.writeShort(0x3c3c); // 占2个字节 raf.writeInt(0x75); // 占4个字节 raf.writeLong(0x1234567890123456L); // 占8个字节 raf.writeFloat(4.7f); // 占4个字节 raf.writeDouble(8.256);// 占8个字节 raf.writeUTF("UTF严"); // UTF-8格式写入 raf.writeChar('\n'); // 占2个字符。“换行符” raf.close(); &#125; catch(IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 通过RandomAccessFile读取文件 */ private static void testRead() &#123; try &#123; // 创建文件“file.txt”对应File对象 File file = new File(FileName); // 创建文件“file.txt”对应的RandomAccessFile对象，以只读方式打开 RandomAccessFile raf = new RandomAccessFile(file, "r"); // 读取一个字符 char c1 = raf.readChar(); System.out.println("c1="+c1); // 读取一个字符 char c2 = raf.readChar(); System.out.println("c2="+c2); // 跳过54个字节。 raf.seek(54); // 测试read(byte[] buffer, int byteOffset, int byteCount) byte[] buf = new byte[20]; raf.read(buf, 0, buf.length); System.out.println("buf="+(new String(buf))); raf.close(); &#125; catch(IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java IO源码分析 - Reader，Writer系列（一）]]></title>
    <url>%2Fjava-io-sourcecode-ReaderWriter1.html</url>
    <content type="text"><![CDATA[说明整个系列的文章全部参考或直接照搬下面两位作者的文章，这里只是根据自己需要对原作者的文章梳理的总结，仅给自己日后复习时提供思路，如有读者看到学习时建议移步原作。再次重申并非我所写 潘威威：Java8 I/O源码-目录 skywang12345：Java I/O系列 助于理解需要铭记的就是，字符输入输出流，最终我们都只是在操作各字符输入输出流中的char数组。所以它才叫字符输入输出流。各种不同类型的字符输入输出流在构造时需要传入的对象也是Reader和Writer而不可能是InputStream和OutputStream。 字符输入流操控字符，字节输入流操控字节。一定要搞清楚这一点。 FileFile 是“文件”和“目录路径名”的抽象表示形式。 File 直接继承于Object，实现了Serializable接口和Comparable接口。实现Serializable接口，意味着File对象支持序列化操作。而实现Comparable接口，意味着File对象之间可以比较大小；File能直接被存储在有序集合(如TreeSet、TreeMap中)。 File类源码分析，在分析File类源码的时候很多地方引用到了抽象类FileSystem的函数，而File类默认FileSystem的默认实例是WinNTFileSystem类。即Windows平台的文件系统对象，应该是我们下载时Java官方根据我们请求的主机来反回了不同jdk。 由于扯到了WinNTFileSystem这个类，所以对于File类的函数，只要知道结果和File层异常抛出情况即可。123456789101112131415161718192021222324252627282930313233343536373839public class File implements Serializable, Comparable&lt;File&gt; &#123; // 代表所在平台的文件系统对象 private static final FileSystem fs = DefaultFileSystem.getFileSystem(); // 文件路径名 private final String path; // 内联枚举类,地址是否合法 private static enum PathStatus &#123; INVALID, CHECKED &#125;; // 指示文件路径是否无效的标志 private transient PathStatus status = null; // 路径前缀的长度 private final transient int prefixLength; // 分隔符，分隔同一个路径字符串中的目录的 // UNIX systems is '/' | Microsoft is '\\' public static final char separatorChar = fs.getSeparator(); // 分隔符 public static final String separator = "" + separatorChar; // 路径分割符,分隔连续多个路径字符串的分隔符。 // UNIX systems this character is ':' | on Microsoft Windows systems it is ';' public static final char pathSeparatorChar = fs.getPathSeparator(); // 路径分割符 public static final String pathSeparator = "" + pathSeparatorChar; //根据 parent 父路径和 child 子路径名字符串创建一个新 File 实例 public File(File parent, String child) &#123;// this.path，this.prefixLength &#125; //通过将给定路径字符串转换为抽象路径名来创建一个新 File 实例。 public File(String pathname) &#123; &#125; // 根据 parent 父路径名字符串和 child 子路径名字符串创建一个新 File 实例。 public File(String parent, String child) &#123; &#125; // 通过将给定的 file: URI 转换为一个抽象路径名来创建一个新的 File 实例。 public File(URI uri) &#123; &#125;&#125; 看完File类的成员变量后，我们大致了解了File类有哪些信息供直接表示，以及File类的所有构造函数并没有真正的构造File对象，都是先初始化了path，prefixLength两个成员变量。 File类函数列表即释义1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 成员函数boolean canExecute() // 测试应用程序是否可以执行此抽象路径名表示的文件。boolean canRead() // 测试应用程序是否可以读取此抽象路径名表示的文件。boolean canWrite() // 测试应用程序是否可以修改此抽象路径名表示的文件。int compareTo(File pathname) // 按字母顺序比较两个抽象路径名。boolean createNewFile() // 当且仅当不存在具有此抽象路径名指定名称的文件时，不可分地创建一个新的空文件。static File createTempFile(String prefix, String suffix) // 在默认临时文件目录中创建一个空文件，使用给定前缀和后缀生成其名称。static File createTempFile(String prefix, String suffix, File directory) // 在指定目录中创建一个新的空文件，使用给定的前缀和后缀字符串生成其名称。boolean delete() // 删除此抽象路径名表示的文件或目录。void deleteOnExit() // 在虚拟机终止时，请求删除此抽象路径名表示的文件或目录。boolean equals(Object obj) // 测试此抽象路径名与给定对象是否相等。boolean exists() // 测试此抽象路径名表示的文件或目录是否存在。File getAbsoluteFile() // 返回此抽象路径名的绝对路径名形式。String getAbsolutePath() // 返回此抽象路径名的绝对路径名字符串。File getCanonicalFile() // 返回此抽象路径名的规范形式。String getCanonicalPath() // 返回此抽象路径名的规范路径名字符串。long getFreeSpace() // 返回此抽象路径名指定的分区中未分配的字节数。String getName() // 返回由此抽象路径名表示的文件或目录的名称。String getParent() // 返回此抽象路径名父目录的路径名字符串；如果此路径名没有指定父目录，则返回 null。File getParentFile() // 返回此抽象路径名父目录的抽象路径名；如果此路径名没有指定父目录，则返回 null。String getPath() // 将此抽象路径名转换为一个路径名字符串。long getTotalSpace() // 返回此抽象路径名指定的分区大小。long getUsableSpace() // 返回此抽象路径名指定的分区上可用于此虚拟机的字节数。int hashCode() // 计算此抽象路径名的哈希码。boolean isAbsolute() // 测试此抽象路径名是否为绝对路径名。boolean isDirectory() // 测试此抽象路径名表示的文件是否是一个目录。boolean isFile() // 测试此抽象路径名表示的文件是否是一个标准文件。boolean isHidden() // 测试此抽象路径名指定的文件是否是一个隐藏文件。long lastModified() // 返回此抽象路径名表示的文件最后一次被修改的时间。long length() // 返回由此抽象路径名表示的文件的长度。String[] list() // 返回一个字符串数组，这些字符串指定此抽象路径名表示的目录中的文件和目录。String[] list(FilenameFilter filter) // 返回一个字符串数组，这些字符串指定此抽象路径名表示的目录中满足指定过滤器的文件和目录。File[] listFiles() // 返回一个抽象路径名数组，这些路径名表示此抽象路径名表示的目录中的文件。File[] listFiles(FileFilter filter) // 返回抽象路径名数组，这些路径名表示此抽象路径名表示的目录中满足指定过滤器的文件和目录。File[] listFiles(FilenameFilter filter) // 返回抽象路径名数组，这些路径名表示此抽象路径名表示的目录中满足指定过滤器的文件和目录。static File[] listRoots() // 列出可用的文件系统根。boolean mkdir() // 创建此抽象路径名指定的目录。boolean mkdirs() // 创建此抽象路径名指定的目录，包括所有必需但不存在的父目录。boolean renameTo(File dest) // 重新命名此抽象路径名表示的文件。boolean setExecutable(boolean executable) // 设置此抽象路径名所有者执行权限的一个便捷方法。boolean setExecutable(boolean executable, boolean ownerOnly) // 设置此抽象路径名的所有者或所有用户的执行权限。boolean setLastModified(long time) // 设置此抽象路径名指定的文件或目录的最后一次修改时间。boolean setReadable(boolean readable) // 设置此抽象路径名所有者读权限的一个便捷方法。boolean setReadable(boolean readable, boolean ownerOnly) // 设置此抽象路径名的所有者或所有用户的读权限。boolean setReadOnly() // 标记此抽象路径名指定的文件或目录，从而只能对其进行读操作。boolean setWritable(boolean writable) // 设置此抽象路径名所有者写权限的一个便捷方法。boolean setWritable(boolean writable, boolean ownerOnly) // 设置此抽象路径名的所有者或所有用户的写权限。String toString() // 返回此抽象路径名的路径名字符串。URI toURI() // 构造一个表示此抽象路径名的 file: URI。URL toURL() // 已过时。 此方法不会自动转义 URL 中的非法字符。建议新的代码使用以下方式将抽象路径名转换为 URL：首先通过 toURI 方法将其转换为 URI，然后通过 URI.toURL 方法将 URI 装换为 URL。 File类API典型应用当前目录的子目录下，再新建一个目录例如，我们想要在当前目录的子目录“dir”下，再新建一个子目录。有一下几种方法: 方法112File sub1 = new File("dir", "sub1");sub1.mkdir(); 说明：上面的方法作用是，在当前目录下 “dir/sub1”。它能正常运行的前提是“sub1”的父目录“dir”已经存在！ 方法212File sub2 = new File(dir, "sub2");sub2.mkdir(); 说明：上面的方法作用是，在当前目录下 “dir/sub2”。它能正常运行的前提是“sub2”的父目录“dir”已经存在！ 方法312File sub3 = new File("dir/sub3");sub3.mkdirs(); 说明：上面的方法作用是，在当前目录下 “dir/sub3”。它不需要dir已经存在，也能正常运行；若“sub3”的父母路不存在，mkdirs()方法会自动创建父目录。 新建文件的几种常用方法例如，我们想要在当前目录的子目录“dir”下，新建一个文件。有一下几种方法1234567try &#123; File dir = new File("dir"); // 获取目录“dir”对应的File对象 File file1 = new File(dir, "file1.txt"); file1.createNewFile();&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 说明：上面代码作用是，在“dir”目录(相对路径)下新建文件“file1.txt”。 方法2123456try &#123; File file2 = new File("dir", "file2.txt"); file2.createNewFile();&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 说明：上面代码作用是，在“dir”目录(相对路径)下新建文件“file2.txt”。 方法3123456try &#123; File file3 = new File("D:/dir/file4.txt"); file3.createNewFile();&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 上面代码作用是，下新建文件“D:/dir/file4.txt”(绝对路径)。 FileDescriptor FileDescriptor 是“文件描述符”。 FileDescriptor 可以被用来表示开放文件、开放套接字等。 以FileDescriptor表示文件来说：当FileDescriptor表示某文件时，我们可以通俗的将FileDescriptor看成是该文件。但是，我们不能直接通过FileDescriptor对该文件进行操作；若需要通过FileDescriptor对该文件进行操作，则需要新创建FileDescriptor对应的FileOutputStream，再对文件进行操作。 in, out, err介绍123(01) in -- 标准输入(键盘)的描述符(02) out -- 标准输出(屏幕)的描述符(03) err -- 标准错误输出(屏幕)的描述符 它们3个的原理和用法都类似。 out是标准输出(屏幕)的描述符。但是它有什么作用呢？我们可以通俗理解，out就代表了标准输出(屏幕)。若我们要输出信息到屏幕上，即可通过out来进行操作；但是，out又没有提供输出信息到屏幕的接口(因为out本质是FileDescriptor对象，而FileDescriptor没有输出接口)。怎么办呢？很简单，我们创建out对应的“输出流对象”，然后通过“输出流”的write()等输出接口就可以将信息输出到屏幕上。如下代码：123456try &#123; FileOutputStream out = new FileOutputStream(FileDescriptor.out); out.write('A'); out.close();&#125; catch (IOException e) &#123;&#125; 执行上面的程序，会在屏幕上输出字母’A’。 为了方便我们操作，java早已为我们封装好了“能方便的在屏幕上输出信息的接口”：通过System.out，我们能方便的输出信息到屏幕上。因此，我们可以等价的将上面的程序转换为如下代码：System.out.print(&#39;A&#39;); 123456789101112131415public static final FileDescriptor out = standardStream(1); private static FileDescriptor standardStream(int fd) &#123; FileDescriptor desc = new FileDescriptor(); desc.handle = set(fd); return desc;&#125;/** * 构造一个无效的FileDescriptor对象 */public /**/ FileDescriptor() &#123; fd = -1; handle = -1;&#125; 由于standardStream函数中调用的set函数是JNI，所以我们只能推测默认构造函数生成的FileDescriptor对象是无效的FileDescriptor对象。由此可知要想生成一个有效的FileDescriptor对象只能选择其内部声明好的3个静态域对象。至此我们大致也能猜出set函数应该是对fd变量赋值，并将返回值赋予handle，执行成功那么该返回的对象desc就不再是一个无效的FileDescriptor对象了。 fd对象是非常重要的一个变量，“fd=1”就代表了“标准输出”，“fd=0”就代表了“标准输入”，“fd=2”就代表了“标准错误输出”。 FileOutputStream out = new FileOutputStream(FileDescriptor.out); 就是利用构造函数FileOutputStream(FileDescriptor fdObj)来创建“Filed.out对应的FileOutputStream对象”。 通过上面的学习，我们知道，我们可以自定义标准的文件描述符[即，in(标准输入),out(标准输出),err(标准错误输出)]的流，从而完成输入/输出功能；但是，java已经为我们封装好了相应的接口，即我们可以更方便的System.in, System.out, System.err去使用它们。 FileInputStream，FileOutputStreamFileInputStream是文件输入流，用于从文件系统中的某个文件中获得输入字节。FileInputStream用于读取诸如图像数据之类的原始字节流。要读取字符流，请考虑使用FileReader。 FileOutputStream是文件输出流，用于将数据写入File或FileDescriptor的输出流。FileOutputStream用于写入诸如图像数据之类的原始字节的流。要写入字符流，请考虑使用FileWriter。 FileInputStream123456789101112131415161718192021222324252627282930313233343536373839404142public class FileInputStream extends InputStream &#123; //打开的文件的文件描述符，负责handle文件 private final FileDescriptor fd; //引用文件的路径，null if the stream is created with a file descriptor private final String path; //文件通道 private FileChannel channel = null; //关闭锁 private final Object closeLock = new Object(); //标识流是否关闭 private volatile boolean closed = false; // 根据传入的文件名来创建File对象 public FileInputStream(String name) throws FileNotFoundException &#123; this(name != null ? new File(name) : null); &#125; public FileInputStream(File file) throws FileNotFoundException &#123; //获取文件名 String name = (file != null ? file.getPath() : null); //获取安全管理器 SecurityManager security = System.getSecurityManager(); if (security != null) &#123; //如果调用线程没有访问指定文件的权限,抛出SecurityException security.checkRead(name); &#125; if (name == null) &#123; throw new NullPointerException(); &#125; if (file.isInvalid()) &#123; throw new FileNotFoundException("Invalid file path"); &#125; //fd表示此文件连接 fd = new FileDescriptor(); fd.attach(this); path = name; //打开文件以便读取 open(name); &#125;&#125; close，getChannel，getFD，finalize123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 关闭此文件输入流并释放与此流有关的所有系统资源。// 如果此流有一个与之关联的通道，则关闭该通道public void close() throws IOException &#123; synchronized (closeLock) &#123; if (closed) &#123; return; &#125; closed = true; &#125; //如果此流有一个与之关联的通道，则关闭该通道。 if (channel != null) &#123; channel.close(); &#125; fd.closeAll(new Closeable() &#123; public void close() throws IOException &#123; close0(); &#125; &#125;);&#125;/** * 返回与此文件输入流有关的唯一FileChannel对象。 */public FileChannel getChannel() &#123; synchronized (this) &#123; if (channel == null) &#123; channel = FileChannelImpl.open(fd, path, true, false, this); &#125; return channel; &#125;&#125;/** * 返回表示到文件系统中实际文件的连接的FileDescriptor对象 */public final FileDescriptor getFD() throws IOException &#123; if (fd != null) &#123; return fd; &#125; throw new IOException();&#125;/** * 确保在不再引用文件输入流时调用其close方法。 */protected void finalize() throws IOException &#123; if ((fd != null) &amp;&amp; (fd != FileDescriptor.in)) &#123; close(); &#125;&#125; FileOutputStream12345678910111213141516171819202122232425262728293031323334353637383940414243public class FileOutputStream extends OutputStream &#123; /** * 文件描述符 */ private final FileDescriptor fd; /** * 标识添加还是替换文件的内容 */ private final boolean append; /** * 关联的通道 * 懒加载 */ private FileChannel channel; //引用文件的路径 private final String path; //锁 private final Object closeLock = new Object(); //标识流是否关闭 private volatile boolean closed = false; // 创建一个向具有指定name的文件中写入数据的输出文件流。 // 如果第二个参数为append为true，则将字节写入文件末尾处，而不是写入文件开始处。 public FileOutputStream(String name, boolean append) throws FileNotFoundException &#123; this(name != null ? new File(name) : null, append); &#125; // 创建一个向指定文件描述符处写入数据的输出文件流，该文件描述符表示一个到文件系统中的某个实际文件的现有连接。 public FileOutputStream(FileDescriptor fdObj) &#123; SecurityManager security = System.getSecurityManager(); if (fdObj == null) &#123; throw new NullPointerException(); &#125; if (security != null) &#123; security.checkWrite(fdObj); &#125; this.fd = fdObj; this.append = false; this.path = null; fd.attach(this); &#125;&#125; write123// 将指定字节写入此文件输出流。// append 控制是写到文件尾还是头private native void write(int b, boolean append) throws IOException; 可以看出FileOutputStream和FileInputStream的相同功能函数处理逻辑一致。 总结 FileInputStream是文件输入流，用于从文件系统中的某个文件中获得输入字节。FileInputStream用于读取诸如图像数据之类的原始字节流。要读取字符流，请考虑使用FileReader。 FileOutputStream是文件输出流，用于将数据写入File或FileDescriptor的输出流。FileOutputStream用于写入诸如图像数据之类的原始字节的流。要写入字符流，请考虑使用FileWriter。 Java语言本身不能对操作系统底层进行访问和操作，但是可以通过JNI接口调用其他语言来实现对底层的访问。 FileInputStream不支持mark方法与set方法。 ObjectInputStream，ObjectOutputStreamObjectInputStream 和 ObjectOutputStream 的作用是，对基本数据和对象进行==序列化操作==支持。 创建“文件输出流”对应的ObjectOutputStream对象，该ObjectOutputStream对象能提供对“基本数据或对象”的持久存储；当我们需要读取这些存储的“基本数据或对象”时，可以创建“文件输入流”对应的ObjectInputStream，进而读取出这些“基本数据或对象”。 ==注意==： 只有支持 java.io.Serializable 或 java.io.Externalizable 接口的对象才能被ObjectInputStream/ObjectOutputStream所操作！ 头123456789public class ObjectOutputStream extends OutputStream implements ObjectOutput, ObjectStreamConstants &#123; &#125;public class ObjectInputStream extends InputStream implements ObjectInput, ObjectStreamConstants &#123; &#125; 演示程序123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * ObjectInputStream 和 ObjectOutputStream 测试程序 * * 注意：通过ObjectInputStream, ObjectOutputStream操作的对象，必须是实现了Serializable或Externalizable序列化接口的类的实例。 * * @author skywang */import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.ObjectInputStream; import java.io.ObjectOutputStream; import java.io.Serializable; import java.util.Map;import java.util.HashMap;import java.util.Iterator; public class ObjectStreamTest &#123; private static final String TMP_FILE = "box.tmp"; public static void main(String[] args) &#123; testWrite(); testRead(); &#125; /** * ObjectOutputStream 测试函数 */ private static void testWrite() &#123; try &#123; ObjectOutputStream out = new ObjectOutputStream( new FileOutputStream(TMP_FILE)); out.writeBoolean(true); out.writeByte((byte)65); out.writeChar('a'); out.writeInt(20131015); out.writeFloat(3.14F); out.writeDouble(1.414D); // 写入HashMap对象 HashMap map = new HashMap(); map.put("one", "red"); map.put("two", "green"); map.put("three", "blue"); out.writeObject(map); // 写入自定义的Box对象，Box实现了Serializable接口 Box box = new Box("desk", 80, 48); out.writeObject(box); out.close(); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; &#125; /** * ObjectInputStream 测试函数 */ private static void testRead() &#123; try &#123; ObjectInputStream in = new ObjectInputStream( new FileInputStream(TMP_FILE)); System.out.printf("boolean:%b\n" , in.readBoolean()); System.out.printf("byte:%d\n" , (in.readByte()&amp;0xff)); System.out.printf("char:%c\n" , in.readChar()); System.out.printf("int:%d\n" , in.readInt()); System.out.printf("float:%f\n" , in.readFloat()); System.out.printf("double:%f\n" , in.readDouble()); // 读取HashMap对象 HashMap map = (HashMap) in.readObject(); Iterator iter = map.entrySet().iterator(); while (iter.hasNext()) &#123; Map.Entry entry = (Map.Entry)iter.next(); System.out.printf("%-6s -- %s\n" , entry.getKey(), entry.getValue()); &#125; // 读取Box对象，Box实现了Serializable接口 Box box = (Box) in.readObject(); System.out.println("box: " + box); in.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;class Box implements Serializable &#123; private int width; private int height; private String name; public Box(String name, int width, int height) &#123; this.name = name; this.width = width; this.height = height; &#125; @Override public String toString() &#123; return "["+name+": ("+width+", "+height+") ]"; &#125;&#125; 结果12345678910boolean:truebyte:65char:aint:20131015float:3.140000double:1.414000two -- greenone -- redthree -- bluebox: [desk: (80, 48) ] ==再次提示==：通过ObjectInputStream, ObjectOutputStream操作的对象，必须是实现了Serializable或Externalizable序列化接口的类的实例。 字节输入流输出流分析结束Reader，Writer输入流的抽象类Reader，字符输出流的抽象类Writer。 ReaderReader是字符输入流的抽象类。看一下类的结构可以知道，子类必须实现的方法只有read(char[], int, int) 和close()函数。但是，多数子类将重写此处定义的一些方法，以提供更高的效率和/或其他功能。 看一下类的签名可知其实现了Readable和Closeable接口。12345678910111213public abstract class Reader implements Readable和, Closeable &#123;&#125;public interface Readable &#123; public int read(java.nio.CharBuffer cb) throws IOException;&#125;public interface Closeable extends AutoCloseable &#123; public void close() throws IOException;&#125; Reader类成员域123456789101112131415161718192021222324252627public abstract class Reader implements Readable, Closeable &#123; //用于同步针对此流的操作的对象。 protected Object lock; /** Maximum skip-buffer size */ private static final int maxSkipBufferSize = 8192; /** Skip buffer, null until allocated */ private char skipBuffer[] = null; /** * 构造函数之一 * 创建一个新的字符流Reader，其重要部分将同步其自身。 */ protected Reader() &#123; this.lock = this; &#125; /** * 构造函数之一 * 创建一个新的字符流reader，其重要部分将同步给定的对象lock */ protected Reader(Object lock) &#123; if (lock == null) &#123; throw new NullPointerException(); &#125; this.lock = lock; &#125;&#125; read，skip1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 试图将字符读入指定的字符缓冲区。 * 缓冲区可照原样用作字符的存储库：所做的唯一改变是put操作的结果。不对缓冲区执行翻转或重绕操作。 * 将输入流管道中的target.length个字节读取到指定的缓存字符数组target中、返回实际存放到target中的字符数。 */public int read(java.nio.CharBuffer target) throws IOException &#123; //获取此缓冲区中的剩余空间大小 int len = target.remaining(); char[] cbuf = new char[len]; //试图将输入流中的len个字符读入cbuf，返回实际读取的字节数n int n = read(cbuf, 0, len); //如果实际读到字符的个数大于0 if (n &gt; 0) //将实际读取到的n个字符存入缓冲区 target.put(cbuf, 0, n); //返回实际读取的字符数 return n;&#125;/** * 从输入流中读取单个字符。 */public int read() throws IOException &#123; char cb[] = new char[1]; if (read(cb, 0, 1) == -1) return -1; else return cb[0];&#125;/** * 跳过字符 * * @param n 要跳过的字符数 * @return 实际跳过的字符数 * */public long skip(long n) throws IOException &#123; //如果n为负数，抛出异常 if (n &lt; 0L) throw new IllegalArgumentException("skip value is negative"); //不允许n大于maxSkipBufferSize int nn = (int) Math.min(n, maxSkipBufferSize); synchronized (lock) &#123; //如果现有缓冲区为null或者大小小于nn，就新建一个大小为nn的缓冲区 if ((skipBuffer == null) || (skipBuffer.length &lt; nn)) skipBuffer = new char[nn]; long r = n; //循环跳过输入流中字符，一次尝试跳过nn个字符，直到到达输入流末尾或者n个字符被全部跳过 while (r &gt; 0) &#123; int nc = read(skipBuffer, 0, (int)Math.min(r, nn)); if (nc == -1) break; r -= nc; &#125; //返回实际跳过的字符数 return n - r; &#125;&#125; 剩下的函数大部分都需要没有具体实现需要子类重写实现自己的处理逻辑。对于大部分操作Reader抽象类，默认是unsupported的 writerWriter是字符输出流的抽象类。子类必须实现的方法仅有 write(char[], int, int)、flush() 和 close()。但是，多数子类将重写此处定义的一些方法，以提供更高的效率和/或其他功能。 从类的结构图可以看出，该类实现了Appendable接口的全部的3个抽象函数。并重写了父类Closeable，Flushable的全部的close，flush函数。但只是再次抽象声明，并没有提供默认实现。任然需要子类重写扩展 1234567891011121314151617181920212223242526272829303132public abstract class Writer implements Appendable, Closeable, Flushable &#123; /** * 字符缓存数组。 * 用于临时存放要写入字符输出流中的字符 */ private char[] writeBuffer; /** * 字符缓存数组的默认大小。 */ private static final int WRITE_BUFFER_SIZE = 1024; /** * 用于同步此流的操作的对象。 */ protected Object lock; /** * 构造方法 * 创建一个新的字符流writer，其关键部分将同步其自身。 */ protected Writer() &#123; this.lock = this; &#125; /** * 构造方法 * 建一个新的字符流writer，其关键部分将同步给定的对象。 */ protected Writer(Object lock) &#123; if (lock == null) &#123; throw new NullPointerException(); &#125; this.lock = lock; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 写入单个字符。 * 要写入的字符包含在给定整数值的16个低位中，16高位被忽略。 */public void write(int c) throws IOException &#123; synchronized (lock) &#123; if (writeBuffer == null)&#123; writeBuffer = new char[WRITE_BUFFER_SIZE]; &#125; //char为16位。所以要写入的字符包含在给定整数值的16个低位中，16高位被忽略。 writeBuffer[0] = (char) c; write(writeBuffer, 0, 1); &#125;&#125;// 试图将字符串中从off开始的len个字符写入输出流中。// 尽量写入len个字符，但写入的字节数可能少于len个，也可能为零。public void write(String str, int off, int len) throws IOException &#123; synchronized (lock) &#123; char cbuf[]; if (len &lt;= WRITE_BUFFER_SIZE) &#123; if (writeBuffer == null) &#123; writeBuffer = new char[WRITE_BUFFER_SIZE]; &#125; cbuf = writeBuffer; &#125; else &#123; // Don't permanently allocate very large buffers. cbuf = new char[len]; &#125; //将字符串中从off开始到off+len的字符复制到cbuf中 str.getChars(off, (off + len), cbuf, 0); // 将该方法的暂存数组写入到输出流中。 // 前面的一系列判断决定了是否使用Writer类给定的默认大小的字符串冲数组// 当大小超出则使用临时新定义的更大的缓冲数组 write(cbuf, 0, len); &#125;&#125;/** * 添加字符序列的一部分 */public Writer append(CharSequence csq, int start, int end) throws IOException &#123; CharSequence cs = (csq == null ? "null" : csq); write(cs.subSequence(start, end).toString()); return this;&#125; 总结 Reader是字符输入流的抽象类。子类必须实现的方法只有read(char[], int, int) 和close()。但是，多数子类将重写此处定义的一些方法，以提供更高的效率和/或其他功能。如重写read方法提供更高的效率；重写mark/set方法提供标记功能。 Writer是字符输出流的抽象类。子类必须实现的方法仅有 write(char[], int, int)、flush() 和 close()。但是，多数子类将重写此处定义的一些方法，以提供更高的效率和/或其他功能。 Reader与InputStream区别 操作对象的不同。字节流操作字节、字符操作字符。 实现的接口不同。Reader比InputStream多实现了一个Readable接口，用于提供一个可以将字符写入到指定缓存数组的方法。 close方法不同。Reader的close方法是抽象的、子类必须重写，而InputStream则不是(空实现，即不要求子类必须重写)。 InputStream的close方法则不是抽象的。 Writer与OutputStream区别 操作对象的不同。字节流操作字节、字符操作字符。 实现的接口不同。Writer相比与OutputStream多实现了一个Appendable接口、用于提供几个向此流中追加字符的方法。 close、flush方法不同。Writer的close、flush方法都是抽象的，而OutputStream则不是(空实现，即不要求子类必须重写)。 CharArrayReader，CharArrayWriter CharArrayReader实现一个可用作字符输入流的字符缓冲区。支持mark/set。 CharArrayWriter实现一个可用作字符输出流的字符缓冲区。缓冲区会随向流中写入数据而自动增长。可使用 toCharArray()和 toString()获取数据。 CharArrayReader1234567891011121314151617181920212223242526272829303132333435363738public class CharArrayReader extends Reader &#123; /** 字符缓冲区 */ protected char buf[]; /** 缓冲区中下一个被获取的字符的索引 */ protected int pos; /** 缓冲区中标记的位置. */ protected int markedPos = 0; /** 字符缓冲区大小 **/ protected int count; /** * 根据指定的char数组创建一个CharArrayReader。 * * buf不是复制得到的 */ public CharArrayReader(char buf[]) &#123; this.buf = buf; this.pos = 0; this.count = buf.length; &#125; // 根据指定的char数组创建一个CharArrayReader。 public CharArrayReader(char buf[], int offset, int length) &#123; //如果offset为负或大于buf.length，或者length为负，或者这两个值的和为负，抛出IllegalArgumentException。 if ((offset &lt; 0) || (offset &gt; buf.length) || (length &lt; 0) || ((offset + length) &lt; 0)) &#123; throw new IllegalArgumentException(); &#125; this.buf = buf; this.pos = offset; //count为length或buf.length-offset其中的较小者 this.count = Math.min(offset + length, buf.length); this.markedPos = offset; &#125;&#125; ensureOpen，ready，reset123456789101112131415161718192021222324252627282930313233343536373839404142434445/** 检查流是否被关闭。若字符缓冲为null，则认为流已关闭。*/private void ensureOpen() throws IOException &#123; if (buf == null) throw new IOException("Stream closed");&#125;/** * 读取单个字符。 * 如果到达缓冲区末尾，返回-1 */public int read() throws IOException &#123; synchronized (lock) &#123; // 输入流的打开检测 ensureOpen(); // 缓冲区容量判断 if (pos &gt;= count) return -1; else return buf[pos++]; &#125;&#125;/** * 判断此流是否已准备好被读取。 */public boolean ready() throws IOException &#123; synchronized (lock) &#123; ensureOpen(); // 缓冲区有数据可读即算准备好 return (count - pos) &gt; 0; &#125;&#125;/** * 将该流重置为最新的标记。 * 如果从未标记过，则将其重置到开头。 * * @exception IOException If an I/O error occurs */public void reset() throws IOException &#123; synchronized (lock) &#123; ensureOpen(); pos = markedPos; &#125;&#125; ==注意：== 从ready函数我们可以总结出，CharArrayRead类相比于InputStream抽象类一派的子类来说性能更高，因为InputStream的子类在对需要加锁操作的方法上的处理是直接在函数签名上添加synchronized来保证的。这样的话锁的就是这个对象，这样对一些没有加锁的方法调用时性能就会很受影响。而这里CharArrayRead类则是使用其内部声明的对象锁来保证的，很好地解决了这个问题。 ==注意：== 关于reset函数这里再贴一遍是为了提醒自己，不要忘记markPos变量声明时直接指定其值为0。也就是即便函数并没有调用过mark函数指定标记位置，也没有调用public CharArrayReader(char buf[], int offset, int length) {该多参构造函数构造对象，指定其markPos变量为offset位置。该值也会有默认reset到的位置。 测试程序1234567891011121314151617181920212223242526272829303132333435363738394041424344@Slf4jpublic class TestController &#123; public static void main(String[] args) &#123; charArrayReaderTest(); &#125; public static void charArrayReaderTest() &#123; char[] chars = new char[]&#123;'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j'&#125;; CharArrayReader charArrayReader = new CharArrayReader(chars); char[] container = new char[2]; try &#123; if (charArrayReader.ready()) &#123; char target = (char) charArrayReader.read(); System.out.println(target);// a - b if (charArrayReader.markSupported()) &#123; charArrayReader.mark(0); &#125; charArrayReader.skip(2);// - d int containerLoaded = charArrayReader.read(container, 0, container.length); System.out.println(containerLoaded);// 2 - g charArrayReader.reset(); // - b container = new char[6]; charArrayReader.read(container); for (int i = 0; i &lt; container.length; i++) &#123; System.out.println(container[i]);// b-j &#125; if (charArrayReader.ready()) &#123;// 有没有数据要被读 charArrayReader.close(); charArrayReader.read(); // throw IOException &#125; &#125; &#125; catch (IOException e) &#123; log.error("buf is null"); &#125; &#125;&#125; 结果123456789a2bcdefg15:26:12.561 [main] ERROR com.mmall.concurrency.TestController - buf is null 总结 CharArrayReader实现了一个可和字符输入流一样使用的字符缓冲区。也就是说，其实CharArrayReader只是一个缓冲区，其数据总量也就是CharArrayReader实例在构造时传入的char数组的大小。 ==有意思的是== 它实现了Reader函数，包装成了输入流的样子，可以供我们以输入流的方式读取其缓冲池中的数据。 ==有点儿不懂的是==，还没有给默认的缓冲池，一定要求我们以输入流的方式读取我们给定的char数组中的数据。 在做所有操作前，都要确认流处于open状态。判断流处于open状态的依据是buf不为null。close方法中会将buf置为null。 CharArrayReader支持mark()，reset()操作。 CharArrayWriter12345678910111213141516171819202122232425262728293031public class CharArrayWriter extends Writer &#123; /** * 存储数据的字符缓冲区 */ protected char buf[]; /** * 缓冲区中的字符个数 */ protected int count; /** * 创建一个新的CharArrayWriter。 * 缓冲区大小默认为32 */ public CharArrayWriter() &#123; this(32); &#125; /** * 创建一个新的CharArrayWriter，指定缓冲区大小为initialSize * 如果initialSize为负数，抛出异常 */ public CharArrayWriter(int initialSize) &#123; if (initialSize &lt; 0) &#123; throw new IllegalArgumentException("Negative initial size: "+ initialSize); &#125; buf = new char[initialSize]; &#125;&#125; write，writeTo，reset，toCharArray1234567891011121314151617181920212223242526272829303132333435363738394041/** * 将一个指定字符写到缓冲区中 */public void write(int c) &#123; synchronized (lock) &#123; int newcount = count + 1; //如果buf存满、则将buf容量扩大1倍、并将原来buf中count字符copy到新的buf中 if (newcount &gt; buf.length) &#123; buf = Arrays.copyOf(buf, Math.max(buf.length &lt;&lt; 1, newcount)); &#125; // 插入到字符数据缓冲区的数据也尽量不要超过2个字节的表示区， // 否则结果不是你想要的，高16位舍去 buf[count] = (char)c; count = newcount; &#125;&#125;/** * 将缓冲区的内容写入另一个字符流out。 */public void writeTo(Writer out) throws IOException &#123; synchronized (lock) &#123; out.write(buf, 0, count); &#125;&#125;/** * 重置该缓冲区，以便再次使用它而无需丢弃已分配的缓冲区。 */public void reset() &#123; count = 0;&#125;/** * 返回输入数据的副本。 */public char toCharArray()[] &#123; synchronized (lock) &#123; return Arrays.copyOf(buf, count); &#125;&#125; reset方法和toCharArray设计上行还是很简洁的。该类的flush，close方法无效。 总结 CharArrayWriter实现了一个可用作字符输出流的字符缓冲区，默认大小32。 CharArrayWriter的缓冲区会随着向流中写入数据的增多而自动增长(动态扩容 系数为1)。 可使用CharArrayWritert的toCharArray()和 toString()获取缓冲区中数据或者writeTo数据传递到另一个Writer流中也行。 CharArrayWriter中close()，flush()方法无效(空实现)。]]></content>
      <categories>
        <category>Java基础</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 快速入门]]></title>
    <url>%2Fjava-jvm-1.html</url>
    <content type="text"><![CDATA[声明文章整理自 Java3y 的学习JVM是如何从入门到放弃的？一文。 ！！！！！！！！！！！！！！！ 并非我原创，整理记录只是方便自己查阅温习。如果能帮助到你，我也非常开心。 类加载器Java默认有三种类加载器： 各个加载器的工作责任： Bootstrap ClassLoader：负责加载$JAVA_HOME中jre/lib/rt.jar里所有的class，由C++实现，不是ClassLoader子类 Extension ClassLoader：负责加载java平台中扩展功能的一些jar包，包括$JAVA_HOME中jre/lib/*.jar或-Djava.ext.dirs指定目录下的jar包 App ClassLoader：负责加载classpath中指定的jar包及目录中class 工作过程： 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载 如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException 其实这就是所谓的==双亲委派模型==。简单来说：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上。 好处： 防止内存中出现多份同样的字节码(安全性角度) 特别说明： 类加载器在成功加载某个类之后，会把得到的 java.lang.Class类的实例缓存起来。下次再请求加载该类的时候，类加载器会直接使用缓存的类的实例，而不会尝试再次加载(所以就不会出现多份同样的类字节码)。 类加载详细过程 加载，查找并加载类的二进制数据，同时在Java堆中也创建一个该类对应的java.lang.Class类对象。 连接，连接又包含三块内容：验证、准备、解析。 验证：文件格式、元数据、字节码、符号引用验证； 准备：为类的静态变量分配内存，并将其初始化为默认值； 解析：把类中的符号引用转换为直接引用 初始化，为类的静态变量赋予正确的初始值。 在类加载检查过程通过后，接下来虚拟机将为新生对象分配内存。 类的生命周期： JIT即时编辑器JVM是这样实现的： 就是把这些Java字节码重新编译优化，生成机器码，让CPU直接执行。这样编出来的代码效率会更高。 编译也是要花费时间的，我们一般对热点代码做编译(JIT即是编译器)，非热点代码直接解析就好了。 热点代码解释：一、多次调用的方法。二、多次执行的循环体 使用热点探测来检测是否为热点代码，热点探测有两种方式： 采样 计数器 目前HotSpot使用的是计数器的方式，它为每个方法准备了两类计数器： 方法调用计数器（Invocation Counter） 回边计数器（Back EdgeCounter）。 在确定虚拟机运行参数的前提下，这两个计数器都有一个确定的阈值，当计数器超过阈值溢出了，就会触发JIT编译。 JVM的运行时数据区基于jdk1.8画的JVM的内存模型，这张图的常量池是不存在的。指的是class文件中的常量池中的内容。 堆：存放对象实例，几乎所有的对象实例都在这里分配内存 虚拟机栈：虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息 本地方法栈：和虚拟机栈一致，只不过是为Java的Native方法服务。 方法区：存储已被虚拟机加载的类元数据信息(元空间) 程序计数器：当前线程所执行的字节码的行号指示器 JVM运行时数据区和JMM(Java内存模型)的区别 对象的创建过程参考： 图解JAVA对象的创建过程 Java3yJVM文章的1.5.2例子中的流程 Java程序编译和运行的过程 JVM垃圾回收JVM对程序中不需要的对象可以自动进行垃圾回收，但是进行垃圾回收操作前必定有一步判断对象是活着还是已死的步骤。常用有两种方式： 引用计数法–&gt;这种难以解决对象之间的循环引用的问题 可达性分析算法–&gt;主流的JVM采用的是这种方式 判断了哪些对象是死亡对象后就可以对这些死亡对象进行垃圾回收了。对于JMM中的垃圾对象来说，不同区域的对象死亡的快慢不同，回收的方式也是有讲究的。如果一个区域的对象，你知道程序从头到尾他都不会死亡，你还一直扫描他对他垃圾回收毫无疑问效率是极其低的。 所以垃圾回收也有好几种算法： 标记-清除算法(老年代) 复制算法(新生代) 标记-整理算法(老年代) 分代收集算法 无论是可达性分析算法，还是垃圾回收算法，JVM使用的都是准确式GC。 JVM是使用一组称为OopMap的数据结构，来存储所有的对象引用(这样就不用遍历整个内存去查找了，空间换时间)。在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举（可达性分析）。 上面所讲的垃圾收集算法只能算是方法论，落地实现的是垃圾收集器： Serial收集器 ParNew收集器 Parallel Scavenge收集器 Serial Old收集器 Parallel Old收集器 CMS收集器 G1收集器 上面这些收集器大部分是可以互相组合使用的 JVM参数与调优 JVM系列三:JVM参数设置、分析 JVM面试题 详细jvm内存模型 讲讲什么情况下回出现内存溢出，内存泄漏？ 说说Java线程栈 JVM 年轻代到年老代的晋升过程的判断条件是什么呢？ JVM 出现 fullGC 很频繁，怎么去线上排查问题？ 类加载为什么要使用双亲委派模式，有没有什么场景是打破了这个模式？ 类的实例化顺序 JVM垃圾回收机制，何时触发MinorGC等操作 JVM 中一次完整的 GC 流程（从 ygc 到 fgc）是怎样的 各种回收器，各自优缺点，重点CMS、G1 各种回收算法 OOM错误，stackoverflow错误，permgen space错误 详细jvm内存模型jdk1.7以前的PermGen（永久代），jdk1.8替换成Metaspace（元空间） 原本永久代存储的数据：符号引用(Symbols)转移到了native heap；字面量(interned strings)转移到了java heap；类的静态变量(class statics)转移到了java heap Metaspace（元空间）存储的是类的元数据信息（metadata） 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。 替换的好处：一、字符串存在永久代中，容易出现性能问题和内存溢出。二、永久代会为 GC 带来不必要的复杂度，并且回收效率偏低 图片来源：https://blog.csdn.net/tophawk/article/details/78704074 参考资料： https://www.cnblogs.com/paddix/p/5309550.html 讲讲什么情况下回出现内存溢出，内存泄漏？内存泄漏内存泄漏的原因很简单： 对象是可达的(一直被引用) 但是对象不会被使用 常见的内存泄漏例子：123456789101112131415public static void main(String[] args) &#123; Set set = new HashSet(); for (int i = 0; i &lt; 10; i++) &#123; Object object = new Object(); set.add(object); // 设置为空，这对象我不再用了 object = null; &#125; // 但是set集合中还维护这obj的引用，gc不会回收object对象 System.out.println(set); &#125; 解决这个内存泄漏问题也很简单，将set设置为null，那就可以避免上诉内存泄漏问题了。其他内存泄漏得一步一步分析了。 内存溢出内存溢出的原因： 内存泄露导致堆栈内存不断增大，从而引发内存溢出。(堆) 大量的jar，class文件加载，装载类的空间不够，溢出。(元空间) 操作大量的对象导致堆内存空间已经用满了，溢出。(老年代) nio直接操作内存，内存过大导致溢出 解决： 查看程序是否存在内存泄漏的问题 设置参数加大空间 代码中是否存在死循环或循环产生过多重复的对象实体、 查看是否使用了nio直接操作内存。 参考： java内存溢出的情况解决方法 Java常见内存溢出异常分析 说说线程栈JVM规范让每个Java线程拥有自己的独立的JVM栈，也就是Java方法的调用栈。 当方法调用的时候，会生成一个栈帧。栈帧是保存在虚拟机栈中的，栈帧存储了方法的局部变量表、操作数栈、动态连接和方法返回地址等信息 线程运行过程中，只有一个栈帧是处于活跃状态，称为“当前活跃栈帧”，当前活动栈帧始终是虚拟机栈的栈顶元素。 通过jstack工具查看线程状态 参考资料： http://wangwengcn.iteye.com/blog/1622195 https://www.cnblogs.com/Codenewbie/p/6184898.html https://blog.csdn.net/u011734144/article/details/60965155 JVM 新生代到年老代的晋升过程的判断条件是什么呢？ 部分对象会在From和To区域中复制来复制去,如此交换15次(由JVM参数MaxTenuringThreshold决定,这个参数默认是15),最终如果还是存活,就存入到老年代。 如果对象的大小大于Eden的二分之一会直接分配在old，如果old也分配不下，会做一次majorGC，如果小于eden的一半但是没有足够的空间，就进行minorgc也就是新生代GC。 minor gc后，survivor仍然放不下(大对象原本在Eden区存放，当进行一次minorGC的时候存活对象会从Eden区转移到survivorTo区，此时如果survivorTo区存不下转移过来的大对象)，则放到老年代。 动态年龄判断 ，大于等于某个年龄的对象且超过了survivor空间一半 ，或者直接大于等于某个年龄的对象直接进入老年代。 JVM 出现 fullGC 很频繁，怎么去线上排查问题Full GC触发条件： 调用System.gc时，系统建议执行Full GC，但是不必然执行 老年代空间不足 方法区空间不足 通过Minor GC后进入老年代的对象平均大小大于老年代的可用内存 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 参考： R大回答 — Major GC和Full GC的区别是什么？触发条件呢？ GC详解及Minor GC和Full GC触发条件总结 这题就依据full GC的触发条件来做： 如果有perm gen的话(jdk1.8就没了)，要给perm gen分配空间，但没有足够的空间时，会触发full gc。 所以看看是不是perm gen区的值设置得太小了。 System.gc()方法的调用 当统计得到的Minor GC晋升到旧生代的平均大小大于老年代的剩余空间，则会触发full gc(这就可以从多个角度上看了) 是不是频繁创建了大对象(也有可能eden区设置过小)(大对象直接分配在老年代中，导致老年代空间不足—&gt;从而频繁gc) 是不是老年代的空间设置过小了(Minor GC几个对象就大于老年代的剩余空间了) 类加载为什么要使用双亲委派模式，有没有什么场景是打破了这个模式？双亲委托模型的重要用途是为了解决类载入过程中的安全性问题。 假设有一个开发者自己编写了一个名为java.lang.Object的类，想借此欺骗JVM。现在他要使用自定义ClassLoader来加载自己编写的java.lang.Object类。 然而幸运的是，双亲委托模型不会让他成功。因为JVM会优先在Bootstrap ClassLoader的路径下找到java.lang.Object类，并载入它 Java的类加载是否一定遵循双亲委托模型？ 在实际开发中，我们可以通过自定义ClassLoader，并重写父类的loadClass方法，来打破这一机制。 SPI就是打破了双亲委托机制的(SPI：服务提供发现，Service Provider Interface)。SPI资料： https://zhuanlan.zhihu.com/p/28909673 https://www.cnblogs.com/huzi007/p/6679215.html https://blog.csdn.net/sigangjun/article/details/79071850 参考： Classloader的双亲委托机制 类的实例化顺序 父类静态成员和静态初始化块 ，按在代码中出现的顺序依次执行 子类静态成员和静态初始化块 ，按在代码中出现的顺序依次执行 父类实例成员和实例初始化块 ，按在代码中出现的顺序依次执行 父类构造方法 子类实例成员和实例初始化块 ，按在代码中出现的顺序依次执行 子类构造方法 每一次的 new 都经历了 加载: 将 Class 文件读入内存，并为之创建一个 java.lang.Class 对象 连接: 为静态域分配内存 初始化: 初始化超类，执行 static 实例化: 创建一个 Object 对象 每一次 new 一个对象时都会（都是先父类再子类） 如果是第一次 new ，则按顺序执行静态代码块和静态变量（凌驾于所有动态代码块和构造器之上） 按顺序执行动态代码块和动态变量（非 static 的变量都是动态变量） 构造器 监测代码：1234567891011121314151617181920212223242526272829303132333435363738394041class Dervied extends Base &#123; private String name = "Java3y"; public Dervied() &#123; tellName(); printName(); &#125; public void tellName() &#123; System.out.println("Dervied tell name: " + name); &#125; public void printName() &#123; System.out.println("Dervied print name: " + name); &#125; public static void main(String[] args) &#123; new Dervied(); &#125;&#125;class Base &#123; private String name = "公众号"; public Base() &#123; tellName(); printName(); &#125; public void tellName() &#123; System.out.println("Base tell name: " + name); &#125; public void printName() &#123; System.out.println("Base print name: " + name); &#125;&#125; 输出1234Dervied tell name: nullDervied print name: nullDervied tell name: Java3yDervied print name: Java3y 如果父类构造器调用了被子类重写的方法，且通过子类构造函数创建子类对象，调用了这个父类构造器（无论显示还是隐式），就会导致父类在构造时实际上调用的是子类覆盖的方法（你需要了解java继承中的初始化机制）。 ==缺点：== 如果在父类构造函数中调用被子类重写的方法，会导致子类重写的方法在子类构造器的所有代码之前执行，从而导致子类重写的方法访问不到子类实例变量的值，因为此时这些变量还没有被初始化。 参考： java父类调用被子类重写的方法 JVM垃圾回收机制，何时触发MinorGC等操作当young gen中的eden区分配满的时候触发MinorGC(新生代的空间不够放的时候)。 JVM 中一次完整的 GC 流程（从 ygc 到 fgc）是怎样的 YGC和FGC是什么 YGC ：对新生代堆进行gc。频率比较高，因为大部分对象的存活寿命较短，在新生代里被回收。性能耗费较小。 FGC ：全堆范围的gc。默认堆空间使用到达80%(可调整)的时候会触发fgc。以我们生产环境为例，一般比较少会触发fgc，有时10天或一周左右会有一次。GC的速度比较慢 什么时候执行YGC和FGC eden空间不足,执行 young gc old空间不足，perm空间不足，调用方法System.gc() ，ygc时的悲观策略, dump live的内存信息时(jmap –dump:live)，都会执行full gc 各种回收算法GC最基础的算法有三种： 标记 -清除算法 复制算法 标记-压缩算法 分代收集算法：我们常用的垃圾回收器一般都采用分代收集算法(其实就是组合上面的算法，不同的区域使用不同的算法)。 具体： 标记-清除算法：“标记-清除”（Mark-Sweep）算法，如它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。 复制算法，“复制”（Copying）的收集算法，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。 当这一块的内存用完了，就==将还存活着的对象复制到另外一块上面==，然后再把已使用过的内存空间一次清理掉。 标记-压缩算法：标记过程仍然与“标记-清除”算法一样，对所有可回收对象进行标记，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向内存一端移动，然后直接清理掉端边界以外的内存 分代收集算法，“分代收集”（Generational Collection）算法，把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。 各种回收器，各自优缺点，重点CMS、G1图中两个收集器之间有连线，说明它们可以配合使用。 Serial收集器，串行收集器是最古老，最稳定以及效率高的收集器，但可能会产生较长的停顿，只使用一个线程去回收。 ParNew收集器，ParNew收集器其实就是Serial收集器的多线程版本。 Parallel Scavenge收集器，Parallel Scavenge收集器类似ParNew收集器，Parallel收集器更关注系统的吞吐量。 Parallel Old收集器，Parallel Old是Parallel Scavenge收集器的老年代版本，使用多线程“标记－整理”算法 CMS收集器，CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它需要消耗额外的CPU和内存资源，在CPU和内存资源紧张，CPU较少时，会加重系统负担。CMS无法处理浮动垃圾。CMS的“标记-清除”算法，会导致大量空间碎片的产生。 G1收集器，G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC停顿时间要求的同时,还具备高吞吐量性能特征。 stackoverflow错误，permgen space错误stackoverflow错误主要出现： 在虚拟机栈中(线程请求的栈深度大于虚拟机栈锁允许的最大深度) permgen space错误(针对jdk之前的1.7版本)： 大量加载class文件 常量池内存溢出 1.6的时候可能是字符串常量池溢出。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM 学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程的逻辑 -- 并发章 -- 线程的中断]]></title>
    <url>%2Fjava-concurrentProgramming-readingNotes-15-4.html</url>
    <content type="text"><![CDATA[线程中断在Java中，停止一个线程的主要机制是中断，中断并不是强迫终止一个线程，它是一种协作机制，是给线程传递一个取消信号，但是由线程来决定如何以及何时退出。本节我们主要就是来理解Java的中断机制 线程中断的三个方法：123public boolean isInterrupted()public void interrupt()public static boolean interrupted() isInterrupted返回当前线程是否被中断。true/false interrupted不但具有isInterrupted的共同，同时每次调用还会清空该中断标志位。即某一个线程被中断了第一次调用为true第二次一般就为false。需要注意的是该方法是静态方法，中断的是正在执行的线程。 而其他两个方法则是中断this对象指定的线程。 interrupt中断对应线程。 线程不同状态对中断的反应interrupt ()对线程的影响与线程的状态和在进行的IO操作有关。我们主要考虑线程的状态，I/O操作的影响和具I/O以及操作系统有关，我们就不讨论了。 线程状态有： RUNNABLE:线程在运行或具备运行条件只是在等待操作系统调度。 WAITING/TIMED_WAITING:线程在等待某个条件或超时。 BLOCKED:线程在等待锁，试图进入同步块。 NEWATERMINATED:线程还未启动或已结束。 1.RUNNABLE如果线程在运行中，且没行执行I/O操作，interrupt()只是会设置线程的中断标忐位，没行任何其他作用。线程应该在运行过程中合适的位置检查中断标志位，比如，如果主体代码是一个循环，可以在循环开始处进行检查，如下所示：12345678910public class InterruptRunnableDemo extends Thread &#123; @Override public void run() &#123; while(!Thread.currentThread().isInterrupted()) &#123; //…单词循环代码 &#125; System.out.println(&quot;done &quot;); &#125; //其他代码&#125; 2.WAITING/TIMED_WAITING线程调用join/wait/sleep方法会进入WAITING或TIMED_WAITING状态。在对线程对象调用interrupt()后，当线程处于中断状态时，如果再由wait、sleep以及jion三个方法引起的阻塞，那么JVM会将线程的中断标志重新设置为false，并抛出一个InterruptedException异常。比如，执行如下代码：12345678910111213141516Thread t = new Thread ()&#123; @Override public void run() &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; System.out.println(isInterrupted()); &#125; &#125;&#125;;t.start();try &#123; Thread.sleep(100);// 确保该线程 睡开了&#125; catch (InterruptedException e) &#123;&#125;t.interrupt(); 程序的输出为false。 IntemiptedException是一个受检异常，线程必须进行处理。我们在异常处理中介绍过，处理异常的基本思路是：如果知道怎么处理，就进行处理，如果不知道，就应该向上传递，通常情况下不应该捕获异常然后忽略。 捕获到InterruptedException,通常表示希望结朿该线程，线程大致有两种处理方式： 向上传递该异常，这使得该方法也变成一个可中断的方法(相当于封装了一下)，需要调用者记性处理。 有些情况，不能向上传递异常，比如 Thread的run方法，它的声明是固定的，不能 ++抛出++ 任何受检异应该捕获异常， 进行合适的清理操作，清理后，一般应该调用Thread的interrupt方法设置中断标志位，使得其他代码有办法知道它发生了中断。 第一种示例代码：12345对Thread类的sleep方法进行了封装而不是直接在run方法中调用就可以保证interruptedException可以在run方法调用该interruptibleMethod方法时被抛出了。public void interruptibleMethod() throws InterruptedException&#123; //…这里可以是wait, join 或者 sleep 方法 Thread.sleep(1000);&#125; 第二种示例代码：1234567891011121314151617public class InterruptWaitingDemo extends Thread &#123; @Override public void run() &#123; while(!Thread.currentThread().isInterrupted()) &#123; try &#123; //模拟任务代码 Thread.sleep(2000); &#125; catch(InterruptedException e) &#123; //…清理操作 //重新设置中断标志位 方便其他代码知道该线程发生了中断 Thread.currentThread().interrupt(); &#125; &#125; System.out.println(isInterrupted()); &#125; //其他代码&#125; 3.BLOCKED当线程处于BLOCKED状态等待CPU调度时。调用线程的interrupt()方法并不能使一个正在等待的线程真正中断。 4.NEW/TERMINATE如果线程尚未启动(NEW)，或者已经结束(TERMINATE)，则调用interrupt()方法对其没有任何效果。并且线程的中断标志位也不会被设置。 总结本节主要讲的是如何取消以及关闭线程，主要采用的是中断技术。他是一种协作机制，并不会强制中断线程。并且介绍了线程在不同状态下对于中断操作的反应。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程的逻辑 -- 并发章 -- 线程的基本协作机制]]></title>
    <url>%2Fjava-concurrentProgramming-readingNotes-15-3.html</url>
    <content type="text"><![CDATA[线程的基本协作多线程间除了竞争访问同一资源外，也经常需要相互协作的去执行一些任务。而对于协作的基本机制用的最多的无疑是wait/notify。 协作的场景 生产者消费者模式：共享队列，一个负责放一个负责取。如果队列长度有限且满了之后则等待。 同时开始：类似运动员比赛，多个线程同时开始执行。 等待结束：主线程分发给各个子任务去执行任务，主任务开始执行前需要等待各个子任务执行完毕。 异步结果： 集合点 wait/notifywait和notify方法都是Object类提供给所有子类进行线程协作的一种实现机制。 wait:12public final void wait() throws InterruptedExceptionpublic final native void wait(long timeout) throws InterruptedException; 一个带时间参数，表示最多等待这么长时间。一个不带，默认为0，表示无限期等待。 如果在wait的过程中线程被中断，则会抛出InterruptedException。我们在之前关于Thread类的的博文中也提到过这个。 wait在等什么？ 我们之前说过的每个对象都有一把锁和一个等待队列，一个线程在进入synchronized代码块时，会尝试获取锁，如果获取不到则会把当前线程加入等待队列中，其实，除了对于锁的等待队列，每个对象还有另一个等待队列，即条件队列，该队列用于线程间的协作。调用wait就会把当前线程放到条件队列上并阻塞，表示当前线程执行不下去了，它需要等待一个条件，这个条件它自己改变不了，需要其他线程改变。当其他线程改变了条件后，应该调用Object(等待哪个对象就用哪个对象)的notify方法：12public final native void notify();public final native void notifyAll(); notify做的事情就是从条件队列中选一个线程，将其从队列中移除并唤醒，notifyAll和notify的区別是，它会移除条件队列中所有的线程并全部唤醒。 1234567891011121314151617181920212223242526public class WaitThread extends Thread &#123; private volatile boolean fire = false; @Override public void run() &#123; try &#123; synchronized (this) &#123; while(!fire) &#123; wait(); &#125; &#125; System.out.println(&quot;fired&quot;); &#125; catch(InterruptedException e) &#123; &#125; &#125; public synchronized void fire() &#123; this.fire = true; notify(); &#125; public static void main(String[] args) throws InterruptedException &#123; WaitThread waitThread = new WaitThread(); waitThread.start(); Thread.sleep(1000); System.out.println(&quot;fire&quot;); waitThread.fire(); &#125;&#125; 代码中的协作的条件变量式fire，两个线程都要访问该fire变量，容易出现竞态条件所以相关代码都被synchronized保护了。 需要特别注意的是： wait和notify方法的调用只能再synchronized代码块中。如果在调用wait/notify方法时，当前线程没有对象锁的话，那么会抛出java.lang.IllegalMonitor-StateException。 wait的具体过程： 把当前线程放入条件等待队列，++释放对象锁++，阻塞等待，线程状态变为WAITING或TIMED_WAITING 等待时间到或被其他线程调用notify/notifyAll从条件队列中移除，这时，要重新竞争对象锁 如果能够获得锁，线程状态变为RUNNABLE，并从wait调用中返回。 否则，该线程加入对象锁等待队列，线程状态变为BLOCKED，只有在获得锁后才会从wait调用返回。 这里我们一定要区别好两个等待队列，一个是线程没有分配到cpu时间片进入到的对象锁等待队列。另一个则是线程执行遇到条件不满足的情况进入条件等待队列。 当线程从条件队列中返回不代表其等待的条件就满足了，也有可能是wait方法限定的时间到达了。我们在使用wait方法的时候当其跳出后还应该再判断一次。一般我们通过while循环的方式来做到。123456synchronized (obj) &#123; while(条件不成立) obj.wait(); …//执行条件满足后的操作&#125; 调用notify会把在条件队列中等侍的线程唤醍并从队列中移除，但它不会释放对象锁，也就是说，只有在包含notify的synchronized代码块(被synchronized修饰过了)执行完后，等待的线程才会从wait调用中返回。这一点需要铭记 我们在使用wait时最难的是搞清楚wait到底等的是什么？，而notify通知的又是什么？ 我们需要知道，它们被不同的线程调用，并共亨相同的锁和条件等待队列（相同对象的synchronized代码块内），它们围绕一个共享的条件变量进行协作，这个条件变量是程序自己维护的，当条件不成立时，线程调用wait进入条件等待队列，另一个线程修改条件后调用notify,调用wait的线程被唤醒后需要重新检查条件变量。从多线程的角度看，它们围绕共享变量进行协作，从调用wait的线程角度看，它阻塞等待一个条件的成立。我们在设立多线程协作时，需要想清楚协作的++共享变量++和++条件++是什么，这是协作的核心。 线程的基本协作示例我们前面说了线程基本协作的场景，这里书上给出了对于这几种场景的代码示例： 生产者消费者模式 同时开始 等待结束 异步结果 集合点 生产者/消费者模式队列：1234567891011121314151617181920212223static class MyBlockingQueue&lt;E&gt; &#123; private Queue&lt;E&gt; queue = null; private int limit; public MyBlockingQueue(int limit) &#123; this.limit = limit; queue = new ArrayDeque&lt;&gt;(limit); &#125; public synchronized void put(E e) throws InterruptedException &#123; while(queue.size() == limit) &#123; wait(); &#125; queue.add(e); notifyAll(); &#125; public synchronized E take() throws InterruptedException &#123; while(queue.isEmpty()) &#123; wait(); &#125; E e = queue.poll(); notifyAll(); return e; &#125;&#125; 生产者：1234567891011121314151617181920static class Producer extends Thread &#123; MyBlockingQueue&lt;String&gt; queue; public Producer(MyBlockingQueue&lt;String&gt; queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; int num = 0; try &#123; while(true) &#123; String task = String.valueOf(num); queue.put(task); System.out.println(&quot;produce task &quot; + task); num++; Thread.sleep((int) (Math.random() * 100)); &#125; &#125; catch (InterruptedException e) &#123; &#125; &#125;&#125; 消费者：1234567891011121314151617static class Consumer extends Thread &#123; MyBlockingQueue&lt;String&gt; queue; public Consumer(MyBlockingQueue&lt;String&gt; queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; try &#123; while(true) &#123; String task = queue.take(); System.out.println(&quot;handle task &quot; + task); Thread.sleep((int)(Math.random()*100)); &#125; &#125; catch(InterruptedException e) &#123; &#125; &#125;&#125; 主程序：12345public static void main(String[] args) &#123; MyBlockingQueue&lt;String&gt; queue = new MyBlockingQueue&lt;&gt;(10); new Producer(queue).start(); new Consumer(queue).start();&#125; 在生产者消费者模式中，put等待的是队满而take等待的却是队空。但他们都会进入相同的对象的条件等待队列中。由于等待的条件不同，但两者的共享变量却都是该队列，所以此处不能使用notify，因为notify只能唤醒一个线程，而由于线程调度的机制。唤醒的如果是同类线程的话则起不到协调的作用，所以在共用同一个条件队列而等待的条件却相反时应该使用notifyAll。 Java提供了专门的阻塞队列，包括： 接口 BlockingQueue和BlockingDeque 基于数组的实现类 ArrayBlockingQueue 基于链表的实现类 LinkedBlockingQueue和LinkedBlockingDeque 基于堆的实现类 PriorityBlockingQueue 在实际场景中，应该优先使用这些实现类。 同时开始同时开始的按例好比运动员比赛，一个主线程(裁判)决定着各个子线程(运动员)何时开始。 协作对象fired：123456789101112static class FireFlag &#123; private volatile boolean fired = false; public synchronized void waitForFire() throws InterruptedException &#123; while(!fired) &#123; wait(); &#125; &#125; public synchronized void fire() &#123; this.fired = true; notifyAll(); &#125;&#125; 运动员：123456789101112131415static class Racer extends Thread &#123; FireFlag fireFlag; public Racer(FireFlag fireFlag) &#123; this.fireFlag = fireFlag; &#125; @Override public void run() &#123; try &#123; this.fireFlag.waitForFire(); System.out.println(&quot;start run &quot; + Thread.currentThread().getName()); &#125; catch (InterruptedException e) &#123; &#125; &#125;&#125; 裁判：1234567891011public static void main(String[] args) throws InterruptedException &#123; int num = 10; FireFlag fireFlag = new FireFlag(); Thread[] racers = new Thread[num]; for(int i = 0; i &lt; num; i++) &#123; racers[i] = new Racer(fireFlag); racers[i].start(); &#125; Thread.sleep(1000); fireFlag.fire();&#125; 等待结束Thread类的join方法的实现其实就是借助于wait方法。其主要代码：123while (isAlive()) &#123; wait(0);&#125; 该代码意义是：只要该等待线程活着就会一直等待，join的结束依赖与线程运行结束的时候Java系统调用notifyAll来通知该等待线程。 使用join有时比较麻烦需要等待各个子线程结束。这里书上给出的例子采用了另一种写法，主线程与子线程协作的是一个数，这个数表示未完成的线程的个数，初始值为子线程个数，主线程需要等待该值变为0，每个子线程结束后需要将该值减一，当为0时调用notifyAll。 协作对象MyLatch：1234567891011121314151617public class MyLatch &#123; private int count; public MyLatch(int count) &#123; this.count = count; &#125; public synchronized void await() throws InterruptedException &#123; while(count &gt; 0) &#123; wait(); &#125; &#125; public synchronized void countDown() &#123; count--; if(count &lt;= 0) &#123; notifyAll(); &#125; &#125;&#125; 子线程：1234567891011121314static class Worker extends Thread &#123; MyLatch latch; public Worker(MyLatch latch) &#123; this.latch = latch; &#125; @Override public void run() &#123; try &#123; //simulate working on task Thread.sleep((int) (Math.random() * 1000)); this.latch.countDown(); &#125; catch (InterruptedException e) &#123; &#125;&#125; 主线程：1234567891011public static void main(String[] args) throws InterruptedException &#123; int workerNum = 100; MyLatch latch = new MyLatch(workerNum); Worker[] workers = new Worker[workerNum]; for(int i = 0; i &lt; workerNum; i++) &#123; workers[i] = new Worker(latch); workers[i].start(); &#125; latch.await(); System.out.println(&quot;collect worker results&quot;);&#125; MyLatch也可以应用在“同时开始”的场景，初始值设为1。12345678910111213141516171819202122232425262728public class RacerWithLatchDemo &#123; static class Racer extends Thread &#123; MyLatch latch; public Racer(MyLatch latch) &#123; this.latch = latch; &#125; @Override public void run() &#123; try &#123; this.latch.await(); System.out.println(&quot;start run &quot; + Thread.currentThread().getName()); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; int num = 10; MyLatch latch = new MyLatch(1); Thread[] racers = new Thread[num]; for(int i = 0; i &lt; num; i++) &#123; racers[i] = new Racer(latch); racers[i].start(); &#125; Thread.sleep(1000); latch.countDown(); &#125;&#125; Java中提供了一个专门的同步类CountDownLatch，在实际开发中应该使用它。 异步结果在主从模式中，手工创建线程比较麻烦。一种常见的模式是异步调用，异步调用一般返回一个名为Future的对象，通过它可以获得最终的结果。在Java中表示子任务的接口是Callable。如下是书上例子： 子任务：Callable123public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; 异步调用的结果：Future123public interface MyFuture &lt;V&gt; &#123; V get() throws Exception ;&#125; 通过该接口的get方法返回真正的结果。如果结果还没有计算完成，get方法会阻寒直到计算完成，如果调用过程发生异常，则get方法抛出调用过程中的异常。 方便主线程调用子任务的类 MyExecutor1public &lt;V&gt; MyFuture&lt;V&gt; execute(final Callable&lt;V&gt; task) 通过该方法主线程就不需要在创建并管理子线程了。可以方便的获取到异步调用的结果。如下：1234567891011121314151617181920212223public static void main(String[] args) &#123; MyExecutor executor = new MyExecutor(); // 子任务 Callable&lt;Integer&gt; subTask = new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; //…执行异步任务 int millis = (int) (Math.random() * 1000); Thread.sleep(millis); return millis; &#125; &#125;; //异步调用子任务，返回一个MyFuture对象 MyFuture&lt;Integer&gt; future = executor.execute(subTask);//内部创了个子线程去执行 //…执行其他操作 try &#123; //获取异步调用的结果 Integer result = future.get(); System.out.println(result); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125;&#125; 所以重点是，MyExecutor类的execute方法是怎么实现的呢 ？它封装了创建子线程，同步获取结果的过程，它会创建一个执行子线程。 MyFuture类的execute具体实现：1234567891011121314151617181920212223public &lt;V&gt; MyFuture&lt;V&gt; execute(final Callable&lt;V&gt; task) &#123; final Object lock = new Object(); final ExecuteThread&lt;V&gt; thread = new ExecuteThread&lt;&gt;(task, lock); thread.start(); MyFuture&lt;V&gt; future = new MyFuture&lt;V&gt;() &#123; @Override public V get() throws Exception &#123; synchronized (lock) &#123; while(!thread.isDone()) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; &#125; &#125; if(thread.getException() != null) &#123; throw thread.getException(); &#125; return thread.getResult(); &#125; &#125; &#125;; return future;&#125; execute方法启动一个执行子线程，并返回携带执行结果的MyFuture对象。MyFuture的方法会阻塞等待知道子线程运行结束返回结果。 执行子线程 ExecuteThread123456789101112131415161718192021222324252627282930313233static class ExecuteThread&lt;V&gt; extends Thread &#123; private V result = null; private Exception exception = null; private boolean done = false; private Callable&lt;V&gt; task; private Object lock; public ExecuteThread(Callable&lt;V&gt; task, Object lock) &#123; this.task = task; this.lock = lock; &#125; @Override public void run() &#123; try &#123; result = task.call(); &#125; catch (Exception e) &#123; exception = e; &#125; finally &#123; synchronized (lock) &#123; done = true; lock.notifyAll(); &#125; &#125; &#125; public V getResult() &#123; return result; &#125; public boolean isDone() &#123; return done; &#125; public Exception getException() &#123; return exception; &#125;&#125; Java中也已经包含了一套完善的方案，有： 表示异步结果的接口Future和实现类FutureTask。 用于执行异步任务的接口Executor，以及有更多功能的子接口ExecutorService。 用于创建Executor和ExecutorService的工厂方法类Executors。 集合点和之前等待结束和同时开始案例相似。各线程分开行动，各自到大一个集合点，在集合点需要集齐所有线程，交换数据然后再进行下一步动作。协作的共享变量n，初始值为线程总数，当有一个线程到达集合点n减一。直到变为0即最后一个也到达，通过notifyAll来唤醒所有条件等待线程。 协作对象：AssemblePoint12345678910111213141516171819协作对象public class AssemblePoint &#123; private int n; public AssemblePoint(int n) &#123; this.n = n; &#125; public synchronized void await() throws InterruptedException &#123; if(n &gt; 0) &#123; n--; if(n == 0) &#123; notifyAll(); &#125; else &#123; while(n != 0) &#123; wait(); &#125; &#125; &#125; &#125;&#125; 主线程：AssemblePointDemo1234567891011121314151617181920212223242526272829public class AssemblePointDemo &#123; static class Tourist extends Thread &#123; AssemblePoint ap; public Tourist(AssemblePoint ap) &#123; this.ap = ap; &#125; @Override public void run() &#123; try &#123; //模拟先各自独立运行 Thread.sleep((int) (Math.random() * 1000)); //㼿㼿 ap.await(); System.out.println(&quot;arrived&quot;); //…㼿㼿㼿㼿㼿㼿㼿㼿㼿 &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; public static void main(String[] args) &#123; final int num = 10; Tourist[] threads = new Tourist[num]; AssemblePoint ap = new AssemblePoint(num); for(int i = 0; i &lt; num; i++) &#123; threads[i] = new Tourist(ap); threads[i].start(); &#125; &#125;&#125; Java中有一个专门的同步工具类CyclicBarrier可以替代该AssemblePoint类。 总结该节主要介绍了Java中线程间协作的基本机制wait/notify，协作关键要想淸楚协作的共享变贵和条件是什么。Java中有专门为协作而建的阻塞队列、同步工具类，以及Executors框架。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程的逻辑 -- 并发章 -- Synchronized]]></title>
    <url>%2Fjava-concurrentProgramming-readingNotes-15.2.html</url>
    <content type="text"><![CDATA[Synchronized共享内存有两个重要问题，一个是竞态条件，一个是内存可见性。其实一种解决方案则是Synchronized 原理我们首先来看一段synchronized修饰方法和代码块的代码：1234567891011121314public class Main &#123; //修饰方法 public synchronized void test1()&#123; &#125; public void test2()&#123; // 修饰代码块 synchronized (this)&#123; &#125; &#125;&#125; 来反编译看一下： 从上面可以看出，同步代码块是使用monitorenter和monitorexit指令实现的，同步方法（在这看不出来需要看JVM底层实现）依靠的是方法修饰符上的ACC_SYNCHRONIZED实现。 同步代码块：monitorenter指令插入到同步代码块的开始位置，monitorexit指令插入到同步代码块的结束位置，JVM需要保证每一个monitorenter都有一个monitorexit与之相对应。任何对象都有一个monitor与之相关联，当一个monitor被持有之后，他将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor所有权，即尝试获取对象的锁。synchronized底层是通过monitor对象，对象有自己的对象头，存储了很多信息，其中一个信息标示是被哪个线程持有。 同步方法：synchronized方法则会被翻译成普通的方法调用和返回指令如:invokevirtual、areturn指令，在VM字节码层面并没有任何特别的指令来实现被synchronized修饰的方法，而是在Class文件的方法表中将该方法的access_flags字段中的synchronized标志位置1，表示该方法是同步方法并使用调用该方法的对象或该方法所属的Class在JVM的内部对象表示Klass做为锁对象。(摘自：http://www.cnblogs.com/javaminer/p/3889023.html) 具体可参考： https://blog.csdn.net/chenssy/article/details/54883355 https://blog.csdn.net/u012465296/article/details/53022317 用法1. 实例方法123456789public class Counter &#123; private int count; public synchronized void incr()&#123; count ++; &#125; public synchronized int getCount() &#123; return count; &#125;&#125; Synchronized可以用来修饰实例方法，静态方法，(静态或实例)代码块。 多个线程可以同时执行一个Synchronized方法，只要他们访问的不是同一个实例对象即可。 Synchronized实际上保护的是当前实例对象，而不是它仅描述的那个方法。此时this对象有一个锁和一个等待队列，锁只能被一个线程持有， 其他试图获得同样锁的线程需要等待。当前线程不能获得锁的时候，它会加入等待队列，线程的状态会变为BLOCKED。 Thread有一个与其状态对应的枚举类。Thread.State枚举类：12345678public enum State &#123; NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED;&#125; 关于这些状态.我们简单解释下：1) NEW:没有调用start的线程状态为NEW。2) TERMINATED:线程运行结朿后状态为TERMINATED。3) RUNNABLE:调用start后线程在执行run方法且没有阻寒时状态为RUNNABLE,不过，RUNNABLE不代表CPU—定在执行该线程的代码，可能正在执行也可能在等待操作系统分配时间片，只是它没有在等待其他条件。 4) BLOCKED、WAITING、TIMED_WAmNG:都表示线程被阻塞了，在等待一些条件。其中BLOCKED表示当前线程在等待的是CPU的时间片而WAITING、TIMED_WAmNG则等待的是外部条件。Synchronized保护的是对象而非方法块，只要访问的是同一个对象的synchronized方法，即使是不同的方法块，也会被同步顺序访问。比如，对于Counter类中的两个同步实例方法get和incr，对同一个Counter对象，一个线程执行get，另一个执行incr,它们是不能同时执行的，会被synchronized同步顺序执行。 此外，需要说明的是，synchronized方法不能防止非synchronized方法被同时执行。比如，如果给Counler类增加一个非synchronized方法：123public void decr()&#123; count --;&#125; 则该方法可以和synchronized的incr方法同时执行，这通常会出现非期望的结果，所以，一般在保护变量时，需要在所有访问该变量的方法前加shsynchronizcd(不一定)。 2. 静态方法123456789public class StaticCounter &#123; private static int count = 0; public static synchronized void incr() &#123; count++; &#125; public static synchronized int getCount() &#123; return count; &#125;&#125; 对实例方法，synchronized保护的是当前实例对象this,对静态方法，保护的是类对象，这里是StaticCounter.class。实际上，每个对象都有一个锁和一个等待队列，Class类对象也不例外。 synchronized静态方法和synchronized实例方法保护的是不同的对象，不同的两个线程，可以一个执行synchronized静态方法，另一个执行synchronized实例方法。所以他们可以同时运行 3. 代码块123456789101112131415public class Counter &#123; private int count; public void incr()&#123; synchronized(this)&#123; count ++; &#125; &#125; public int getCount() &#123; synchronized(this)&#123; return count; &#125; &#125;&#125; synchronized括号里即保护的对象，对于实例方法而言则是this，{}是执行同步的代码。对于上例中的StaticCounter类，等价的代码则是：12345678910111213public class StaticCounter &#123; private static int count = 0; public static void incr() &#123; synchronized(StaticCounter.class)&#123; count++; &#125; &#125; public static int getCount() &#123; synchronized(StaticCounter.class)&#123; return count; &#125; &#125;&#125; synchronized同步的对象可以是任意对象，任意对象都有一个锁和等待队列，或者说，任何对象都可以作为锁对象。如下的类成员lock。所以在如下这种情况中，所有的线程中所跑的涉及域lock的方法都会在一个等待队列中排队执行。1234567891011121314public class Counter &#123; private int count; private Object lock = new Object(); public void incr()&#123; synchronized(lock)&#123; count ++; &#125; &#125; public int getCount() &#123; synchronized(lock)&#123; return count; &#125; &#125;&#125; 特性 可重入性 内存可见性 死锁 可重入性Synchronized是一种可重入锁。 可重入锁是通过记录锁的持有线程和持有数来实现的，当调用被synchronized保护的代码时，检查对象是否已被锁，如果是，再检查是否被当前线程锁定，如果是，增加持有数量，如果不是被当前线程锁定，才加入等待队列，当释放锁时，减少持有数量，当数量变为0时才释放整个锁。 内存可见性Synchronized除了可以保证原子性，同时还可以保证内存可见性。在释放锁时，所有的写入都会从寄存器或缓存(工作内存)写回内存，而获得锁后都会从内存中获得最新数据。 但如果只是为了保证内存可见性，使用synchronized关键字的成本则要高于volatile修饰符的使用。 如下代码：123456789public class Switcher &#123; private boolean on; public boolean isOn() &#123; return on; &#125; public void setOn(boolean on) &#123; this.on = on; &#125;&#125; 该代码在并发执行的时候不涉及非原子操作，仅修改变量on的状态，是一个原子操作。所以这里完全不必要用synchronized修饰符来附加在setOn方法上来锁住整个对象。它并不面临原子性问题，而是面临的内存可见性问题，只需要对on变量用volatile来修饰即可。123456789public class Switcher &#123; private volatile boolean on; public boolean isOn() &#123; return on; &#125; public void setOn(boolean on) &#123; this.on = on; &#125;&#125; 死锁经典示例：12345678910111213141516171819202122232425262728293031323334353637383940public class DeadLockDemo &#123; private static Object lockA = new Object(); private static Object lockB = new Object(); private static void startThreadA() &#123; Thread aThread = new Thread() &#123; @Override public void run() &#123; synchronized (lockA) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; synchronized (lockB) &#123; &#125; &#125; &#125; &#125;; aThread.start(); &#125; private static void startThreadB() &#123; Thread bThread = new Thread() &#123; @Override public void run() &#123; synchronized (lockB) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; &#125; synchronized (lockA) &#123; &#125; &#125; &#125; &#125;; bThread.start(); &#125; public static void main(String[] args) &#123; startThreadA(); startThreadB(); &#125;&#125; 运行后aThread和bThread陷入了相互等待。怎么解决呢？首先，座该尽量避免在持有一个锁的同时去中请另一个锁，如果确实需要多个锁，所有代码都砹该按照相同的顺序去申请锁。比如，对于上面的例子，可以约定都先申请lockA，再申请lockB，而不是像代码中那样分开申请。 不过，在复杂的项目代码中，这种约定可能难以做到。还有一种方法是显示锁接口Lock，它支持尝试获取锁（tryLock)和带时间限制的获取锁方法，使用这些方法可以在获取不到锁的时候释放已经持有的锁，然后再次尝试获取锁或干脆放弃，以避免死锁。如采还是出现了死锁，Java不会主动处理，不过借助一些工貝，我们可以发现运行中的死锁，比如，Java自带的jsiadc命令会报告发现的死锁。 同步容器类Collections中提供了一些方法，返回线程安全的同步容器。 它们是給所有容器方法都加上synchronized来实现线程安全的。 1234567891011121314151617181920static class SynchronizedCollection&lt;E&gt; implements Collection&lt;E&gt; &#123; final Collection&lt;E&gt; c; //Backing Collection final Object mutex; //Object on which to synchronize SynchronizedCollection(Collection&lt;E&gt; c) &#123; if(c==null) throw new NullPointerException(); this.c = c; mutex = this; &#125; public int size() &#123; synchronized (mutex) &#123;return c.size();&#125; &#125; public boolean add(E e) &#123; synchronized (mutex) &#123;return c.add(e);&#125; &#125; public boolean remove(Object o) &#123; synchronized (mutex) &#123;return c.remove(o);&#125; &#125; //…&#125; 这里的线程安全指的是容器对象，即当多个线程并发访问同一个容器对象时不需要额外的同步操作，也不会出现错误的结果。 加了synchronized之后所有操作都变成了原子操作，但并不意味着客户端在调用的时候就绝对安全了。以下情况还需注意： 复合操作，比如先检查后更新 伪同步 迭代 1. 复合操作1234567891011121314151617public class EnhancedMap &lt;K, V&gt; &#123; Map&lt;K, V&gt; map; public EnhancedMap(Map&lt;K,V&gt; map)&#123; this.map = Collections.synchronizedMap(map); &#125; public V putIfAbsent(K key, V value)&#123; V old = map.get(key); if(old!=null)&#123; return old; &#125; return map.put(key, value); &#125; public V put(K key, V value)&#123; return map.put(key, value); &#125; //…&#125; 代码中的putIfAbsent方法在多线程下显然是不安全的。如果多个线程都执行这一步则必然会出现竞态条件。 2. 伪同步1234567public synchronized V putIfAbsent(K key, V value)&#123; V old = map.get(key); if(old!=null)&#123; return old; &#125; return map.put(key, value);&#125; 如上代码即便加上synchronized关键字修饰也任然是不安全的。因为我们同步错了对象，putlfAbsent同步使用的是EnhancedMap对象，而其他方法(如代码中的put方法）使用的是Collections.synchronizedMap返回的对象map、两者是不同的对象。要解决这个问题，所有方法必须使用相同的锁，可以使用EnhancedMap的对象锁，也可以使用map对象锁。使用EnhancedMap对象作为锁，则Enhanced-Map中的所有方法都需耍加上synchronized。使用map作为锁，putlfAbsent方法可以改为：123456789public V putIfAbsent(K key, V value)&#123; synchronized(map)&#123; V old = map.get(key); if(old!=null)&#123; return old; &#125; return map.put(key, value); &#125;&#125; 3. 迭代对于同步容器虽然单个操作是安全的，但是迭代却不是。如下代码截取自Collections.SynchronizedList类。可以看到函数并不是同步实现的。1234567public ListIterator&lt;E&gt; listIterator() &#123; return list.listIterator(); // Must be manually synched by user&#125;public ListIterator&lt;E&gt; listIterator(int index) &#123; return list.listIterator(index); // Must be manually synched by user&#125; 我们通过两个线程来并发的修改和迭代该同步容器则会出现List迭代时规定的并发修改异常。123456789101112131415161718192021222324252627282930313233private static void startModifyThread(final List&lt;String&gt; list) &#123; Thread modifyThread = new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i = 0; i &lt; 100; i++) &#123; list.add(&quot;item &quot; + i); try &#123; Thread.sleep((int) (Math.random() * 10)); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; &#125;); modifyThread.start();&#125;private static void startIteratorThread(final List&lt;String&gt; list) &#123; Thread iteratorThread = new Thread(new Runnable() &#123; @Override public void run() &#123; while (true) &#123; for(String str : list) &#123; &#125; &#125; &#125; &#125;); iteratorThread.start();&#125;public static void main(String[] args) &#123; final List&lt;String&gt; list = Collections .synchronizedList(new ArrayList&lt;String&gt;()); startIteratorThread(list); startModifyThread(list);&#125; 运行结果：123Exception in thread &quot;Thread-0&quot; java.util.ConcurrentModificationException at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:859) at java.util.ArrayList$Itr.next(ArrayList.java:831) 我们知道对于遍历操作而言，如果迭代时容器发生了结构性变化。就会抛出该异常。很显然同步容器并没有解决这个问题，要想避免这个问题则需要在遍历的时候给整个容器对象加锁。 即谁无法保证线程安全，方法体中的代码块就锁谁。 12345678910111213private static void startIteratorThread(final List&lt;String&gt; list) &#123; Thread iteratorThread = new Thread(new Runnable() &#123; @Override public void run() &#123; while(true) &#123; synchronized(list)&#123; for(String str : list) &#123; &#125; &#125; &#125; &#125; &#125;);&#125; 4. 并发容器在使用synchronized的时候除了需要注意以上注意事项，同时同步容器的性能也是比较低的，当并发访问量比较大的时候性能比较差。但Java还为我们提供了很多专为并发设计的容器类。比如： CopyOnWriteArrayList ConcurrentHashMap ConcurrentLinkedQueue ConcurrentSkipListSet 这些容器类都是线程安全的，仍但都没有使用synchronized，没存迭代问题，直接支持一些复合操作，性能也搞得多。 释放锁的时机 当方法(代码块)执行完毕后会自动释放锁，不需要做任何的操作。 当一个线程执行的代码出现异常时，其所持有的锁会自动释放。 不会由于异常导致出现死锁现象。]]></content>
  </entry>
  <entry>
    <title><![CDATA[并发编程实战读书笔记]]></title>
    <url>%2Fjava-concurrent-shizhan.html</url>
    <content type="text"><![CDATA[前言从今天开始读并发编程实战， 这边文章仅简单记录自己学习时遇到的琐碎知识点 第一章 简介操作系统保证了系统可以运行多个程序，它为多个不同的进程分配各种资源，包括内存，文件句柄，以及安全证书等。如果需要，不同进程间还可以通过一些粗粒度的通信机制来交换数据，包括：套接字，信号处理器，共享内存，信号量及文件。 同一个程序中的多个线程也可以被同时调度到多个CPU上运行。 如果在程序中只有一个线程，那么它最多同时只能在一个处理器上运行。在有十个处理器的的系统上，单线程的程序只能使用1/10的CPU资源。另一方面多线程程序可以同时在多个处理器上工作，进而提高处理器的利用率来提升系统吞吐率。 使用多个线程还有助于在单处理器系统上获得更高的吞吐率。如果程序是单线程的，那么当程序等待某个同步 I/O 操作(CPU置空)完成时，处理器将处于空闲状态。而在多线程程序中，如果一个、线程在等待 I/O 操作完成，另一个线程可以继续运行，使程序能够在 I/O 阻塞期间继续运行。（这就好比在等待水烧开的同时看报纸，而不是等到水烧开之后再开始看报纸）。 非线程安全的数值序列生成器：12345678910@NotThreadSafepublic class UnsafeSequence &#123; private int value; /* 返回一个唯一的数值 */ public int getValue() &#123; return value++; &#125;&#125; 并发情况下程序可能的执行流程：A：线程A，B：线程B 由于JVM中存在指令重排序的可能，因此实际情况可能更糟。 在多线程的环境下，只要我们不使用成员变量(线程间共享数据),那么就不会出现线程安全的问题了。 活跃性问题：当某个操作无法继续执行下去时，就会发生活跃性问题。形式单线程中之一就是程序无意中造成的无限循环，多线程情况下的死锁问题。 性能问题：在多线程程序中，当线程调度器临时挂起活跃线程并转而运行另一个线程时，就会频繁地出现上下文切换操作，这种操作将带来极大的开销：保存和恢复执行上下文，丢失局部性，并且CPU时间将更多地花在线程调度而不是线程运行上。 当线程共享数据时，必须使用同步机制，而这些机制往往会抑制某些编译器优化，使内存缓存区(工作内存)中的数据无效，以及增加共享内存总线的同步流量。 第二章 线程安全性Java 中的主要同步机制是关键字 synchronized ，它提供了一种独占的加锁方式，但“同步”．这个术语还包括 volatile 类型的变量，显式锁（ ExPllcit Lock ）以及原子变量。 有时候，面向对象中的抽象和封装会降低程序的性能（尽管很少有开发人员相信），但在编写并发应用程序时，一种正确的编程方法就是：首先使代码正确运行，然后再提高代码的速度。 即便如此，最好也只是当性能测试结果和应用需求告诉你必须提高性能，以及测量结果表明这种优化在实际环境中确实能带来性能提升时，才进行优化。 需要明白的是，完全由线程安全类构成的程序并不一定就是线程安全的， 而在线程安全的类中也可以包含非线程安全的类。 一个类是无状态的意味着该类不包含任何属于本类的域(成员变量)，也不包含任何其他类中域的引用(其他类属性)。无状态对象一定是线程安全的。 竞态条件：当某个计算的正确性需要依赖多线程交替执行时。如下代码块： 避免：要避免竞态条件问题，就必须在某个线程修改该变量时，通过某种方式防止其他线程使用这个变量，从而确保其他线程只能在修改操作完成之前或之后读取和修改状态，而不是在修改状态的过程中。 延迟初始化示例：12345678910111213@NotThreadSafepublic class Singleton &#123; private Singleton singleton = null; public static Singleton getInstance() &#123; if (singleton == null) &#123;// 竞态条件 singleton = new Singleton(); &#125; return singleton; &#125;&#125; 为了确保线程安全性，“先检查后执行”（例如延迟初始化）和“读取一修改一写入” （例如递增运算）等操作必须是原子的。我们将“先检查后执行”以及“读取一修改一写入”等操作统称为复合操作：包含了一组必须以原子方式执行的操作以确保线程安全性。 改进写法：123456789101112131415161718192021@ThreadSafepublic class Singleton &#123; private static volatile Singleton singleton = null; /* 这里使用volatile修饰的目的是可以提升程序的性能， 对于没有进入if代码块的线程关于singleton变量的修改可以第一时间被通知到， 这样就不会有过多的线程由于没有拿到已被初始化的singleton了 ，而出的大量的涌入到同步代码块中去争锁的情况。*/ public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123;// 通过synchronized关键字来对代码块上锁 if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 延迟初始化示例中我们通过synchronized独占锁来保证了“先检查后执行”操作的原子性。 在没有synchronized关键字做出保证的情况下，只有volatile关键字修饰的变量，在不能保证运算操作的原子性问题上我们可以借助Java提供的concurrent包下的atomic包中的原子类来保证。 数据竞争：多线程情况下数据不同步导致带来的并发修改等问题，(volatile关键字做的事情就是在其修饰的变量保证不涉及非原子性的操作的基础上，来保证多线程间共享变量的同步的) 在一般实际开发过程中的多线程环境下，应尽可能的使用现有的线程安全对象(例如AtomicLong)来管理类的状态。即类中的成员属性应该尽可能的都由线程安全的对象来修饰，进而保证如果以后这类成员变量遇到修改操作等 可以直接拿来使用，扩展性更高。(当某个成员变量已经可以通过其他同步方式保证那么不建议这么做) 要保证多线程中状态的一致性，就需要在单个原子操作中更新所有相关的状态变量。 以关键字synchronized来修饰的方法就是一种横跨整个方法体的同步代码块，其中该同步代码块的锁就是方法调用所在的对象。静态的synchronized方法以 Class 对象作为锁。 synchronized关键字的锁是一种排它锁，通过其修饰的内容可以保证了多线程间的安全问题，但紧接着就会出现的是性能问题。 我们在书写同步代码块的时候，应该尽量将不影响共享状态且执行时间较长的操作从同步代码块中分离出去。 如果一种同步机制已经可以在安全上带来保证，那么应该杜绝多种同步机制的联合使用。比如对于一个并发计数操作，我们一个基本类型的int变量在同步代码块中已经保证了他的并发修改的安全性，你还要把这个int类型的变量用AtomicInteger来取代。那么无论从性能上还是安全上来考虑都是极不合理的。 要判断同步代码块的合理大小，个铃求必须得到满足）、需要在各种设计需求之间进行权衡，简单性和性能。有时候．包括安全性(这个需求必须得到满足)，简单性和性能。有时候，在简单性与性能之间会发生冲突，在二者之间通常能找到某种合理的平衡。当实现某个同步策略时，一定不要盲目的为了性能而牺牲简单性(这可能会破坏安全性)。 当使用锁时，你应该清楚代码块中实现的功能，以及在执行该代码块时是否需要很长的时间。无论是执行计算密集的操作，还是在执行某个可能阻塞的操作．如果持有锁的时间过长，那么都会带来活跃性或性能问题。当执行时间较长的计算或者可能无法快速完成的操作时（例如，网络I/O或控制台I/O），一定不要持有锁。 第三章 对象的共享第四章 对象的组合]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thread类源码剖析]]></title>
    <url>%2Fjava-thread.html</url>
    <content type="text"><![CDATA[Thread 类 常见Api剖析Thread类构造函数123456789101112131415public Thread() &#123; init(null, null, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;public Thread(Runnable target) &#123; init(null, target, &quot;Thread-&quot; + nextThreadNum(), 0);&#125;public Thread(Runnable target, String name) &#123; init(null, target, name, 0);&#125;public Thread(String name) &#123; init(null, null, name, 0);&#125; 虽然4个构造函数的函数签名不同，但是低层调用的init方法却是一致的。 12345678/** * Initializes a Thread with the current AccessControlContext. * @see #init(ThreadGroup,Runnable,String,long,AccessControlContext) */private void init(ThreadGroup g, Runnable target, String name, long stackSize) &#123; init(g, target, name, stackSize, null);&#125; 该初始化方法负责构造当前线程所在的线程组ThreadGroup，真实运行的线程对象target，线程名name，线程栈的大小stackSize，访问控制的上下文null。 getName12345678/** * Returns this thread&apos;s name. */private volatile String name; // 线程名，volatile修饰保证了并发修改情况下的可见性public final String getName() &#123; return name;&#125; setName123456789101112131415161718192021/* Java thread status for tools, * initialized to indicate thread &apos;not yet started&apos; */private volatile int threadStatus = 0;// 线程状态 初始为0，表示已被创建/** * Changes the name of this thread to be equal to the argument * &lt;code&gt;name&lt;/code&gt;. */public final synchronized void setName(String name) &#123; checkAccess();// 查看当前线程是否为null 以及是否具有修改权限 if (name == null) &#123; throw new NullPointerException(&quot;name cannot be null&quot;); &#125; this.name = name; if (threadStatus != 0) &#123; setNativeName(name); &#125;&#125; checkAccess该checkAccess方法可以确定当前正在运行的线程是否有权修改此线程。123456789101112131415161718192021/** * Determines if the currently running thread has permission to * modify this thread. */public final void checkAccess() &#123; SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkAccess(this); &#125;&#125;public void checkAccess(Thread t) &#123; if (t == null) &#123; throw new NullPointerException(&quot;thread can&apos;t be null&quot;); &#125; if (t.getThreadGroup() == rootGroup) &#123; checkPermission(SecurityConstants.MODIFY_THREAD_PERMISSION); &#125; else &#123; // just return &#125;&#125; 守护线程守护线程是为其他线程服务的 垃圾回收线程就是守护线程 守护线程有一个特点： 当别的用户线程执行完了，虚拟机就会退出，守护线程也就会被停止掉了。 也就是说：守护线程作为一个服务线程，没有服务对象就没有必要继续运行了。 使用线程的时候要注意的地方 在线程启动前设置为守护线程，方法是setDaemon(boolean on) 使用守护线程不要访问共享资源(数据库、文件等)，因为它可能会在任何时候就挂掉了。 守护线程中产生的新线程也是守护线程 setDaemon123456789101112/** * Marks this thread as either a &#123;@linkplain #isDaemon daemon&#125; thread * or a user thread. The Java Virtual Machine exits when the only * threads running are all daemon threads. */public final void setDaemon(boolean on) &#123; checkAccess(); if (isAlive()) &#123;// 如果当前线程活着 throw new IllegalThreadStateException(); &#125; daemon = on;&#125; 通过注释可以看出，当运行的唯一线程也为守护线程的时候JVM退出。 通过代码中if语句的判断也可以看出，我们需要在线程启动之前即调用start函数之前设置其是否为守护线程。否则会跑出异常 优先级线程线程优先级高仅仅表示线程获取的CPU时间片的几率高，但这不是一个确定的因素！ 线程的优先级是高度依赖于操作系统的，Windows和Linux就有所区别(Linux下优先级可能就被忽略了) 1234567891011121314/** * The minimum priority that a thread can have. */public final static int MIN_PRIORITY = 1;/** * The default priority that is assigned to a thread. */public final static int NORM_PRIORITY = 5;/** * The maximum priority that a thread can have. */public final static int MAX_PRIORITY = 10; setPriority123456789101112131415161718192021222324/** * Changes the priority of this thread. * &lt;p&gt; * ··· * ··· * Otherwise, the priority of this thread is set to the smaller of * the specified &lt;code&gt;newPriority&lt;/code&gt; and the maximum permitted * priority of the thread&apos;s thread group. */public final void setPriority(int newPriority) &#123; ThreadGroup g; checkAccess(); if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) &#123; throw new IllegalArgumentException(); &#125; if((g = getThreadGroup()) != null) &#123; if (newPriority &gt; g.getMaxPriority()) &#123;// newProiority控制在当前线程组的最大值中。 newPriority = g.getMaxPriority(); &#125; setPriority0(priority = newPriority); &#125;&#125;private native void setPriority0(int newPriority); 头注释也交代的很清楚，如果该传入的参数newPriority大于当前线程所在线程组的最大优先值得话就让该newPriority等于线程组的最大优先值。 线程生命周期线程有3个基本状态：执行、就绪、阻塞 Thread上很多的方法都是用来切换线程的状态的，这一部分是重点！ 其实上面这个图是不够完整的，省略掉了一些东西。后面在讲解的线程状态的时候我会重新画一个。 sleep1234567/** * Causes the currently executing thread to sleep (temporarily cease * execution) for the specified number of milliseconds, subject to * the precision and accuracy of system timers and schedulers. The thread * does not lose ownership of any monitors. */public static native void sleep(long millis) throws InterruptedException; 如头注释所说在指定的毫秒数内让当前正在执行的线程休眠（阻塞状态）。且该线程不丢失任何监视器的所属权。 需要注意的是，等时间到了，进入的是就绪状态而并非是运行状态。 如图所示： yield123456/** * A hint to the scheduler that the current thread is willing to yield * its current use of a processor. The scheduler is free to ignore this * hint */public static native void yield(); 如头注释所述yield方法会向调度程序提示当前线程愿意让出正在使用的CPU，但是这个调度程序可以自由的忽略这个提示。言外之意当前线程调用yield方法会先让别的线程执行，但是不不确保真正的让出了CPU，最终还是要看调度器是什么行为。该方法很少被使用，因为他并不是一个确定的行为。 我有空，可以的话(CPU决定)，让你们先执行 此时刚才的图就能补充成这样： join调用join方法，会等待该线程执行完毕后(死亡)才执行别的线程。1234567891011121314151617181920212223242526272829303132333435363738394041/** * Waits for this thread to die. */public final void join() throws InterruptedException &#123; join(0);&#125;/** * Waits at most &#123;@code millis&#125; milliseconds for this thread to * die. A timeout of &#123;@code 0&#125; means to wait forever. * * &lt;p&gt; This implementation uses a loop of &#123;@code this.wait&#125; calls * conditioned on &#123;@code this.isAlive&#125;. As a thread terminates the * &#123;@code this.notifyAll&#125; method is invoked. It is recommended that * applications not use &#123;@code wait&#125;, &#123;@code notify&#125;, or * &#123;@code notifyAll&#125; on &#123;@code Thread&#125; instances. */public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis();// 记录当前系统时间 毫秒单位 long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(&quot;timeout value is negative&quot;); &#125; if (millis == 0) &#123; while (isAlive()) &#123;// millis == 0时，在当前线程活动状态下无线等待 wait(0); &#125; &#125; else &#123; while (isAlive()) &#123;// millis非0有限定时间 一段时间内该线程没有死亡就不等了 long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125; join(long millis)方法头注释所述： 等待该线程终止的时间最长为millis毫秒。如果millis为0意味着要一直等下去。 依赖isAlive()判断条件判断当前线程所处的状态，如果为活动状态那么循环调用wait方法直到其死亡。 当线程终止时，调用notifyAll方法来唤醒。建议应用程序不要在Thread实例上使用wait，notify或notifyAll方法(像join方法所示类中直接调用)。 join 方法参考资料 https://www.zhihu.com/question/27485990/answer/36824828 waitwait方法是在Object上定义的，它是native本地方法。函数意图：在其他线程调用此对象的 notify() 方法或 notifyAll() 方法前，导致当前线程等待。1public final native void wait(long timeout) throws InterruptedException; wait方法实际上它也是计时等待(如果带时间参数) 的一种！，于是我们的图就可以补充为： 等待处，即我们调用join方法来使当前线程在一段时间内等待其死亡，如果死亡了那么他就结束了。如果没有那就进入就绪态等待获取执行权继续执行。 interrupt线程中断在之前的版本有stop方法，但是被设置过时了。现在已经没有强制线程终止的方法了！ 由于stop方法可以让一个线程A终止掉另一个线程B 被终止的线程B会立即释放锁，这可能会让对象处于不一致的状态。 线程A也不知道线程B什么时候能够被终止掉， 如果线程B还处于运行计算阶段，线程A调用stop方法将线程B终止，那么进度就丢失了。 总而言之，Stop方法看起来设计的就很不合理，不安全而且太暴力，所以被设置过时了。 在终止线程上我们一般使用的是interrupt方法来请求终止线程。 要注意的是：interrupt不会真正停止一个线程，它仅仅是给这个线程发了一个信号告诉它，它应该要结束了(明白这一点非常重要！) 也就是说：Java设计者实际上是想线程自己来终止，通过上面的信号，就可以判断处理什么业务了。 具体到底中断还是继续运行，应该由被通知的线程自己处理 也就是我们不会杀死当前线程，只是给它标记了一个标志位告诉他他该中断了。但是具体是否要中断由它自己。 示例代码如下：12345678910Thread t1 = new Thread( new Runnable()&#123; public void run()&#123; // 若未发生中断，就正常执行任务 while(!Thread.currentThread.isInterrupted())&#123; // 正常任务代码…… &#125; // 中断的处理代码…… doSomething(); &#125;&#125; ).start(); 再次说明：调用interrupt()并不是要真正终止掉当前线程，仅仅是设置了一个中断标志。这个中断标志可以给我们用来判断什么时候该干什么活！什么时候中断由我们自己来决定，这样就可以安全地终止线程了！ 来看一下源码是如何叙述的： 只有当前线程自己可以调用interrupt中断方法。否则会抛出SecurityException。 如果当前线程在调用Object的wait()，wait(long)或wait(long, int)方法，或者该类的 join(),、join(long),join(long, int),sleep(long)或 sleep(long, int)方法时被调用interrupt方法而中断了的话。由于那些方法本身已经使线程中断，所以interrupt方法在这里所做的功能就是解除线程中断的左右。所以该线程的中断状态将被解除，JVM会将线程的中断标志重新设置为false(interrupt方法有这个功能)，并且还将收到一个 InterruptedException。这些调用时会抛出InterruptedException的方法是支持线程中断的方法(就是在监视线程的中断状态，一旦线程的中断状态被置为“中断状态”，就会抛出中断异常)。 被阻塞的类调用中断状态是没有意义的。 1234567891011121314public void interrupt() &#123; if (this != Thread.currentThread())// 判断是否是当前线程本身调用的 checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123;// 判断线程是否被阻塞了 interrupt0(); // interrupt status将清除 b.interrupt(this); // 打断线程并抛出InterruptedException return; &#125; &#125; interrupt0();// 如果没有被阻塞那么直接修改线程中断标记位即可。&#125; 再来看看刚才说抛出的异常是什么东东吧： 所以说：interrupt方法压根是不会对线程的状态造成影响的，它仅仅设置一个标志位罢了 interrupt线程中断还有另外两个方法(检查该线程是否被中断)： 静态方法interrupted()–&gt;会清除中断标志位 实例方法isInterrupted()–&gt;不会清除中断标志位 interrupted() 测试当前线程是否已经中断。如果已经中断那么调用该方法会清除线程的中断标志位，如果没有中断则返回false。函数功能相当于解除线程中断标志的功能。123public static boolean interrupted() &#123; return currentThread().isInterrupted(true);&#125; isInterrupted 测试线程是否已经中断。线程的中断状态不受该方法的影响。123public boolean isInterrupted() &#123; return isInterrupted(false);&#125; 上面还提到了，如果阻塞线程调用了interrupt()方法，那么会抛出异常，设置标志位为false，同时该线程会退出阻塞的。我们来测试一波： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Main &#123; /** * @param args */ public static void main(String[] args) &#123; Main main = new Main(); // 创建线程并启动 Thread t = new Thread(main.runnable); System.out.println(&quot;This is main &quot;); t.start(); try &#123; // 在 main线程睡个3秒钟 Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;In main&quot;); e.printStackTrace(); &#125; // 设置中断 t.interrupt(); &#125; Runnable runnable = () -&gt; &#123; int i = 0; try &#123; while (i &lt; 1000) &#123; // 睡个半秒钟我们再执行 Thread.sleep(500); System.out.println(i++); &#125; &#125; catch (InterruptedException e) &#123; // 判断该阻塞线程是否还在 System.out.println(Thread.currentThread().isAlive()); // 判断该线程的中断标志位状态 System.out.println(Thread.currentThread().isInterrupted()); System.out.println(&quot;In Runnable&quot;); e.printStackTrace(); &#125; &#125;;&#125; 结果： 接下来我们分析它的执行流程是怎么样的： 其实中心思想也就是我们新开的线程任在sleep的时候main线程中调用了t.interrupt方法让新线程中断。但是我们前面说过如下异常： 我们新线程正在调用sleep或者wait方法的时候会短暂的让该线程处于阻塞状态，阻塞状态下让该线程中断则是不合理的。那么就会设置其中断位为false并且跑出异常。 1234567891011121314public void interrupt() &#123; if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); return; &#125; &#125; interrupt0();&#125; 再次结合源码的处理逻辑来思考。 interrupt 方法参考资料 www.cnblogs.com/w-wfy/p/641… www.cnblogs.com/carmanlonel… www.zhihu.com/question/41… www.zhihu.com/question/41…]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[thymeleaf渲染视图失败]]></title>
    <url>%2FtemplateEngine-thymeleaf.html</url>
    <content type="text"><![CDATA[前言在最近做课设的时候，由于前台视图需要用到模板引擎来进行渲染，所以选用了thymeleaf这个模板引擎。但是在解析视图的时候却报了如下错误: 12345678910org.thymeleaf.exceptions.TemplateProcessingException: Could not parse as expression: &quot;&#123;checkbox: true, fixed: true&#125;, &#123;field: &apos;originalFileName&apos;, title: &apos;文件名&apos;, width: 400, sort: true&#125;, &#123;field: &apos;fileType&apos;, title: &apos;文件类型&apos;, width: 100&#125;, &#123;field: &apos;fileSize&apos;, title: &apos;文件大小&apos;, width: 110, sort: true&#125;, &#123;field: &apos;createTime&apos;, title: &apos;上传时间&apos;, width: 170, sort: true&#125;, &#123;field: &apos;dpStatus&apos;, title: &apos;数据处理状态&apos;, width: 122, templet: &apos;#statusTpl&apos;, sort: true&#125;, &#123;field: &apos;updateTime&apos;, title: &apos;数据处理完成时间&apos;, width: 170, templet: &apos;#updateTimeTpl&apos;, sort: true&#125;, &#123;fixed: &apos;right&apos;, title: &apos;操作&apos;, align: &apos;center&apos;, width: 300, toolbar: &apos;#operating&apos;&#125;&quot; (template: &quot;textManagement&quot; - line 125, col 22) 即意为无法解析。这是因为[[…]]之间的表达式在thymeleaf被认为是内联表达式,所以渲染错误。 我们需要把其中所有的[[ ]]都改成如下这种写法:1234567[ [ ]] 但由于我所用的视图文件是框架自动生成的，每个有2万+的代码，所以出现这种异常的地方也是数不胜数。后来我果断采取了另一种解决方式，换了另一种模板引擎。采用了Freemaker 解决解决方式也很简单，只需要pom文件把thymeleaf的依赖改成freemaker的依赖即可。 12345678910&lt;!--&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;--&gt;&lt;!-- 由于 thymeleaf 语法中[[…]]是它的内联表达式,不支持 echarts 生成的模板中的[[]]排版，所以会渲染错误，所以弃用 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;&lt;/dependency&gt; 参考：thymeleaf+layui渲染错误]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>模板引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 对resources-templates目录下的View视图文件访问404问题]]></title>
    <url>%2Fspringboot-thymeleaf-404.html</url>
    <content type="text"><![CDATA[前言在做课设的时候Controller层原本要映射resources目录下的templates目录下html页面。但是不知道什么原因总是出现404的情况。无论访问任何templates下的视图都会出现这种情况。即静态资源无法映射，这让自己有点儿不解，对于SpringBoot而言，resources目录不是它默认的视图资源映射路径吗。应该是不走DispatcherServlet进行分发的啊，它是Vip通道啊，可为什么会出现这种情况呢？ 原因思考之后只有一种猜想有可能，默认映射肯定出问题了。说明SpringBoot的默认的静态资源的访问规则没有起作用。但是为什么会出现这种问题呢，网上查阅后说是启用了@EnableWebMvc这个注解。这个注解意思是你想完全地进行web配置，那么Spring就会忽略默认的配置信息，去寻找相应的你的设置文件。如果你没有设置，就会出现上面这个问题了。 可是我非常明确的是我并没有启用它，但不知道为什么还是莫名其妙的出现了这个问题。所以我就尝试着根据这个问题来进行解决它。只要配置我们默认的资源映射路径即可 解决由于原本的WebMvcConfigurerAdapter在Spring最新版本已经过时了。所以我们应该选用WebMvcConfigurationSupport 123456789@Configurationpublic class WebConfiguration extends WebMvcConfigurationSupport &#123; @Override public void addResourceHandlers(ResourceHandlerRegistry registry)&#123; registry.addResourceHandler("/**") .addResourceLocations("classpath:/templates/"); &#125;&#125; 就这样问题就解决了。 参考：SpringBoot添加对静态文件css/html/jpg等的直接访问的支持 扩展在找解决办法的时候在SegmentFault上看到的别人遇到的问题，虽然和我遇到的问题情况一样，但是问题却是不同的。但这个问题看上去也很难处理，所以这里简单记录一下，以防以后自己用到。 它也是正常配置，没有启用@EnableWebMvc这个注解。所以也没有自己配置@Configuration中静态资源的路径。而是jar包的问题，他清除了maven 的m2目录，然后打开项目让maven重新下载之后就解决了。 参考：Spring Boot项目访问template模板文件页面返回404]]></content>
      <categories>
        <category>框架</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[net--error]]></title>
    <url>%2Fnet-error.html</url>
    <content type="text"><![CDATA[前言在做课设的时候自己找了几个不错的html想做视图，但是奈何映射的时候一直没有效果。后来网上查阅资料说是视图找不到依赖的资源文件所导致的。如下 解决后来才发现自己确实资源文件的请求路径错了。 比如navigat.ftl视图需要引入static目录下的style.css文件。 我之前的写法： 1&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;../static/css/style.css&quot;/&gt; 但是却忘记了对于SpringBoot而言static目录也是它默认的静态资源映射路径。所以相当于templates和static目录下的资源文件是在同一个文件目录下的。所以其实我们就不需要再在目录间切来切去的了 改正后的写法: 1&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;css/style.css&quot;/&gt; 就这样问题解决啦。]]></content>
      <categories>
        <category>前台</category>
      </categories>
      <tags>
        <tag>前台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的static关键字解析]]></title>
    <url>%2Fjava-keyword-static.html</url>
    <content type="text"><![CDATA[static关键字是很多朋友在编写代码和阅读代码时碰到的比较难以理解的一个关键字，也是各大公司的面试官喜欢在面试时问到的知识点之一。下面就先讲述一下static关键字的用法和平常容易误解的地方，最后列举了一些面试笔试中常见的关于static的考题。 转载自：海子：Java中的static关键字解析 一、static关键字的用途 在《Java编程思想》P86页有这样一段话： “static方法就是没有this的方法。在static方法内部不能调用非静态方法，反过来是可以的。而且可以在没有创建任何对象的前提下，仅仅通过类本身来调用static方法。这实际上正是static方法的主要用途。” 这段话虽然只是说明了static方法的特殊之处，但是可以看出static关键字的基本作用，简而言之，一句话来描述就是： 方便在没有创建对象的情况下来进行调用（方法/变量）。 很显然，被static关键字修饰的方法或者变量不需要依赖于对象来进行访问，只要类被加载了，就可以通过类名去进行访问。 static可以用来修饰类的成员方法、类的成员变量，另外可以编写static代码块来优化程序性能。 static方法 static方法一般称作静态方法，由于静态方法不依赖于任何对象就可以进行访问，因此对于静态方法来说，是没有this的，因为它不依附于任何对象，既然都没有对象，就谈不上this了。并且由于这个特性，在静态方法中不能访问类的非静态成员变量和非静态成员方法，因为非静态成员方法/变量都是必须依赖具体的对象才能够被调用。 但是要注意的是，虽然在静态方法中不能访问非静态成员方法和非静态成员变量，但是在非静态成员方法中是可以访问静态成员方法/变量的。 举个简单的例子： 在上面的代码中，由于print2方法是独立于对象存在的，可以直接用过类名调用。假如说可以在静态方法中访问非静态方法/变量的话，那么如果在main方法中有下面一条语句： MyObject.print2(); 此时对象都没有，str2根本就不存在，所以就会产生矛盾了。同样对于方法也是一样，由于你无法预知在print1方法中是否访问了非静态成员变量，所以也禁止在静态成员方法中访问非静态成员方法。 而对于非静态成员方法，它访问静态成员方法/变量显然是毫无限制的。 因此，如果说想在不创建对象的情况下调用某个方法，就可以将这个方法设置为static。我们最常见的static方法就是main方法，至于为什么main方法必须是static的，现在就很清楚了。因为程序在执行main方法的时候没有创建任何对象，因此只有通过类名来访问。 另外记住，关于构造器是否是static方法可参考：http://blog.csdn.net/qq_17864929/article/details/48006835 static变量 static变量也称作静态变量，静态变量和非静态变量的区别是：静态变量被所有的对象所共享，在内存中只有一个副本，它当且仅当在类初次加载时会被初始化。而非静态变量是对象所拥有的，在创建对象的时候被初始化，存在多个副本，各个对象拥有的副本互不影响。 static成员变量的初始化顺序按照定义的顺序进行初始化。 static代码块static关键字还有一个比较关键的作用就是 用来形成静态代码块以优化程序性能。 static块可以置于类中的任何地方，类中可以有多个static块。在类初次被加载的时候，会按照static块的顺序来执行每个static块，并且只会执行一次。 为什么说static块可以用来优化程序性能，是因为它的特性:只会在类加载的时候执行一次。下面看个例子: 12345678910111213class Person&#123; private Date birthDate; public Person(Date birthDate) &#123; this.birthDate = birthDate; &#125; boolean isBornBoomer() &#123; Date startDate = Date.valueOf(&quot;1946&quot;); Date endDate = Date.valueOf(&quot;1964&quot;); return birthDate.compareTo(startDate)&gt;=0 &amp;&amp; birthDate.compareTo(endDate) &lt; 0; &#125;&#125; isBornBoomer是用来这个人是否是1946-1964年出生的，而每次isBornBoomer被调用的时候，都会生成startDate和birthDate两个对象，造成了空间浪费，如果改成这样效率会更好： 12345678910111213141516class Person&#123; private Date birthDate; private static Date startDate,endDate; static&#123; startDate = Date.valueOf(&quot;1946&quot;); endDate = Date.valueOf(&quot;1964&quot;); &#125; public Person(Date birthDate) &#123; this.birthDate = birthDate; &#125; boolean isBornBoomer() &#123; return birthDate.compareTo(startDate)&gt;=0 &amp;&amp; birthDate.compareTo(endDate) &lt; 0; &#125;&#125; 因此，很多时候会将一些只需要进行一次的初始化操作都放在static代码块中进行。 二、static关键字的误区static关键字会改变类中成员的访问权限吗？ 有些初学的朋友会将java中的static与C/C++中的static关键字的功能混淆了。在这里只需要记住一点：与C/C++中的static不同，Java中的static关键字不会影响到变量或者方法的作用域。在Java中能够影响到访问权限的只有private、public、protected（包括包访问权限）这几个关键字。看下面的例子就明白了： 提示错误”Person.age 不可视”，这说明static关键字并不会改变变量和方法的访问权限。 能通过this访问静态成员变量吗？ 虽然对于静态方法来说没有this，那么在非静态方法中能够通过this访问静态成员变量吗？先看下面的一个例子，这段代码输出的结果是什么？123456789101112public class Main &#123; static int value = 33; public static void main(String[] args) throws Exception&#123; new Main().printValue(); &#125; private void printValue()&#123; int value = 3; System.out.println(this.value); &#125;&#125; 这里面主要考察队this和static的理解。this代表什么？this代表当前对象，那么通过new Main()来调用printValue的话，当前对象就是通过new Main()生成的对象。而static变量是被对象所享有的，因此在printValue中的this.value的值毫无疑问是33。在printValue方法内部的value是局部变量，根本不可能与this关联，所以输出结果是33。在这里永远要记住一点：静态成员变量虽然独立于对象，但是不代表不可以通过对象去访问，所有的静态方法和静态变量都可以通过对象访问（只要访问权限足够）。 static能作用于局部变量么？ 在C/C++中static是可以作用域局部变量的，但是在Java中切记：static是不允许用来修饰局部变量。，这是Java语法的规定。 具体原因可以参考这篇博文的讨论：Java static关键字为什么不能应用于局部变量？ 三、常见的笔试面试题 下面列举一些面试笔试中经常遇到的关于static关键字的题目，仅供参考，如有补充欢迎下方留言。 1.下面这段代码的输出结果是什么？ 12345678910111213141516171819202122232425public class Test extends Base&#123; static&#123; System.out.println(&quot;test static&quot;); &#125; public Test()&#123; System.out.println(&quot;test constructor&quot;); &#125; public static void main(String[] args) &#123; new Test(); &#125;&#125; class Base&#123; static&#123; System.out.println(&quot;base static&quot;); &#125; public Base()&#123; System.out.println(&quot;base constructor&quot;); &#125;&#125; 至于为什么是这个结果，我们先不讨论，先来想一下这段代码具体的执行过程，在执行开始，先要寻找到main方法，因为main方法是程序的入口，但是在执行main方法之前，必须先加载Test类(加载Test类是执行Main方法的前驱事件，必须先把其所在类进行加载 )， 而在加载Test类的时候发现Test类继承自Base类，因此会转去先加载Base类，在加载Base类的时候，发现有static块，便执行了static块。在Base类加载完成之后，便继续加载Test类，然后发现Test类中也有static块，便执行static块。在加载完所需的类之后，便开始执行main方法。在main方法中执行new Test()的时候会先调用父类的构造器，然后再调用自身的构造器。因此，便出现了上面的输出结果。 2.这段代码的输出结果是什么？1234567891011121314151617181920212223242526272829303132333435public class Test &#123; Person person = new Person(&quot;Test&quot;); static&#123; System.out.println(&quot;test static&quot;); &#125; public Test() &#123; System.out.println(&quot;test constructor&quot;); &#125; public static void main(String[] args) &#123; new MyClass(); &#125;&#125; class Person&#123; static&#123; System.out.println(&quot;person static&quot;); &#125; public Person(String str) &#123; System.out.println(&quot;person &quot;+str); &#125;&#125; class MyClass extends Test &#123; Person person = new Person(&quot;MyClass&quot;); static&#123; System.out.println(&quot;myclass static&quot;); &#125; public MyClass() &#123; System.out.println(&quot;myclass constructor&quot;); &#125;&#125; 类似地，我们还是来想一下这段代码的具体执行过程。首先加载Test类，因此会执行Test类中的static块。接着执行new MyClass()，而MyClass类还没有被加载，因此需要加载MyClass类。在加载MyClass类的时候，发现MyClass类继承自Test类，但是由于Test类已经被加载了，所以只需要加载MyClass类，那么就会执行MyClass类的中的static块。在加载完之后，就通过构造器来生成对象。而在生成对象的时候，必须先初始化父类的成员变量，因此会执行Test中的Person person = new Person()， 而Person类还没有被加载过，因此会先加载Person类并执行Person类中的static块，接着执行父类的构造器，完成了父类的初始化，然后就来初始化自身了，因此会接着执行MyClass中的Person person = new Person()，最后执行MyClass的构造器。 3.这段代码的输出结果是什么？ 12345678910111213public class Test &#123; static&#123; System.out.println(&quot;test static 1&quot;); &#125; public static void main(String[] args) &#123; &#125; static&#123; System.out.println(&quot;test static 2&quot;); &#125;&#125; 虽然在main方法中没有任何语句，但是还是会输出，原因上面已经讲述过了。另外，static块可以出现类中的任何地方（只要不是方法内部，记住，任何方法内部都不行），并且执行是按照static块的顺序执行的。 参考资料： http://lavasoft.blog.51cto.com/62575/18771/ http://www.51cto.com/specbook/24/35011.htm http://blog.csdn.net/zhu_apollo/article/details/1888219 http://blog.sina.com.cn/s/blog_70b845780100n9zz.html http://hi.baidu.com/yuiezt/item/b71ff5fbfe9c385cc8f3370d http://bbs.csdn.net/topics/330251070 http://yezixingchen.iteye.com/blog/1597186 《Java编程思想》]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程简单了解一下]]></title>
    <url>%2Fmulti-threading.html</url>
    <content type="text"><![CDATA[参考自：Fysddsw_lc：java 多线程 进程，线程进程： 进程是程序或者任务的执行过程，进程是系统进行资源分配和调度的独立单位。 每一个进程都有它自己的内存空间和系统资源。他是内存和线程的载体。 每个进程在执行的时候都会被分配内存 其中的线程就比如QQ在聊天的线程和接受文件的线程等，处理同一个进程(程序)不同任务的执行。 进程已经是可以进行资源分配和调度了，为什么还要线程呢？ 多任务处理被所有的现代操作系统所支持。然而，多任务处理有两种截然不同的类型：基于进程的和基于线程的。 基于进程的多任务处理是更熟悉的形式。进程（process）本质上是一个执行的程序。因此基于进程的多任务处理的特点是允许你的计算机同时运行两个或更多的程序。 比如，基于进程的多任务处理是你在编辑文本的时候可以同时运行Java编译器。 为使程序能并发执行，系统必须进行以下的一系列操作： 创建进程，系统在创建一个进程时，必须为它分配其所必需的、除处理机以外的所有资源，如内存空间、I/O设备，以及建立相应的PCB； 撤消进程，系统在撤消进程时，又必须先对其所占有的资源执行回收操作，然后再撤消PCB； 进程切换，对进程进行上下文切换时，需要保留当前进程的CPU环境，设置新选中进程的CPU环境，因而须花费不少的处理机时间。 如图所示： 可以看到进程实现多处理机环境下的进程调度，分派，切换时，都需要花费较大的时间和空间开销 而在基于线程（thread-based）的多任务处理环境中，线程是最小的执行单位。这意味着一个程序可以同时执行两个或者多个任务的功能。 比如，一个文本编辑器可以在打印的同时格式化文本。 而线程本身的数据通常只有寄存器数据，以及一个程序执行时使用的堆栈，所以线程的切换负担比进程切换的负担要小。引入线程主要是为了提高系统的执行效率，减少处理机的空转时间和调度切换的时间，以及便于系统管理。 使OS具有更好的并发性 简单来说：进程实现多处理非常耗费CPU的资源，而我们引入线程是作为调度和分派的基本单位（取代进程的部分基本功能【调度】）。 线程： 线程是系统中最小的执行单元，进程的一个实体，是CPU调度和分派的基本单位。同样的进程中可以有多个线程，而线程共享进程的资源。多线程编程的目的，就是“最大限度地利用cpu资源” 线程交互方式： 互斥：通常表现在多个线程竞争同一资源，所以也就面临着线程等待的问题 同步：同步就是协同步调，按预定的先后次序进行运行。如进程、线程同步，可理解为进程或线程A和B一块配合，A执行到一定程度时要依靠B的某个结果，于是停下来，示意B运行；B依言执行，再将结果给A；A再继续操作。 线程 vs 进程 进程作为资源分配的基本单位 线程作为资源调度的基本单位，是程序的执行单元，执行路径(单线程：一条执行路径，多线程：多条执行路径)。是程序使用CPU的最基本单位。 并发，并行并行： 并行性是指同一时刻内发生两个或多个事件。 并行是在不同实体上的多个事件 并发： 并发性是指同一时间间隔内发生两个或多个事件。 并发是在同一实体上的多个事件 由此可见：并行是针对进程的，并发是针对线程的。 线程的实现在Java中通过run方法为线程指明要完成的任务，有两种技术来为线程提供run方法： 继承Thread类并重写它的run方法。之后创建这个子类的对象并调用start()方法。 通过定义实现Runnable接口的实现类进而实现run方法。这个类的对象在创建Thread对象的时候会被作为参数而传入，然后调用Thread对象的start()方法。 两种方法都需要执行线程Thread的start()方法为线程分配必须的系统资源，调度线程运行并执行线程的run（）方法。 需要注意的是： start（）方法是启动线程的唯一的方法。start()方法首先为线程的执行准备好系统资源，然后再去调用它的run（）方法。一个线程只能启动一次，再次启动就不合法了。 run（）方法中放入了线程的逻辑，即我们要这个线程去做事情。 通常我一般是使用第二种方法来实现的，第一种方式会在单继承的规则上制约我们的扩展。即当一个线程已经继承了另一个类时，只能用第二种方法来构造，即实现Runnable接口。 Thread 实现1234567891011121314151617181920212223242526public class Main &#123; static class SonOfThread extends Thread &#123; private String threadName; public SonOfThread(String threadName) &#123; this.threadName = threadName; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(threadName + &quot; : &quot; + i); &#125; &#125; &#125; public static void main(String[] args) &#123; SonOfThread sonOfThread = new SonOfThread(&quot;sonOfThread&quot;); sonOfThread.start(); &#125;&#125; 当使用第一种方式（继承Thread的方式）来生成线程对象时，我们需要重写run()方法，因为Thread类的run()方法默认是调用构造Thread对象时传入的Runnable接口的实现类对象的run方法。但我们这里并没有打算通过这种方式构建Thread对象，所以这里默认的run函数什么都不会做，我们应该重写它。1234567891011/* What will be run. */private Runnable target;····@Overridepublic void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; Runnable 实现12345678910111213141516171819202122232425262728public class Main &#123; static class MyThread implements Runnable &#123; private String threadName; public MyThread(String threadName) &#123; this.threadName = threadName; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(threadName + &quot; : &quot; + i); &#125; &#125; &#125; public static void main(String[] args) &#123; MyThread myThread = new MyThread(&quot;myThread&quot;); Thread thread = new Thread(myThread); thread.start(); &#125;&#125; 其实还是很好理解的，我们最终都要执行线程的run方法，而start方法是run方法执行的唯一入口，我们只能通过Thread对象来显示的调用start方法来为线程的执行准备好系统资源，并由start方法来后续调用run方法。 Runnable源码1234567package java.lang;publicinterface Runnable &#123; public abstract void run(); &#125; 需要注意的是： 当生成一个线程对象时，如果没有为其指定名字，那么线程对象的名字将使用如下形式：Thread-number，该number是自动增加的数字，并被所有的Thread对象所共享，因为它是一个static的成员变量。 停止线程 现在线程的消亡不能通过调用stop()命令，应该让run()方法自然结束。stop()方法是不安全的，已经废弃。 停止线程推荐的方式：设定一个标志变量，在run()方法中是一个循环，由该标志变量控制循环是继续执行还是跳出；循环跳出，则线程结束。 线程共享资源值得注意的是： 多线程的存在，不是提高程序的执行速度。其实是为了提高应用程序的使用率，程序的执行其实都是在抢CPU的资源，CPU的执行权。多个进程是在抢这个资源，而其中的某一个进程如果执行路径比较多，就会有更高的几率抢到CPU的执行权 多线程编程很常见的情况下是希望多个线程共享资源， 通过多个线程同时消费资源来提高效率，但是新手一不小心很容易陷入一个编码误区。 举个例子： 下面的代码，希望通过 3 个线程同时执行 i– ，使得输出i的值为 0，但3次输出的结果都为2。这是因为在main方法中创建的三个线程都独自持有一个i变量，该变量式线程独有的，它并非static变量并不是线程共有的。我们的目的应该是3个线程共享一个i变量。123456789101112131415161718192021class ThreadTest1 extends Thread &#123; private int i = 3; @Override public void run() &#123; i--; System.out.println(i); &#125;&#125;public class ThreadTest &#123; public static void main(String[] strings) &#123; Thread thread1 = new ThreadTest1(); thread1.start(); Thread thread2 = new ThreadTest1(); thread2.start(); Thread thread3 = new ThreadTest1(); thread3.start(); &#125;&#125;输出 // 2 2 2 在这种非共有变量的情况下我们应该这么写：12345678910应该这么写public class ThreadTest &#123; public static void main(String[] strings) &#123; Thread thread1 = new ThreadTest1(); thread1.start(); thread1.start(); thread1.start(); &#125;&#125; 即让该线程的run方法执行3次。每次对i进行--操作。 多个线程执行同样的代码在这种情况下，可以使用同一个Runnable对象（看上一篇博客，这是一种创建线程的方式）将需要共享的数据，植入这个Runnable对象里面。例如买票系统，余票是需要共享的，不过在这样做的时候，我想还应该加上synchronized关键字修饰！ 多个线程执行的代码不一样在这种情况下，就两种思路可以实现（这里参考张孝祥老师的观点） 其一：将共享数据封装再另外一个对象中，然后将这个对象逐一传递给各个Runnable对象。每个线程对共享数据的操作方法也分配到那个对象身上去完成，这样容易实现对改数据进行的各个操作的互斥和通信。 其二：将这些Runnable对象作为某一个类中的内部类，共享数据作为这个外部类中的成员变量，每个线程对共享数据的操作方法也分配给外部类，以便实现对共享数据进行的各个操作的互斥和通信，作为内部类的各个Runnable对象调用外部类的这些方法。 组合：将共享数据封装再另外一个对象中，每个线程对共享数据的操作方法也分配到那个对象身上去完成，对象作为这个外部类中的成员变量或方法中的局部变量，每个线程的Runnable对象作为外部类中的成员内部类或局部内部类。（示例代码所使用的方法），总之，要同步互斥的几段代码最好是分别放在几个独立的方法中，这些方法再放在同一个类中，这样比较好容易实现它们之间的同步互斥通信 简单粗暴的方式在程序中，定义一个static变量 线程的生命周期线程的生命周期其实就是一个线程从创建到消亡的过程。 线程可以有6种状态： New（新创建），Runnable（可运行），Blocked（被阻塞），Waiting（等待），Timed waiting（计时等待） Terminated(被终止)。 要想确定一个线程的当前状态，可调用getState()方法。 1.创建状态当用new操作符创建一个新的线程对象时，如 new Thread(t)，该线程还没有开始运行,该线程处于创建状态，程序还没有开始运行线程中代码。处于创建状态的线程只是一个空的线程对象，系统不为它分配资源。 2.可运行状态一旦调用了start()方法，线程处于runnable状态。一个可运行的线程可能正在运行页可能没有运行，这取决于操作系统给线程提供运行的时间。 一旦一个线程开始运行，它不必始终保持运行。事实上，运行的线程被中断，目的是为了让其他线程获得运行机会。线程调度的细节依赖于操作系统提供的服务。 记住，在任何给定时刻，一个可运行的线程可能正在运行页可能没有运行，这就是为什么说成为runnable状态后才能为可运行而不是运行。 3.不可运行状态不可运行状态包括被阻塞或等待状态，此时线程暂时不活动，不运行任何代码且消耗最少的资源。直到线程调度器重新激活它。 当一个线程试图获取一个内部的对象锁，而该锁被其他线程所持有，则进入阻塞状态。当所有其他线程释放完琐，线程调度器允许该线程持有它的时候，该线程将变成非阻塞状态。 当线程等待另一个线程通知 调度器调度一个条件时，它自己进入等待转态。在thread对象调用wait方法和join方法时，就会出现这种情况。 1234567public final void wait()&#123;&#125;在其他线程调用此对象的 notify() 方法或 notifyAll() 方法前，导致当前线程等待。public final void join(long millis)&#123;&#125;等待该线程终止。 有些方法有一个超时参数，例如，sleep，wait，join。调用他们导致线程进入计时等待状态。这一状态将保持到超时期满或者受到适当通知。 通俗一点： 当发生下列事件时，处于运行状态的线程会转入到不可运行状态： 调用了sleep()方法； 线程调用wait()方法等待特定条件的满足； 线程输入/输出阻塞。 返回可运行状态： 处于睡眠状态的线程在指定的时间过去后； 如果线程在等待某一条件，另一个对象必须通过notify()或notifyAll()方法通知等待线程条件的改变； 如果线程是因为输入输出阻塞，等待输入输出完成。 4.被终止状态线程因如下两个原因之一而被终止： 因为run方法正常退出而自然消亡 因为一个没有捕获的异常终止了run方法而消亡 线程的优先级Java线程有优先级的设定，高优先级的线程比低优先级的线程有更高的几率得到执行。 当前线程没有指定优先级时，所有线程都是普通优先级。 优先级从1到10的范围指定。10表示最高优先级，1表示最低优先级，5是普通优先级。 优先级最高的线程在执行时被给予优先。但是不能保证线程在启动时就进入运行状态。 与在线程池中等待运行机会的线程相比，正在运行的线程可能总是拥有更高的优先级。 由调度程序决定哪一个线程被执行。 t.setPriority()用来设定线程的优先级。 记住在线程开始方法被调用之前，线程的优先级应该被设定。 你可以使用常量，如MIN_PRIORITY,MAX_PRIORITY，NORM_PRIORITY来设定优先级Java线程的优先级是一个整数，其取值范围是1(Thread.MIN_PRIORITY) —— 10(Thread.MAX_PRIORITY)。 123public static final int MIN_PRIORITY = 1;public static final int NORM_PRIORITY = 5;public static final int MAX_PRIORITY = 10; 可以通过setPriority方法（final的，不能被子类重载）更改优先级。优先级不能超过1-10的取值范围，否则抛出IllegalArgumentException。另外如果该线程已经属于一个线程组（ThreadGroup），该线程的优先级不能超过该线程组的优先级。 Thread通过前面的理论论述我们知道了Java实现多线程是通过Thread类来实现的。所以我们接下来了解一下Thread这个类 可以根据图中标注处来了解Thread类的声明规范。但该图标注处并非我所翻译。所以其实该图是有对源码理解有误的地方的。 可以结合jdk中文官方文档来理解。 总的来说： Java 虚拟机允许应用程序并发地运行多个执行线程 每个线程都有一个优先级，高优先级线程的执行优先于低优先级线程。 每个线程都可能被标记为一个守护程序。 当某个线程中运行的代码创建一个新 Thread 对象时，该新线程的初始优先级被设定为创建线程的优先级，并且当且仅当创建线程是守护线程时，被创建的新线程才是守护程序。 当 Java 虚拟机启动时，通常都会有一个非守护线程（它通常调用一些指定类的main方法）Java虚拟机将继续执行线程，直到出现以下任一情况。 调用了 Runtime 类的 exit 方法，并且安全管理器允许退出操作发生。 非守护线程的所有线程都已停止运行，无论是通过从对 run 方法的调用中返回，还是通过抛出一个传播到 run 方法之外的异常。 创建新执行线程有两种方法。 一种方法是将类声明为 Thread 的子类。该子类应重写 Thread 类的 run 方法。接下来可以分配并启动该子类的实例。 另一种方法是声明实现 Runnable 接口的实现类。该类要实现Runnable接口的 run 方法。然后再声明一个该类的实例，并在创建 Thread 实例时作为其构造函数的参数来传入并调用其start函数来启动该线程。 每个线程都有一个标识名，多个线程可以同名。如果线程创建时没有指定标识名，就会为其生成一个新名称。 除非函数特别表情，否则将一个为null的参数传递给构造函数或者其他函数都会抛出一个空指针异常。 之前我们说过了创建多线程的两种方式，这里测试一下运行结果：12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Main &#123; static class MyThread implements Runnable &#123; private String threadName; public MyThread(String threadName) &#123; this.threadName = threadName; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(threadName + &quot; : &quot; + i); &#125; &#125; &#125; static class SonOfThread extends Thread &#123; private String threadName; public SonOfThread(String threadName) &#123; this.threadName = threadName; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(threadName + &quot; : &quot; + i); &#125; &#125; &#125; public static void main(String[] args) &#123; MyThread myThread = new MyThread(&quot;myThread&quot;); Thread thread = new Thread(myThread); SonOfThread sonOfThread = new SonOfThread(&quot;sonOfThread&quot;); sonOfThread.start(); thread.start(); &#125;&#125; 最后都会正确输出各自线程的处理结果99。 关于Thread需要注意的点run()和start()方法区别： run():仅仅是封装被线程执行的代码，直接调用是普通方法，线程并没有启动，系统资源也就更不会被分配了。 start():首先启动了线程，然后再由jvm去调用该线程的run()方法。 jvm虚拟机的启动是单线程的还是多线程的? 是多线程的。不仅仅是启动main线程，还至少会启动垃圾回收线程的，不然谁帮你回收不用的内存~ 两种方式实现多线程，我们使用哪一种？ 一般我们使用实现Runnable接口 可以避免java中的单继承的限制 应该将并发运行任务和运行机制解耦，因此我们选择实现Runnable接口这种方式！]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 如何有效地避免OOM：善于利用软引用和弱引用]]></title>
    <url>%2Freference.html</url>
    <content type="text"><![CDATA[参考： 海子：Java 如何有效地避免OOM：善于利用软引用和弱引用 前言想必很多朋友对OOM（OutOfMemory）这个错误不会陌生，而当遇到这种错误如何有效地解决这个问题呢？今天我们就来说一下如何利用软引用和弱引用来有效地解决程序中出现的OOM问题。 了解 强引用、软引用、弱引用、虚引用的概念在Java中，虽然不需要程序员手动去管理对象的生命周期，但是如果希望某些对象具备一定的生命周期的话（比如内存不足时JVM就会自动回收某些对象从而避免OutOfMemory的错误）就需要用到软引用和弱引用了。 从Java SE2开始，就提供了四种类型的引用：强引用、软引用、弱引用和虚引用。Java中提供这四种引用类型主要有两个目的：第一是可以让程序员通过代码的方式决定某些对象的生命周期；第二是有利于JVM进行垃圾回收。下面来阐述一下这四种类型引用的概念： 强引用（StrongReference） 强引用就是指在程序代码之中普遍存在的，比如下面这段代码中的object和str都是强引用： 12Object object = new Object();String str = &quot;hello&quot;; 只要某个对象有强引用与之关联，JVM必定不会回收这个对象，即使在内存不足的情况下，JVM宁愿抛出OutOfMemory错误也不会回收这种对象。比如下面这段代码： 12345678910public class Main &#123; public static void main(String[] args) &#123; new Main().fun1(); &#125; public void fun1() &#123; Object object = new Object(); Object[] objArr = new Object[1000]; &#125;&#125; 当运行至Object[] objArr = new Object[1000];这句时，如果内存不足，JVM会抛出OOM错误也不会回收object指向的对象。不过要注意的是，当fun1运行完之后，object和objArr都已经不存在了，所以它们指向的对象都会被JVM回收。 如果想中断强引用和某个对象之间的关联，可以显示地将引用赋值为null，这样一来的话，JVM在合适的时间就会回收该对象。 比如Vector类的clear方法中就是通过将引用赋值为null来实现清理工作的： 12345678910111213141516171819202122232425/** * Removes the element at the specified position in this Vector. * Shifts any subsequent elements to the left (subtracts one from their * indices). Returns the element that was removed from the Vector. * * @throws ArrayIndexOutOfBoundsException if the index is out of range * (&#123;@code index &lt; 0 || index &gt;= size()&#125;) * @param index the index of the element to be removed * @return element that was removed * @since 1.2 */public synchronized E remove(int index) &#123;modCount++;if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index);Object oldValue = elementData[index];int numMoved = elementCount - index - 1;if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved);elementData[--elementCount] = null; // Let gc do its workreturn (E)oldValue;&#125; 软引用（SoftReference）软引用是用来描述一些有用但并不是必需的对象，在Java中用java.lang.ref.SoftReference类来表示。对于软引用关联着的对象，只有在内存不足的时候JVM才会回收该对象。 因此，这一点可以很好地用来解决OOM的问题，并且这个特性很适合用来实现缓存：比如网页缓存、图片缓存等。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被JVM回收，这个软引用就会被加入到与之关联的引用队列中。下面是一个使用示例： 123456789import java.lang.ref.SoftReference; public class Main &#123; public static void main(String[] args) &#123; SoftReference&lt;String&gt; sr = new SoftReference&lt;String&gt;(new String(&quot;hello&quot;)); System.out.println(sr.get()); &#125;&#125; 弱引用（WeakReference） 弱引用也是用来描述非必需对象的，当JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。 在java中，用java.lang.ref.WeakReference类来表示。下面是使用示例： 123456789101112import java.lang.ref.WeakReference; public class Main &#123; public static void main(String[] args) &#123; WeakReference&lt;String&gt; sr = new WeakReference&lt;String&gt;(new String(&quot;hello&quot;)); System.out.println(sr.get()); System.gc(); //通知JVM的gc进行垃圾回收 System.out.println(sr.get()); &#125;&#125; 输出结果为： 12hellonull 第二个输出结果是null，这说明只要JVM进行垃圾回收，被弱引用关联的对象必定会被回收掉。不过要注意的是，这里所说的被弱引用关联的对象是指只有弱引用与之关联，如果存在强引用同时与之关联，则进行垃圾回收时也不会回收该对象（软引用也是如此）。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被JVM回收，这个软引用就会被加入到与之关联的引用队列中。 虚引用（PhantomReference）虚引用和前面的软引用、弱引用不同，它并不影响对象的生命周期。在java中用java.lang.ref.PhantomReference类表示。如果一个对象与虚引用关联，则跟没有引用与之关联一样，在任何时候都可能被垃圾回收器回收。 要注意的是，虚引用必须和引用队列关联使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之 关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 1234567891011import java.lang.ref.PhantomReference;import java.lang.ref.ReferenceQueue; public class Main &#123; public static void main(String[] args) &#123; ReferenceQueue&lt;String&gt; queue = new ReferenceQueue&lt;String&gt;(); PhantomReference&lt;String&gt; pr = new PhantomReference&lt;String&gt;(new String(&quot;hello&quot;), queue); System.out.println(pr.get()); &#125;&#125; 进一步理解软引用和弱引用 对于强引用，我们平时在编写代码时经常会用到。而对于其他三种类型的引用，使用得最多的就是软引用和弱引用，这2种既有相似之处又有区别。它们都是用来描述非必需对象的，但是被软引用关联的对象只有在++内存不足时才会被回收++，而被弱引用关联的对象在++JVM进行垃圾回收时总会被回收++。 在SoftReference类中，有三个方法，两个构造方法和一个get方法（WekReference类似）： 两个构造方法： 123456789public SoftReference(T referent) &#123; super(referent); this.timestamp = clock;&#125; public SoftReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); this.timestamp = clock;&#125; get方法用来获取与软引用关联的对象的引用，如果该对象被回收了，则返回null。 在使用软引用和弱引用的时候，我们可以显示地通过System.gc()来通知JVM进行垃圾回收，但是要注意的是，虽然发出了通知，JVM不一定会立刻执行，也就是说这句是无法确保此时JVM一定会进行垃圾回收的。 如何利用软引用和弱引用解决OOM问题 前面讲了关于软引用和弱引用相关的基础知识，那么到底如何利用它们来优化程序性能，从而避免OOM的问题呢？ 下面举个例子，假如有一个应用需要读取大量的本地图片，如果每次读取图片都从硬盘读取，则会严重影响性能，但是如果全部加载到内存当中，又有可能造成内存溢出，此时使用软引用可以解决这个问题。 设计思路是：用一个HashMap来保存图片的路径 和 相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM会自动回收这些缓存图片对象所占用的空间，从而有效地避免了OOM的问题。在Android开发中对于大量图片下载会经常用到。 下面这段代码是摘自博客： 12345678910111213141516171819202122232425262728293031323334353637383940.....private Map&lt;String, SoftReference&lt;Bitmap&gt;&gt; imageCache = new HashMap&lt;String, SoftReference&lt;Bitmap&gt;&gt;();&lt;br&gt;....public void addBitmapToCache(String path) &#123; // 强引用的Bitmap对象 Bitmap bitmap = BitmapFactory.decodeFile(path); // 软引用的Bitmap对象 SoftReference&lt;Bitmap&gt; softBitmap = new SoftReference&lt;Bitmap&gt;(bitmap); // 添加该对象到Map中使其缓存 imageCache.put(path, softBitmap);&#125;public Bitmap getBitmapByPath(String path) &#123; // 从缓存中取软引用的Bitmap对象 SoftReference&lt;Bitmap&gt; softBitmap = imageCache.get(path); // 判断是否存在软引用 if (softBitmap == null) &#123; return null; &#125; // 取出Bitmap对象，如果由于内存不足Bitmap被回收，将取得空 Bitmap bitmap = softBitmap.get(); return bitmap;&#125; 当然这里我们把缓存替换策略交给了JVM去执行，这是一种比较简单的处理方法。复杂一点的缓存，我们可以自己单独设计一个类，这里面就涉及到缓存策略的问题了，具体可以参考之前的一篇博文：《缓存算法（页面置换算法）-FIFO、LFU、LRU》 参考资料： 《深入理解JVM虚拟机》 http://blog.csdn.net/arui319/article/details/8489451 http://blog.csdn.net/zsuguangh/article/details/6429592 http://mobile.51cto.com/abased-406998.htm]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程：深入剖析ThreadLocal]]></title>
    <url>%2Fthreadlocal.html</url>
    <content type="text"><![CDATA[转载自： 海子：Java并发编程：深入剖析ThreadLocal 在原作者的内容上自己又从别处copy了一些揉成的一篇文章。 对ThreadLocal的理解 ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，其实意思差不多。可能很多朋友都知道ThreadLocal为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。 这句话从字面上看起来很容易理解，但是真正理解并不是那么容易。 我们还是先来看一个例子： 12345678910111213141516class ConnectionManager &#123; private static Connection connect = null; public static Connection openConnection() &#123; if(connect == null)&#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public static void closeConnection() &#123; if(connect!=null) connect.close(); &#125;&#125; 假设有这样一个数据库链接管理类，这段代码在单线程中使用是没有任何问题的，但是如果在多线程中使用呢？很显然，在多线程中使用会存在线程安全问题：第一，这里面的2个方法都没有进行同步，很可能在openConnection方法中会多次创建connect；第二，由于connect是共享变量，那么必然在调用connect的地方需要使用到同步来保障线程安全，因为很可能一个线程在使用connect进行数据库操作，而另外一个线程调用closeConnection关闭链接。 所以出于线程安全的考虑，必须将这段代码的两个方法进行同步处理，并且在调用connect的地方需要进行同步处理。 这样将会大大影响程序执行效率，因为一个线程在使用connect进行数据库操作的时候，其他线程只有等待。 那么大家来仔细分析一下这个问题，这地方到底需不需要将connect变量进行共享？事实上，是不需要的。假如每个线程中都有一个connect变量，各个线程之间对connect变量的访问实际上是没有依赖关系的，即一个线程不需要关心其他线程是否对这个connect进行了修改的。 到这里，可能会有朋友想到，既然不需要在线程之间共享这个变量，可以直接这样处理，在每个需要使用数据库连接的方法中具体使用时才创建数据库链接，然后在方法调用完毕再释放这个连接。比如下面这样：12345678910111213141516171819202122232425262728class ConnectionManager &#123; private Connection connect = null; public Connection openConnection() &#123; if(connect == null)&#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public void closeConnection() &#123; if(connect!=null) connect.close(); &#125;&#125; class Dao&#123; public void insert() &#123; ConnectionManager connectionManager = new ConnectionManager(); Connection connection = connectionManager.openConnection(); //使用connection进行操作 connectionManager.closeConnection(); &#125;&#125; 这样处理确实也没有任何问题，由于每次都是在方法内部创建的连接，那么线程之间自然不存在线程安全问题。但是这样会有一个致命的影响：导致服务器压力非常大，并且严重影响程序执行性能。由于在方法中需要频繁地开启和关闭数据库连接，这样不尽严重影响程序执行效率，还可能导致服务器压力巨大。 那么这种情况下使用ThreadLocal是再适合不过的了，因为ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。 但是要注意，虽然ThreadLocal能够解决上面说的问题，但是由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。 深入解析ThreadLocal类 在上面谈到了对ThreadLocal的一些理解，那我们下面来看一下具体ThreadLocal是如何实现的。 先了解一下ThreadLocal类提供的几个方法：1234public T get() &#123; &#125;public void set(T value) &#123; &#125;public void remove() &#123; &#125;protected T initialValue() &#123; &#125; get()方法是用来获取ThreadLocal在当前线程中保存的变量副本，set()用来设置当前线程中变量的副本，remove()用来移除当前线程中变量的副本，initialValue()是一个protected方法，一般是用来在使用时进行重写的，它是一个延迟加载方法，下面会详细说明。 首先我们来看一下ThreadLocal类是如何为每个线程创建一个变量的副本的。 先看下get方法的实现：12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 第一句是取得当前线程，然后通过getMap(t)方法获取到一个map，map的类型为ThreadLocalMap。然后接着下面获取到&lt;key,value&gt;键值对，注意这里获取键值对传进去的是 this，而不是当前线程t。 如果获取成功，则返回value值。 如果map为空，则调用setInitialValue方法返回value。 我们上面的每一句来仔细分析： 首先看一下getMap方法中做了什么：123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 可能大家没有想到的是，在getMap中，是调用当期线程t，返回当前线程t中的一个成员变量threadLocals。 那么我们继续取Thread类中取看一下成员变量threadLocals是什么：123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 实际上就是一个ThreadLocalMap，这个类型是ThreadLocal类的一个内部类，我们继续取看ThreadLocalMap的实现： 关于弱引用WeakReference的学习可参考：理解Java中的弱引用（Weak Reference）12345678910111213141516171819202122static class ThreadLocalMap &#123; /** * The entries in this hash map extend WeakReference, using * its main ref field as the key (which is always a * ThreadLocal object). Note that null keys (i.e. entry.get() * == null) mean that the key is no longer referenced, so the * entry can be expunged from table. Such entries are referred to * as &quot;stale entries&quot; in the code that follows. */ static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; ····&#125; 可以看到ThreadLocalMap的Entry继承了弱引用WeakReference，而WeakReference的泛型也指向了Entry中的键值ThreadLocal。也就是说ThreadLocalMap是使用ThreadLocal的弱引用作为key的，它这么设计的原因也是为了方便它的键值ThreadLocal在外部没有强引用引用的情况下进行内存的释放。 下图是本文介绍到的一些对象之间的引用关系图，实线表示强引用，虚线表示弱引用： 然后网上就传言，ThreadLocal会引发内存泄露，他们的理由是这样的： 如上图，ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc的时候，这个ThreadLocal势必会被回收， 这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链： ThreadLocal Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value 永远无法回收，造成内存泄露。 我们来看看到底会不会出现这种情况。 其实，在JDK的ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施，下面是ThreadLocalMap的getEntry方法的源码： 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; // Entry 继承 WeakReference if (e != null &amp;&amp; e.get() == key) // e.get()拿出的是WeakReferencere的referent return e;// 如果桶有元素且元素刚好是此ThreadLocal else return getEntryAfterMiss(key, i, e);&#125; getEntryAfterMiss函数的源码：12345678910111213141516 private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) // 如果从桶中取出的Entry的key==null expungeStaleEntry(i); else i = nextIndex(i, len); // 类似HsahMap中取桶中的链表的下一元素 e = tab[i]; &#125; return null;&#125; expungeStaleEntry函数的源码：1234567891011121314151617181920212223242526272829303132333435 private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; 整理一下ThreadLocalMap的getEntry函数的流程： 首先从ThreadLocal的直接索引位置(通过ThreadLocal.threadLocalHashCode &amp; (len-1)运算得到)获取Entry e，如果e不为null并且key相同则返回e； 如果e为null或者key不一致则向下一个位置查询，如果下一个位置的key和当前需要查询的key相等，则返回对应的Entry，否则，如果key值为null，则擦除该位置的Entry，否则继续向下一个位置查询 在这个过程中遇到的key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，自然会被回收。 仔细研究代码可以发现，set操作也有类似的思想，将key为null的这些Entry都删除，防止内存泄露。 需要注意的是： 虽然ThreadLocalMap内部有对这样的Key为null的Entry的处理机制，但是光这样还是不够的，上面的设计思路依赖一个前提条件：要调用ThreadLocalMap的genEntry函数或者set函数。 这当然是不可能任何情况都成立的，所以很多情况下需要使用者手动调用ThreadLocal的remove函数，手动删除不再需要的ThreadLocal，防止内存泄露。 所以JDK建议将ThreadLocal变量定义成private static的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露(针对Value)。 参考：ThreadLocal和synchronized的区别? 然后再继续看setInitialValue方法的具体实现：12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 很容易了解，就是如果map不为空，就设置键值对，为空，再创建Map，看一下createMap的实现：123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 至此，可能大部分朋友已经明白了ThreadLocal是如何为每个线程创建变量的副本的： 首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。 初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。 然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。 下面通过一个例子来证明通过ThreadLocal能达到在每个线程中创建变量副本的效果：1234567891011121314151617181920212223242526272829303132333435363738394041public class Test &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;(); ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;(); public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final Test test = new Test(); test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread()&#123; public void run() &#123; test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;; &#125;; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;&#125; 这段代码的输出结果为：1234561main8Thread-01main 从这段代码的输出结果可以看出，在main线程中和thread1线程中，longLocal保存的副本值和stringLocal保存的副本值都不一样。最后一次在main线程再次打印副本值是为了证明在main线程中和thread1线程中的副本值确实是不同的。 总结一下： 实际的通过ThreadLocal创建的副本是存储在每个线程自己的threadLocals中的； 为何threadLocals的类型ThreadLocalMap的键值为ThreadLocal对象，因为每个线程中可有多个threadLocal变量，就像上面代码中的longLocal和stringLocal； 在进行get之前，必须先set，否则通过ThreadLoca的get函数取出的值为null(默认initValue()函数的结果)。 如果想在get之前不需要调用set就能正常访问的话，必须重写initialValue()方法。因为在上面的代码分析过程中，我们发现如果没有先set的话，即在map中查找不到对应的存储，则会通过调用setInitialValue方法返回i，而在setInitialValue方法中，有一个语句是T value = initialValue()， 而默认情况下，initialValue方法返回的是null。 123456789101112131415161718192021222324public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 看下面这个例子：12345678910111213141516171819202122232425262728293031323334353637public class Test &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;(); ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;(); public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final Test test = new Test(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread()&#123; public void run() &#123; test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;; &#125;; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125; &#125; 在main线程中，没有先set，直接get的话，运行时会报空指针异常。 但是如果改成下面这段代码，即重写了initialValue方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class Test &#123; ThreadLocal&lt;Long&gt; longLocal = new ThreadLocal&lt;Long&gt;()&#123; protected Long initialValue() &#123; return Thread.currentThread().getId(); &#125;; &#125;; ThreadLocal&lt;String&gt; stringLocal = new ThreadLocal&lt;String&gt;()&#123;; protected String initialValue() &#123; return Thread.currentThread().getName(); &#125;; &#125;; public void set() &#123; longLocal.set(Thread.currentThread().getId()); stringLocal.set(Thread.currentThread().getName()); &#125; public long getLong() &#123; return longLocal.get(); &#125; public String getString() &#123; return stringLocal.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; final Test test = new Test(); test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); Thread thread1 = new Thread()&#123; public void run() &#123; test.set(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;; &#125;; thread1.start(); thread1.join(); System.out.println(test.getLong()); System.out.println(test.getString()); &#125;&#125; 就可以直接不用先set而直接调用get了。 # 三.ThreadLocal的应用场景 最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。 如：123456789private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() &#123; public Connection initialValue() &#123; return DriverManager.getConnection(DB_URL); &#125;&#125;; public static Connection getConnection() &#123; return connectionHolder.get();&#125; 下面这段代码摘自： 正确理解ThreadLocal 1234567891011121314private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s;&#125; 可以看出每个线程操控属于自己的一个Session。 关于ThreadLocal在exchange中的用法当某个线程被程序分配到执行某个用户的请求时，由于对于每次来请求的用户的身份未知，所以为了该线程所处理的函数间用户身份信息的传递确认，会用ThreadLocal来存储用户信息。这里ThreadLocal的作用也就是相当于方便函数间参数传递的工具 exchange项目的代码中做的处理就是每个请求过来先走PassportInterceptor来确认用户身份并且绑定到Hostholder中 这样无论程序分配的是哪个线程来处理用户的请求 函数间传递的都是该身份的用户不会出错。并且由于每个请求都走该拦截器，所以用户每次过来当前线程的ThreadLocal对应的对象都是当前用户会替换掉之前存储在其中的用户。 ThreadLocal与Synchonized的对照ThreadLocal和Synchonized都用于解决多线程并发訪问。可是ThreadLocal与synchronized有本质的差别。synchronized是利用锁的机制，使变量或代码块在某一时该仅仅能被一个线程訪问。而ThreadLocal为每个线程都提供了变量的副本，使得每个线程在某一时间訪问到的并非同一个对象，这样就隔离了多个线程对数据的数据共享。而Synchronized却正好相反，它用于在多个线程间通信时可以获得数据共享。 Synchronized用于线程间的数据共享，而ThreadLocal则用于线程间的数据隔离。 学习时必看的另两篇文章 正确理解ThreadLocal java ThreadLocal(应用场景及使用方式及原理) 参考参考资料： 《深入理解Java虚拟机》 《Java编程思想》 http://ifeve.com/thread-management-10/ http://www.ibm.com/developerworks/cn/java/j-threads/index3.html http://www.iteye.com/topic/103804 http://www.iteye.com/topic/777716 http://www.iteye.com/topic/757478 http://blog.csdn.net/ghsau/article/details/15732053 http://ispring.iteye.com/blog/162982 http://blog.csdn.net/imzoer/article/details/8262101 http://www.blogjava.net/wumi9527/archive/2010/09/10/331654.html http://bbs.csdn.net/topics/380049261]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合考点总结]]></title>
    <url>%2Fcollection-summary.html</url>
    <content type="text"><![CDATA[一、ArrayList和Vector的区别共同点： 都实现了List接口继承了AbstractList接口 底层实现都是数组。所以说都是存储有序的集合 允许存储null 不同点： ArrayList是线程不安全的，Vector则是线程安全的，即便我们需要线程安全的数组容器也是会选择ArrayList，只是在初始化的时候通过Collections集合类的工具类来进行包装一下。因为这种同步实现更科学 扩容时ArrayList扩容系数为1.5，Vector则是2 二、HashMap和Hashtable的区别总的来说HashTable的存在和Vector是一个意思。都是早期的实现，并且盲目的保证了集合的线程安全。却在一些不必要的操作上影响了集合的性能，并且早期函数的命名并不科学简洁严谨。 共同点： 实现了Map接口 不同点： HashMap非同步，HashTable同步。当我们需要同步的映射容器的时候Java也提供了ConcurrentHashMap这个类。 HashMap允许null键和null值，HashTable不允许null键或者null值。 HashMap没有保留HashTable的contains函数，而且和HashTable一样添加了containsValue和containsKey函数。并选用containsKey函数来替代contains的功能。 两者继承不同。HashTable继承自Dictionary父类而HashMap继承自AbstractMap父类。 三、List和Map的区别存储结构不同 List是单列存储，Map是key-value键值存储 List允许存重复元素,Map则key值不能重复 List存储有序，Map映射存储无序。 四、Set集合定义存储在其中的元素是不能重复的，元素的重复与否是如何判断的？是用==还是equals()?首先需要清楚Set集合的常见实现类的底层实现用的都是Map映射的子类。 拿HashSet来举例，它的底层是现金就是HashMap。而我们知道HashSet的存储方式是把存入的元素对应的存到了HashMap的key中，而value则是固定的Object对象的常量。 所以问题就落到了HashMap是如何处理存入相同key的情况的呢？ HashMap源码的632-635行是这样判断的，如果key值散列到的桶的头元素与该key的hash值相等。并且key值相==或者key值equals的话，那么就认为该key值已经存在在了HashMap中。那么就跳出判断循环。1234567891011121314Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; =============if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue;&#125; HashMap源码652行做了如上处理，即拿出旧值并返回，对应的节点的value替换上新值。 解答： 所以针对上述问题，对于Set来说，当插入重复元素的时候，就代表这HashMap要插入具有重复key值得节点。那么由于插入到Set集合的节点的value均是相同的无意义的Object常量对象。所以底层HashMap相当于只是在频繁的修改无疑的value。 从源码可以看出来==和equals两者都用了。 五、Collection和Collections的区别 Collection是集合类的顶级接口，实现它的有Set接口和=，List接口，Queue接口。 Collections是集合的工具类。提供了一系列的静态函数来对集合进行搜索，查找，以及同步的一些操作等。 六、说出ArrayList,LinkedList的存储性能和特性ArrayList底层是数组实现，存储有序。LinkedList底层是双向链表实现的，存储无序。 由于ArrayList底层实现是动态数组，所以对于ArrayList来说访问其元素可以根据角标的方式访问，非常快。而LinkedList要访问元素的时候只能通过遍历来找到要找的元素。所以ArrayList比LinkedList的访问速度要快，性能要好。 同样的由于是数组的原因也就导致它在进行增删操作的时候是不方便的比较缓慢的(移动数组元素，扩容复制数组)。LinkedList只需要修改对应节点next指针即可。消耗很小，所以LinkedList比ArrayList的增删速度要快，性能要好。 注意： 但同时我们需要细想一个删除操作具体体现的不仅仅是删除这一个操作。对于不同的数据结构而言，找到要删除的元素也是一个性能差异很大的点。 比如对于LinkedList的删除操作而言，删除节点本身是很简易的，但是慢就慢在它需要对所有元素去迭代一遍来找这个元素。而对于ArrayList来说删除操作是不易的，因为它要面临着被删除位置后的数组元素前移的操作。而找元素这个操作对数组来说却是速度很快的一个操作。所以整体上来说两者增删操作的性能差异就不是那么的确定了。比较时考虑的点还是比较的多 HashTable，SynchronizedMap，ConcurrentHashMap区别HashTable 相比于HashMap，HashTable与其最大的区别就是所有函数都实现了同步。并且HashTable由于是最早设计的容器框架，有许多设计上的不足，并且后续并没有改进。最典型的元素插入时的put函数，元素的散列位置是通过%来计算的，而非像HashMap中(table.length-1)&amp;hash(key) synchronizedMap synchronizedMap可以作用于任何Map实现类上，但是相比于HashTable最大的区别则是它并不是盲目的对所有的函数都实现了同步。一定程度上性能要高于HashTable不少。但是两者都是对象锁。所以当并发情况下有一个线程在执行被锁函数那么并发情况下的其它线程必然都是等待状态。synchronizedMap相比于HashTable保证的只是非同步方法在多线程情况下的并行运行。 潜在问题：123456Java代码// shm是SynchronizedMap的一个实例if(shm.containsKey(&apos;key&apos;))&#123; shm.remove(key);&#125; 这段代码用于从map中删除一个元素之前判断是否存在这个元素。这里的 containsKey和reomve方法都是同步的，但是整段代码却不是。考虑这么一个使用场景：线程A执行了containsKey方法返回 true，准备执行remove操作；这时另一个线程B开始执行，同样执行了containsKey方法返回true，并接着执行了remove操作；然 后线程A接着执行remove操作时发现此时已经没有这个元素了。要保证这段代码按我们的意愿工作，一个办法就是对这段代码进行同步控制，但是这么做付出 的代价太大。 同样还有： 并发情况下的迭代及修改。可能我们在迭代的时候某个线程对该Map正在执行并发修改的操作。此时就会报出并发修改的异常 参考：SynchronizedMap和ConcurrentHashMap 区别 ConcurrentHashMap ConcurrentHashMap相比于前两者不但汲取了synchronizedMap的优点并没有对一些必要的函数实现同步。并且非同步的函数和HashMap的函数处理逻辑基本一致。而对于需要同步的函数，其内部采用的也是“桶锁”，它不会对整个Map映射上锁。这从一定程度上大大提升了性能，使其可以在多线程并发的情况下函数间并行执行，而不会影响执行结果和效率。 ArrayList和LinkedList增删分析ArrayList插入分析： ArrayList的add(E e)函数默认是尾插。 我们如果采用该方法插入大量元素的话。不会存在元素移位的情况。这种插入方式和LinkedList的插入方式一样高效，复杂度都是O(1)。不存在元素移位的情况，而如果采用add(int index, E element)函数来对某个索引处的元素前插入大量元素的话，每插入一次元素都会 使数组索引后续元素都进行一次元素移动的操作，复杂度是O(n)。关键区别看你插入大量元素时想插到哪里 LinkedList插入分析： LinkedList的add(E e)函数默认插入方式是尾插法。由于它是双向链表并且纪录了头尾两个节点。所以用这个方式插入大量元素的时间复杂度是0(1)。addFirst和addLast同样的道理由于纪录了头尾两节点的原因。 ArrayList删除分析：而ArrayList提供的remove函数在删除大量元素的时候，就必然会进行数组元素的移位操作。它的耗时操作也就在此处。 LinkedList删除分析： LinkedList由于是双向链表，所以头删尾删都有性能上的优势，复杂度均是O(1)。只需要考虑查找元素的复杂度即可。而且LinkedList中进行了折半查找，先对元素的索引和总元素数size进行比较来确认从头迭代的找还是尾迭代的找。元素总规模先&gt;&gt;后才进行的迭代。 扩展：ArrayList和LinkedList增删性能比较ArrayList的增删未必就是比LinkedList要慢。 如果增删都是在末尾来操作【每次调用的都是remove()和add()】，此时ArrayList就不需要移动数组元素了(增加元素的时候还是有可能触发扩容操作可能会扩容并复制数组)。如果数据量有百万级的时，ArrayList的速度是会比LinkedList要快的。(我测试过) 如果删除操作的位置是在中间。由于LinkedList的消耗主要是在遍历上，ArrayList的消耗主要是在数组元素的移动上(底层调用的是arraycopy()方法，是native方法)。LinkedList的遍历速度是要慢于ArrayList的数组元素移动的速度的如果数据量有百万级的时，还是ArrayList要快。(我测试过) 删末尾元素 ArrayList 删掉最后一个元素， LinkedList删掉最后一个元素。指针的变化，相对复杂一些 删中间元素，ArrayList需要做的是移动数组后续元素。而arraycopy是native函数，在JVM运行时有性能优势而且本身进行的也是赋值操作，简单速度快 LinkedList需要做的是遍历元素，内存中指针的移动相对速度慢于赋值操作一些。所以LinkedList的遍历速度要慢于ArrayList的移动速度。 所以可以认为百万级别的增删，如果是在容器中间或中间以后的元素操作基本都是ArrayList快 七、Set集合的各实现类首先有3个，HashSet，TreeSet，LinkedHashSet HashSet常用的应该是HashSet，底层实现是HashMap(由于LinkedHashSet继承自HashSet，所以底层实现也提供了一种LinkedHashMap的构造函数)，无论存储还是查询都具有很好性能。都可以根据元素的hash值快速的散列到所在桶的位置，然后进行相应的操作。同时由于HashMap在jdk1.8的时候把HashMap底层的实现换成了散列表+红黑树的方式。导致即便碰巧大量元素散列到一个桶上也不会出现链表特别长，遍历性能不好的情况。当链表数量超过8个时会自动将链表哦转化成红黑树(元素数大于64)，遍历时性能非常好。由于底层是HashMap实现，所以我们在迭代的时候调用iterator方法返回的其实是HashMap迭代时调用的keySet函数返回的Set集合的Iterator对象来进行迭代。HashMap底层会对所有的Key用一个Set集合来进行存储(不重)。对所有value用一个Collection来进行存储。 TreeSetTreeSet底层实现是TreeMap，即根据插入元素的自然排序或者自定义比较方式来比较插入元素的大小来决定其插入位置。进而形成一个有序的红黑树。TreeSet和TreeMap一样，插入的元素会有序的存储在一个红黑树上。根据我们制定的规则，或者元素的自然排序顺序。一般Tree系列的数据结构，我们用来保证一种有序性的数据结构才会用，存入到其中的元素必须实现Comparable或者Comparator接口来保证元素的可比较性。我们一般都是重写compareTo或者compare方法来制定自己的比较规则，让后续存到数据结构中的元素满足我们想要的顺序。 LinkedHashSetLinkedHashSet继承自HashSet，底层实现是LinkedHashMap即散列表和双向链表。HashSet也为LinkedHashSet提供了一个构造LinkedHashMap的构造函数，但需要注意的是，HashSet只为LinkedHashSet提供了一种只有initialCapacity和loadFactor的构造函数，也就意味着LinkedHashSet的元素无法像LinkedHashMap那样具有两种迭代顺序，又由于默认LinkedHashMap的迭代顺序是元素的插入顺序，所以它一般的作用就是用来保证元素的存储顺序和我们插入元素的顺序一致。这样我们在迭代获取元素的时候有一个预估值和期望值。 HashSet各方面性能好，不用排序一般用它，也是因为HashMap的优势。TreeSet一般用在比较根据元素进行排序的时候，LinkedHashSet则是用到我们要元素的插入顺序的时候。 八、Map集合及实现类首先有3个，HashMap，TreeMap，LinkedHashMap。 HashMap最常用的一般是HashMap，底层实现是散列表+单链表+红黑树。从性能上来讲，无论增删还是查都可以根据传入的key值快速定位到元素所在的桶。并且桶的数据结构也对大量hash碰撞的特殊情况做了优化，单链表元素数超过8采用红黑树存储。允许使用null做键值。迭代的时候有三种方式 12345678910111.for (Entry&lt;String, String&gt; entry : map.entrySet())2.for (String keys : map.keySet())3.Iterator&lt;String&gt; keys = map.keySet().iterator();while (keys.hasNext())&#123; &#125; 第一种调用的是HashIterator。根据散列表的数组下标来进行迭代。 第二种和第三种其实是一样的。keySet()返回的KeySet类继承自AbstractSet，在foreach迭代的时候会自动调用该类的iterator()方法，返回KeyIterator类，而这个类又继承自HashIterator类。只是实现了next()方法，但函数内也还是调用了HashIterator类的nextNode()方法。1234final class KeyIterator extends HashIterator implements Iterator&lt;K&gt; &#123; public final K next() &#123; return nextNode().key; &#125;&#125; TreeMapTreeMap是TreeSet的底层实现。底层数据结构式红黑树，实现了SortedMap接口，该映射是根据其键的自然顺序进行排序的，或者根据在构建TreeMap时传入的Comparator来进行排序。需要注意，存入的元素必须实现了Comparable接口或者其类型被指定的Comparator所接受。而且比较的对象参数不能为null。在使用这种数据结构的时候我们要注的除了是元素需要具有可比性，同时我们还需要注意元素具体的比较规则，即元素的类重写的compare方法和compareTo方法的比较逻辑。 LinkedHashMapLinkedHashMap是LinkedHashSet的底层实现，继承自HashMap，底层数据结构是散列表+单链表+红黑树+双向链表。所以和HashMap一样无论增删还是查找元素都具有极高的性能。不同的是迭代元素的方式。HashMap是通过迭代每一个“桶”来进行的迭代，迭代时获取的Entry都是未知的。而LinkedHashMap则默认是通过节点的插入顺序来进行迭代，或者通过节点的最近最少来进行迭代。之所以可以如此，是因为LinkedHashMap扩展了HashMap的Node节点。LinkedHashMap的Entry节点比其多维护两个指针变量。分别指向该节点的前驱和后继节点，所以比HashMap可以多维护一个双向链表。123456789/** * HashMap.Node subclass for normal LinkedHashMap entries. */static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; LinkedHashMap默认是按key的插入顺序来排序，也可以通过在构造时通过指定accessOrder为true来使其按元素的LRU顺序来排序，在其迭代的时候可以看出它的元素排列顺序。 LinkedHashMap不允许存储的元素的key值为null。两种比较方式都不支持。元素在插入到红黑树的时候肯定会与其他树中的节点进行比较，此时会报错。 参考：HashMap,LinkedHashMap,TreeMap的区别 九、Enumeration和Iterator接口的区别Enumeration最早出来主要是针对当时所有的集合类的如Vector和HashTable的。但是由于原本Vector与Hashtable设计上的问题，以及Enumeration在设计上的一些缺陷到之后来出现了Iterator替代了它。 并且Iterator支持所有集合类。并对Enumeration进行了扩展，1. 添加了一个可选择的删除操作。并且在2. 函数命名上也更加科学，简洁了。同时Iterator也在并发操作的时候针对其实现类在并发情况下可能出现的3.并发修改问题利用fail-fast机制进行补足。Enumeration由于本身针对的就是并发情况下同步的类Vector和HashTable所以不存在并发上的问题。 十、ListIterator的特点我们前面说到Enumeration最早吹来是服务于Vector和HashTable来进行遍历的。后来Iterator的出现替代了它，但是对应不同的集合类迭代方式也不尽相同。所以ListIterator继承自Iterator，看类名就知道他是负责List集合的迭代的。 继承自Iterator接口，用于遍历List集合的元素。 可以实现双向遍历。添加元素。设置元素 十一、Java中HashMap的key值要是为类对象则该类需要满足什么条件？需要同时重写该类的hashCode()方法和它的equals()方法。 因为HashMap在插入元素的时候在put函数中就会向调用的putVal函数传递key的hash值。然后putVal函数再对key的哈希值进行散列，找到对应的桶。既然这样，那和重写对象到的hashcode有什么关系呢？ 那是因为我们的对象做为key来存到hashMap中的话，我们最后肯定是根据key来获取到对应的value。而这个entry又存储在桶中，我们要想找到对应的桶，对于HashMap函数来说只能通过对象的hashcode值来进行散列，散列到对应的桶上。但是我们存储和取出的时候其实用的是两个对象(两次都会new新的对象)。但是两个对象具有相同的属性值。 如果我们不重写对象的hashcode的函数的话，去更改他hash值的生成策略的话是无法散列到对应的桶的(根据对象地址生成的hash值)。也就无法取出我们存进去的值。所以我们需要重写它的hashcode函数让它生成是只需要根据对象的属性进行生成即可，这样下次我们无论穿进去这个类的哪个对象，只要它保证我们指定的生成hashcode参考的属性相等即可。equals函数就更不用说了，Object类的equals默认比较的是两个对象的地址。而对我们开发来说这样的意义并不大。一般来说我们认为只要两个对象的成员变量的值是相等的，那么我们就认为这两个对象是相等的！ 显然hashcode相比于equals函数具偶然性。在hashmap元素的比较中也是把hash值得比较前置了。因为hashcode可能在一些情况下出现hash碰撞相等的情况。所以我们重写equals函数前必须先重写hashcode函数，这样既保证了正确性，也在性能上得到了提升。 十二、与Java集合框架相关的有哪些最好的实践 根据需要确定集合的类型。如果是单列的集合，我们考虑用Collection下的子接口ArrayList和Set。如果是映射，我们就考虑使用Map 确定完我们的集合类型，我们接下来确定使用该集合类型下的哪个子类~我认为可以简单分成几个步骤： 是否需要同步 找线程安全的集合类使用 迭代时是否需要有序(插入顺序有序) 找Linked双向列表结构的 是否需要排序(自然顺序或者手动排序) 找Tree红黑树类型的(JDK1.8) 估算存放集合的数据量有多大，无论是List还是Map，它们实现动态增长，都是有性能消耗的。在初始集合的时候给出一个合理的容量会减少动态增长时的消耗 使用泛型，避免在运行时出现ClassCastException 尽可能使用Collections工具类，或者获取只读、同步或空的集合，而非编写自己的工具函数。它提供了我们常用的针对List集合的功能函数，具有很高的重用性，以及更好的稳定性和可维护性。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Set集合了解一下]]></title>
    <url>%2Fset.html</url>
    <content type="text"><![CDATA[前言 本文使用用的是jdk1.8 Set 接口我们前面再Collection集合的文章中已经简单的说过Set集合的特点。 不包含重复元素，即两个元素e1.equals(e2)不可相等。 需要注意的是： 当可变对象存储到Set集合中的时候，如果通过一种可以影响对象的equals函数的比较结果的方式改变了该对象的话那么Set集合的行为则是不确定的。 Set 集合的常见实现类 HashSet：底层是通过HashMap来实现的，所以底层数据结构式是 散列表+红黑树 的数据结构。 TreeSet：底层数据结构是通过NavigableMap来实现的，底层数据结构是 红黑树。可保证元素的排列方式 LinkedHashSet：继承自HashSet，和LinkedHashMap意义相似，底层数据结构是 散列表+双向链表 HashSet 总的来说： 实现了Set接口，底层其实是一个HashMap实例，所以由于HashMap的特性，无法保证元素的迭代的顺序(HashMap扩容后的重散列会导致元素存储位置的变更)。同时和HashMap一样可以使用null元素做键值，但只能是一个。 对Set结合进行迭代所需的时间与HashSet实例的大小(元素的数量)和底层HashMap实例（桶的数量）的“容量”的和成比例。如果某个Set的迭代性能比较重要，不要将初始容量设置的太高，或者将加载因子设置的太小(会出现很多空桶)。 非同步，并发不安全。可以程序外部手动同步，也可以借助Collections.synchronizedSet函数来对该Set集合进行包装来实现同步。 迭代器是快速失败的 HashSet的属性及函数 一眼看上去还是很简单的。只有两个属性，一个是它具体实现类HsahMap，另一个则是一个Object实例。这个Object实例在这里是充当HashMap实例中所有元素的公共value的。因为我们HashSet底层是通过HashMap来实现的，所有元素实际都存储在key中，那么所对应的value如果不赋值则是null值得存在。所以HashSet的处理方式就是将所有元素的value都赋予该Object实例。 所以整个HashSet整体上来说几乎所有的操作都是在底层操作了一个HashMap实例。根据上图我们来看一下HashSet所实现的Set接口的函数都是怎么实现的。 1234567891011121314151617181920212223public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;public void clear() &#123; map.clear();&#125;public boolean contains(Object o) &#123; return map.containsKey(o);&#125;public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator();&#125;public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125;public int size() &#123; return map.size();&#125; 所有的构造函数所做的也是统一的初始化HashMap的操作1234567891011121314151617181920public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125;HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; TreeSet 总的来说： 底层实现：和HashSet实现方式一样，底层其实是由一个TreeMap实例来实现的。并实现了NavigableSet接口，是一个基于TreeMap的NavigableSet的实现 有序：由于实现的NavigableSet接口继承自SortedSet接口，所以存入TreeSet的所有元素都必须是实现了Comparable接口的，即保证这些元素在存入TreeSet的时候在通过compareTo函数进行比较并自然排序的时候不会报ClassCastException。或者也可以在Set实例构造的时候通过传入的 Comparator来进行控制排序。 非同步：并发线程不安全。还是老样子，倘若想同步需要函数外手动进行控制，或者在创建Set集合的时候借助Collections类。Collections.synchronizedSortedSet的方法来对某个Set集合进行包装。 迭代器：迭代器是快速失败的 复杂度：基本操作函数如add,remove,contains的复杂度都是log(n)级别的(TreeMap底层红黑树)。 TreeSet的属性和函数 从图可以很明显的看出它的实现机制和HashSet是一模一样的。底层通过NavigableMap来实现，而NavigableMap则只有TreeMap这一个实现类。我们也可以称之为底层是由TreeMap来实现的，而Object实例则是充当所有元素的value的存在。 我们来看一下TreeSet的5个构造函数都是如何实现的123456789101112131415161718192021public TreeSet() &#123; this(new TreeMap&lt;E,Object&gt;());&#125;public TreeSet(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125;public TreeSet(Comparator&lt;? super E&gt; comparator) &#123; this(new TreeMap&lt;&gt;(comparator));&#125;TreeSet(NavigableMap&lt;E,Object&gt; m) &#123; this.m = m;&#125;public TreeSet(SortedSet&lt;E&gt; s) &#123; this(s.comparator()); addAll(s);&#125; 还是清晰的。都是通过构造一个TreeMap来实现整个TreeSet的所有操作的。 LinkedHashSet 总的来说： 实现：LinkedHashSet底层由散列表和双向链表来实现的。这一点和LinkedHashMap一样。LinkedHashSet由HashSet和LinkedList共同来实现的。底层是HashMap，只是各节点Entry另外的还添加了两个属性before和after，通过双向列表来链接。 迭代：迭代有序，由于所有元素都通过LinkedeList双向链表来维护，所以将按照元素插入到set中的顺序（插入顺序）进行迭代。需要注意的是如果一个元素已经存在于LinkedHashSet中如果再插入该元素的话，该元素会被重新插入。并且迭代的时候和HashSet容量没有关系。因为它结构中维护的一个双向链表，迭代的时候是迭代这个双向链表。相比于此HashSet迭代时则要受到容器容量很大的限制。 优点 使用LinkedHashSet可以不用像HashSet一样元素杂乱无序，而保证元素一定的有序性，可以做到TreeSet的功能却不用TreeSet的成本。 初始容量的大小对LinkedHasSet的影响要比对HashSet小很多，因为它在迭代的时候不受容器大小的影响。 缺点 性能比HashSet要差一点儿，因为还要维护一个双向链表。 允许null。非同步的，迭代是快速失败的 LinkedHashSet的属性和函数 很纯粹的类，没有自己实现的东西。所有的函数都是继承自各个父类 我们来看一下它的构造函数：1234567891011121314151617public LinkedHashSet(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor, true);&#125;public LinkedHashSet(int initialCapacity) &#123; super(initialCapacity, .75f, true);&#125;public LinkedHashSet() &#123; super(16, .75f, true);&#125;public LinkedHashSet(Collection&lt;? extends E&gt; c) &#123; super(Math.max(2*c.size(), 11), .75f, true); addAll(c);&#125; 可以看出，都是去构造其父类HashSet。 总结可以看到整个Set集合的实现都是Map映射。 HashSet：无序，允许为null，底层是HashMap(散列表+红黑树)，非线程同步 TreeSet：有序，不允许为null，底层是TreeMap(红黑树)，非线程同步 LinkedHashSet：迭代有序，允许为null，底层是HashMap+双向链表，非线程同步]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConCurrentHashMap了解一下]]></title>
    <url>%2FconCurrentHashMap.html</url>
    <content type="text"><![CDATA[前言 本人使用的是jdk1.8 ConcurrentHashMap 1.7首先我们来回顾一下在jdk1.7当中ConcurrentHashMap是如何实现的。 还在jdk1.7的时候ConcurrentHashMap的底层数据结构其实是由Segment数组和多个HashEntry组成。如图： Segment数组的意义就是将一个大的table分割成多个小的table来进行加锁，也就是上面的提到的锁分段技术，而每一个Segment元素存储的是HashEntry数组+链表，这个和HashMap的散列表+链表的数据存储结构是一样的。这里的每个table就像我们之前所说的HashTable一样。 不同于HashTable为了并发情况下的安全性锁整个table那么暴力不同，ConcurrentHashMap的处理方式则是对其进行了优化，是把一个大table分割成小table来分别锁住。也就是我们常说的锁分段。 同时从源码中我们可以看出，Segment继承了ReentrantLock(独占锁)类。使大table中的每个小table都有了一个锁。1static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable ConcurrentHashMap 1.8在jdk1.8中，ConCurrentHashMap的数据结构底层是：散列表+链表+红黑树，其变化与HashMap在1.8的变化是一样的。 ConcurrentHashMap头注释信息123456789101112131415161718192021222324252627282930313233343536/** * A hash table supporting full concurrency of retrievals and * high expected concurrency for updates. This class obeys the * same functional specification as &#123;@link java.util.Hashtable&#125;, and * includes versions of methods corresponding to each method of * &#123;@code Hashtable&#125;. However, even though all operations are * thread-safe, retrieval operations do &lt;em&gt;not&lt;/em&gt; entail locking, * and there is &lt;em&gt;not&lt;/em&gt; any support for locking the entire table * in a way that prevents all access. This class is fully * interoperable with &#123;@code Hashtable&#125; in programs that rely on its * thread safety but not on its synchronization details. * * &lt;p&gt;Retrieval operations (including &#123;@code get&#125;) generally do not * block, so may overlap with update operations (including &#123;@code put&#125; * and &#123;@code remove&#125;). Retrievals reflect the results of the most * recently &lt;em&gt;completed&lt;/em&gt; update operations holding upon their * onset. (More formally, an update operation for a given key bears a * &lt;em&gt;happens-before&lt;/em&gt; relation with any (non-null) retrieval for * that key reporting the updated value.) For aggregate operations * such as &#123;@code putAll&#125; and &#123;@code clear&#125;, concurrent retrievals may * reflect insertion or removal of only some entries. Similarly, * Iterators, Spliterators and Enumerations return elements reflecting the * state of the hash table at some point at or since the creation of the * iterator/enumeration. They do &lt;em&gt;not&lt;/em&gt; throw &#123;@link * java.util.ConcurrentModificationException ConcurrentModificationException&#125;. * However, iterators are designed to be used by only one thread at a time. * Bear in mind that the results of aggregate status methods including * &#123;@code size&#125;, &#123;@code isEmpty&#125;, and &#123;@code containsValue&#125; are typically * useful only when a map is not undergoing concurrent updates in other threads. * Otherwise the results of these methods reflect transient states * that may be adequate for monitoring or estimation purposes, but not * for program control. * * ······ * ······ */ 从头注释中我们可以知道： ConcurrentHashMap支持高并发情况下对哈希表的访问和更新。 ConcurrentHashMap与HashTable相似，与HashMap不同。 ConcurrentHashMap的所有操作都是线程安全的。 它不允许null用作键或值 get操作没有上锁。是非阻塞的。所以在并发情况下可以与阻塞的put或remove函数交迭。但在聚合操作下比如putAll和clean，并发情况下由于线程调度的原因get函数可能只能检索到插入和删除的一些Entries(函数还未执行完)。 与get函数的处理相类似的还有Iterators, Spliterators,Enumerations，在其创建时或之后，倘若ConcurrentHashMap再发生改变就不会再抛ConcurrentModificationException了。取而代之的是在其改变时new新的数据从而不影响原有的数据，Iterator会在其完成后再将头指针替换为新的数据，这样Iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变，更重要的，这保证了多个线程并发执行的连续性和扩展性，是性能提升的关键。 不过，迭代器被设计成每次仅由一个线程使用。 同时需要注意：size,isEmpty,containsValue等函数的使用，在ConcurrentHashMap实例并发情况下是无意义的。它只能反映该实例的一个暂态，除非此时它并未发生并发修改。 ConcurrrentHashMap关键属性由于ConcurrentHashMap的属性众多，我们挑几个典型关键的来进行分析。 volatile Node&lt;K,V&gt;[] table：装载Node的数组，作为ConcurrentHashMap的数据容器，采用懒加载的方式，直到第一次插入数据的时候才会进行初始化操作，数组的大小总是为2的幂次方。 transient volatile Node&lt;K,V&gt;[] nextTable：扩容时使用，平时为null，只有在扩容的时候才为非null transient volatile long baseCount：元素数量基础计数器，该值也是一个阶段性的值(产出的时候可能容器正在被修改)。通过CAS的方式进行更改。 transient volatile int sizeCtl：散列表初始化和扩容的大小都是由该变量来控制。 当为负数时，它正在被初始化或者扩容。 -1表示正在初始化 -N表示N-1个线程正在扩容 当为整数时， 此时如果当前table数组为null的话表示table正在初始化过程中，sizeCtl表示为需要新建的数组的长度，默认为0 若已经初始化了,表示当前数据容器（table数组）可用容量也可以理解成临界值（插入节点数超过了该临界值就需要扩容）,具体指为数组的长度n 乘以 加载因子loadFactor。 当值为0时，即数组长度为默认初始值。 static final sun.misc.Unsafe U：在ConcurrentHashMapde的实现中可以看到大量的U.compareAndSwapXXXX的方法去修改ConcurrentHashMap的一些属性。这些方法实际上是利用了CAS算法保证了线程安全性，这是一种乐观策略，假设每一次操作都不会产生冲突(变量实际值!=期望值)，当且仅当冲突发生的时候再去尝试。 在大量的同步组件和并发容器的实现中使用CAS是通过sun.misc.Unsafe类实现的。该类提供了一些可以直接操控内存和线程的底层操作，可以理解为java中的“指针”。该成员变量的获取是在静态代码块中：12345678static &#123; try &#123; U = sun.misc.Unsafe.getUnsafe(); ······ &#125; catch (Exception e) &#123; throw new Error(e); &#125;&#125; CAS操作依赖于现代处理器指令集，通过底层CMPXCHG指令实现。CAS(V,O,N)核心思想为：若当前变量实际值V与期望的旧值O相同，则表明该变量没被其他线程进行修改，因此可以安全的将新值N赋值给变量；若当前变量实际值V与期望的旧值O不相同，则表明该变量已经被其他线程做了处理，此时将新值N赋给变量操作就是不安全的，再进行重试。 ConcurrentHashMap为何存在我们知道由于HashMap在多线程情况下是线程不安全的。而和其对应的HashTable虽然是线程安全的，但是却是十分极端的在所有涉及多线程的操作上都加上了synchronized关键字来锁住整个table。这就意味着在多线程情况下，所有的线程都在竞争同一把锁。虽然是线程安全的，但是却无疑是效率低下的。 其实HashTable有很多的优化空间，锁住整个table这么粗暴的方法可以变相的柔和点，比如在多线程的环境下，对不同的数据集进行操作时其实根本就不需要去竞争一个锁，因为他们不同hash值，不会因为rehash造成线程不安全，所以互不影响，这就是锁分离技术，将锁的粒度降低，利用多个锁来控制多个小的table，这就是ConcurrentHashMap的核心思想 总而言之： Hashtable是在每个方法上都加上了Synchronized完成同步，效率低下。 ConcurrentHashMap通过在部分加锁和利用CAS算法来实现同步。 CAS算法上面我们提到ConcurrentHashMap是通过CAS算法来实现同步的。接下来我们就简单了解一下什么是CAS算法 什么是CASCAS: 全称Compare and swap，字面意思:”比较并交换“，一个 CAS 涉及到以下操作： 12345我们假设内存中的原数据V，旧的预期值A，需要修改的新值B。比较 A 与 V 是否相等。（比较）如果比较相等，将 B 写入 V。否则什么都不做（交换）返回操作是否成功。 当多个线程尝试使用CAS同时更新同一个变量的时候，只有其中一个线程能够更新变量的值。当其他线程失败后，不会像获取锁一样被挂起，而是可以再次尝试，或者不进行任何操作，这种灵活性就大大减少了锁活跃性风险。 我们知道采用锁对共享数据进行处理的话，当多个线程竞争的时候，都需要进行加锁，没有拿到锁的线程会被阻塞，以及唤醒，这些都需要用户态到核心态的转换，这个代价对阻塞线程来说代价还是蛮高的，那cas是采用无锁乐观方式进行竞争，性能上要比锁更高些才是，为何不对锁竞争方式进行替换？ 在高度竞争的情况下，锁的性能将超过cas的性能，但在中低程度的竞争情况下，cas性能将超过锁的性能。多数情况下，资源竞争一般都不会那么激烈。 参考：java多线程——CAS ConcurrentHashMap构造函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 构造一个空map映射，初始容量16public ConcurrentHashMap() &#123;&#125;// 初始化时明确给定一个初始容量，减少resize次数public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); // tableSizeFor 函数返回一个最接近入参 initialCapacity 容量的2进制整数 int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125;// 创建一个与给定的 Map 映射具有相同元素的 ConcurrentHashMappublic ConcurrentHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; // 我们前面所述 sizeCtl 两个含义，构造和扩容。 // 此处必然是构造容量为 DEFAULT_CAPACITY = 16 的 ConcurrentHashMap this.sizeCtl = DEFAULT_CAPACITY; putAll(m);&#125;public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; // 初始化数组容量，防止直接迭代insert导致频繁扩容 tryPresize(m.size()); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) putVal(e.getKey(), e.getValue(), false);&#125;// 构造一个空的 Map 映射，并给定其初始容量与加载因子public ConcurrentHashMap(int initialCapacity, float loadFactor) &#123; this(initialCapacity, loadFactor, 1);&#125;// 构造一个空的 Map 映射，并给定其初始容量，加载因子与预估的并发更新的线程数public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins // 该情况下，一个更新线程负责一个HashEntry initialCapacity = concurrencyLevel; // as estimated threads // 确定 table 的初始容量 = 初始容量 initialCapacity / 元素密度 loadFactor // 比如你有30个元素，构造Map的时候传入30和0.75，那么table真实容量就应该是 30/0.75。保证你元素数量是table容器的0.75倍 long size = (long)(1.0 + (long)initialCapacity / loadFactor); int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap;&#125; 需要注意的就是最后一个构造函数中引用的tableSizeFor函数：12345678910111213/** * Returns a power of two table size for the given desired capacity. * See Hackers Delight, sec 3.2 */private static final int tableSizeFor(int c) &#123; int n = c - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 通过注释就很清楚了，该方法会将调用构造器方法时指定的大小转换成一个2的幂次方数，也就是说ConcurrentHashMap的大小一定是2的幂次方，比如，当指定大小为18时，为了满足2的幂次方特性，实际上concurrentHashMapd的大小为2的5次方（32）。 另外，需要注意的是，调用构造器方法的时候并未构造出table数组（可以理解为ConcurrentHashMap的数据容器），只是算出table数组的长度，当第一次向ConcurrentHashMap插入数据的时候才真正的完成初始化创建table数组的工作。 ConcurrentHashMap 常见Api解析initTable()1234567891011121314151617181920212223242526private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) // 1. 保证只有一个线程正在进行初始化操作 Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; // 2. 得出数组的大小 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) // 3. 这里才真正的初始化数组 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; // 4. 计算数组中可用的大小：实际大小n*0.75（加载因子） sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 代码的逻辑请见注释，有可能存在一个情况是多个线程同时走到这个方法中，为了保证能够正确初始化，在第1步中会先通过if进行判断，若当前已经有一个线程正在初始化即sizeCtl值变为-1，这个时候其他线程在If判断为true从而调用Thread.yield()让出CPU时间片。正在进行初始化的线程会调用U.compareAndSwapInt方法将sizeCtl改为-1即正在初始化的状态。 另外还需要注意的事情是，在第四步中会进一步计算数组中可用的大小即为数组实际大小n乘以加载因子0.75.可以看看这里乘以0.75是怎么算的，0.75为四分之三，这里n - (n &gt;&gt;&gt; 2)是不是刚好是n-(1/4)n=(3/4)n，挺有意思的吧:)。如果选择是无参的构造器的话，这里在new Node数组的时候会使用默认大小为DEFAULT_CAPACITY（16），然后乘以加载因子0.75为12，也就是说数组的可用大小为12。 putVal(K key, V value, boolean onlyIfAbsent)当且仅当table中不存在该key对应的Entry时才插入该Entry。否则不替换table中原有的Entry中的value123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); // 1. 计算key的hash值，与HashMap处理逻辑一样 int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 2. 如果当前table还没有初始化先调用initTable方法将tab进行初始化 if (tab == null || (n = tab.length) == 0) tab = initTable(); // 3. tab中索引为i的位置的元素为null，则直接使用CAS将值插入即可 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; /* 4. 如果要插入的位置是一个forwordingNode节点，表示正在扩容，那么当前线程帮助扩容 这里我有个问题：为什么该位置会是forwordingNode节点 */ else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else &#123; V oldVal = null; // 5. 进行到这一步，说明要插入的位置有值，需要对该桶加锁。 synchronized (f) &#123; // 确定f是tab中的头节点 if (tabAt(tab, i) == f) &#123; // fh = 桶首元素的hast值。如果头结点的哈希值大于等于0，说明要插入的节点在(链表)中。否则有可能该桶的数据结构不是链表而是红黑树 if (fh &gt;= 0) &#123; binCount = 1; // 开始迭代找key的节点，f = 桶首元素 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 如果某一节点的key的哈希值及key与参数相等，替换该节点的value if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; // 没有找到则继续向后迭代，当迭代到最后一个元素还没有找到时，将该Entry插入到链表尾。 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 6. 如果要插入的节点在红黑树中，则按照树的方式插入或替换节点 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // 7. 如果binCount不为0，说明插入或者替换操作完成了 if (binCount != 0) &#123; // 判断节点数量是否大于等于8，如果是就需要把链表转化成红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) // 链表转成红黑树 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // 8. 对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容 // 能执行到这一步，说明节点不是被替换的，是被插入的，否则在binCount判断 !=0 的时候就要被return了。 addCount(1L, binCount); return null;&#125;private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 整体流程下来就是： 计算key哈希值 根据哈希值计算在table中的位置 根据哈希值执行插入或替换操作 如果这个位置没有值，直接将键值对放进去，不需要加锁。 如果要插入的位置是一个forwordingNode节点，表示正在扩容，那么当前线程帮助扩容 加锁。以下操作都需要加锁。 如果要插入的节点在链表中，遍历链表中的所有节点，如果某一节点的key哈希值和key与参数相等，替换节点的value，记录被替换的值；如果遍历到了最后一个节点，还没找到key对应的节点，根据参数新建节点，插入链表尾部 如果要插入的节点在树中，则按照树的方式插入或替换节点。如果是替换操作，记录被替换的值 判断节点数量是否大于8，如果大于就需要把链表转化成红黑树 如果操作3中执行的是替换操作，返回被替换的value。程序结束。 能执行到这一步，说明节点不是被替换的，是被插入的，所以要将map的元素数量加1。 get(Object key)据我们之前的类头注释所译。get函数没有必要加锁的。但是可以看到的是ConcurrentHashMap对其Node类的next属性加上了volatile关键字进行修饰。来保证并发情况下其他线程若正在与get函数同步的修改该节点的next属性，保证了它的可见性。123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; // 散列key int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 根据key的散列值h来找到桶头元素e if ((eh = e.hash) == h) &#123; // key相等值相等，则桶头元素刚好就是所找元素 if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 如果hash &lt; 0 那么在红黑树中 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; // 在该桶的链表上，不是桶头元素上，迭代继续向下寻找 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 整体流程： 首先先看当前的hash桶数组节点即table[i]是否为查找的节点，若是则直接返回；若不是，则继续再看当前是不是树节点？通过看节点的hash值是否为小于0，如果小于0则为树节点。如果是树节点在红黑树中查找节点；如果不是树节点，那就只剩下为链表的形式的一种可能性了，就向后遍历查找节点，若查找到则返回节点的value即可，若没有找到就返回null。 ConcurrrentHashMap关键类Node内部类Node类实现了Map.Entry接口，主要存放key-value对，并且具有next域1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; ......&#125; 另外可以看出很多属性都是用volatile进行修饰的，也是为了保证并发情况下的该属性的可见性。同事对hash和key用final进行修饰也是提供了这两个常用变量的缓存，性能上有所提高。 TreeNode 树节点继承于承载数据节点Node类。而红黑树的操作是针对TreeBin类的，从该类的注释也可以看出，也就是TreeBin会将TreeNode进行再一次封装1234567static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; ······ TreeBin 树箱这个类并不负责包装用户的key、value信息，而是包装的很多TreeNode节点。实际的ConcurrentHashMap“数组”中，存放的是TreeBin对象，而不是TreeNode对象。1234567891011static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock ····· &#125; ForwardingNode在扩容时才会出现的特殊节点，其key,value,hash全部为null。并拥有nextTable指针引用新的table数组。12345678static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125; ······ &#125; CAS 关键操作我们之前说到，在ConcurrentHashMap中会有大量的CAS操作来修改它的一些属性和操作。所以先来看一些常用的CAS操作是如何保证线程安全的 tabAt获取table数组中索引为i的Node元素。123static final &lt;K,V&gt; Node&lt;K,V&gt; tabAt(Node&lt;K,V&gt;[] tab, int i) &#123; return (Node&lt;K,V&gt;)U.getObjectVolatile(tab, ((long)i &lt;&lt; ASHIFT) + ABASE);&#125; casTabAt利用CAS操作设置table数组中索引为i的元素1234static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125; compareAndSwapInt1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 这是一个Native函数。函数的作用是修改当前类的var2属性。如果var2属性和var4属性一样的就修改，否则什么都不做。 总结 底层结构是散列表(数组+链表)+红黑树，这一点和HashMap是一样的。 Hashtable是将所有的方法进行同步，效率低下。而ConcurrentHashMap作为一个高并发的容器，它是通过synchronized+CAS算法来进行实现线程安全的。使用3个CAS操作来确保node的一些操作的原子性，这种方式代替了锁。 采用synchronized而不是ReentrantLock。 CAS算法是乐观锁的一种 ConcurrentHashMap的key和Value都不能为null get方法是非阻塞，无锁的。重写Node类，通过volatile修饰next来实现每次获取都是最新设置的值。相比于在jdk1.7中的变化就是不采用segment而采用node，锁住node来实现减小锁粒度。 sizeCtl的不同值来代表不同含义，起到了控制的作用。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TreeMap了解一下]]></title>
    <url>%2Ftreemap.html</url>
    <content type="text"><![CDATA[前言 本文使用用的是jdk1.8 TreeMap 基于红黑树的NavigableMap的实现。 TreeMap实现了NavigableMap接口，而NavigableMap接口继承着SortedMap接口，致使我们的TreeMap符合SotredMap接口的定义。TreeMap根据key自然顺序进行排序，或者在构造实例构造的时候传递 Comparator 进行自定义规则排序。 由于是实现自SortedMap，所以存入TreeMap的所有元素的key都必须是实现了Comparable接口的，即保证其key相互调用k1.compareTo(k2)的时候不会报ClassCastException。 containsKey、get、put 和 remove 函数的时间复杂度是log(n) 有序映射使用它的compareTo（或compare）方法对所有键进行比较，只要这两个方法认为相等，那么在有序映射中的两个键就是相等的。 非同步的 此类方法返回的所有Entry是其真实的映射关系的快照。它们不支持Entry.setValue方法来更改值。不过put函数是可以的 TreeMap类继承图 实现了NavigableMap接口，而NavigableMap接口继承着SortedMap接口，致使我们的TreeMap符合SotredMap接口的定义。元素有序 不同的是SortdeMap要求：插入SortedMap的所有元素的键都必须实现 Comparable 接口。或者类型在Comparator类(对应TreeMap维护的comparator变量)中所接受。即对有序映射中的任意两个键 k1 和 k2 执行 k1.compareTo(k2)（或 comparator.compare(k1, k2)）必须是正确的。 TreeMap的域12345678910111213141516171819/** * The comparator used to maintain order in this tree map, or * null if it uses the natural ordering of its keys. * * @serial */private final Comparator&lt;? super K&gt; comparator;private transient Entry&lt;K,V&gt; root;/** * The number of entries in the tree */private transient int size = 0;/** * The number of structural modifications to the tree. */private transient int modCount = 0; comparator:TreeMap中维护了一个Comparator类型的变量。用来保证TreeMap的有序性。构造时传入该比较器 root：红黑树根节点 size: Entry数量 modCount：结构性修改的次数 TreeMap的构造函数1234567891011121314151617181920212223public TreeMap() &#123; comparator = null;&#125;public TreeMap(Comparator&lt;? super K&gt; comparator) &#123; this.comparator = comparator;&#125;public TreeMap(Map&lt;? extends K, ? extends V&gt; m) &#123; comparator = null; putAll(m);&#125;public TreeMap(SortedMap&lt;K, ? extends V&gt; m) &#123; comparator = m.comparator(); try &#123; buildFromSorted(m.size(), m.entrySet().iterator(), null, null); &#125; catch (java.io.IOException cannotHappen) &#123; &#125; catch (ClassNotFoundException cannotHappen) &#123; &#125;&#125; 共四个，每个都对其实例维护的Comparator引用进行了赋值。 TreeMap()：无参构造函数规定，插入该有序Map的所有元素的键都必须实现Comparable接口，保证了其的可比较性。进而根据其键的自然排序来生成一个有序Map。 TreeMap(Comparator&lt;? super K&gt; comparator)：参数是Comparator引用的构造函数规定，插入该有序Map的所有元素的键都需要根据该Comparator来进行比较。 TreeMap(Map&lt;? extends K, ? extends V&gt; m)：参数是一个Map映射的构造函数会在其元素基础上构造一个TreeMap。同时该TreeMap规定元素需要满足TreeMap的默认规定，即和无惨构造函数所要求的一样。 TreeMap(SortedMap&lt;K, ? extends V&gt; m)：参数是SortedMap的构造函数会拷贝一份和其相同元素和顺序的TreeMap。线性时间 TreeMap常见Api解析put(K key, V value)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = root; // 如果红黑树为空 if (t == null) &#123; // key非空检查 compare(key, key); // type (and possibly null) check root = new Entry&lt;&gt;(key, value, null); size = 1; modCount++; return null; &#125; int cmp; Entry&lt;K,V&gt; parent; // split comparator and comparable paths Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123;// 根据自定义比较器进行比较 // 根据key找到元素在树中应该落点的位置 do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; else &#123;// 根据元素的键实现的Comparable接口进行比较 if (key == null)// key不允许为null throw new NullPointerException(); @SuppressWarnings(&quot;unchecked&quot;) Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; do &#123;// 根据key找好元素在树的中落点 parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; // 循环跳出，parent即元素所在点的父节点。 Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent); if (cmp &lt; 0) parent.left = e; else parent.right = e; // 调整红黑树 fixAfterInsertion(e); size++; modCount++; return null;&#125; put函数规定：如果Entry已经存在那么oldValue替换成newValue。如果Entry第一次插入，返回null。 函数整体逻辑：判断当前红黑树是否为空，key是否为空检查，实例变量的维护。通过Comparable或者Comparator来找元素的落点，然后赋值。最后调整红黑树 Comparable接口的排序了解一下该接口强行对实现它的每个类的对象进行整体排序(隐式的)。这种排序被称为类的自然排序，类的 compareTo 方法被称为它的自然比较方法。 实现了这个接口的对象的列表或数组可以通过其Collections.sort或Arrays.sort进行自动排序。 同时实现该接口的对象可以用作有序映射中的键或有序集合中的元素，无需再指定比较器。 一般的继承该接口的类型比较的时候，我们应该尽量保证其compareTo函数的比较结果与equals函数的比较结果一致。 Comparator接口的排序了解一下强行对某个对象 collection 进行整体排序 的接口。可以将 Comparator 传递给 sort 方法（如 Collections.sort 或 Arrays.sort），从而允许在排序顺序上实现精确控制。还可以使用 Comparator 来控制某些数据结构（如有序 set或有序映射）的顺序，或者为那些没有自然顺序的对象 collection 提供排序。 Comparable与Comparator接口比较总结相比于Comparable接口的比较，Comparator的比较规则则是一种自定义规则的比较。也就意味着，对于实现了Comparable接口的类来说如果要想排序必须实现其compareTo函数，并且只有这一种方式。相比于我们自定义比较器可以有多个实现类的多个比较器的比较方式而言比较单一。并且没有比较器那么自由，可以随意安插。 Comparator体现了一种策略模式，就是不改变对象自身，而用一个策略对象来改变它的行为。 总的来说 Comparable是自已完成比较，Comparator是外部程序实现比较。 两种方法各有优劣,用Comparable简单,只要实现Comparable 接口的对象直接就成为一个可以比较的对象,但是需要修改源代码,用Comparator的好处是不需要修改源代码, 而是另外实现一个比较器,当某个自定义的对象需要作比较的时候,把比较器和对象一起传递过去就可以比大小了, 并且在Comparator里面用户可以自己实现复杂的可以通用的逻辑,使其可以匹配一些比较简单的对象,那样就可以节省很多重复劳动了。 get(Object key)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public V get(Object key) &#123; Entry&lt;K,V&gt; p = getEntry(key); return (p==null ? null : p.value);&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; // Offload comparator-based version for sake of performance if (comparator != null) // 自定义比较器存在，那么就调用getEntryUsingComparator函数来从红黑树中来找对应的Entry return getEntryUsingComparator(key); if (key == null) throw new NullPointerException(); @SuppressWarnings(&quot;unchecked&quot;) Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key; Entry&lt;K,V&gt; p = root; while (p != null) &#123; // 否则通过Comparable接口的compareTo函数来找 int cmp = k.compareTo(p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; return null;&#125;// 函数很简单，从红黑树中找到key对应的Entry并返回final Entry&lt;K,V&gt; getEntryUsingComparator(Object key) &#123; @SuppressWarnings(&quot;unchecked&quot;) K k = (K) key; Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = cpr.compare(k, p.key); if (cmp &lt; 0) p = p.left; else if (cmp &gt; 0) p = p.right; else return p; &#125; &#125; return null;&#125; remove(Object key)函数的作用：删除该Entry，并返回Entry.value12345678910public V remove(Object key) &#123; // 从红黑树中找到对应的Entry Entry&lt;K,V&gt; p = getEntry(key); if (p == null) return null; V oldValue = p.value; deleteEntry(p); return oldValue;&#125; 上面我们分析过了getEntry的函数逻辑。而deleteEntry函数的主要作用则是删除红黑树中该节点并且调整红黑树。设计红黑树的比较复杂这里就不细说了 遍历12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * Base class for TreeMap Iterators */abstract class PrivateEntryIterator&lt;T&gt; implements Iterator&lt;T&gt; &#123; // 下一个要迭代到的元素 Entry&lt;K,V&gt; next; // 迭代最后一次所返回的元素 Entry&lt;K,V&gt; lastReturned; int expectedModCount; PrivateEntryIterator(Entry&lt;K,V&gt; first) &#123; expectedModCount = modCount; lastReturned = null; next = first; &#125; public final boolean hasNext() &#123; return next != null; &#125; final Entry&lt;K,V&gt; nextEntry() &#123; Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); next = successor(e); lastReturned = e; return e; &#125; final Entry&lt;K,V&gt; prevEntry() &#123; Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); next = predecessor(e); lastReturned = e; return e; &#125; public void remove() &#123; if (lastReturned == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); // deleted entries are replaced by their successors if (lastReturned.left != null &amp;&amp; lastReturned.right != null) next = lastReturned; deleteEntry(lastReturned); expectedModCount = modCount; lastReturned = null; &#125;&#125;// 返回下一个要迭代的元素static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) &#123; if (t == null) return null; // 如果元素有右子树开始迭代右子树(因为既然遍历到了该元素，左子树肯定遍历完了) else if (t.right != null) &#123; Entry&lt;K,V&gt; p = t.right; // 找右子树中最小的 while (p.left != null) p = p.left; return p; &#125; else &#123; // 该返回其父节点了 Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; // 下一个该返回的节点下左右子树全部清空，往上追溯，确认该节点的位置 while (p != null &amp;&amp; ch == p.right) &#123; ch = p; p = p.parent; &#125; return p; &#125;&#125; 对于successor函数我们需要时刻清晰，其迭代顺序是前序遍历的。先左后中后右 总结 TreeMap底层是红黑树，能够实现该Map集合有序，很多函数的时间复杂度甚至可以到O(logn) key不能为null 想要自定义比较，在构造方法中传入Comparator对象，否则使用key的自然排序来进行比较 非同步，除非外部手动同步或者Collections封装。 该数据结构的精髓： 如果在构造方法中传递了Comparator对象，那么就会以Comparator对象的方法进行比较，来排序。否则，则使用Comparable的compareTo(T o)方法来比较排序。 需要注意的是 如果TreeMap使用Comparable接口来保证有序，那么使用其compareTo(T o)函数来比较时，key不能为null，并且该key必须实现了Comparable接口。 相对的如果是使用的是Comparator接口，使用compare函数来比较，key也不能为null，并且必须是Comparator接口支持的泛型类型。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedHashMap了解一下]]></title>
    <url>%2Flinkedhashmap.html</url>
    <content type="text"><![CDATA[前言 本文使用用的是jdk1.8 LinkedHashMap类继承图我们先来了解一下LinkedHashMap的继承实现图吧。 LinkedHashMap简述 归纳整理一下： 底层实现是散列表和双向链表。其实LinkedHashMap就是HashMap和LinkedList结合。底层还是HashMap，只是各节点Entry另外的还添加了两个属性before和after，通过双向列表来链接。 迭代有序。默认就是链表的元素插入顺序，可通过accessOrder变量修改迭代顺序，是插入顺序还是访问顺序。 当映射中已经存在key对应的一组Entry。再来一组key对应的Entry插入，会替换掉原来的Entry。元素顺序不受影响。 使用LinkedHashMap可以不用像HashMap一样元素杂乱无序，而保证元素一定的有序性，做到TreeMap的功能却不用TreeMap的成本。 提供了LinkedHashMap(int initialCapacity,float loadFactor,boolean accessOrder)这个构造函数来构建LinkedHashMap，这样的LinkedHashMap的元素迭代顺序是从最近访问最少到最多(LRU算法)。 和HashMap一样允许键值为NULL的元素。 由于增加了双向链表的维护，大多数情况下其性能很可能比 HashMap 稍逊一筹。不过有一点例外的是LinkedHashMap 的 元素集迭代所需时间与映射Entry的数量 成比例，因为其迭代的时候是对其维护的双向列表进行迭代，有几个Entry迭代几次，而不是迭代其桶数。HashMap 迭代时间很可能开支较大，因为它所需要的时间与其容量成比例。 和HashMap一样有两个重要参数影响它的性能，初始容量和加载因子。为初始容量选择非常高的值对LinkedHashMap的影响比对 HashMap 要小，因为此类的迭代时间不受容量的影响，所以影响程度减少一些，但其他方面还是会有影响。 该类是非同步的。如果要使用该映射需要外部手动同步。或者在其初始化的时候外部封装Map m = Collections.synchronizedMap(new LinkedHashMap(...))。 在按插入顺序组成的LinkedHashMap中，修改Entry的key对应的value不是结构修改。 在按访问顺序组成的LinkedHashMap中，仅通过get函数访问元素就已经算结构修改了。 LinkedHashMap的属性 注释给出的解释很清楚，和LinkedHashMap继承HashMap一样，我们知道HashMap维护的是一个单链表。而LinkedHasshMap对其的扩展就是保证了元素的有序性，其维护的是一个双向链表。即图中Entry，其多了两个属性before和after即双向链表中节点的前驱指针后后继指针。 更多的它还维护了两个节点变量即head和tail，即双向链表的头尾指针，保证了迭代的时候性能。这一点和LinkedList的实现一致。所以说根本上LinkedHashMap就是LinkedList和HashMap的一种结合实现。有HashMap存取增删时的性能，同时规避了HashMap迭代时性能的缺陷，有LinkedList迭代时的性能优势。 accessOrder属性则代表着LinkedHashMap的迭代顺序。该变量默认情况下是false，即代表插入顺序。为true的时候代表LinkedHashMap的迭代顺序是访问顺序(最近最久未使用优先)。在LinkedHashMap构造的时候统一赋值。 LinkedHashMap的构造函数123456789101112131415161718192021222324252627public LinkedHashMap(int initialCapacity, float loadFactor) &#123; super(initialCapacity, loadFactor); accessOrder = false;&#125;public LinkedHashMap(int initialCapacity) &#123; super(initialCapacity); accessOrder = false;&#125;public LinkedHashMap() &#123; super(); accessOrder = false;&#125;public LinkedHashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; super(); accessOrder = false; putMapEntries(m, false);&#125;public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125; LinkedHashMap有5个构造函数，根本上都是调用了其父类HashMap的构造函数，唯一不同的就是多了一个accessOrder变量的赋值。上面我们已经对accessOrder进行了解读 LinkedHashMap常见Api解析put(K key, V value) 可以从类结构图中看出。LinkdeHashMap的所有put函数都是继承自自己的父类HashMap，AbstractMap以及实现的Map接口。 我们知道HashMap的put函数的具体逻辑最后都封装到了putVal函数中。而putVal函数中节点的创建则落在了newNode函数中。由于LinkedHashMap重写了newNode函数，所以新创的节点链接在内部双向链表的尾部。 get(Object key) 可以从LinkedHashMap类结构图看出其重写了HashMap的get函数和getOrDefault函数，继承了getNode函数。 1234567891011121314151617public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value;&#125;public V getOrDefault(Object key, V defaultValue) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return defaultValue; if (accessOrder) afterNodeAccess(e); return e.value;&#125; LinkedHashMap重写了get()和getOrDefault()函数。调用继承自HashMap的getNode函数来找到哈希表中key对应的Entry。 对比HashMap中的实现,LinkedHashMap只是增加了在成员变量(构造函数时赋值)accessOrder为true的情况下，要去回调afterNodeAccess(Node&lt;K,V&gt; e)函数的判断。 HashMap的实现：1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 在afterNodeAccess()函数中，会将当前被访问到的节点e，移动至内部的双向链表的尾部。 12345678910111213141516171819202122232425262728293031void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last;//原尾节点 // 如果accessOrder 是true ，且原尾节点不等于e if (accessOrder &amp;&amp; (last = tail) != e) &#123; // 节点e强转成双向链表节点p LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; // p现在是尾节点， 后置节点一定是null p.after = null; // 如果p的前置节点是null，则p以前是头结点，所以更新现在的头结点是p的后置节点a if (b == null) head = a; else // 否则更新p的前直接点b的后置节点为 a b.after = a; // 如果p的后置节点不是null，则更新后置节点a的前置节点为b if (a != null) a.before = b; else // 如果原本p的后置节点是null，则p就是尾节点。 此时 更新last的引用为 p的前置节点b last = b; if (last == null) // 原本尾节点是null 则，链表中就一个节点 head = p; else &#123; // 否则 更新 当前节点p的前置节点为 原尾节点last， last的后置节点是p p.before = last; last.after = p; &#125; // 尾节点的引用赋值成p tail = p; // 修改modCount。 ++modCount; &#125;&#125; 需要注意的是： afterNodeAccess()函数中，会修改modCount变量,因此当你正在accessOrder=true的模式下,迭代LinkedHashMap时，如果同时查询访问数据，也会导致fail-fast，因为迭代的顺序已经改变。 remove(Object key) LinkedHashMap也没有重写remove()方法，因为它的删除逻辑和HashMap并无区别。 在remove函数中无论是节点的查找时的逻辑判断以及真正的节点删除时的逻辑处理在单链表以及双向链表中的逻辑都是一致的， 但它重写了afterNodeRemoval()这个回调方法。该方法会在真正封装了删除逻辑的Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable)方法中回调，用来保证双向链表的结构性。并且该remove函数(5参)会在所有涉及到删除节点的方法中被调用因为其是删除节点操作的真正执行者。 containsValue(Object value)它重写了该方法，相比HashMap的实现，更为高效。12345678public boolean containsValue(Object value) &#123; for (LinkedHashMap.Entry&lt;K,V&gt; e = head; e != null; e = e.after) &#123; V v = e.value; if (v == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; return false;&#125; 遍历一遍链表，去比较有没有value相等的节点，并返回 HashMap实现：12345678910111213 public boolean containsValue(Object value) &#123; Node&lt;K,V&gt;[] tab; V v; if ((tab = table) != null &amp;&amp; size &gt; 0) &#123; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; if ((v = e.value) == value || (value != null &amp;&amp; value.equals(v))) return true; &#125; &#125; &#125; return false;&#125; 双重for循环。相对低效 LinkedHashMap只重写了HashMap的containsValue函数并没有重写其containsKey函数。是因为如果按containsValue的重写逻辑来做，需要遍历整个KeySet来找。 而HashMap的实现是通过hash算法来找的。效率要高很多123public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null;&#125; afterNode *()我们在看HashMap源码的时候就曾看到这些函数的存在。注释也给的很清楚，专门为LinkedHashMap准备的回调函数。1234// Callbacks to allow LinkedHashMap post-actionsvoid afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;void afterNodeInsertion(boolean evict) &#123; &#125;void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; 从LinkedHashMap中也可以看出也确实重写了这三个函数。分别作用在函数的访问，插入和删除后的回调。 afterNodeAccess函数在LinkedHashMap指定迭代顺序是访问顺序的时候获取元素时会回调。来保证双向链表的顺序。 1234567891011void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; removeNode(hash(key), key, null, false, true); &#125;&#125;protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; afterNodeInsertion：回调函数，新节点插入之后回调，根据evict来 判断是否需要删除最早插入的节点。如果实现LruCache会用到这个方法。 removeEldestEntry：LinkedHashMap中默认返回false 则不删除最早节点。 返回true 代表要删除最早的节点。通常构建一个LruCache会在达到Cache的上限时返回true afterNodeInsertion(boolean evict)以及removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)是构建LruCache需要的回调，在LinkedHashMap里可以忽略它们。 LinkedHashIterator() 从图中可以看出HashMap的迭代规则是遍历哈希表。从第一个桶存在元素的桶开始遍历。所以当初始容量大了之后，桶数也会上去。迭代的时候数据量就会上去 而LinkedHashMap迭代时是迭代的双向链表。从head节点开始一直到tail结束。并不是遍历每个桶，只是遍历双向链表的每个节点。所以受初始容量影响小。 LinkedHashMap 示意图； 总结LinkedHashMap继承了HashMap，相比于HashMap仅重写了几个方法，以改变它迭代遍历时的顺序。这也是其与HashMap相比最大的不同。 在每次插入数据，或者访问、修改数据时，会增加节点、或者调整链表的节点顺序。以决定迭代时输出的顺序。 accessOrder ,默认是false，则迭代时输出的顺序是插入节点的顺序。若为true，则输出的顺序是按照访问节点的顺序。为true时，可以在这基础之上构建一个LruCache. LinkedHashMap并没有重写任何put方法。但是其重写了构建新节点的newNode()方法.在每次构建新节点时，将新节点链接在内部双向链表的尾部 accessOrder=true的模式下,在afterNodeAccess()函数中，会将当前被访问到的节点e，移动至内部的双向链表的尾部。值得注意的是，afterNodeAccess()函数中，会修改modCount,因此当你正在accessOrder=true的模式下,迭代LinkedHashMap时，如果同时查询访问数据，也会导致fail-fast，因为迭代的顺序已经改变。 nextNode() 就是迭代器里的next()方法 。该方法的实现可以看出，迭代LinkedHashMap，就是从内部维护的双链表的表头开始循环输出。而双链表节点的顺序在LinkedHashMap的增、删、改、查时都会更新。以满足按照插入顺序输出，还是访问顺序输出。 它与HashMap比，还有一个小小的优化，重写了containsValue()方法，直接遍历内部链表去比对value值是否相等。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap了解一下]]></title>
    <url>%2Fhashmap.html</url>
    <content type="text"><![CDATA[前言 本文基于jdk1.8 HashMap先来看一下Java官方描述 基于哈希表的 Map 接口的实现。 允许使用 null 值和 null 键。 除了非同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。 不保证映射的顺序，特别是它不保证该顺序恒久不变（扩容后元素在底层会重散列）。 迭代所需的时间与 HashMap实例的“容量”（桶的数量）及键-值映射数成比例。即初始容量设置得太高（或将负载因子设置得太低）对遍历的性能影响都很大。 负载因子 = 总键值对数 / 箱子个数(数组元素) HashMap 的实例有两个参数影响其性能：初始容量 和负载因子。当元素个数超过当前容量(桶数)与负载因子的乘机时，哈希表会对其元素rehash，底层的桶数*2。 默认负载因子(0.75)，加载因子过高虽然减少了空间开销，但同时也增加了查询成本。在设置初始容量时应该考虑到Map中所要容纳的元素数量及其加载因子，以便最大限度地减少rehash操作次数。如果初始容量大于最大条目数除以加载因子，则不会发生rehash操作。 如果从一开始就知道有多少元素要存到Map中，最好一开始就指定好Map初始容量，尽量避免其rehash操作。性能会大大提高 此实现不是同步的。想要同步在一些列操作外手动同步，或者使用Map m = Collections.synchronizedMap(new HashMap(...));方法来“包装”该映射。最好在创建时完成这一操作，以防止对映射进行意外的非同步访问 HashMap类继承图 实现了Serializable，Cloneable接口 继承了父类AbstractMap HashMap属性静态属性： DEFAULT_INITIAL_CAPACITY: 初始容量，也就是默认会创建 16 个箱子，箱子的个数不能太多或太少。如果太少，很容易触发扩容，如果太多，遍历哈希表会比较慢。 MAXIMUM_CAPACITY: 哈希表最大容量，一般情况下只要内存够用，哈希表不会出现问题。 DEFAULT_LOAD_FACTOR: 默认的负载因子。因此初始情况下，当键值对的数量大于 16 * 0.75 = 12 时，就会触发扩容。 TREEIFY_THRESHOLD: 上文说过，如果哈希函数不合理，即使扩容也无法减少箱子中链表的长度，因此 Java 的处理方案是当链表太长时，转换成红黑树。这个值表示当某个箱子中，链表长度大于等于 8 时，有可能会转化成树。 UNTREEIFY_THRESHOLD: 在哈希表扩容时，如果发现链表长度小于 6，则会由树重新退化为链表。 MIN_TREEIFY_CAPACITY: 在转变成树之前，还会有一次判断，只有键值对数量大于 64 才会发生转换。这是为了避免在哈希表建立初期，多个键值对恰好被放入了同一个链表中而导致不必要的转化。 成员属性： table：HashMap的链表数组。它在自扩容时总是2的次幂 entrySet: HashMap实例中的Entry的Set集合。 size: HashMap实例中映射的数量 modCount: 这个HashMap被结构修改的次数 threshold: 桶数 loadFactor: 哈希表的负载因子 HashMap简单总结： 存取无序 键值允许为NULL 非同步类 底层是哈希表 初始容量和装载因子是决定整个类性能的关键点。 HashMap构造函数HashMap的构造函数共4个。 HashMap(int initialCapacity, float loadFactor) 我们可以看到loadFactor参数Java官方还对其进行了Float.NaN(0.0f/0.0f)的判断。可以说考虑的非常周到了 同时在构造函数的最后一行，在为threshold赋值的时候，调用了tableSizeFor()函数来对输入的初始容量进行判断，来保证该初始容量是2的整数次幂。 函数具体释义可参考：HashMap源码注解 之 静态工具方法hash()、tableSizeFor()（四） 此时不经要想为什么是将2的整数幂的数赋给threshold？ 首先我们先来了解一下threshold这个属性： threshold这个成员变量是阈值，决定了是否要将散列表扩容充重散列。它的值应该是：(capacity * loadfactor）才对的。 那我们就更奇怪了，那这里还给他赋值干什么？ 其实这里仅仅是一个初始化，当创建哈希表的时候，它会在resize函数中根据一些条件判断来重新定义赋值的。 HashMap(Map&lt;? extends K, ? extends V&gt; m) 这个构造函数其实本质上和刚才我们所看的给初始容量和负载因子的构造函数一致。函数最终做的除了参数上可以看出来的，把一个Map实例中的元素都插入到HashMap实例中外，由于负载因子没有显示指定所以赋予了loadFactory默认值。 并且把具体的Map迭代放在了调用的putMapEntries函数中。从该函数注释中看出，该函数是服务于putAll函数和constructor构造函数的。 从putMapEntries函数注释中也可以看出，如果这个函数在初始化Map时被调用evict参数传入的是false。而如果这个函数是在afterNodeInsertion函数后调用的，那么则需要传入的是true。 从putMapEntries函数的具体代码实现上可以看出，其在Map第一次初始化的时候和我们刚才所看的构造函数一致，都是在真正构造HashMap前先为阈值赋予一个可靠地初值。然后才迭代入参map集合，将其元素都插入到HashMap中。 其余的构造函数都是大同小异。就不一一赘述了 总结： 从构造函数中我们可以看出，HashMap的构造函数其实工作就只有一个。赋值 赋值负载因子 赋值阈值 HashMap常见Api解析put(K key, V value)123456789 /** * Associates the specified value with the specified key in this map. * If the map previously contained a mapping for the key, the old * value is replaced. * */public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 可以看出put函数具体实现其实是调用了putVal函数。并且从注释中可以得知如果该映射存在，新值会替换掉旧值。 还可以看到的是传入了5个参数，我们来了解简单一下这5个参数。 123456789101112 /** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don&apos;t change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; 注释很直白解释的很清楚，按序号来 key的哈希值 key value 如果映射存在不替换原值？ 如果是false，代表当前HashMap正处于创建阶段。 我们大概知道了这5个参数是干嘛的了，就可以针对第一个参数具体的去了解一下key的哈希值是如何计算得了。 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 这里就比较疑惑了，为什么不直接用key类型对应的hashcode函数直接得到对应的哈希码呢？从这段代码可以看出来Java官方拿key的哈希码和其哈希码向右移位16位的结果进行异或操作。我们知道右移高位补0，由于哈希码返回的是一个4字节32位int类型的值。所以总共可以看成是高16位，低16位组成的。 而这里对其哈希码进行右移16位之后高位空缺补0，原高位到了现低位。然后再拿原哈希码与现哈希码进行异或操作，而我们知道任何数跟0异或都是其本身。所以可以看出Java官方最终目的，是想让哈希码原低16位与其高16位进行异或操作。而原高16位却不变，原来如此~ 但为什么要这样呢？ 其实这个与HashMap中元素插入时对应位置table数组下标的计算有关。 核心代码：12n = (tab = resize()).length;i =（n-1） &amp; hash 我们暂且不看resize函数，putVal函数在初次进来的时候该resize函数做的其实就是哈希表初始化的工作。由于DEFAULT_INITIAL_CAPACITY变量的存在，我们暂且认为该哈希表的大小length为16。即n=16 那么在计算元素插入位置的时候，由于底层是数组。所以真正存储的位置就是[0-15]。所以n-1。 而因为，table的length属性都是2的幂，因此i仅与hash值的低n位有关（此n非table.length，而是2的幂指数）假设table.length=2^4=16。 由上图可以看到，32位的hash值只有低4位参与了运算。仅有4位的异或很容易产生碰撞。但是由于table.length的大小只能由插入数据的多少来改变，而hash值得高16位又由于与操作置0了，所以设计人员相出一个好办法就是通过对key的hash值进行高16位与低16位异或来将高位与低位整合。这样不但可以保留原来key哈希值的差异性(高位地位同时作用)，同时来增加低16位2进制数值在计算时的差异性进而减少这种哈希冲突的情况。 参考：HashMap源码注解 之 静态工具方法hash()、tableSizeFor()（四） putVal(int hash, K key, V value, boolean onlyIfAbsent,boolean evict)接下来便可以继续分析真正的put函数了。 总结下来就是： 散列表初次put数组任为NULL时，调用resize函数(单独拉出来说)来初始化散列表 当根据元素的哈希值可以确认分配到散列表的下标时，如果此处没有元素，那么就直接插入 当该元素就是和我一样的元素。即此处元素的hash值和key值都与要插入的元素相等时。通过变量e指向该元素。 当该元素已经不是一个链表结构而是一个红黑树结构的时候(元素肯定过6)，将该元素插入到红黑树中，并用e指向该元素 否则该处就是一个链表，链表头结点不是要插入的元素，但不能排除其他节点不是。所以然后遍历这个数组，当该链表中遍历到的节点的下一节点为空时将该元素插入到链表尾，循环跳出。如果不为空的话，对下一节点进行判断看是否是待插入节点。如果是跳出 程序进行到绿框时，此时程序只有两种情况。元素最后找到空出插入了，但是e无法指向。或者说元素找到和自己一样的元素了，并且由变量e指向。 新旧值替换，根据函数一开始传入的参数onlyIfAbsent或者oldValue的特殊情况来决定是否替换。 key对应的旧值如果为NULL，那么无论onlyIfAbsent是否决定替换。都将被替换。 key对应的旧值如果不为NULL，那么如果onlyIfAbsent是false就替换。 最后返回被替换掉的值。 修改了实例结构所以modCount+1。 加入元素后判断元素个数是否超过了阈值。如果是resize函数扩桶数 这样我们的putVal函数其实思路就理清了，看上去很复杂，其实宗旨没变，也就是判断，扩容，找位置，去除特殊情况，元素插入，只不过数据结构的差异性导致其特殊情况较多，判断的复杂了些。接下来该分析resize函数了。我们可以明显的看到putVal函数多出调用了resize函数。所以要想彻底理清HashMap实例是如何构建的，resize函数必然需要了解一下。 目前对resize的了解：table==null时，调用resize初始化table。元素数量&gt;=threshold时，调用resize扩容。 Node[] resize()123456789/** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table */final Node&lt;K,V&gt;[] resize() &#123;&#125; 从该函数的开头我们也可以确认我们刚才的观点。用来初始化和给table扩容的。 总结下来就是： 哈细表扩容： 当旧表容量大于0时，即旧表被初始化过了 并且如果其容量大于或等于int的最大值。那么阈值设置为int的最大值。并返回旧旧表，此时表已经不能再扩容了，能做的只有置阈值为其能到大的最大值，尽可能的减少扩容次数。 当旧表容量不及最大容量的一半时，并且旧表容量大于默认容量16时。由于函数resize被调用了。所以需要满足外界扩容需求，旧表阈值&lt;&lt;1。 当旧表没被初始化，但HashMap实例被初始化了。 否则当旧表还未被初始化时，只是在初始化HashMap实例的时候赋予了阈值和负载因子(结合构造函数思考)，当旧阈值&gt;0时，哈希表初始容量设置为阈值。 否则，当构造HashMap实例时如果连阈值也没有赋值(默认为0)只是初始化了负载因子的话(默认无参构造函数)。初始化哈希表容量为DEFAULT_INITIAL_CAPACITY即16，阈值为DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY即12。 当阈值=0时，新阈值=新容量*负载因子。当HashMap实例被被初始化时阈值也被初始化时会走这一分支 最后确定容量和阈值后初始化哈细表。 数据迁移： 当旧哈细表存在时，迭代哈细表每个元素。因为每个元素中存的都是链表或者红黑树。根据每个元素的哈希值重新散列到新哈希表的对应位置上。底层数据结构和节点的存储位置很大程度上会更改。 get(Object key)从注释中可以看出，返回 null 值并不一定 表明该映射不包含该键的映射关系；也可能该映射将该键显示地映射为 null。可使用 containsKey 操作来区分这两种情况。 12345678910111213 /** * ····· * &lt;p&gt;A return value of &#123;@code null&#125; does not &lt;i&gt;necessarily&lt;/i&gt; * indicate that the map contains no mapping for the key; it&apos;s also * possible that the map explicitly maps the key to &#123;@code null&#125;. * The &#123;@link #containsKey containsKey&#125; operation may be used to * distinguish these two cases. * ····· */public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 函数具体查询逻辑封装到了getNode函数。 简单来说： key对应的哈希值计算出来落到哈希表对应的地方上，如果有元素存在。 有元素存在就需要比较了，因为元素上可能存的是链表或者红黑树。 第一个元素就是搜寻的key本身 第一个不是，但其是红黑树结构。参数传递并去红黑树中找 不是红黑树结构，那么就是链表结构，进行迭代寻找，获取key对应的value。 remove(Object key)1234567891011121314/** * Removes the mapping for the specified key from this map if present. * * @param key key whose mapping is to be removed from the map * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125; 从函数的注释中可以看出，该函数删除key对应的Entry并返回与 key 关联的旧值；如果 key 没有任何映射关系，则返回 null。但需要注意的是： 返回 null 还可能表示该映射之前将 null 与 key 关联。 函数再次把元素的通过hash函数包装传了进去，这很好理解，因为底层是哈希表嘛，不这样怎么能找到key到底在哈希表什么位置呢。我们可以看到删除逻辑的具体逻辑封装到了removeNode函数中。 removeNode(int hash, Object key, Object value,boolean matchValue, boolean movable)先来对removeNod函数的多个参数进行一番分析。12345* @param hash hash for key * @param key the key* @param value the value to match if matchValue, else ignored* @param matchValue if true only remove if value is equal* @param movable if false do not move other nodes while removing hash(key) key 对应matchValue参数，如果matchValue为true。那么删除key时其value必须与value相等，否则跳过这次删除 如果true。只有当值相等时才删除。 如果为false，那么在删除节点时不移动其他节点。 总的来说： 先判断key是否可以映射到哈希表上。 如果可以，判断一下映射的位置头元素是否为该查找的元素。 如果头元素不是要找元素，判断一下头元素后有无其他元素。如果有再判断一下这个元素的数据结构是否为红黑树，如果是，用node变量指向该key对应在红黑树中的节点。 如果不是那说明哈希表该索引处是一个链表结构，然后对链表元素迭代寻找该元素，并用node节点指向寻找到的该元素。需要注意的是，p变量的逻辑定位，由于do while循环体中break语句相对于p=e语句置前，p变量在循环退出时指向的是node节点的前驱节点。 经历过橘黄色和红色两大块逻辑判断，成功找到了待删除节点的位置，并用node节点指向。如果该Node节点被成功找到了的话。 红黑树：如果node节点所在哈希表的位置元素的存储结构式是红黑树的话。调用红黑树的删除方法 链表：如果头节点就是待删除节点的话，那么待删除节点的next节点做头结点 链表：如果待删除节点是链表中间部分的某个节点。借助p变量进行删除。 modCount+1，size-1，并将删除的节点返回。 HashMap与HashTable对比我们从一开始就曾说，两者从存储结构和实现来讲基本上都是相同的。两者最大的差别就是HashTable是线程安全的，而HashMap是线程不安全的。并且在数据存储时，HashMap允许key和value为null。而HashTable则不允许。并且HashTable规定用作键的对象必须实现 hashCode 方法和 equals 方法。 HashTable在Map映射中的地位有点儿像Vector在List集合中的定位。也是比较过时的类，设计上有一些缺陷，不需要线程安全的情况下可以使用HashMap替代它，而需要线程安全的情况下也可以用ConcurrentHashMap来替代它。 总结 HashMap的底层是：数组+链表+红黑树 HashMap的实例有两个重要参数影响其性能。负载因子和初始容量，(装载因子*初始容量)&lt; 散列表元素时，该散列表会扩容2倍，并重散列。 负载因子：默认0.75，无论是初始大了还是初始小了对HashMap的性能都不好 初始值大了，可以减少散列表再散列(扩容的次数)，但同时会导致散列冲突的可能性变大(散列冲突也是耗性能的一个操作，要得操作链表(红黑树) 初始值小了，可以减小散列冲突的可能性，但同时扩容的次数可能就会变多！ 初始容量：默认值是16，无论初始大了还是小了对HashMap都是有影响的 初始容量过大，那么遍历时速度就会受影响~ 初始容量过小，散列表再散列(扩容的次数)可能就变得多，扩容也是一件非常耗费性能的一件事 参考公式：阈值 = 容量 * 负载因子 HashMap在计算元素在哈希表中存储位置的时候，并不是直接拿key的哈希值来用的，会先对key的哈希值进行右移16位，然后再与其key的哈希值进行异或操作。根本上就是高位不变，低位变为高16位和低16位的异或结果，使得元素在存储时的随机性更大了。分布更加均匀了，减少了哈希冲突发生的概率 并不是箱子上元素大于等于8位元素的时候该哈希表的元素底层就能变成红黑树，它得同时满足哈希表总容量大于64才行，同时当红黑树元素数量低于8时，并不是会立马变回链表。而是在其元素小于6时才会。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Map集合了解一下]]></title>
    <url>%2Fmap.html</url>
    <content type="text"><![CDATA[前言首先声明本文使用的是jdk1.8 Map映射Map即双列集合。但我们一般称它为映射，即键值对的形式。 Map映射的特点 键值对形式存储元素。 Collection集合子接口List元素可以重复，Set不可以重复，而Map是键唯一，值可以重复。 Map集合的数据结构针对于键，和值无关。Collection的数据结构针和元素有关。 Map接口结构 图中叙述的很清楚。 Entry作为Map映射的特有接口而存在于Map接口中属于内部接口。 重写了Object类的hashcode和equals函数。 自定义了一套接口函数 提供了系列可直接使用的函数 Map接口常见Api解析由于是顶级Map接口，官方只由注释定义了其实现规则，所以我们做的也只是解读注释而已。 put(K key, V value)将指定的值与此映射中的指定键关联。如果此映射以前包含一个该键的映射关系，则用指定值替换旧值（当且仅当 m.containsKey(k) 返回 true 时，才能说映射 m 包含键 k 的映射关系）。 putAll(Map&lt;? extends K,? extends V&gt; m)从指定映射中将所有映射关系复制到此映射中（可选操作）。对于指定映射中的每个键 k 到值 v 的映射关系，此调用等效于对此映射调用一次 put(k, v)。 remove(Object key)如果存在一个键的映射关系，则将其从此映射中移除。返回此映射中以前关联该键的值，如果此映射不包含该键的映射关系，则返回 null。 需要注意的是： 如果此映射允许 null 值，则返回 null 值并不一定 表示该映射不包含该键的映射关系；也可能该映射将该键显示地映射到 null。 clear()从此映射中移除所有映射关系（可选操作）。此调用返回后，该映射将为空。 isEmpty()如果此映射未包含键-值映射关系，则返回 true。 containsKey(Object key)如果此映射包含指定键的映射关系，则返回 true。 containsValue(Object value)如果此映射将一个或多个键映射到指定值，则返回 true。 get(Object key)返回指定键所映射的值；如果此映射不包含该键的映射关系，则返回 null。 需要注意的是： 如果此映射允许 null 值，则返回 null 值并不一定 表示该映射不包含该键的映射关系；也可能该映射将该键显示地映射到 null。使用 containsKey 操作可区分这两种情况。 entrySet()返回此映射中包含的映射关系的Set集合。即Entry集合 需要注意的是： 如果对该Set进行迭代的同时修改了映射。则迭代结果是不确定的。迭代结果可能由于并发操作的影响超出我们的预期。 但如果通过迭代器自己的remove操作，或者通过对迭代器返回的映射项Entry执行setValue操作除外。因为这样的修改结果在我们的预知范围之内。 keySet()返回此映射中包含的键的Set集合。 需要注意的是： 如果对该set进行迭代的同时修改了映射，则迭代结果是不确定的。因为是线程不同步的，所以并发操作其他线程的修改结果我们不会预知，可能会发生异常，可能正常进行但是结果不是我们预期的结果 但通过迭代器自己的remove操作除外。还是那个原因，通过Iterator的迭代方式进行remove的时候是可以保证在remove的时候expectedModCount = modCount的。 所以如果在使用Iterator迭代的时候如果其他线程并发的修改了映射类的话。Iteratore会返回一个并发修改的异常。相比于其他迭代方式对Set集合遇到并发修改的行为的返回结果是确定的。 values()返回此映射中包含的值的Collection集合。 size()返回此映射中的键-值映射关系数。如果该映射包含的元素大于Integer.MAX_VALUE,则返回Integer.MAX_VALUE。 Map接口常见实现类 红框所标都是Map接口关键的实现类。 其中需要针对HashMap和TreeMap两种需要提前了解一下他们底层的数据结构实现。分别是哈希表(散列表)和红黑树 散列表针对于Map接口的HashMap实现类以及Set接口的HashSet我们来学习一下散列表。 什么是散列表散列表其实也很好理解，就是一个链表数组。数组的每一个元素都是一个链表。 散列表最重要的就是它当中的元素之如何存储的。在我们之前所了解的无论是链表还是数组，如果想查找某一元素都是量元素间相互比较，通过比较的方式来迭代遍历元素的，知道找到那个元素。这样的方式无疑当数据量上去之后对我们时间上的开销非常的巨大。所以散列表的存储方式就诞生了 散列表的工作原理哈希表的存储过程如下: 根据 key 计算出它的哈希值 h。 假设箱子的个数为 n，那么这个键值对应该放在第 (h % n) 个箱子中。 如果该箱子中已经有了键值对，就使用开放寻址法或者拉链法解决冲突。 散列冲突我们刚才说了，底层容器是一个链表数组。为什么是链表呢，那肯定是数组的一个位置可以存不止一个元素。必然，我们还没有了解过散列表是如何为每个要存入的元素计算其散列值的呢，会不会出现两个元素散列值一样的情况。但既然我们知道散列表底层的数据结构了，肯定就会知道一定是会出现这种情况的。我们一般称这种情况为哈希冲突(hash碰撞)，但一般情况下的哈希函数设计都十分合理，这种现象很少出现。即便出现了，也有对应的措施。 此时的处理方式： 判断该数组的链表元素中是否存储了该元素。如果没有就放入，如果有就跳过。 哈希冲突解决办法： 开放寻址法：即散列到冲突地址的下一空闲位置插入即可。 缺点：散列表空间不足时，无法处理冲突也无法插入数据 解决办法：由于需要负载因子(空间/插入数据)&gt;=1。所以进行扩容(数组扩容) 拉链法：即如果遇到冲突，他就会在原地址新建一个空间，然后以链表结点的形式插入到该空间。 缺点：这种解决办法的哈希表在极端情况下会变成线性表，性能极低。 解决办法：Java8中Java官方的处理方案是当链表太长时，转换成红黑树。 负载因子负载因子(load factor)，它用来衡量哈希表的 空/满 程度，一定程度上也可以体现查询的效率 负载因子 = 总键值对数 / 箱子个数(数组元素) 负载因子越大，意味着哈希表越满，越容易导致冲突，性能也就越低。因此，一般来说，当负载因子大于某个常数(可能是 1，一般为 0.75 等)时，哈希表将自动扩容。 哈希表在自动扩容时，一般会创建两倍于原来个数的箱子，因此即使 key 的哈希值不变，对箱子个数取余的结果也会发生改变，因此所有键值对的存放位置都有可能发生改变，这个过程也称为重哈希(rehash)。 哈希表的扩容并不总是能够有效解决负载因子过大的问题。假设所有 key 的哈希值都一样，那么即使扩容以后他们的位置也不会变化。虽然负载因子会降低，但实际存储在每个箱子中的链表长度并不发生改变，因此也就不能提高哈希表的查询性能。 哈希表的两个问题我们可以从刚才的分析中得出哈希表的如下两个问题： 如果哈希表中本来箱子就比较多，扩容时需要重新哈希并移动数据，性能影响较大。 如果哈希函数设计不合理，哈希表在极端情况下会变成线性表，性能极低。 这两个问题在Java8中Java官方已经为我们解决了。 对于箱子，给定了一个合理的初始容量，既没有太多也没有太少。既不会影响哈希表的遍历速度也很少触发扩容操作 当箱子成了长链表之后，在链表长度超过8之后会变成红黑树。 红黑树同样我们针对于Map接口的TreeMap实现类和Set接口的TreeSet实现类来学习一下红黑树。 什么是红黑树红黑树也是平衡二叉树的一种。 他为什么会出生呢，究其原因肯定是在某些方面该数据结构具有更好地效率。 我们知道，由于二叉查找树在特殊情况下会变成链表大大影响查找性能的原因我们有了AVL树，而紧接着由于AVL树高度平衡的性质，频繁的插入和删除，会引起频繁的reblance，导致效率下降的原因我们就有了红黑树这个数据结构。 红黑树不是高度平衡的，算是一种折中，它是局部平衡的。插入最多两次旋转，删除最多三次旋转。 二叉查找树偏向问题： 在二叉查找树上，我们插入节点的过程是这样的：小于节点值往右继续与左子节点比，大于则继续与右子节点比，直到某节点左或右子节点为空，把值插入进去。这样无法避免偏向问题 所以我们就有了平衡树这么一个概念。这样的树结构能够使我们任何的元素在插入与删除的时候依旧能够保持任意节点左右子树高度不相差1。 红黑树原型2-3树红黑树明显很好地解决了这个问题。但是它的原型其实是2-3树。 如图即是一个典型的2-3树。 在2-3树中，共有两种节点。第一种是“2-节点”： 该节点性质和二叉查找树种节点性质一致。左孩子小于该节点，右孩子大于该节点 第二种是“3-节点”： 该节点和2-节点不同的是多了一条分支。最左边的儿子表示比a小的子树，中间的儿子表示大于a但小于b的子树，右边的儿子表示比b大的子树。 虽然这是2-3树，我们能直观的看到数中是不存在“4-节点”的。但是为了保持树的平衡性，我们将会利用4-节点来在插入和删除过程中保持树的完美平衡。下面是一个4-节点： 该节点的分支思路和3-节点一致。 那么2-3树是如何避免二叉查找树中偏向的问题的呢？ 很简单，我们来参考一个节点插入步骤图。 总的概括起来就是当有新节点插入时 合并2-节点为3-节点，扩充将3-节点扩充为一个4-节点 分解4-节点为3-节点，再分解3-节点为2-节点，分解后多出的元素向上回溯。 重复不断调整，致使整个树平衡。 当然我们一个树的平衡，不光是要插入时保持平衡同时在做删除操作操作的时候我们也要保持它的持续平衡。2-3树的删除操作平衡调整比较复杂。我也没有完全理解，有兴趣可以参考： 2-3树与红黑树 2-3到红黑树我们在了解了2-3树对于解决节点偏移的问题的处理思路之后可以很明显的感觉到，其中需要大量的节点变换。这些变换在实际代码中是很复杂的。所以现在几乎没有2-3树的具体实现。 红黑树也是一种平衡二叉树，但相比于2-3树，红黑树只有一种2-节点。但既然我们要想做和2-3树一样的工作却不给它3-节点，无疑我们把3节点都用合理的方式拆分了。 如何表示3-节点呢？我们尝试一种特殊的边：默认情况下节点的颜色均为黑色。我们将某个节点染为红色，表示它和父亲的的链接是红色的，就像下图： 当我们将红链接画平时 可以看到，这不就是我们刚才2-3树种的3-节点吗。而事实上，我们完全可以用这样的方式来表示2-3树中的3-节点。 如下即是一颗典型的红黑树： 将该树种所有红链接画平，将得到一棵完美平衡的“2-3树”。 红黑树是如何保证平衡相比于2-3树不断变换节点的缺陷来说。由于红黑树的节点都是2-节点所以其处理方式更简洁。 旋转：顺时针旋转和逆时针旋转 反色：交换红黑的颜色 这两个操作相对于2-3树种的节点变换要简单许多。 具体可以参考：2-3树与红黑树 红黑树如何定义 红黑树是二叉搜索树。 根节点必须为黑色。毕竟根节点没有父亲。 红链接必须在左侧。将红链接统一在一个方向是为了方便其它操作。 不允许两个连续的红链接。因为连续的连个红链接表示的是4-节点。 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点(每一条树链上的黑色节点数量（称之为“黑高”）必须相等)。 总结 简单介绍了Map接口的结构及其常用Api 介绍了Map接口的常用实现类并为后面研究其实现类做铺垫了解了其实现类HashMap和TreeMap的底层数据结构，散列表和红黑树]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[List集合了解一下]]></title>
    <url>%2Flist.html</url>
    <content type="text"><![CDATA[前言首先声明本文使用的是jdk1.8 List 常见实现类根据上篇Collection的文章我们了解了List的几个常见实现类。 ArrayList：底层数据结构是数组。线程不安全 LinkedList：底层数据结构是链表。线程不安全 Vector：底层数据结构是数组。线程安全 ArrayListArrayList的实现和继承结构 ArrayList类特点 可动态的改变数组的大小(数组的拷贝)。 和Vector类函数实现相似，区别只是线程不安全。 另外Vector有许多设计上的不足，不建议使用。当多条线程访问ArrayList集合时，程序需要手动保证该集合的同步性，而Vector则是线程安全的。 ArrayList解析ArrayList属性解析 其实注释写的都很清晰 构造函数 前两种方式十分的简单，需要注意的就是第三种： 在通过一个Collection来构造ArrayList的时候，其toArray函数可能不能成功返回一个Object[]类型的数组。需要我们再把elementData数组中的元素拷贝到Object[size]类型的数组中并重新赋值给elementData。 add() 函数处理步骤： 检查是否需要扩容 插入元素 元素在插入到集合前需要先对ArrayList进行判断是否需要扩容。 ensureCapacityInternal函数来确定真正的数组最小容量minCapacity 拿（当前元素个数+1）来进行判断。如果当前容器没有进行初始化。那么取minCapacity和DEFAULT_CAPACITY两个元素中较大的值作为数组的最小容量(也就是需求容量在10以下我们也把数组初始化成了容量为10，防止频繁的扩容操作)。 ensureExplicitCapacity函数记录容器的更改状态并判断容器是否真的需要扩容 modCount记录容器被修改过的次数。当通过ensureCapacityInternal函数确定的容器最小容量minCapacity大于数组当前大小时。调用grow函数来对数组进行扩容 如果扩容1.5倍后还小于需要的最小容量，干脆让数组容量等于minCapacity。 如果数组要求的最小容量已经大于数组所被允许的最大容量限制。让其容量最大只能等于Integer.MAX_VALUE。 1234567/** * The maximum size of array to allocate. * Some VMs reserve some header words in an array. * Attempts to allocate larger arrays may result in * OutOfMemoryError: Requested array size exceeds VM limit */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 根据释义我们可以知道一些虚拟机在数组头会保存一些头元素。 请求的数组过大的话会出现OOM异常。可能会超出部分VM的限制 源码叙述的很清晰。接着上面的看，对elementData进行拷贝。将该数组元素拷贝到一个也是该数组类型的且容量为newCapacity的数组中。 总结： 首先去检查一下数组的容量是否足够 足够：直接添加 不足够：扩容 扩容到原来的1.5倍 第一次扩容后，如果容量还是小于minCapacity，就将容量扩充为minCapacity。 add(int index, E element) 函数处理步骤： 要插入元素的位置判断。是否小于0或超出当前数组元素 扩容判断 数组拷贝 由于ensureCapacityInternal函数的保障，所以这里数组元素移位即可。 可以发现在ArrayList中由于底层实现是由数组来作为容器。所以与扩容相关的add函数底层其实都是arraycopy()来实现的。 而其又是native函数，底层是由C/C++来编写的。但该函数的相比于我们自定义的数组拷贝实现要性能高得多。更有可能得到细致的优化，应该尽可能去使用它。 参考R大回答：https://www.zhihu.com/question/53749473 get(int index) 字面意思 set(int index, E element) 字面意思 remove(int index) 正如注释中所述。 函数处理步骤： index索引边界判断 modCount变量的维护 取出数组index处元素用于结果返回 数组元素从index+1处开始依次往前移一位。 其实看完remove函数之后，我比较疑惑为什么jdk开发人员在设计remove函数的时候不和add函数一样动态的维护数组的大小呢？因为我自己在学习数据结构的时候，设计我的ArrayList集合类的时候其add函数和remove函数都根据数组现有元素数量和数组总容量做了一个系数比，根据系数比动态的维护了其容量。 后来仔细一想，这么设计也确实很合理。ArrayList作为List接口常用的实现类之一，既然其容量确实到达过一个峰值。即便其后来被降下来了，也很难保证其后续不会再升回去。因为既然原来能到达，那么后续也肯定可以到达。所以既然这样就需要函数体中频繁的判断，频繁的扩容缩容性能上无疑会更大的放大了ArrayList在增删上的劣势。不可取 trimToSize() remove函数由于性能影响在删除元素后既然不能缩容，Java开发人员提供了该函数供开发人员根据自己的需要来对数组缩容。底层依旧调用的是System类的arraycopy函数。 我设计的ArrayListGithub地址 - 我设计的ArrayList 实现了Arraylist的部分常见功能。 Vector与ArrayList区别 Java开发人员已经告诉我们了。 出生于jdk1.0时代，并在jdk1.2的时候被改造为实现List接口。 底层也是动态数组实现 它是线程安全的 如果不需要线程安全的实现，建议使用ArrayList代替Vector(早期设计有些许缺陷)。 可以从图中很明显的看出，Vector类在很多对其底层数组结构有修改作用的函数上都加上了synchronized关键字来保证其线程安全性。 如果想要ArrayList实现同步，可以使用Collections的方法：List list = Collections.synchronizedList(new ArrayList(...));，就可以实现同步了。 还有另一个区别： ArrayList在底层数组不够用时在原来的基础上扩展0.5倍，而Vector如果未指定其capacityIncrement参数时，其默认初始容量为10，且该参数容量自动增长值为0。那么Vector的容量扩展1倍。 LinkedListLinkedList的实现和继承结构 LinkedList类特点 LinkedList底层是双向链表 允许存储NULL 线程不安全的，解决办法和Arraylist一样，通过Collections工具类来封装一下。并且在迭代的时候需要外部手动锁住该LinkedList的实例 LinkedList 类还为在列表的开头及结尾 get，remove 和 insert 元素提供了统一的命名方法。这些操作允许将链接列表用作堆栈、队列或双端队列。 LinkedList解析LinkedList属性解析 LinkedList的属性和我们自己设计的LinkedList一模一样。 很简单由于是双向链表就必然有头结点和尾节点两个属性，再加一个size变量指定LinkedList元素数量方便我们维护。 构造函数 其实构造思路很简单。第二种无非就是把一个集合迭代的跟到LinkedList实例之后。然后根据一些不同的case进行处理。和我们设计的LinkedList处理思路是一样的，只是可能它设计的更严谨一些。 add(E e) 我设计的LinkedList是单向链表，所以为了保证add函数的性能选择了头插法。而LinkedList的实现由于是双向链表，所以必然是尾插法才合理。 remove(Object o) 如注释所述，删除链表中第一次出现和指定元素的item属性equals的元素。 前提是需要对可能存在的NULL元素做过滤处理。避免空指针异常。 unlike函数： 其实就是具体的负责链表中元素的删除工作。 modCount变量的维护 具体逻辑的判断不同case的处理(其实和我们的实现思路一样) 可以看出unlink函数的局部变量使用了final关键字来修饰。从一定程度上避免了一些由于LinkedList是线程不安全的类所带来的线程安全问题。同时也带来了一些性能上的提升 get(int index) 和我们正常获取元素的思路一致。对于LinkedList来说由于底层是双向链表，我们要向获取到指定位置的元素只能通过遍历的方式。但是Java开发人员想的非常周到，首先对index索引进行了大小判断，看时候大于size的一半，直接就是查询范围缩小了一半。更加高效 set(int index, E element) 如同注释描述的一致，没有多余操作，由于关系到index索引，所以按例检查一下。然后进行替换即可。 我设计的LinkedListGithub地址 - 我设计的ArrayList 总结ArrayList ArrayList是基于动态数组实现的，在增删时候，需要调用System类的arraycopy函数进行拷贝复制((navite 函数底层由C/C++实现)。 ArrayList的默认初始化容量是10，每次扩容时候增加原先容量的一半，也就是变为原来的1.5倍 删除元素时不会减少容量，若希望减少容量则调用trimToSize() 它大体上相似Vector，但不是线程安全的。多线程环境下，任何关于ArrayList集合类结构上的更改，为保障线程安全，我们都需要程序内手动的维护 能存放NULL值，元素可重复，且有序。 LinkedList LinkedList底层是双向链表(更方便获取指定元素) 允许存储NULL 线程不安全的，解决办法和Arraylist一样，通过Collections工具类来封装一下。并且在迭代的时候需要外部手动锁住该LinkedList的实例 Vector 出生于jdk1.0时代，并在jdk1.2的时候被改造为实现List接口。 底层也是动态数组实现 它是函数操作是线程安全的 现在已少用，被ArrayList替代，原因： Vector所有方法都是同步，函数执行上有性能的损失，并且程序在函数执行前后要加锁和释放锁开销都比较大。 Vector初始length是10 超过length时，如果未指定扩容大小。以成倍态势增长，相比于ArrayList开销更多内存。 出生早，设计可能不那么好 并且它唯一的优点，部分函数的线程安全对于我们来说，也不是必须的。 具体可参考：java数据结构中，什么情况下用Vector,什么情况下用ArrayList呢？ 场景 查询多用ArrayList，增删多用LinkedList。 ArrayList增删慢也是在大数据量的前提下。在我实现的数据结构中进行了测试(10w~),少量数据差别不大]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Collection 接口详解]]></title>
    <url>%2Fcollection.html</url>
    <content type="text"><![CDATA[集合家族 Collection接口Collection接口Api一览 由图中我们可以看出： 重写了Iterable接口的iterator方法。 重写了Object类的equals和hashCode方法。 定义了一系列待实现方法。 为什么重写Iterable接口的iterator方法 很直观。我们一看注释其实就能大概明白Java设计人员的思路，其实Iterable接口可以看成许多容器类共同特性被提取出来做了接口。而相对于不同容器，这个共有特性的具体实现细节又不同。既然不同所以又要自己定义自己系列的迭代器规则，并让所有实现类都遵循这个规则。 对于Collection接口来说，它规定子接口及其实现类都必须满足它重新设定的规则。 Returns an iterator over the elements in this collection. There are no guarantees concerning the order in which the elements are returned 针对于集合中的所有元素返回一个该集合的迭代器。 但是该迭代器无法保证元素间具有顺序性。(除非这个集合是某个具有这一特性的类的实例) Collection Api 详解这里大家可以看Api文档，讲的比我自己理解的好很多。这里我只是想顺便锻炼一下自己看英文文献的能力。并且很多不懂的我都是照搬了Api文档 boolean add(E e) 向集合中添加一个元素。集合更改则添加成功返回true，如果该集合不允许重复并且已经包含指定的元素。返回false。部分子类的add方法可能会限制添加到集合中的元素类型，或者不会将NULL添加到集合中。 boolean addAll(Collection&lt;? extends E&gt; c) 将指定集合中的所有元素添加到此集合中。在添加过程中如果被添加的集合发生了更改，addAll方法不具有幂等性。 void clear() 清空掉集合中的所有元素 boolean contains(Object o) 如果集合中包含指定元素那么返回true。特别的，如果集合中也包含NULL元素的时候并且要查找的元素也是NULL的时候也返回true。 boolean containsAll(Collection&lt;?&gt; c) 如果该集合中包含指定集合中的所有元素的时候返回true。 boolean isEmpty() 如果集合中没有元素返回true。 boolean remove(Object o) 删除集合中的指定的元素。如果存在NULL，也删除。 boolean removeAll(Collection&lt;?&gt; c) 删除当前集合中所有等于指定集合中的元素。 boolean retainAll(Collection&lt;?&gt; c) 仅保留该指定集合中存在的所有元素。其余删除 int size() 返回该集合中元素的个数。如果超过了Integer.MAX_VALUE，那么返回Integer.MAX_VALUE。 Object[] toArray() 这个方法是集合和数组转化的桥梁。 见名知意，返回包含此集合中所有元素的数组。如果这个集合的迭代器保证元素有序，那么该方法与其迭代器中元素顺序一致。并且该方法返回的数组是拷贝出来的(某些集合底层数组实现，区别这个)，可以进行任意的更改。 &lt;T&gt; T[] toArray(T[] a) 该方法可以对返回的数组类型进行精确控制。而非像toArray方法一样返回Object[]。 返回集合中所有元素到该数组中。如果这个数组可以容纳下的话，否则返回一个新new的数组，容量和集合中元素数量一致。如果指定的数组容量大于集合中元素个数，数组空闲位置填NULL。如果这个集合的Iterator具有顺序性的话，数组元素顺序与该迭代器一致。 Collection接口在Java8中的函数扩展新增抽象方法： 新增重写方法splIterator以及继承方法forEach。 Iterator 接口从刚才的Colllection接口的结构体中我们可以看出，该Collection接口实现了Iterable接口，说明了Collection接口是可迭代的。而这个Iterable接口又只有一个iterator方法。返回值是Iterator对象。即返回的是对应实现类的迭代器对象。 如图，Iterator接口只有三个抽象函数。 首先我们先来对Iterator接口了解一下： Iterator Api详解 boolean hasNext() 如果迭代器中还有元素那么返回true。 E next() 返回迭代器中游标的下一元素 void remove() 从迭代器指向的 collection 中移除迭代器返回的最后一个元素。每次调用 next 后只能调用一次此方法。如果进行迭代时用调用此方法之外的其他方式修改了该迭代器所指向的 collection，则迭代器的行为是不确定的。 ArrayList的自定义迭代器我们拿了一个Collection接口的实现类来看了一下。 ArrayList写了一个内部类Itr来实现Iterator接口作为自己的迭代器。 变量： cursor:迭代器下一个要返回的元素的索引 lastRet：迭代器最后一个返回的元素的索引 expectedModCount：期望中ArrayList集合的底层数组容器的修改次数，来和父类AbstractList中设定的变量modCount来进行比较。 方法： hasNext：判断游标是否指到了size即可。因为底层容器是数组所以size位置没有元素当游标指到的时候就是迭代器结束迭代的时候。 next：首先判断容器是否在Itr初始化之后就已经被其他线程进行了更改。如果是那么就会根据checkForComodification方法的判断规则来跑出一个异常。然后就是通过游标来对容器进行迭代，并动态的修改lastRet的值。 remove： 因为是更改操作，先判断一下容器是否被动过。然后调用该ArrayList类的实例的remove方法删除掉指定索引处的元素。此时动态的维护cursor和lastRet，expectedModCount变量。此处可有看出Iterator接口的remove方法的解释是什么意思了。 checkForComodification：该方法就是简单的对expectedModCount变量和AbstractList类中的modCount变量进行判断看是否容器被其他线程更改了。这也就是为什么Iterator接口的remove方法的释义说迭代器的行为是不确定的。这里ArrayList由于是线程不安全的类，所以在其迭代器中设定了如果线程间冲突时的处理规则。 List 接口List接口Api一览 重写了Collection接口的一些列函数。 继承了add和addAll两个函数的规则。 新增了一些列函数。 List集合的特点 和Set集合最大的不同即红框中所述： 有序 允许重复元素 从Api列表中我们可以看到List接口定义了一个listIterator函数，返回一个ListIterator接口。该接口继承自Iterator接口，并提供了更多的函数。 ListIterator接口 从ListIterator接口的Api描述中总结出的几点就是： 相比于hasNext函数多了一个对应的hasPrevious函数，来检测游标指向的元素是否具有前驱元素。 相比于next函数多了一个previous函数，来获取游标指向的元素的前一位元素。 多了nextIndex和previousIndex函数，用来返回迭代器下一元素和前一迭代过的元素的索引。 多了set函数和add函数，set函数允许替换掉previous和next函数操作后返回的元素。add函数允许将元素插入到容器中游标前的位置。 List常见实现类 ArrayList：底层数据结构是数组。线程不安全 LinkedList：底层数据结构是链表。线程不安全 Vector：底层数据结构是数组。线程安全 Set 接口Set接口Api一览 并没有新增自己的函数 重写了Collection接口的部分函数 继承了add函数和addAll函数 Set集合特点 相比于List集合最大的区别： 不包含重复元素。 这里我们强调一下，有些地方说Set集合是无序的，其实是不严谨的。可以看到jdk注释中是没有指明这一点的，那么List集合的注释中的有序和有些人常说的Set集合是无序的是什么意思呢？ 首先要搞清楚、Java中有序和无序的概念： 有序指的是存储顺序与添加顺序相同，并且可以通过下标访问，List就是这样。 无序刚好相反，指的是存储顺序与添加顺序无关，没有下标，当然也不可能通过下标访问，Set就是如此。 这里需要注意的是，有序、无序中的“序”与我们平常所说的“顺序”无关。 而TreeSet是无序，但又是排好序的。即添加顺序与存储顺序无关，但是其中的对象实现了排序。 Set集合常用子类 HashSet：底层数据结构是哈希表(是一个元素为链表的数组) TreeSet：底层数据结构是红黑树(是一个自平衡的二叉树)。保证元素的排序方式 LinkedHashSet：底层数据结构由哈希表和链表组成。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每日几个Linux命令，十天了解工作中常用的那些命令(一)]]></title>
    <url>%2Flinux-1.html</url>
    <content type="text"><![CDATA[Centos下常用Linux命令的学习ls显示当前目录下非影藏文件与目录1[root@localhost ~]# ls 显示当前目录下包括影藏文件在内的所有文件列表1[root@localhost ~]# ls -a 可见隐藏文件与非隐藏文件在CentOS下的区别就是文件名前的. 输出长格式列表1[root@localhost ~]# ls -1 水平输出文件列表1[root@localhost /]# ls -m 最近修改的文件显示在最上面。1[root@localhost /]# ls -t 打印文件的UID和GID12345678[root@localhost /]# ls -ntotal 254drwxr-xr-x 2 0 0 4096 Jun 12 04:03 bindrwxr-xr-x 4 0 0 1024 Jun 15 14:45 bootdrwxr-xr-x 6 0 0 4096 Jun 12 10:26 datadrwxr-xr-x 10 0 0 3520 Sep 26 15:38 devdrwxr-xr-x 75 0 0 4096 Oct 16 04:02 etc 用户ID(UID)：每个用户必需指定UID。UID 0是保留给root用户的，UID 1~99是保留给其它预定义用户的， UID 100~999是保留给系统用户的 组ID(GID)：主组ID(保存在/etc/group文件中)； 列出文件和文件夹的详细信息1[root@localhost /]# ls -l 按时间列出文件和文件夹详细信息1[root@localhost /]# ls -lt 按修改时间列出文件和文件夹详细信息1[root@localhost /]# ls -ltr mkdir选项12-m&lt;目标属性&gt; 建立目录的同时设置目录的权限-p 若所要建立目录的上层目录目前尚未建立，则会一并建立上层目录 在目录/usr/meng下建立子目录test，并且只有文件主有读、写和执行权限，其他人无权访问1mkdir -m 700 /usr/meng/test 在当前目录中建立bin和bin下的os_1目录，权限设置为文件主可读、写、执行，同组用户可读和执行，其他用户无权访问1mkdir -mp 750 bin/os_1 rm选项123-f：强制删除文件或目录-i：删除已有文件或目录之前先询问用户-r或-R：递归处理，将指定目录下的所有文件与子目录一并处理 交互式删除当前目录下的文件test和example123rm -i test exampleRemove test ?n（不删除文件test)Remove example ?y（删除文件example) 删除当前目录下除隐含文件外的所有文件和子目录1# rm -r * 需要注意的是：指定被删除的文件列表，如果参数中含有目录，则必须加上-r或者-R选项。 pwdpwd命令以绝对路径的方式显示用户当前工作目录。12[root@localhost ~]# pwd/root scp scp命令用于在Linux下进行远程拷贝文件的命令，和它类似的命令有cp，不过cp只是在本机进行拷贝不能跨服务器。 从远处复制文件到本地目录1scp root@10.10.10.10:/opt/soft/nginx-0.5.38.tar.gz /opt/soft/ 从远处复制目录到本地(递归)1scp -r root@10.10.10.10:opt/soft/mongodb /opt/soft/ 上传本地文件到远程机器指定目录1scp /opt/soft/nginx-0.5.38.tar.gz root@10.10.10.10:/opt/soft/scptest 上传本地目录到远程机器指定目录1scp -r /opt/soft/mongodb root@10.10.10.10:/opt/soft/scptest 需要注意：上传先写文件名后写服务器地址名，下载先写服务器地址名，后写本机存放位置 cp 如果把一个文件复制到一个目标文件中，而目标文件已经存在，那么，该目标文件的内容将被破坏。 cp命令不能复制目录，如果要复制目录，则必须使用-R选项 选项12-p：保留源文件或目录的属性-R/r：递归处理，将指定目录下的所有文件与子目录一并处理 将指定文件复制到当前目录下1cp ../mary/homework/assign . 将文件file复制到目录/usr/men/tmp下，并改名为file11cp file /usr/men/tmp/filel 将目录/usr/men下的所有文件及其子目录复制到目录/usr/zh中1cp -r /usr/men /usr/zh iostat iostat命令被用于监视系统输入输出设备和CPU的使用情况。它的特点是汇报磁盘活动统计情况，同时也会汇报出CPU使用情况。同vmstat一样，iostat也有一个弱点，就是它不能对某个进程进行深入分析，仅对系统的整体情况进行分析。 用iostat -x /dev/sda1来观看磁盘I/O的详细情况：1234567891011121314iostat -x /dev/sda1 Linux 2.6.18-164.el5xen (localhost.localdomain)2010年03月26日 avg-cpu: %user %nice %system %iowait %steal %idle 0.11 0.02 0.18 0.35 0.03 99.31 Device: tps Blk_read/s Blk_wrtn/s Blk_read Blk_wrtn sda1 0.02 0.08 0.00 2014 4 第三行和第四行显示CPU使用情况（具体内容和mpstat命令相同）。I/O输出的信息，如下所示：123456789101112131415标示 说明Device 监测设备名称rrqm/s 每秒需要读取需求的数量wrqm/s 每秒需要写入需求的数量r/s 每秒实际读取需求的数量w/s 每秒实际写入需求的数量rsec/s 每秒读取区段的数量wsec/s 每秒写入区段的数量rkB/s 每秒实际读取的大小，单位为KBwkB/s 每秒实际写入的大小，单位为KBavgrq-sz 需求的平均大小区段avgqu-sz 需求的平均队列长度await 等待I/O平均的时间（milliseconds）svctm I/O需求完成的平均时间%util 被I/O需求消耗的CPU百分比 lsof lsof命令用于查看你进程打开的文件，打开文件的进程。进程打开的端口TCP,UDP找回，恢复删除的文件。是十分方便的系统工具，因为lsof需要访问系统核心内存及各种文件，所以需要root权限。在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件。所以如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符。该文件描述符为应用程序与基础操作系统之间的交互提供了通用接口。因为应用程序打开文件的描述符列表提供了大量关于这个应用程序本身的信息，因此通过lsof工具能够查看这个列表对系统监测以及排错将是很有帮助的。 123456789101112131415161718192021222324252627lsofcommand PID USER FD type DEVICE SIZE NODE NAMEinit 1 root cwd DIR 8,2 4096 2 /init 1 root rtd DIR 8,2 4096 2 /init 1 root txt REG 8,2 43496 6121706 /sbin/initinit 1 root mem REG 8,2 143600 7823908 /lib64/ld-2.5.soinit 1 root mem REG 8,2 1722304 7823915 /lib64/libc-2.5.soinit 1 root mem REG 8,2 23360 7823919 /lib64/libdl-2.5.soinit 1 root mem REG 8,2 95464 7824116 /lib64/libselinux.so.1init 1 root mem REG 8,2 247496 7823947 /lib64/libsepol.so.1init 1 root 10u FIFO 0,17 1233 /dev/initctlmigration 2 root cwd DIR 8,2 4096 2 /migration 2 root rtd DIR 8,2 4096 2 /migration 2 root txt unknown /proc/2/exeksoftirqd 3 root cwd DIR 8,2 4096 2 /ksoftirqd 3 root rtd DIR 8,2 4096 2 /ksoftirqd 3 root txt unknown /proc/3/exemigration 4 root cwd DIR 8,2 4096 2 /migration 4 root rtd DIR 8,2 4096 2 /migration 4 root txt unknown /proc/4/exeksoftirqd 5 root cwd DIR 8,2 4096 2 /ksoftirqd 5 root rtd DIR 8,2 4096 2 /ksoftirqd 5 root txt unknown /proc/5/exeevents/0 6 root cwd DIR 8,2 4096 2 /events/0 6 root rtd DIR 8,2 4096 2 /events/0 6 root txt unknown /proc/6/exeevents/1 7 root cwd DIR 8,2 4096 2 / lsof输出各列信息的意义如下：123456COMMAND：进程的名称PID：进程标识符PPID：父进程标识符（需要指定-R参数）USER：进程所有者PGID：进程所属组FD：文件描述符，应用程序通过文件描述符识别该文件。 uname uname命令用于打印当前系统相关信息（内核版本号、硬件架构、主机名称和操作系统类型等）。 显示在网络上的主机名称12[root@localhost ~]# uname -nlocalhost 显示操作系统名称12[root@localhost ~]# uname -sLinux]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的BigDecimal类你了解多少？]]></title>
    <url>%2Fjava-bigdecimal.html</url>
    <content type="text"><![CDATA[前言我们都知道浮点型变量在进行计算的时候会出现丢失精度的问题。如下一段代码： 12345678910System.out.println(0.05 + 0.01);System.out.println(1.0 - 0.42);System.out.println(4.015 * 100);System.out.println(123.3 / 100);输出：0.0600000000000000050.5800000000000001401.499999999999941.2329999999999999 可以看到在Java中进行浮点数运算的时候，会出现丢失精度的问题。那么我们如果在进行商品价格计算的时候，就会出现问题。很有可能造成我们手中有0.06元，却无法购买一个0.05元和一个0.01元的商品。因为如上所示，他们两个的总和为0.060000000000000005。这无疑是一个很严重的问题，尤其是当电商网站的并发量上去的时候，出现的问题将是巨大的。可能会导致无法下单，或者对账出现问题。所以接下来我们就可以使用Java中的BigDecimal类来解决这类问题。 普及一下： Java中float的精度为6~7位有效数字。double的精度为15~16位。 API构造器： 构造器 描述 BigDecimal(int) 创建一个具有参数所指定整数值的对象。 BigDecimal(double) 创建一个具有参数所指定双精度值的对象。 BigDecimal(long) 创建一个具有参数所指定长整数值的对象。 BigDecimal(String) 创建一个具有参数所指定以字符串表示的数值的对象。 函数： 方法 描述 add(BigDecimal) BigDecimal对象中的值相加，然后返回这个对象。 subtract(BigDecimal) BigDecimal对象中的值相减，然后返回这个对象。 multiply(BigDecimal) BigDecimal对象中的值相乘，然后返回这个对象。 divide(BigDecimal) BigDecimal对象中的值相除，然后返回这个对象。 toString() 将BigDecimal对象的数值转换成字符串。 doubleValue() 将BigDecimal对象中的值以双精度数返回。 floatValue() 将BigDecimal对象中的值以单精度数返回。 longValue() 将BigDecimal对象中的值以长整数返回。 intValue() 将BigDecimal对象中的值以整数返回。 由于一般的数值类型，例如double不能准确的表示16位以上的数字。 BigDecimal精度也丢失我们在使用BigDecimal时，使用它的BigDecimal(String)构造器创建对象才有意义。其他的如BigDecimal b = new BigDecimal(1)这种，还是会发生精度丢失的问题。如下代码： 12345678910BigDecimal a = new BigDecimal(1.01);BigDecimal b = new BigDecimal(1.02);BigDecimal c = new BigDecimal("1.01");BigDecimal d = new BigDecimal("1.02");System.out.println(a.add(b));System.out.println(c.add(d));输出：2.03000000000000002664535259100375697016716003417968752.03 可见论丢失精度BigDecimal显的更为过分。但是使用Bigdecimal的BigDecimal(String)构造器的变量在进行运算的时候却没有出现这种问题。 究其原因计算机组成原理里面都有，它们的编码决定了这样的结果。long可以准确存储19位数字，而double只能准备存储16位数字。double由于有exp位，可以存16位以上的数字，但是需要以低位的不精确作为代价。如果需要高于19位数字的精确存储，则必须用BigInteger来保存，当然会牺牲一些性能。所以我们一般使用BigDecimal来解决商业运算上丢失精度的问题的时候，声明BigDecimal对象的时候一定要使用它构造参数为String的类型的构造器。 同时这个原则Effective Java和MySQL 必知必会中也都有提及。float和double只能用来做科学计算和工程计算。商业运算中我们要使用BigDecimal。 而且我们从源码的注释中官方也给出了说明，如下是BigDecimal类的double类型参数的构造器上的一部分注释说明： 1234567891011121314151617181920212223* The results of this constructor can be somewhat unpredictable. * One might assume that writing &#123;@code new BigDecimal(0.1)&#125; in * Java creates a &#123;@code BigDecimal&#125; which is exactly equal to * 0.1 (an unscaled value of 1, with a scale of 1), but it is * actually equal to * 0.1000000000000000055511151231257827021181583404541015625. * This is because 0.1 cannot be represented exactly as a * &#123;@code double&#125; (or, for that matter, as a binary fraction of * any finite length). Thus, the value that is being passed * &lt;i&gt;in&lt;/i&gt; to the constructor is not exactly equal to 0.1, * appearances notwithstanding. …… * When a &#123;@code double&#125; must be used as a source for a * &#123;@code BigDecimal&#125;, note that this constructor provides an * exact conversion; it does not give the same result as * converting the &#123;@code double&#125; to a &#123;@code String&#125; using the * &#123;@link Double#toString(double)&#125; method and then using the * &#123;@link #BigDecimal(String)&#125; constructor. To get that result, * use the &#123;@code static&#125; &#123;@link #valueOf(double)&#125; method. * &lt;/ol&gt;public BigDecimal(double val) &#123; this(val,MathContext.UNLIMITED);&#125; 第一段也说的很清楚它只能计算的无限接近这个数，但是无法精确到这个数。第二段则说，如果要想准确计算这个值，那么需要把double类型的参数转化为String类型的。并且使用BigDecimal(String)这个构造方法进行构造。 去获取结果。 正确运用BigDecimal另外，BigDecimal所创建的是对象，我们不能使用传统的+、-、*、/等算术运算符直接对其对象进行数学运算，而必须调用其相对应的方法。方法中的参数也必须是BigDecimal的对象，由刚才我们所罗列的API也可看出。 在一般开发过程中，我们数据库中存储的数据都是float和double类型的。在进行拿来拿去运算的时候还需要不断的转化，这样十分的不方便。这里我写了一个工具类： 1234567891011121314151617181920212223242526272829303132333435/** * @author: Ji YongGuang. * @date: 19:50 2017/12/14. */public class BigDecimalUtil &#123; private BigDecimalUtil() &#123; &#125; public static BigDecimal add(double v1, double v2) &#123;// v1 + v2 BigDecimal b1 = new BigDecimal(Double.toString(v1)); BigDecimal b2 = new BigDecimal(Double.toString(v2)); return b1.add(b2); &#125; public static BigDecimal sub(double v1, double v2) &#123; BigDecimal b1 = new BigDecimal(Double.toString(v1)); BigDecimal b2 = new BigDecimal(Double.toString(v2)); return b1.subtract(b2); &#125; public static BigDecimal mul(double v1, double v2) &#123; BigDecimal b1 = new BigDecimal(Double.toString(v1)); BigDecimal b2 = new BigDecimal(Double.toString(v2)); return b1.multiply(b2); &#125; public static BigDecimal div(double v1, double v2) &#123; BigDecimal b1 = new BigDecimal(Double.toString(v1)); BigDecimal b2 = new BigDecimal(Double.toString(v2)); // 2 = 保留小数点后两位 ROUND_HALF_UP = 四舍五入 return b1.divide(b2, 2, BigDecimal.ROUND_HALF_UP);// 应对除不尽的情况 &#125;&#125; 该工具类提供了double类型的基本的加减乘除运算。直接调用即可。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据类型范围]]></title>
    <url>%2Flonglongdouble.html</url>
    <content type="text"><![CDATA[常识 类型 字节 范围 byte 1字节，8位 8位 256(-128 到127) bool 1字节，8位 8位 256(-128 到127) char 1字节，8位 8位 256(-128 到127) short 2字节，16位 65535( –32,768 到 32,767) int 4字节，32位 4294967296( –2,147,483,648 到 2,147,483,647) unsigned int 4字节，32位 4294967296(0 到 4,294,967,295) long 4字节，32位 4294967296( –2,147,483,648 到 2,147,483,647) long long 8字节，64位 18446744073709551616( –9,223,372,036,854,775,808 到 9,223,372,036,854,775,807) float 4字节，32位 3.4E +/- 38（7 位数） double 8字节，64位 1.7E +/- 308（15 位数） 这里需要注意的是long和int的区别，看上去在范围上两者好像一样。但是这是取决于你所在的平台的。但无论什么凭条都必须遵守 [ int 至少 16 位，long int 至少 32 位，并且 sizeof(int) &lt;= sizeof(long)」的规则。 这就类似，你觉得「爱人」和「妻子」不可能有区别，但是在日语里，这两个确实有天壤之别。我们这里都是按照数据类型在一些情况下最小范围进行罗列。 所以我们再来个表： 类型 16位系统/字节 32位系统/字节 64位系统/字节 char 1 1 1 char* 2 4 8 short 2 2 2 int 2 4 4 long 4 4 8 long long 8 8 8 我们多罗列了个unsigned int，是为了说明unsigned的情况。所有数据类型除bool，unsigned时范围变化都一致。所能表示的最大数是原来的2倍，所能表示的范围没变。]]></content>
      <categories>
        <category>数据类型</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大话数据结构 你需要了解的那些常识]]></title>
    <url>%2Fdatastructure.html</url>
    <content type="text"><![CDATA[算法 树一对多，图多对多 一般除了内存，都叫外存储结构，文件结构 在考虑数据结构的时候，数据的物理关系，逻辑关系要平衡好，双向考虑。 健壮性：对任何输入数据，无论是否合法，都能合理处理返回相应的结果。不会产生异常或莫名其妙的结果 CPU使用率或内存的占用情况也可能影响算法所耗费的时间 对于多个循环，假设循环体的时间复杂度为O(n)，各个循环的循环次数分别是a, b, c...，则这个循环的时间复杂度为 O(n×a×b×c...)。分析的时候应该由里向外分析这些循环。如下： 12345678void aFunc(int n) &#123; for(int i = 0; i &lt; n; i++) &#123; // 循环次数为 n for(int j = 0; j &lt; n; j++) &#123; // 循环次数为 n printf("Hello, World!\n"); // 循环体时间复杂度为 O(1) &#125; &#125;&#125;此时时间复杂度为 O(n × n × 1)，即 O(n^2)。 时间复杂度分析的基本策略是：从内向外分析，从最深层开始分析。如果遇到函数调用，要深入函数进行分析。 线性表 线性表需要相同的数据类型 线性表的处理方式都是先取代，后目的。比如删除链式线性表的某个节点的流程，先取代delete point使它的前驱节点指向它的后继节点，这样就完成了取代。然后再free()掉这个节点，这样就达到了目的。再比如加入某个节点，先使add point指向add index要加入处的后继节点，这即取代。然后再使add index的前驱节点指向add point。 解题步骤：1. 先考虑特殊情况，边缘值 2. 进入退出循环时需要找准条件，考虑清楚退出循环时所需要的变量的终值是多少，方便使用 3. 审视全局，带正确的值判断是否AC 对于链表，如果用数组实现。那即是静态链表 链表分好几类： 有单向链表， 一个节点指向下一个节点 双向链表 一个节点两个指针域 循环链表 能通过任何一个节点找到其他所有节点，将两种(双向，单向)链表的最后一个节点指向第一个节点从而实现循环。 操作链表要时刻记住的是： 节点中指针域指向的就是一个节点了！ 12345678910int i = 1;while (i &lt; index) &#123; headNode = headNode.getNextNode(); i++;&#125;这段代码意义即，从初始化i=0开始，如果要插入到第i个。那么就取第i-1个。如果取i-1个。那么由i控制的话，原本从0开始计数到i个。是i+1个但是如果取到`&lt;i`个。那么就是i个。要想取它前面那个，那么就需要把i的起点增高，即起始为1。而不是0 操作一个链表只需要知道它的头指针就可以做任何操作了， 添加数据到链表中 那么无疑是找到尾节点插入即可。while(tempNode.getNextNode()!=null)当退出循环时，那么就定位到了节点。 遍历链表 从头结点开始输出，知道尾节点。while(tempNode!=null)那么退出循环时即所有节点全部输出。 给定位置插入节点到链表中 因为要往指定位置插入节点。比如2143要往第3个位置插，那么即插到1,4中间。 所以要往哪个位置插那么必须找到他的前驱节点1。 如下进入判断条件中，如果起始条件是0的时候，那么需要注意，每进入一次循环+1。那么它总共会进入3次。0,1,2。可是循环中节点向下遍历。如果首次进入循环的开始节点是第一个节点而非头结点的话即2。往后跳三次，就会找到3节点，很明显不是我们想要的。 所以我们应该明白如果要插入到第10个位置，我们需要找到第九个节点，那么循环起始从第一个开始的话，找到第九个需要进循环8次退出循环时才是第9个节点。所以我们可以看出，要插到第10个位置我们需要循环得是8次而不是9次。 我们知道如果i从0- i&lt;10是10次。即0-9那么我们可以控制i从i = 1开始，这样只使循环少了一次。那么另一次怎么减呢 我们可以再通过使第一次进入循环的节点是头结点而不是第一个拥有实际value的节点开始。这样我们就可以使无用节点也占用一次循环，也就相当于使循环次数-1了。 123456789101112131415index = 3;----int i = 0;temp = headNode.getNextNode();while(i &lt; index)&#123; tempNode = tempNode.getNextNode(); i++;&#125;int i = 1;temp = headNode;while(i &lt; index)&#123; tempNode = tempNode.getNextNode(); i++;&#125; ​ 然后接下承上，即要插入的这个节点Node.next = 4然后1.next = Node。切不可乱了顺序，否则会丢失指针 获取链表的长度 遍历链表，声明一个变量，每遍历一个节点变量+1。 123456int i = 0;tempNode = headNode.next;while(tempNode!=null) &#123; i++; tempNode = tempNode.next;&#125; 这里需要明白两点。 当tempNode等于头结点的时候，我们可以想到这种情况会使循环多进行一次。 当循环判断条件while()，判断的不是tempNode!=null即当前节点，而是tempNode.next!=null下一节点时。会使循环少进行一次。 这两点很重要，循环进行多少次的掌控就在这几点。 删除给定位置的节点 和从指点位置插入点一样。都是要找指定位置的前驱节点。 总共4个元素，我们要插到第3个位置。即需要找到第2个元素，进入一次循环节点向后移一位， 进入节点时时第一个元素。那么我们需要进循环一次即可。那么即 12345int i = 1；while(i &lt; 3)&#123; i++; temp = temp.next;&#125; 对链表进行排序 冒泡排序 双层循环，外层节点起始位置第一节点temp = headNode.next，退出条件temp != null。这是索引循环起始指向第一节点，最终从末尾节点跳出。 内层循环，起始节点即第一节点nextNode = headNode.next，退出条件nextNode.next != null，因为冒泡是前后元素比大小第1和第2比，第n-1和第n比。所以当指到最后节点的时候就可以跳出。 找到链表中倒数第k个节点 这个起始和正向找节点是一个概念，我们只要变换数字即可。首先我们可以把链表看成一个首尾相连的循环结构。那么倒数第k个，即一个元素正数位置的绝对值加上倒数位置的绝对值比总数多1。比如6个数，我们找倒数第二个。倒数第2个也是正数第5个，2+5-1=6。所以我们要找一个数，正向找无疑很方便，只需要(-k+1+总数) = 元素位置。我们只需要对链表进行排序后获取该元素即可 我们也可以设立两个节点。一个节点比另一个节点快k步。即先行节点走了k下，后行节点出发走第一下。当后行节点跳出循环，那么先行节点必然是倒数第k个节点。 123456789101112131415Node tempNode = headNode;Node nextNode = null;int i = 0;while (tempNode != null) &#123; i++; tempNode = tempNode.getNextNode(); if (tempNode == null) &#123; break; &#125; if (i == k) &#123; nextNode = headNode.getNextNode(); &#125;else if (i &gt; k) &#123; nextNode = nextNode.getNextNode(); &#125;&#125; 删除链表重复数据 双重循环，第一层循环是索引循环，循环进入从第一个元素开始，到尾元素跳出。 内循环，每进入第一层循环的时候赋予最新的外层索引值。然后取该值的next元素与索引值进行比较。依次next。 hashtable做法。使链表上的每个元素插入到hashtable中，插入前进行判断是否在hashtable中存在。 需要注意的是，hashtable在存储的时候是将该值存到了键值的位置。value恒定给值，否则不方便遍历。 123456while (tempNode != null) &#123; if (!hashtable.containsKey(tempNode.getValue())) &#123; hashtable.put(tempNode.getValue(), 1); &#125; tempNode = tempNode.getNextNode();&#125; 查询链表的中间节点 两个指针，一个走两步，一个走一步。同一起点出发，拿先行节点进行判断null值，先行节点为null那么跳出循环，此时后行节点即为中间节点。 递归从尾到头输出单链表 先判断入参元素非空，然后一直递归headNode.next。 排除头元素，输出每个元素的值。 123456if (headNode != null) &#123; traverseByRecursive(headNode.getNextNode()); if (headNode.getValue() != HEAD_POINT_NUMBER) &#123; System.out.println(headNode.getValue()); &#125;&#125; 反转链表 非递归 非递归实现需要注意，每一步我们做了什么。比如4,2,3,3。我们第一步拿出了4，第二步成了2,4。第三步3,2,4。这样。所以我们应该做的是， 首先声明一个节点tempNode，让其根据链表循环向后遍历链表。直到=null。这样我们所有元素都反转了。 其次我们发现第一个元素抽出的时候，即新链表的头我们把他进行标识firstNode以方便为后续抽出的节点的next属性赋值。比如4，它的next元素是null而后抽出的元素他们的next元素都是在它前一位抽出的元素。因为这个next元素的赋值操作发生在循环中，且只有一次是null其他几次都为实际元素，所以我们需要声明一个节点nextNode初始化为null。当他第一次进入循环的时候，即拿出4的时候将其放入tempNode的next属性中。 然后赋值操作后紧跟着对该nextNode元素进行更改，让其等于新链表的头firstNode。 123456while (tempNode != null) &#123; firstNode = tempNode; tempNode = tempNode.getNextNode(); firstNode.setNextNode(nextNode); nextNode = firstNode;&#125; 栈 栈是限定仅在表尾进行插入和删除操作的线性表 栈又称为后进先出的线性表。简称LIFO结构 队列是只允许在一端进行插入操作，而在另一端进行删除操作的线性表 栈可以有两种实现方式，即顺序存储和链式存储(链栈)两种。 顺序存储的缺点就是，需要提前预知栈的容量，如果不够的时候还需要对数组扩容。 而链式的栈则没有这种缺点，可以方便的进行删除和插入元素。他的缺点是每个元素必须含有一个指针域，这无疑在内存上增加了一笔开销。 两种实现方式的差别还是和线性表顺序及链式方式实现的差别相同，在于检索数据和删除增加数据。 最好不要有连续操作，尽量多用变量接需要的中间值。否则容易出现丢失数据的情况(原节点指针移动，节点不被指向，后续却还需要 丢失节点的数据，应在关于该节点的最后操作结束前声明一个指针指向该节点地址)。最后释放 最重要的一点，如果要往栈中存放的元素大小不可预知，有时很小有时很大的话，那么最好使用链栈。 两栈共享空间的栈结构。其实必须是两个具有相同数据类型的栈结构合并才能满足。而且其适应场景也必须是相对的，即一个栈在做插入，那么另一个栈必然在减出。就比如买股票，一个人在买肯定就有人卖出了。不可能所有人都在买，或者所有栈都在插入数据，那么这结构很快就会饱满。 考虑边缘值，特殊情况 2. 如果需要返回值，先满足需求将值返回 3. 根据是链表还是顺序结构，增删元素。注意不同情况，Stack.top的移动规律。 栈的应用：递归，前，中，后缀表达式 每个递归定义必须至少有一个条件。满足时递归不再进行。即不再引用自身而是返回值退出。 递归：波那切数列两种实现： 迭代和递归，迭代使用的是循环结构。递归使用的是选择结构，递归的优点 能使程序的结构更清晰，更简洁。更容易想到和理解，减少代码的读者的时间和精力。大量递归的缺点是递归调用会建立函数的副本，会耗费大量的时间和内存。迭代则不需要反复调用和占用额外的内存。因此我们应该视不同情况选择不同的代码实现方式。 前，中，后缀表达式 队列]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java8 lambda快速上手]]></title>
    <url>%2Fjava-java8-lambda.html</url>
    <content type="text"><![CDATA[学习地址书 -&gt; Java8函数式编程 https://dzone.com/articles/java-lambda-expressions-basics https://nkcoder.github.io/2016/01/16/java-8-lambda-expression-guide/ http://blog.oneapm.com/apm-tech/226.html 代码特点简单、干净、易读 业界要求编写干净、易于维护的代码 优点降低了开发时间和成本 对比使用匿名内部类缺点 lambda的出现。消除声明式匿名内部类的使用 1. 多余样板代码冗余：设计匿名内部类的目的，就是为了方便Java程序员将代码作为数据传递。不过，匿名内部类还是不够简便。为了调用一行重要的逻辑代码，不得不加上4行冗繁的样板代码。 12345button.addActionListener(new ActionListener() &#123; public void actionPerformed(ActionEvent event) &#123; System.out.println(&quot;button clicked&quot;); &#125; &#125;); 2. 语义不清晰：尽管如此，样板代码并不是唯一的问题：这些代码还相当难读，因为它没有清楚地表达程序员的意图。我们不想传入对象，只想传入行为。 1button.addActionListener(event -&gt; System.out.println(&quot;button clicked&quot;)); lambda的参数主要针对，匿名内部类实现的方法 event：方法的参数。类型JVM会查找 sout：方法的具体实现细节。 lambda的多种写法123456789101112Runnable noArguments = () -&gt; System.out.println(&quot;Hello World&quot;); ① ActionListener oneArgument = event -&gt; System.out.println(&quot;button clicked&quot;); ② Runnable multiStatement = () -&gt; &#123; ③ System.out.print(&quot;Hello&quot;); System.out.println(&quot; World&quot;); &#125;; BinaryOperator&lt;Long&gt; add = (x, y) -&gt; x + y; ④ BinaryOperator&lt;Long&gt; addExplicit = (Long x, Long y) -&gt; x + y; ⑤ ① 中所示的Lambda表达式不包含参数，使用空括号()表示没有参数。该Lambda表达式实现了Runnable接口，该接口也只有一个run方法，没有参数，且返回类型为void。 ②中所示的Lambda表达式包含且只包含一个参数，可省略参数的括号 ③中，Lambda表达式的主体不仅可以是一个表达式，而且也可以是一段代码块，使用大括号{}将代码块括起来，该代码块和普通方法遵循的规则别无二致，可以用返回或抛出异常来退出。只有一行代码的Lambda表达式也可使用大括号，用以明确Lambda表达式从何处开始、到哪里结束。 ④中，Lambda表达式也可以表示包含多个参数的方法，这时就有必要思考怎样去阅读该Lambda表达式。这行代码并不是将两个数字相加，而是创建了一个函数，用来计算两个数字相加的结果。变量add的类型是BinaryOperator&lt;Long&gt;，它不是两个数字的和，而是将两个数字相加的那行代码。 ⑤中，到目前为止，所有Lambda表达式中的参数类型都是由编译器推断得出的。这当然不错，但有时最好也可以显式声明参数类型，此时就需要使用小括号将参数括起来，多个参数的情况也是如此。 注意：目标类型是指Lambda表达式所在上下文环境的类型。比如，将Lambda表达式赋值给一个局部变量，或传递给一个方法作为参数，局部变量或方法参数的类型就是Lambda表达式的目标类型。 lambda引用的是值，不是变量 Lambda表达式中引用的局部变量必须是final或既成事实上的final变量 既成事实上的final变量即该变量从第一获取到，就没改变过。 错误代码：123String name = getUserName(); name = formatUserName(name); button.addActionListener(event -&gt; System.out.println(&quot;hi &quot; + name)); 匿名内部类，需要引用方法外的变量的时候。需要将该变量声明为final类型。 匿名内部类中使用final局部变量123456final String name = getUserName(); button.addActionListener(new ActionListener() &#123; public void actionPerformed(ActionEvent event) &#123; System.out.println(&quot;hi &quot; + name); &#125; &#125;) Java 8虽然放松了这一限制，可以引用非final变量，但是该变量在既成事实上必须是final。虽然无需将变量声明为final，但在Lambda表达式中，也无法用作非终态变量。如果坚持用作非终态变量，编译器就会报错。 lambda 参数类型推断Predicate接口的源码，接受一个对象，返回一个布尔值 123public interface Predicate&lt;T&gt; &#123; boolean test(T t); &#125; 图解： T -&gt; Predicate -&gt; boolean Predicate接口图示，接受一个对象，返回一个布尔值 复杂的类型推断1BinaryOperator&lt;Long&gt; addLongs = (x, y) -&gt; x + y; 12345678/** * Applies this function to the given arguments. * * @param t the first function argument * @param u the second function argument * @return the function result */R apply(T t, U u); 写lambda实现前，可以去接口中看一下函数是否是泛型类型(返回值)。 接口对象被调用才实现Check123456public interface Check &#123; boolean check(Predicate&lt;Integer&gt; predicate);// boolean check(IntPred predicate);&#125; Predicate123456789101112public interface Predicate&lt;T&gt; &#123; /** * Evaluates this predicate on the given argument. * * @param t the input argument * @return &#123;@code true&#125; if the input argument matches the predicate, * otherwise &#123;@code false&#125; */ boolean test(T t); &#125; Main123456int y = 0;int w = 2;Check check = (Predicate&lt;Integer&gt; x) -&gt; x.test(y);// test 的参数boolean result = check.check(n -&gt; n &gt; w); // y &gt; w?System.out.println(result);]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 聚合和继承]]></title>
    <url>%2Fmaven-aggregationandinheritance.html</url>
    <content type="text"><![CDATA[Maven 聚合123456789101112131415&lt;projectxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;/groupId&gt; &lt;artifact&gt;account-aggregator&lt;/artifact&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;Account Aggregator&lt;/name&gt; &lt;modules&gt; &lt;module&gt;account-email&lt;/module&gt; &lt;module&gt;account-persist&lt;/module&gt; &lt;/modules&gt;&lt;/project&gt; 该pom文件作为其他pom的容器运行，在pom文件的modules标签中引入我们想要聚合的各个模块。这样就整合了多个模块。 需要注意的是： &lt;packageing&gt;标签在聚合情况下的打包方式必须为pom Maven 继承1234567891011&lt;projectxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:shemaLocation=&quot;http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;/groupId&gt; &lt;artifactId&gt;account-parent&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;Account Parent&lt;/name&gt;&lt;/project&gt; 由于父模块只是为了帮助消除配置的重复，因此它本身不包含除POM之外的项目文件，也就不需要src/main/java之类的文件夹了。需要注意打包类型也为pom即可。 123456789101112131415161718192021222324252627282930&lt;projectxmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:shemaLocation=&quot;http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;parent&gt; &lt;groupId&gt;com.juvenxu.mvnbook.account&lt;groupId&gt; &lt;artifactId&gt;account-parent&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../account-parent/pom.xml&lt;/relativePath&gt; &lt;/parent &lt;artifactId&gt;account-email&lt;/artifactId&gt; &lt;name&gt;Account Email&lt;/name&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; .... &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 和Java中的继承一样需要指定继承的配置文件地址&lt;parent&gt;标签 子pom配置： 12345&lt;parent&gt; &lt;groupId&gt;父pom所在项目的groupId&lt;/groupId&gt; &lt;artifactId&gt;父pom所在项目的artifactId&lt;/artifactId&gt; &lt;version&gt;父pom所在项目的版本号&lt;/version&gt;&lt;/parent&gt; dependencyManagement 在Maven中dependencyManagement的作用其实相当于一个对所依赖jar包进行版本管理的管理器。 pom.xml文件中，jar的版本判断的两种途径 如果dependencies里的dependency自己没有声明version元素，那么maven就会倒dependencyManagement里面去找有没有对该artifactId和groupId进行过版本声明，如果有，就继承它，如果没有就会报错，告诉你必须为dependency声明一个version 所以在继承中父类的pom文件要使用dependencyManagement来承载公共依赖。为底层子pom提供公用的依赖verison。就不需要每个子类频繁声明了。有时候还可能声明的版本不一致 如果dependencies中的dependency声明了version，那么无论dependencyManagement中有无对该jar的version声明，都以dependency里的version为准。 如下 12345678910111213141516171819pom.xml //只是对版本进行管理，不会实际引入jar &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;3.2.7&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; //会实际下载jar包 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 生命周期]]></title>
    <url>%2Fmaven-lifecycle.html</url>
    <content type="text"><![CDATA[Maven 命令命令运行均在操作项目的根目录下。 编译 mvn compile 编译后会在mvn跟目录下生成target目录。然后编译后的文件存在于classes目录下。 测试 mvn test 运行我们所有的测试文件。即/项目/test/java/包结构下的所有****Test.java文件。 运行 mvn [项目名] 编译后即可运行 清理 mvn clean 删除target。target中存在编译后的字节码文件和编译报告，以及打包后的包文件。 改命令一般会配合其他命令一起使用,很少单独使用,没事儿就用用它 打包 mvn package 在项目根目录下运行此命令将会在target目录的根目录下生成.jar或.war打包后的压缩文件。在运行package的时候,clean和test是自动执行的 发布 mvn install 先通过package进行打包，打包后的jar包存在于工作目录中。也可以直接mvn install,执行该命会直接执行mvn package,然后通过install命令将其安装到本地仓库中才会后续被引入依赖。 Maven 生命周期 clean 清理项目 pre-clean 执行项目清理前的工作 clean post-clean default 构建项目 compile test package install site 生成项目站点 pre-site site post-sit site-deploy 发布生成的站点到服务器上 注意: 需要注意的是,执行其中三个阶段的某一阶段的任意一环的时候,它前面的都会执行。比如执行default阶段的mvn package阶段,那么compile和test也都会在package前执行]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 标签]]></title>
    <url>%2Fmaven-label.html</url>
    <content type="text"><![CDATA[Maven 标签 project pom文件的根元素,包含了一些pom文件的约束信息 modelVersion 指定了当前Maven模型的版本号，对于Maven2和Maven3来说，它只能是4.0.0 groupId 顾名思义，这个应该是公司名或是组织名。一般来说groupId是由三个部分组成，每个部分之间以”.”分隔，第一部分是项目用途，比如用于商业的就是”com”，用于非营利性组织的就 是”org”；第二部分是公司名，比如”tengxun”、”baidu”、”alibaba”；第三部分是你的项目名 artifactId 可以认为是Maven构建的项目名，比如你的项目中有子项目，就可以使用”项目名-子项目名”的命名方式 version 版本号，SNAPSHOT意为快照，说明该项目还在开发中，是不稳定的版本。alpha内部测试版本,beta公测版本,Release稳定版本,GA正式版本。 在上面的这些元素之外，还有一些元素，同样罗列一下： packing 项目打包的类型，可以使jar、war、rar、ear、pom，默认是jar name 项目描述名,一般在产生项目文档的时候使用。 url 项目的地址 description 项目的描述 developers 开发人员列表 licenses 许可证信息 organization 组织信息 dependencies和dependency type scop 依赖使用范围,如果为test。那么该依赖的jar只会在项目测试的时候有用，如果项目运行的代码调用该依赖的jar的时候则会报错。三种Classpath选项,编译,测试,运行 compile 默认范围,编译测试运行都有效 provided 编译测试有限 runtime 测试运行有限 test 测试有限 system 编译测试有限,可移植性差 import 只在dependencement中使用,表示从其他pom中继承来的依赖。 如图，B项目依赖了A项目，也就依赖了A项目的所有依赖。 optional 默认false。即子项目默认继承该依赖，如果为true那么子项目需要显示的依赖该依赖。 exclusions 排除依赖传递的列表。比如我们需要spring的jar即可，但是当我们引入了spring的jar的时候，它又引入了很多我们不需要的jar。此时就可以将他们排除出去。 前者包含后者。前面说了，Maven的一个重要作用就是统一管理jar包，为了一个项目可以build或运行，项目中不可避免的，会依赖很多其他的jar包，在Maven中，这些依赖就被称为dependency。 本地仓库和远程仓库是这样的，Maven工程首先会从本地仓库中获取jar包，当无法获取指定jar包时，本地仓库会从远程仓库（中央仓库）中下载jar包，并放入本地仓库以备将来使用。 dependencyManagement 依赖管理。该标签中的依赖不会被引入到实际的项目中作用，该标签主要定义在父模块中，供子模块所继承用的。比如我们很多项目用到junit，我们就可以抽象出来一个父模块，并且在该父模块对junit进行定义，其他子模块直接继承它就可 build parent 通常用于对子模块中对父模块的继承。 modules聚合运行多个maven项目，当我们有多个maven项目的时候可以通过该标签一起进行编译。 参考 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;!--父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。--&gt; &lt;parent&gt; &lt;!--被继承的父项目的构件标识符--&gt; &lt;artifactId/&gt; &lt;!--被继承的父项目的全球唯一标识符--&gt; &lt;groupId/&gt; &lt;!--被继承的父项目的版本--&gt; &lt;version/&gt; &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项 目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。--&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;!--声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。--&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app--&gt; &lt;groupId&gt;cn.erhuowang&lt;/groupId&gt; &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个 特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源 码，二进制发布和WARs等。--&gt; &lt;artifactId&gt;erhuowang-maven2&lt;/artifactId&gt; &lt;!--项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型--&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!--项目当前版本，格式为:主版本.次版本.增量版本-限定版本号--&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--项目的名称, Maven产生的文档用--&gt; &lt;name&gt;erhuo-maven&lt;/name&gt; &lt;!--项目主页的URL, Maven产生的文档用--&gt; &lt;url&gt;http://erhuowang.cn&lt;/url&gt; &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标 签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。--&gt; &lt;description&gt;A maven project to study maven.&lt;/description&gt; &lt;!--描述了这个项目构建环境中的前提条件。--&gt; &lt;prerequisites&gt; &lt;!--构建该项目或使用该插件所需要的Maven的最低版本--&gt; &lt;maven/&gt; &lt;/prerequisites&gt; &lt;!--项目名称和URL--&gt; &lt;issueManagement&gt; &lt;!--项目名字，--&gt; &lt;system&gt;erhuowang&lt;/system&gt; &lt;!--该项目使用的URL--&gt; &lt;url&gt;http://erhuowang.cn&lt;/url&gt; &lt;/issueManagement&gt; &lt;!--项目持续集成信息--&gt; &lt;ciManagement&gt; &lt;!--持续集成系统的名字，例如continuum--&gt; &lt;system/&gt; &lt;!--该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。--&gt; &lt;url/&gt; &lt;!--构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告）--&gt; &lt;notifiers&gt; &lt;!--配置一种方式，当构建中断时，以该方式通知用户/开发者--&gt; &lt;notifier&gt; &lt;!--传送通知的途径--&gt; &lt;type/&gt; &lt;!--发生错误时是否通知--&gt; &lt;sendOnError/&gt; &lt;!--构建失败时是否通知--&gt; &lt;sendOnFailure/&gt; &lt;!--构建成功时是否通知--&gt; &lt;sendOnSuccess/&gt; &lt;!--发生警告时是否通知--&gt; &lt;sendOnWarning/&gt; &lt;!--不赞成使用。通知发送到哪里--&gt; &lt;address/&gt; &lt;!--扩展配置项--&gt; &lt;configuration/&gt; &lt;/notifier&gt; &lt;/notifiers&gt; &lt;/ciManagement&gt; &lt;!--项目创建年份，4位数字。当产生版权信息时需要使用这个值。--&gt; &lt;inceptionYear/&gt; &lt;!--项目相关邮件列表信息--&gt; &lt;mailingLists&gt; &lt;!--该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。--&gt; &lt;mailingList&gt; &lt;!--邮件的名称--&gt; &lt;name&gt;Demo&lt;/name&gt; &lt;!--发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;post&gt;chaibozhou@163.com&lt;/post&gt; &lt;!--订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;subscribe&gt;chaibozhou@163.com&lt;/subscribe&gt; &lt;!--取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建--&gt; &lt;unsubscribe&gt;chaibozhou@163.com&lt;/unsubscribe&gt; &lt;!--你可以浏览邮件信息的URL--&gt; &lt;archive&gt;chaibozhou@163.com&lt;/archive&gt; &lt;/mailingList&gt; &lt;/mailingLists&gt; &lt;!--项目开发者列表--&gt; &lt;developers&gt; &lt;!--某个项目开发者的信息--&gt; &lt;developer&gt; &lt;!--SCM里项目开发者的唯一标识符--&gt; &lt;id&gt;HELLO WORLD&lt;/id&gt; &lt;!--项目开发者的全名--&gt; &lt;name&gt;chaimm&lt;/name&gt; &lt;!--项目开发者的email--&gt; &lt;email&gt;chaibozhou@163.com&lt;/email&gt; &lt;!--项目开发者的主页的URL--&gt; &lt;url/&gt; &lt;!--项目开发者在项目中扮演的角色，角色元素描述了各种角色--&gt; &lt;roles&gt; &lt;role&gt;Project Manager&lt;/role&gt; &lt;role&gt;Architect&lt;/role&gt; &lt;/roles&gt; &lt;!--项目开发者所属组织--&gt; &lt;organization&gt;demo&lt;/organization&gt; &lt;!--项目开发者所属组织的URL--&gt; &lt;organizationUrl&gt;http://erhuowang.cn&lt;/organizationUrl&gt; &lt;!--项目开发者属性，如即时消息如何处理等--&gt; &lt;properties&gt; &lt;dept&gt;No&lt;/dept&gt; &lt;/properties&gt; &lt;!--项目开发者所在时区， -11到12范围内的整数。--&gt; &lt;timezone&gt;-5&lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!--项目的其他贡献者列表--&gt; &lt;contributors&gt; &lt;!--项目的其他贡献者。参见developers/developer元素--&gt; &lt;contributor&gt; &lt;name/&gt;&lt;email/&gt;&lt;url/&gt;&lt;organization/&gt;&lt;organizationUrl/&gt;&lt;roles/&gt;&lt;timezone/&gt;&lt;properties/&gt; &lt;/contributor&gt; &lt;/contributors&gt; &lt;!--该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。--&gt; &lt;licenses&gt; &lt;!--描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。--&gt; &lt;license&gt; &lt;!--license用于法律上的名称--&gt; &lt;name&gt;Apache 2&lt;/name&gt; &lt;!--官方的license正文页面的URL--&gt; &lt;url&gt;http://www.baidu.com/erhuwoang/LICENSE-2.0.txt&lt;/url&gt; &lt;!--项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖--&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;!--关于license的补充信息--&gt; &lt;comments&gt;A business-friendly OSS license&lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!--SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。--&gt; &lt;scm&gt; &lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。--&gt; &lt;connection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection&gt; &lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读--&gt; &lt;developerConnection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection&gt; &lt;!--当前代码的标签，在开发阶段默认为HEAD--&gt; &lt;tag/&gt; &lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。--&gt; &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt; &lt;/scm&gt; &lt;!--描述项目所属组织的各种属性。Maven产生的文档用--&gt; &lt;organization&gt; &lt;!--组织的全名--&gt; &lt;name&gt;demo&lt;/name&gt; &lt;!--组织主页的URL--&gt; &lt;url&gt;http://www.erhuowang.cn&lt;/url&gt; &lt;/organization&gt; &lt;!--构建项目需要的信息--&gt; &lt;build&gt; &lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;sourceDirectory/&gt; &lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。--&gt; &lt;scriptSourceDirectory/&gt; &lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。--&gt; &lt;testSourceDirectory/&gt; &lt;!--被编译过的应用程序class文件存放的目录。--&gt; &lt;outputDirectory/&gt; &lt;!--被编译过的测试class文件存放的目录。--&gt; &lt;testOutputDirectory/&gt; &lt;!--使用来自该项目的一系列构建扩展--&gt; &lt;extensions&gt; &lt;!--描述使用到的构建扩展。--&gt; &lt;extension&gt; &lt;!--构建扩展的groupId--&gt; &lt;groupId/&gt; &lt;!--构建扩展的artifactId--&gt; &lt;artifactId/&gt; &lt;!--构建扩展的版本--&gt; &lt;version/&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值--&gt; &lt;defaultGoal/&gt; &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。--&gt; &lt;resources&gt; &lt;!--这个元素描述了项目相关或测试相关的所有资源路径--&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。--&gt; &lt;targetPath/&gt; &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。--&gt; &lt;filtering/&gt; &lt;!--描述存放资源的目录，该路径相对POM路径--&gt; &lt;directory/&gt; &lt;!--包含的模式列表，例如**/*.xml.--&gt; &lt;includes/&gt; &lt;!--排除的模式列表，例如**/*.xml--&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。--&gt; &lt;testResources&gt; &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明--&gt; &lt;testResource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;!--构建产生的所有文件存放的目录--&gt; &lt;directory/&gt; &lt;!--产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。--&gt; &lt;finalName/&gt; &lt;!--当filtering开关打开时，使用到的过滤器属性文件列表--&gt; &lt;filters/&gt; &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置--&gt; &lt;pluginManagement&gt; &lt;!--使用的插件列表 。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述插件所需要的信息。--&gt; &lt;plugin&gt; &lt;!--插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。--&gt; &lt;extensions/&gt; &lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。--&gt; &lt;executions&gt; &lt;!--execution元素包含了插件执行需要的信息--&gt; &lt;execution&gt; &lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标--&gt; &lt;id/&gt; &lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段--&gt; &lt;phase/&gt; &lt;!--配置的执行目标--&gt; &lt;goals/&gt; &lt;!--配置是否被传播到子POM--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!--项目引入插件所需要的额外依赖--&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--作为DOM对象的配置--&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!--使用的插件列表--&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--在列的项目构建profile，如果被激活，会修改构建处理--&gt; &lt;profiles&gt; &lt;!--根据环境参数或命令行参数激活某个构建处理--&gt; &lt;profile&gt; &lt;!--构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。--&gt; &lt;id/&gt; &lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。--&gt; &lt;activation&gt; &lt;!--profile默认是否激活的标志--&gt; &lt;activeByDefault/&gt; &lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。--&gt; &lt;jdk/&gt; &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。--&gt; &lt;os&gt; &lt;!--激活profile的操作系统的名字--&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;!--激活profile的操作系统所属家族(如 &apos;windows&apos;)--&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;!--激活profile的操作系统体系结构 --&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;!--激活profile的操作系统版本--&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段--&gt; &lt;property&gt; &lt;!--激活profile的属性的名称--&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;!--激活profile的属性的值--&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。--&gt; &lt;file&gt; &lt;!--如果指定的文件存在，则激活profile。--&gt; &lt;exists&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/exists&gt; &lt;!--如果指定的文件不存在，则激活profile。--&gt; &lt;missing&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;!--构建项目所需要的信息。参见build元素--&gt; &lt;build&gt; &lt;defaultGoal/&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;targetPath/&gt;&lt;filtering/&gt;&lt;directory/&gt;&lt;includes/&gt;&lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;directory/&gt;&lt;finalName/&gt;&lt;filters/&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素--&gt; &lt;plugin&gt; &lt;groupId/&gt;&lt;artifactId/&gt;&lt;version/&gt;&lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt;&lt;phase/&gt;&lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt;&lt;inherited/&gt;&lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules/&gt; &lt;!--发现依赖和扩展的远程仓库列表。--&gt; &lt;repositories&gt; &lt;!--参见repositories/repository元素--&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt;&lt;name/&gt;&lt;url/&gt;&lt;layout/&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt;&lt;name/&gt;&lt;url/&gt;&lt;layout/&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素.--&gt; &lt;reports/&gt; &lt;!--该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素--&gt; &lt;reporting&gt; ...... &lt;/reporting&gt; &lt;!--参见dependencyManagement元素--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--参见distributionManagement元素--&gt; &lt;distributionManagement&gt; ...... &lt;/distributionManagement&gt; &lt;!--参见properties元素--&gt; &lt;properties/&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径--&gt; &lt;modules/&gt; &lt;!--发现依赖和扩展的远程仓库列表。--&gt; &lt;repositories&gt; &lt;!--包含需要连接到远程仓库的信息--&gt; &lt;repository&gt; &lt;!--如何处理远程仓库里发布版本的下载--&gt; &lt;releases&gt; &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled/&gt; &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。--&gt; &lt;updatePolicy/&gt; &lt;!--当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。--&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的 策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled/&gt;&lt;updatePolicy/&gt;&lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;!--远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库--&gt; &lt;id&gt;banseon-repository-proxy&lt;/id&gt; &lt;!--远程仓库名称--&gt; &lt;name&gt;banseon-repository-proxy&lt;/name&gt; &lt;!--远程仓库URL，按protocol://hostname/path形式--&gt; &lt;url&gt;http://192.168.1.169:9999/repository/&lt;/url&gt; &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然 而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。--&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表--&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素--&gt; &lt;pluginRepository&gt; ...... &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!--依赖的group ID--&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;!--依赖的artifact ID--&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。--&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应， 尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。--&gt; &lt;type&gt;jar&lt;/type&gt; &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成 JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。--&gt; &lt;classifier&gt;&lt;/classifier&gt; &lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用--&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。--&gt; &lt;systemPath&gt;&lt;/systemPath&gt; &lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。--&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素.--&gt; &lt;reports&gt;&lt;/reports&gt; &lt;!--该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。--&gt; &lt;reporting&gt; &lt;!--true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。--&gt; &lt;excludeDefaults/&gt; &lt;!--所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。--&gt; &lt;outputDirectory/&gt; &lt;!--使用的报表插件和他们的配置。--&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述报表插件需要的信息--&gt; &lt;plugin&gt; &lt;!--报表插件在仓库里的group ID--&gt; &lt;groupId/&gt; &lt;!--报表插件在仓库里的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--被使用的报表插件的版本（或版本范围）--&gt; &lt;version/&gt; &lt;!--任何配置是否被传播到子项目--&gt; &lt;inherited/&gt; &lt;!--报表插件的配置--&gt; &lt;configuration/&gt; &lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标--&gt; &lt;reportSets&gt; &lt;!--表示报表的一个集合，以及产生该集合的配置--&gt; &lt;reportSet&gt; &lt;!--报表集合的唯一标识符，POM继承时用到--&gt; &lt;id/&gt; &lt;!--产生报表集合时，被使用的报表的配置--&gt; &lt;configuration/&gt; &lt;!--配置是否被继承到子POMs--&gt; &lt;inherited/&gt; &lt;!--这个集合里使用到哪些报表--&gt; &lt;reports/&gt; &lt;/reportSet&gt; &lt;/reportSets&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素--&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。--&gt; &lt;distributionManagement&gt; &lt;!--部署项目产生的构件到远程仓库需要的信息--&gt; &lt;repository&gt; &lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素--&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;banseon maven2&lt;/name&gt; &lt;url&gt;file://$&#123;basedir&#125;/target/deploy&lt;/url&gt; &lt;layout/&gt; &lt;/repository&gt; &lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素--&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;Banseon-maven2 Snapshot Repository&lt;/name&gt; &lt;url&gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url&gt; &lt;layout/&gt; &lt;/snapshotRepository&gt; &lt;!--部署项目的网站需要的信息--&gt; &lt;site&gt; &lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置--&gt; &lt;id&gt;banseon-site&lt;/id&gt; &lt;!--部署位置的名称--&gt; &lt;name&gt;business api website&lt;/name&gt; &lt;!--部署位置的URL，按protocol://hostname/path形式--&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url&gt; &lt;/site&gt; &lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。--&gt; &lt;downloadUrl/&gt; &lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。--&gt; &lt;relocation&gt; &lt;!--构件新的group ID--&gt; &lt;groupId/&gt; &lt;!--构件新的artifact ID--&gt; &lt;artifactId/&gt; &lt;!--构件新的版本号--&gt; &lt;version/&gt; &lt;!--显示给用户的，关于移动的额外信息，例如原因。--&gt; &lt;message/&gt; &lt;/relocation&gt; &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从 Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。--&gt; &lt;status/&gt; &lt;/distributionManagement&gt; &lt;!--以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name&gt;value&lt;/name&gt;。--&gt; &lt;properties/&gt; &lt;/project&gt;]]></content>
      <categories>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 锁]]></title>
    <url>%2Fmysql-lock.html</url>
    <content type="text"><![CDATA[数据库层面锁表锁锁定一张表的全部记录 SELECT username FROM user FOR UPDATE; 行锁锁定一行记录 SELECT username FROM user WHERE id = 1 FOR UPDATE; 所以说在InnoDB引擎中，虽然默认为ROW LOCK但是也是在指定检索条件为主键的情况下，否则默认TABLE LOCK 页锁行锁锁定一行记录，表锁锁定一张表中全部记录，页锁即折中。锁定相邻的一组记录。 共享锁共享锁也称为读锁，即给数据添加读锁后，其他线程只能读取不能修改。如果有修改操作会被阻塞，进入队列 需要注意的是：SELECT username FROM user WHERE id = 1 FOR UPDATE; 当抢锁的时候即便是普通的查询也会进入阻塞队列中。 这样就可并发正常查询：SELECT username FROM user WHERE id = 1; 排他锁排他锁也称为写锁，和共享锁的区别在于，其他线程既不能读也不能修改。 业务处理层面思想 乐观锁其实并不会加锁，只是也算是一种处理方式。顾名思义，这种情况认为不会发生并发冲突。抢占资源的情况，在数据库中通过添加version或时间戳的方式来控制数据的版本。1.首先查询数据拿到verison 2.更新数据 3.查询数据对比version是否有变(并发冲突) 4.没有那么更新成功(COMMIT)，如果有那么知道有其他线程进行了DML操作。回滚(ROLL BACK) 悲观锁假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。悲观锁的具体实现即数据库层面的共享锁和排它锁。也只有数据库层面的锁能做到真正对数据的并发控制，多个系统之间并不能做到良好控制。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[索引扫盲]]></title>
    <url>%2Fmysql-index-literacy.html</url>
    <content type="text"><![CDATA[索引是对数据库中一列或多列的值进行排序的一种结构 索引的种类： 普通索引 唯一索引 全文索引 - 替代 Like 模糊查询 B-Tree 索引 - MyISAM,InnoDB Hash 索引 - Memory 存储引擎 B-Tree 索引概述Mysql数据库中使用最频繁的索引类型，基本所有存储引擎都支持BTree索引。正是其优异的检索表现，才使其有这样的地位。 存储结构是使用B-Tree的数据结构来存储数据，但是不同的存储引擎在使用这种数据结构来存储数据时会进行不同的修改，例如MyISAM和InnoDB使用的都是B+Tree结构。但是与B-Tree不同的是，它把所有的数据都存到了叶子节点上。并且所有的叶子节点相互连通，加快相邻数据节点的检索。并且存储策略也进行了修改。 MyISAM 非聚集索引MyISAM的存储策略是，所有的叶子节点存储的并不是真实的数据，而是数据节点的地址。通过地址检索真正的数据，索引文件与数据文件分离存储。这样的存储策略称为非聚集索引。需要注意的是它的主索引与辅助索引的键值不能重复 它的检索策略是检索B-Tree找到对应的数据节点，拿到数据的物理地址，然后去访问。 InnoDB 聚集索引InnoDB的存储策略是叶子节点即数据节点，索引文件与数据文件一起存储。它的主索引存储的是完整的数据记录集合也可以看成索引的索引，而辅助索引存储的是真实的数据，这个数据是数据表中的主键。InnoDB的数据文件本身就是主键索引文件，这样的索引被称为聚集索引。且一个表只能有一个聚集索引 检索的时候它通过主键来确定数据。这样的数据文件本身就是主键索引的存储结构。所以称它为聚集索引 Hash 索引概述及存储结构主要就是通过Hash算法（常见的Hash算法有直接定址法、平方取中法、折叠法、除数取余法、随机数法），将数据库字段数据转换成定长的Hash值，与这条数据的行指针一并存入Hash表的对应位置；如果发生Hash碰撞（两个不同关键字的Hash值相同），则在对应Hash键下以链表形式存储。 检索算法：在检索查询时，就再次对待查关键字再次执行相同的Hash算法，得到Hash值，到对应Hash表对应位置取出数据即可，如果发生Hash碰撞，则需要在取值时进行筛选。目前使用Hash索引的数据库并不多，主要有Memory等。 一般来说，索引的检索效率非常高，可以一次定位，不像B-Tree索引需要进行从根节点到叶节点的多次IO操作。 弊端 查询：只能进行数据等值查询,不能进行范围或者非精确查询,因为hash算法的原因。不同值出现的结果相差很大。所以hash的优势也就不在 排序：hash算法不能排序，因为hash算法的原因,经过hash算法的数值的大小不可确定。排序没有意义 检索表数据：hash算法同样不能避免表数据的扫描，因为会发生hash碰撞的原因，当该情况发生的时候，还显示需要去表中检索数据来确认数据 hash碰撞：当数据中出现大量hash碰撞的时候，就需要进行多次的表数据扫描来确认数据。这样的情况，效率不一定有B+Tree的效率高。如同字典多个相同值因为hash碰撞的原因，存到了hash表的同一位置。比如10,77,256,347,652这些页中的数据，在一个hash表的位置存储，但你无法确认哪个数据是你需要的，你需要一个一个去排查。无形中又是一个大工程，不一定效率高于BTree。 索引查询限制：hash索引不能通过部分索引检索数据，因为hash排列是对整个索引列进行hash算法排列的。部分索引经过hash排列到的位置是没有任何意义的。 Full-Text 索引概述全文索引，目前MySQL中只有MyISAM存储引擎支持，并且只有CHAR、VARCHAR、TEXT类型支持。它用于替代效率较低的LIKE模糊匹配操作，而且可以通过多字段组合的全文索引一次性全模糊匹配多个字段。 存储结构Full-Text索引使用的也是B-Tree存储，但是不同的是换了一种算法。它是先对数据进行列数据分割(一般每4个字节)，然后对分割后的数据再进行索引。索引文件存储的是数据分割前的字符串，以及分割后的索引信息。数据文件存储的是各分割数据的信息，以及在原字符串中的位置。 索引的利弊利端： 减少不相关数据的IO检索次数。所以可以明显的提交数据的检索效率 降低数据库排序的成本。如果索引后文件存储的顺序和取出后数据的存储数据一致(聚集索引)。那么就省去了数据库再对数据排序的操作，同样分组操作时先排序后分组，这样就省去了分组的排序操作。提升了CPU资源的消耗。 弊端： 索引会带来DML操作的索引重排后果。数据变更会带来IO上的负担以及索引重排的计算负担 索引会占用一部分的存储空间。随着数据量的增大，资源消耗愈发的明显。 判断是否适合建立索引适合 经常进行DQL操作的数据列 字段列经常出现在where检索条件及连接条件中。 数据表的量增大时 数据不经常变更 不适合 经常进行DML操作的 数据里很小时 唯一性太差的字段，即便经常被检索。 数据经常变更 官方建议在INNODB中， 所有的第二索引(非主键索引)都会包含主键。所以官方建议，主键索引不要选择在比较长的字段上， 最好就是INT类型的]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 查询执行流程，SQL解析顺序]]></title>
    <url>%2Fmysql-implementationprocess.html</url>
    <content type="text"><![CDATA[SQL示例： 1234567891011121314SELECT DISTINCT &lt; select_list &gt;FROM &lt; left_table &gt; &lt; join_type &gt;JOIN &lt; right_table &gt; ON &lt; join_condition &gt;WHERE &lt; where_condition &gt;GROUP BY &lt; group_by_list &gt;HAVING &lt; having_condition &gt;ORDER BY &lt; order_by_condition &gt;LIMIT &lt; limit_number &gt; 执行顺序：12345678910FROM &lt;left_table&gt;ON &lt;join_condition&gt;&lt;join_type&gt; JOIN &lt;right_table&gt;WHERE &lt;where_condition&gt;GROUP BY &lt;group_by_list&gt;HAVING &lt;having_condition&gt;SELECT DISTINCT &lt;select_list&gt;ORDER BY &lt;order_by_condition&gt;LIMIT &lt;limit_number&gt; 乍一看SQL的解析执行顺序还是让我有点儿出乎意料。但仔细看发现还是很合理的 从哪些表获取数据，这些表中数据通过哪个字段对应，检索什么样的数据，如何进行分组，过滤组，选择排重数据，然后再进行排序限制取几条。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 必知必会知识点]]></title>
    <url>%2Fmysql-bizhibihui-knowledgepoint.html</url>
    <content type="text"><![CDATA[and优于or先执行 SELECT username as uname,age FROM可以从一开始指定检索结果的别名设置。这样适合该查询为主查询时设置别名使用。 也可以像这样SELECT username FROM user WHERE username = &#39;JIYONGGUANG&#39; AS name； 在最后指定检索结果的别名。这样是将该查询作为子查询，并将检索出的该列作为主查询的条件使用(该条件已赋，只是作为联合查询进行数据展现)。如： 1234SELECT cust_name, cust_state, (SELECT COUNT(*) FROM orders WHERE cust_id = cust_id) AS ordersFROM customers ORDER BY cust_name 使用通配符的时候，如果where条件后跟的检索条件是%YongGuang。即以%开头的字符串。那么检索效率会很低 多表查询尽量把条件至于子查询检索出 写SQL前先分析，写出步骤，然后依次实现，再整理 &lt;&gt;不等于 MySQL中默认不区分大小写。即A与a相同。但是这个规则可以进行修改 MySQL会重用回收存储空间。如果一张表中的连续记录在物理地址上也是连续存储的，那么当数据进行删除操作后。那么其物理空间会被回收 多表查询时，连表时用连接条件Inner Join比WHERE有时性能更好 ORDER BY中进行数据排序时，DESC,ASC排序规则作用在其紧跟着的前面那列。SELECT username,age FROM user ORDER BY id DESC,age如此， 作用在id。 条件顺序书写顺序：WHERE -&gt; INNER JOIN -&gt; GROUP BY -&gt; HAVING -&gt; ORDER BY -&gt; LIMIT OFFSET SQL示例：1234567891011121314SELECT DISTINCT &lt; select_list &gt;FROM &lt; left_table &gt; &lt; join_type &gt;JOIN &lt; right_table &gt; ON &lt; join_condition &gt;WHERE &lt; where_condition &gt;GROUP BY &lt; group_by_list &gt;HAVING &lt; having_condition &gt;ORDER BY &lt; order_by_condition &gt;LIMIT &lt; limit_number &gt; 执行顺序：12345678910FROM &lt;left_table&gt;ON &lt;join_condition&gt;&lt;join_type&gt; JOIN &lt;right_table&gt;WHERE &lt;where_condition&gt;GROUP BY &lt;group_by_list&gt;HAVING &lt;having_condition&gt;SELECT DISTINCT &lt;select_list&gt;ORDER BY &lt;order_by_condition&gt;LIMIT &lt;limit_number&gt; 从哪些表获取数据，这些表中数据通过哪个字段对应，检索什么样的数据，如何进行分组，过滤组，选择排重数据，然后再进行排序限制取几条。 BETWEEEN AND改写为&gt;= 、&lt;=之类的。 in转换多个or。字段为索引时，两个都能用到索引，or效率相对in好一点 常量传递。a=b and b=2转换为 a=2 and b=2尽量不使用变量a=b或a=@var MySQL处理定长远快于变长列 CHAR定长列，创建时不指定默认1。 除BIT,BOOLEAN默认所有数值数据类型均有符号，明确字段不存储负值，UNSIGNED可以增大取值范围为原来的2倍。如1个字节的byte取值为-128 - 127那么当该字段设置为UNSIGNED的时候取值范围就成了0-254 存储货币数据类型DECIMAL，因为Java中的float,double类型在进行浮点数运算的时候会出现精度丢失的问题。 每个表只能有一个AUTO_INCREMENT字段，并且必须被索引。 如果一个列被指定为AUTO_INCREMENT。那么只要你手动进行INSERT操作的时候。指定了这个字段。那么之后所有插入的值都是在该值得基础上进行递增。 last_insert_id()此方法返回最后一个插入的数据的AUTO_INCREMENT字段的值 InnoDB 事物，外键，行锁 MYISAM表锁，性能极高，支持全文本搜索。 两个存储引擎各有适用的地方，妥善选择 外键不能跨引擎，即两个不同存储引擎的列不能物理上相互关联。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乐观锁，悲观锁详解]]></title>
    <url>%2Fmysql-optimistic-pessimistic-lock.html</url>
    <content type="text"><![CDATA[并发控制并发控制:当多个连接对记录进行修改的时保证数据的一致性。 悲观锁，乐观锁确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和一致性以及数据库的统一性，乐观锁和悲观锁是并发控制主要采用的技术手段。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作 在查询完数据的时候就把事务锁起来，直到提交事务 实现方式：使用数据库中的锁机制 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 在修改数据的时候把事务锁起来，通过version的方式来进行锁定 实现方式：使用version版本或者时间戳 悲观锁的两种实现 悲观锁应用场景悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。 锁的力度 [锁的颗粒]锁的颗粒: 锁定时的单位 其实只需要对修改的数据精确加锁即可。而无需对所有的资源都加锁。 比如一个用户表一个商品表，当用户修改注册信息的时候只需要对用户表或者用户这条记录加锁即可而不需要对商品表加锁。 同理用户在更新商品信息的时候，只需要对商品表或者商品表中的这一记录进行加锁即可而不需要对用户表也加锁。 所以说：加锁只加最对的而不加最大的。加锁会增加系统的开销 所以，我们需要在[锁策略，锁开销，数据安全之间]寻求一种平衡 锁策略MySQL的锁策略包括两种 表锁:开销最小的锁的策略。 原因：如果存在一张表，把所有用户锁定起来，那么这张表只有一个用户可以操作。 行锁:开销最大的锁的策略。也是支持最大并发操作处理的一种情况 原因：表中有多少条记录，就可能对这张表的每条记录都进行锁。所以是开销最大的 当用户针对数据表操作时用户即获得了这种表的写锁的权限。写锁会禁止其他用户来进行读写的操作。 优劣乐观锁乐观锁可能会在CAS情况中出现ABA问题。、 悲观锁悲观锁在处理并发控制上的态度其实是先取锁再访问。在并发情况下为数据的安全提供了保障，但是带来的是性能上的影响。在处理被加锁的数据上无疑会带来额外的开销，降低了并行性，还有可能产生死锁(事物控制不好)。而且只读型事物不会产生并发冲突，也就不需要用锁，这样做只会增加系统的负载。 实现乐观锁123select * from user where id = #&#123;id&#125;update from user set username = #&#123;username&#125;,version = #&#123;version&#125; + 1 where id = #&#123;id&#125; and version = #&#123;version&#125;; 已经知道该记录在没有发生并发冲突情况下的version了。只是不确定是否发生了并发冲突,所以拿该值过来检测，记录需要满足的条件和该版本号一致。 悲观锁123select * from user where id = #&#123;id&#125; for update;update from user usernmae = #&#123;username&#125; where id = #&#123;id&#125; MySQL中InnoDB引擎的行锁是通过加在什么上完成InnoDB是基于索引来完成行锁 例: select * from tab_with_index where id = 1 for update; for update 可以根据条件来完成行锁锁定,并且 id 是有索引键的列, 如果 id 不是索引键那么InnoDB将完成表锁,并发将无从谈起]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Typora]]></title>
    <url>%2FIlluos1ion-singleton.html</url>
    <content type="text"><![CDATA[Bad Time Make A Good Man.]]></content>
      <categories>
        <category>个人感悟</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[理解Java Integer的缓存策略]]></title>
    <url>%2Fjava-Integer-cache.html</url>
    <content type="text"><![CDATA[转载自： ImportNew - 挖坑的张师傅：理解Java Integer的缓存策略 本文将介绍 Java 中 Integer 缓存的相关知识。这是 Java 5 中引入的一个有助于节省内存、提高性能的特性。首先看一个使用 Integer 的示例代码，展示了 Integer 的缓存行为。接着我们将学习这种实现的原因和目的。你可以先猜猜下面 Java 程序的输出结果。很明显，这里有一些小陷阱，这也是我们写这篇文章的原因。 1234567891011121314151617181920212223package com.javapapers.java; public class JavaIntegerCache &#123; public static void main(String... strings) &#123; Integer integer1 = 3; Integer integer2 = 3; if (integer1 == integer2) System.out.println("integer1 == integer2"); else System.out.println("integer1 != integer2"); Integer integer3 = 300; Integer integer4 = 300; if (integer3 == integer4) System.out.println("integer3 == integer4"); else System.out.println("integer3 != integer4"); &#125;&#125; 大多数人都认为上面的两个判断的结果都是 false。虽然它们的值相等，但由于比较的是对象，而对象的引用不一样，所以会认为两个 if 判断都是 false 的。在 Java 中，== 比较的是对象引用，而 equals 比较的是值。因此，在这个例子中，不同的对象有不同的引用，所以在进行比较的时候都应该返回 false。但是奇怪的是，这里两个相似的 if 条件判断却返回不同的布尔值。 下面是上面代码真正的输出结果， 12integer1 == integer2integer3 != integer4 Java 中 Integer 缓存实现 在 Java 5 中，为 Integer 的操作引入了一个新的特性，用来节省内存和提高性能。整型对象在内部实现中通过使用相同的对象引用实现了缓存和重用。 上面的规则适用于整数区间 -128 到 +127。 这种 Integer 缓存策略仅在自动装箱（autoboxing）的时候有用，使用构造器创建的 Integer 对象不能被缓存。 Java 编译器把原始类型自动转换为封装类的过程称为自动装箱（autoboxing），这相当于调用 valueOf 方法 12Integer a = 10; //this is autoboxingInteger b = Integer.valueOf(10); //under the hood 现在我们知道了 JDK 源码中对应实现的部分在哪里了。我们来看看 valueOf 的源码。下面是 JDK 1.8.0 build 25 中的代码。 1234567891011121314151617181920/** * Returns an &#123;&lt;a href="http://www.jobbole.com/members/java12"&gt;@code&lt;/a&gt; Integer&#125; instance representing the specified * &#123;&lt;a href="http://www.jobbole.com/members/java12"&gt;@code&lt;/a&gt; int&#125; value. If a new &#123;&lt;a href="http://www.jobbole.com/members/java12"&gt;@code&lt;/a&gt; Integer&#125; instance is not * required, this method should generally be used in preference to * the constructor &#123;&lt;a href="http://www.jobbole.com/members/57845349"&gt;@link&lt;/a&gt; #Integer(int)&#125;, as this method is likely * to yield significantly better space and time performance by * caching frequently requested values. * * This method will always cache values in the range -128 to 127, * inclusive, and may cache other values outside of this range. * * @param i an &#123;&lt;a href="http://www.jobbole.com/members/java12"&gt;@code&lt;/a&gt; int&#125; value. * @return an &#123;&lt;a href="http://www.jobbole.com/members/java12"&gt;@code&lt;/a&gt; Integer&#125; instance representing &#123;&lt;a href="http://www.jobbole.com/members/java12"&gt;@code&lt;/a&gt; i&#125;. * &lt;a href="http://www.jobbole.com/members/chchxinxinjun"&gt;@since&lt;/a&gt; 1.5 */ public static Integer valueOf(int i) &#123; if (i &amp;amp;gt;= IntegerCache.low &amp;amp;amp;&amp;amp;amp; i &amp;amp;lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; 在创建新的 Integer 对象之前会先在 IntegerCache.cache 中查找。有一个专门的 Java 类来负责 Integer 的缓存。 IntegerCache 类 IntegerCache 是 Integer 类中一个私有的静态类。我们来看看这个类，有比较详细的文档，可以提供我们很多信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Cache to support the object identity semantics of autoboxing for values between * -128 and 127 (inclusive) as required by JLS. * * The cache is initialized on first usage. The size of the cache * may be controlled by the &#123;&lt;a href="http://www.jobbole.com/members/java12"&gt;@code&lt;/a&gt; -XX:AutoBoxCacheMax=&#125; option. * During VM initialization, java.lang.Integer.IntegerCache.high property * may be set and saved in the private system properties in the * sun.misc.VM class. */ private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty("java.lang.Integer.IntegerCache.high"); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &amp;amp;lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &amp;amp;gt;= 127; &#125; private IntegerCache() &#123;&#125; &#125; Javadoc 详细的说明这个类是用来实现缓存支持，并支持 -128 到 127 之间的自动装箱过程。最大值 127 可以通过 JVM 的启动参数 -XX:AutoBoxCacheMax=size 修改。 缓存通过一个 for 循环实现。从小到大的创建尽可能多的整数并存储在一个名为 cache 的整数数组中。这个缓存会在 Integer 类第一次被使用的时候被初始化出来。以后，就可以使用缓存中包含的实例对象，而不是创建一个新的实例(在自动装箱的情况下)。 实际上在 Java 5 中引入这个特性的时候，范围是固定的 -128 至 +127。后来在 Java 6 中，最大值映射到 java.lang.Integer.IntegerCache.high，可以使用 JVM 的启动参数设置最大值。这使我们可以根据应用程序的实际情况灵活地调整来提高性能。是什么原因选择这个 -128 到 127 这个范围呢？因为这个范围的整数值是使用最广泛的。 在程序中第一次使用 Integer 的时候也需要一定的额外时间来初始化这个缓存。 Java 语言规范中的缓存行为 在 Boxing Conversion 部分的Java语言规范(JLS)规定如下： 如果一个变量 p 的值属于：-128至127之间的整数(§3.10.1)，true 和 false的布尔值 (§3.10.3)，’u0000′ 至 ‘u007f’ 之间的字符(§3.10.4)中时，将 p 包装成 a 和 b 两个对象时，可以直接使用 a == b 判断 a 和 b 的值是否相等。 其他缓存的对象 这种缓存行为不仅适用于Integer对象。我们针对所有整数类型的类都有类似的缓存机制。 有 ByteCache 用于缓存 Byte 对象 有 ShortCache 用于缓存 Short 对象 有 LongCache 用于缓存 Long 对象 有 CharacterCache 用于缓存 Character 对象 Byte，Short，Long 有固定范围: -128 到 127。对于 Character, 范围是 0 到 127。除了 Integer 可以通过参数改变范围外，其它的都不行。 注意修改 -XX:AutoBoxCacheMax参数时可结合这边博文来看： Java包装类的缓存]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring标签的探索]]></title>
    <url>%2Fspring-annoation-%E3%80%8Acontext-annoation-config%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言 在学习Spring的过程中，自己算是好好体会了一把Spring配置文件的繁琐。不切实体会一下就不知道有多让人不爽，众多的配置文件不说，关键是一个功能一个配置文件，而且十分容易忘记。那我们应该怎么办呢？记住他们吗？一定不是，懂得学习的人是不会花过多时间刻意去记那些数不清的schema以及标签的。我们只需要记录即可，记录我们常用的配置，并进行整理。用到即取，不是很方便吗? 在学习Spring的时候，过多的标签总会使我记了又忘忘了又记。搞得自己总是很狼狈，反复学习却效果不是很好。究其原因是用的不多，可是我们也知道，一个项目我们在写的时候从来都是先搭好骨架再进行核心逻辑代码的编写，所以配置文件基本上在一个项目开始的时候就配置的差不多了，一个项目我们做上几个月。时隔很久，我们只有在第一次配置配置文件的时候才算脑中过了一下配置文件中某些配置的概念。所以说，这种东西是和用的多少没有关系的很明显。就连Spring官方代码，都积极的给我们提供了示例项目供我们参考，可见官方也不推荐我们去记住那么众多的配置文件，只是记住有这个东西存在就好，我们用到的时候只要去查阅引入配置标签即可。 今天在编写Spring项目的时候，由于自己最近都在开发SpringBoot相关的内容。所以长期不接触Spring最明显的问题就是配置文件不会写了。过去自己写的时候也一直都是能自己写出来的自己写，写不出来忘记了的的copy原来项目的配置文件。因为具体到业务代码的编写，很明显业务代码才是我们一个程序员应该关注的事情而不是去花大量的时间去搞配置文件，尤其是对于用过SpringBoot的我来说，真的再也受不了去死记硬背那些众多的配置文件了。 问题 开启Spring项目第一件事就是先配置不然你什么都做不了。首先我想要在项目中用我常用的注解@Autowired，我需要在配置文件中声明AutowiredAnnotationBeanPostProcessor这个bean。我又想要在项目中用到@Required这个注解，那我还需要再配置RequiredAnnotationBeanPostProcesso这个bean。一个功能一个bean搞得自己有点儿头大。后来查阅到要想支持这两个注解只需要在配置文件中声明&lt;context:annotation-config/&gt;该标签即可。这个标签自己以前常用，只知道它能为我提供一些注解的支持，但是具体到他能做多少我自己却没有深入研究过。今天就来研究一下，也算是为后续的的Spring标签的探索先踩踩坑。 深入源码 这里我只是简单记录一下我好奇的地方，并记录自己解惑的过程。先上一段代码： 1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;context:annotation-config/&gt;&lt;/beans&gt; 我们来看一下官方对该标签的说明： As always, you can register them as individual bean definitions, but they can also be implicitly registered by including the following tag in an XML-based Spring configuration (notice the inclusion of the context namespace) 翻译过来： 与往常一样，您可以将它们注册为单独的bean定义，但也可以通过在基于XML的Spring配置中包含以下标记来隐式注册它们（注意包含上下文名称空间） 既然官网这么说，可是那么&lt;context:annotation-config/&gt;这个标签什么时候起作用的呢？哪儿体现了他实例化了这几个bean了？ 在Spring容器解析配置文件中时，会加载beans标签中配置的URL，如图： 12345678&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt;&lt;/beans&gt; 我们按住Ctrl点击该标签进入到该目录下： 可以看到代码提供的注释这里写的很清楚，该标签提供了哪些注解的支持 然后我们再根据配置文件中beans标签中配置的xsi:schemaLocation的URL到spring.handlers文件中，找到对应的NamespaceHandler。 比如我上面的是&lt;http://www.springframework.org/schema/context&gt;那么将对应spring.handlers文件中的ContextNamespaceHandler。然后Ctrl B进入 那么这个Handler是做什么的呢？就一个方法，在该方法中，可以看到它的作用就是创建这些标签所对应的解析类。什么是解析类呢？也就是所有的自定义命名空间（像mvc，context等）下的标签解析都是由BeanDefinitionParser接口的子类来完成的。可以看到annotation-config的解析类是AnnotationConfigBeanDefinitionParser。 我们继续Ctrl B进入该类，看一下这个类如何解析这个标签的。 根据上面的代码可以看出真正的解析是在AnnotationConfigUtils.registerAnnotationConfigProcessors()方法中进行的那就进去这个方法看看 这里代码篇幅太长，我们贴了代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public static Set&lt;BeanDefinitionHolder&gt; registerAnnotationConfigProcessors( BeanDefinitionRegistry registry, Object source) &#123; DefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry); if (beanFactory != null) &#123; if (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) &#123; beanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE); &#125; if (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) &#123; beanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver()); &#125; &#125; Set&lt;BeanDefinitionHolder&gt; beanDefs = new LinkedHashSet&lt;BeanDefinitionHolder&gt;(4); // ConfigurationClassPostProcessor if (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // AutowiredAnnotationBeanPostProcessor if (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // RequiredAnnotationBeanPostProcessor if (!registry.containsBeanDefinition(REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(RequiredAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, REQUIRED_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // CommonAnnotationBeanPostProcessor // Check for JSR-250 support, and if present add the CommonAnnotationBeanPostProcessor. if (jsr250Present &amp;&amp; !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class); def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; // PersistenceAnnotationBeanPostProcessor // Check for JPA support, and if present add the PersistenceAnnotationBeanPostProcessor. if (jpaPresent &amp;&amp; !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) &#123; RootBeanDefinition def = new RootBeanDefinition(); try &#123; ClassLoader cl = AnnotationConfigUtils.class.getClassLoader(); def.setBeanClass(cl.loadClass(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME)); &#125; catch (ClassNotFoundException ex) &#123; throw new IllegalStateException( "Cannot load optional framework class: " + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex); &#125; def.setSource(source); beanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)); &#125; return beanDefs;&#125; 到这里我们的问题就完美解决了。由代码可以看出，分别注册了AutowiredAnnotationBeanPostProcessor、RequiredAnnotationBeanPostProcessor、CommonAnnotationBeanPostProcessor以及PersistenceAnnotationBeanPostProcessor、ConfigurationClassPostProcessor这5个BeanPostProcessor。]]></content>
      <categories>
        <category>Spring 学习</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 配置文件中的那些标签该如何正确使用(持续更新)]]></title>
    <url>%2Fspring-annoation.html</url>
    <content type="text"><![CDATA[前言在看这边博客时，如果遇到有什么不清楚的地方，可以参考我另外一边博文。Spring标签的探索，根据这边文章自己来深入源码一探究竟。这里自己只是简单记录一下各标签作用，每个人困惑不同，自然需求也不一定相同，所以还是自己动手深入源码一探究竟比较好。 context:annotation-config 注释说明：配置了该标签意味着激活了bean类中要检测的各种注释，Spring的@Required和@Autowired以及JSR 250的@PostConstruct，@PreDestroy，@Resource，JAX-WS的@WebServiceRef，EJB3的@EJB，和JPA的@PersistenceContext，@PersistenceUnit。或者你可以为这些注释激活单独的BeanPostProcessors 注意：这个标签不会激活处理Spring的@Transactional或EJB3的@TransactionAttribute注解。 考虑使用&lt;tx：annotation-driven&gt;标签。 From Me看源码后分析得知我的Spring标签源码分析文章，它的作用是隐式地向Spring容器注册AutowiredAnnotationBeanPostProcessor,CommonAnnotationBeanPostProcessor,PersistenceAnnotationBeanPostProcessor,RequiredAnnotationBeanPostProcessor这4个BeanPostProcessor。其作用是如果你想在程序中使用注解，就必须先注册该注解对应的类，如下图所示： 依赖的类 注解 CommonAnnotationBeanPostProcessor @Resource 、@PostConstruct、@PreDestroy PersistenceAnnotationBeanPostProcessor @PersistenceContext AutowiredAnnotationBeanPostProcessor @Autowire RequiredAnnotationBeanPostProcesso @Required 另外还支持：@WebServiceRef,@EJB,@PersistenceUnit 当然也可以使用传统的方式要使用对应的注解一个一个去声明自定义注册项目也不会显得那么臃肿，可能就是有点儿难记了。 12&lt;bean class="org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor "/&gt; &lt;bean class="org.springframework.beans.factory.annotation.RequiredAnnotationBeanPostProcessor"/&gt; context:component-scan 注释说明：扫描classpath时，被注释的组件将自动注册为Spring bean。 默认情况下，Spring提供的@Component，@Repository，@Service和@Controller原型会被检测到。 注意：这个标签的存在意味可以不在xml中配置&lt;context:annotation-config&gt;标签了。因为该标签会支持@Required，@Autowired，@PostConstruct，@PreDestroy，@Resource，@PersistenceContext和@PersistenceUnit这些注释，这通常是自动检测组件的理想选择（没有外部配置）。 当然你可以选择设置annotation-config属性为false来弃用这个默认行为，该属性默认为true。例如当你想使用自定义的BeanPostProcessor来处理这些注释的时候你可以这么做。 From Me另外需要注意：当Spring配置需要文件分层的时候，该标签应该保证每一个配置文件都配置一次。这时就可以有点儿讲究了，SpringMVC的dispatcher-servlet.xml配置文件可以只扫描带有@Controller注解的类，而在Spring的applicationContext.xml文件中则可以扫描其他所有带有注解的类(也可以过滤掉带@Controller注解的类)。 除了必须指定的属性base-package之外，&lt;context:component-scan/&gt;还可以指定如下属性。 resource-pattern：表示可以被自动检测的Class的形式，默认为“**/*.class”，即所有的class文件。这个只是用来告诉Spring需要对哪些文件进行扫描，而并不是把它们自动定义为对应的bean。这个需要与后续需要介绍的filter区分开。 use-default-filters：表示使用使用默认的filter，。&lt;context:component-scan/&gt;将把哪些Class自动注册到bean容器是由对应的filter来控制的。该属性的值默认为true，即默认会使用默认的filter。而默认的filter会将标注了@Component、@Controller、@Service和@Repository的类，包括这四个注解所标注的注解所标注的类，都会将它们自动注册到bean容器中。 annotation-config：是否启用对注解的支持，即隐式的启用&lt;context:annotation-config/&gt;，默认为true。 name-generator：默认的beanName生成器，即在没有显式的指定beanName时，自动注册的bean将如何使用默认的beanName。默认将使用Class的简称，即不包含包名的类名称，并将首字母小写作为当前bean的名称。用户可以通过实现org.springframework.beans.factory.support.BeanNameGenerator接口并指定其为当前的name-generator来改变对应的策略。 scope-resolver：指定用于解析bean定义的scope的ScopeMetadataResolver，默认将通过AnnotationScopeMetadataResolver进行解析，而该解析器将根据类上标注的@Scope注解来解析对应的scope。默认没有指定@Scope的都是单例。 scoped-proxy：表示是否需要为自动检测到的需要加入bean容器中的bean生成对应的代理。默认是不生成。可选值有“no”、“interfaces”和“targetClass”，分别对应不生成、根据接口生成和根据目标class生成。这对需要使用代理的scope是非常有必须要的，如request、session等。更详细的内容请参考先前专门介绍scope的那篇文章。 mvc:annotation-driven From Me &lt;mvc:annotation-driven/&gt;会自动注册LocaleResolver,ThemeResolver,HandlerMapping,HandlerAdapter,HandlerExceptionResolver,RequestToViewNameTranslator,ViewResolver,FlashMapManager这8个组件的实现类，这8个组件便是SpringMVC的核心组件。程序在运行时会先去容器中扫描看是否你自定义了某一组件的实现，如果没有的话就使用properties文件中默认定义的实现类。 从源码可知&lt;mvc:annotation-driven/&gt;标签对应的解析类是AnnotationDrivenBeanDefinitionParser。从其中可以看出，该标签为我们做了这些配置： 支持使用了像@RquestMapping、@ExceptionHandler等等的注解的controller方法去处理请求。 支持使用@RequestBody、@ResponseBody注解。 并提供了：数据绑定支持，@NumberFormat注解的支持对数据类型进行格式化，@DateTimeFormat支持 支持使用@Valid对javaBean进行JSR-303验证。 读写XML的支持（JAXB），读写JSON的支持（Jackson）。 HttpMessageConverter对于HttpMessageConverter，它到底是干什么的呢？用SpringMVC写过REST的人可能略知一二，它是用来将特定的对象转换成字符串并最终作为HttpResponse返回的工具。实际上SpringMVC中面向开发人员的业务逻辑处理主要集中在各种Controller的方法中，基本模式是接受代表着HttpRequest的各种输入参数，在方法体中进行业务逻辑处理，最后得到输出结果，并以返回值的形式交给SpringMvc，Springmvc根据返回值的不同调用不同的处理逻辑并最终以HttpResponse的形式返回给客户端。Controller中的返回值可以有很多种，比如字符串，ModelAndView，普通对象，等等，甚至void类型都是可以的。所以SpringMvc会根据返回值的类型做很多的if else，不同的类型调用不同的处理逻辑。那么当函数受@ResponseBody声明时，Spring就会尝试用配置好的各种HttpMessageConverter来将返回值进行序列化。不同HttpMessageConverter能够处理的对象以及处理方式都是不一样的，Spring会遍历各Converter，如果该Converter能够处理该对象则交由其处理。因此，很多基于Spring的REST风格的应用常常会返回一个model对象，那么你就应该配置好正确的HttpMessageConverter，以便Spring能够正确的将这些对象序列化回客户端。 mvc:default-servlet-handler 注释说明：通过转发到Servlet容器的默认Servlet来配置一个处理器,用来提供静态资源。使用这个处理程序允许使用DispatcherServlet的“ / ”映射，同时仍然使用Servlet容器来提供静态资源 注意：这个处理程序将把所有请求转发给默认的Servlet。因此重要的是，它需要保持在所有其他URL HandlerMappings的顺序之后。 如果您使用annotation-driven元素或者其他情况就是这样。如果您正在设置您的自定义HandlerMapping实例，请务必将它 的“order”属性设置为小于DefaultServletHttpRequestHandler，即Integer.MAX_VALUE。 具体可看源码 From Me其实当一个请求来到的时候，它的执行流程是先经过tomcat的servlet的url-pattern的匹配。进入到了SpringMVC，然后对于SpringMVC框架来说，为了处理对应的请求时，首先会去找对应的HandlerMapping看是否有对应的类来处理该请求，如果有的话再根据HandlerAdapter去找是什么类，以及对应的处理方法。找不到的时候会报404。但当配置了&lt;mvc:default-servlet-handler&gt;标签的时候，它会注册SimpleUrlHandlerMapping来处理请求映射，对应的Handler是DefaultServletHttpRequestHandler，这种情况一般是其他HandlerMapping无法匹配处理，最后才无奈交给DefaultServletHttpRequestHandler来处理。而该Handler具体的做法其实就是转发给了web容器自身的defaultServlet来处理。这个servlet名称可以在mvc:default-servlet-handler标签中进行配置，如果没有配置，采用默认的配置，tomcat默认的servlet名称为default。即tomcat、Jetty等，在容器启动的时候，自身就默认注册了一个name叫default的servlet，DefaultServletHttpRequestHandler就是转发给这些servlet。defaultServlet会去寻找有没有该文件，找到了解析并返回文件内容，比如我们常请求的jsp页面，就是通过JspServlet来进行翻译的。找不到则404。但是你可以通过自定义servlet来替换defaultServlet。给用户返回自定义的一些信息。 mvc:resources &lt;mvc:default-servlet-handler /&gt;将静态资源的处理经由Spring MVC框架交回Web应用服务器处理。而&lt;mvc:resources /&gt;更进一步，由Spring MVC框架自己处理静态资源，并添加一些有用的附加值功能。&lt;mvc:resources /&gt;允许静态资源放在任何地方，如WEB-INF目录下、类路径下等，你甚至可以将JavaScript等静态文件打到JAR包中。通过location属性指定静态资源的位置，由于location属性是Resources类型，因此可以使用诸如classpath:等的资源前缀指定资源位置。传统Web容器的静态资源只能放在Web容器的根路径下，&lt;mvc:resources /&gt;完全打破了这个限制。 来看Spring官方demo中的示例： 12&lt;!-- Handles HTTP GET requests for /resources/** by efficiently serving up static resources in the $&#123;webappRoot&#125;/resources/ directory --&gt;&lt;resources mapping="/resources/**" location="/resources/" /&gt; 参考 ： Spring MVC 解读—— SpringMVC源码总结（二）mvc:annotation-driven以及@Controller和@RequestMapping的那些事 SpringMVC官方Demo spring源码学习之五 元素处理过程 ＜context:annotation-config／＞自动扫描标签详解 SpringMVC从入门到精通之第三章 Spring MVC中的二三事 SpringMVC 学习笔记(七) JSON返回:HttpMessageConverter作用 SpringMVC——消息转换器HttpMessageConverter https://my.oschina.net/HeliosFly/home 使用 Spring 3 MVC HttpMessageConverter]]></content>
      <categories>
        <category>Spring 学习</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常量应该封装到常量类，常量接口，还是枚举类中？]]></title>
    <url>%2Fjava-const.html</url>
    <content type="text"><![CDATA[###前言 之前项目中响应前台的接口中会用到一些公共常量。这个时候就比较纠结，常量到底是放在哪里比较好，因为已经代码不规范，而且有时候用到的不算太集中太多，然后就哪里用到哪个类上声明了一个出来，这样虽然很方便，但是统一维护起来，项目做大了，有些时候你要引用一个你记得你明明声明过的常量，却找半天都找不到，而且后期需要对常量中的内容进行一些修改的时候，维护起来也十分不方便，代码证提交结构也不优雅。所以自己决定研究一下到底常量应该封装到哪个类中比较好呢。因为题目所说的三种自己也都见过，但是具体的区别以及优劣却没有细细钻研。今天这里简单的记录整理一下，以防自己以后忘记。 示例代码 第一种使用接口： 12345public interface Constants&#123; int AUDIT_STATUS_PASS = 1; int AUDIT_STATUS_NOT_PASS = 2;&#125; 第二种使用类： 12345678public final class Constans&#123; private Constans() &#123; &#125; public static final int AUDIT_STATUS_PASS = 1; public static final int AUDIT_STATUS_NOT_PASS = 2;&#125; 第三种使用枚举： 123456789101112131415public enum Constants &#123; AUDIT_STATUS_PASS(1), AUDIT_STATUS_NOT_PASS(2); private int status; private Constants(int status)&#123; this.setStatus(status); &#125; public int getStatus() &#123; return status; &#125;&#125; 首先，前两种可以看成是一样的。第一种写起来更方便一些吧，省去了public static final字段。但是如果从细想，接口可以被继承，可以将内容深入到其实现类代码中。这样对于一个常量类接口来说显然是不合理，但是你确实无法规避这个问题。唯一可以解决的办法就是弃用常量接口，选用常量类的方式。以final字段修饰，防止其被继承。并将其构造函数private化，防止被实例化。这显然在硬性上可以很好地解决这个问题。 但即便如此枚举任然是首选，但是如果不使用枚举的话，在《Effective Java》一书中，作者建议使用一般类加私有构造函数的方式。但是参考了 StackOverFlow 上大牛的讲解，我认为一般类上也应该再加上final字段。这样可以更好的避免一些不必要的麻烦。 参考：StackOverFlow 常量接口 你可能会问常量接口就真的一无是处吗？ 也不是，但是和是也差不多。但是我还是会用，贴一段自己的代码 123456789101112131415161718public final class Const &#123; private Const() &#123; &#125; public static final String CURRENT_USER = "currentUser"; // 这里没有使用interface进行分组是因为 这两个对象不好分组。 public static final String EMAIL = "email"; public static final String USERNAME = "username"; // 普通用户和管理员是一个组，枚举过于繁重 // 内部接口类 把常量进行分组。没有枚举重，但还可以分组，而且里面还是常量 public interface Role &#123; int ROLE_CUSTOMER = 0; // 普通用户 int ROLE_ADMIN = 1; // 管理员 &#125;&#125; 具体常量接口的作用注释中已经写得很清楚了。总结下来就是前提你是内部接口，那么你可以直观分组，还简洁。 总结 综上：优先枚举，常量类，接口(不建议)。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA UUID 生成唯一标识]]></title>
    <url>%2Fjava-UUID.html</url>
    <content type="text"><![CDATA[需求 项目在用户未登录状态下，根据问题回答答案来进行修改密码。我们需要保证当前用户的身份。对用户状态进行唯一的记录，用于对用户接下来的修改密码操作进行判断。 UUID JDK API 是这么说的： ​ “表示通用唯一标识符 (UUID) 的类。 UUID 表示一个 128 位的值。” 1个UUID是1个16字节（128位）的数字；为了方便阅读，通常将UUID表示成如下的方式： 1123e4567-e89b-12d3-a456-426655440000 1个UUID被连字符分为五段，形式为8-4-4-4-12的32个字符。 UUID由以下几部分的组合： （1）当前日期和时间，UUID的第一个部分与时间有关，如果你在生成一个UUID之后，过几秒又生成一个UUID，则第一个部分不同，其余相同。 （2）时钟序列 （3）全局唯一的IEEE机器识别号，如果有网卡，从网卡MAC地址获得，没有网卡以其他方式获得。 代码实现 1234public static void main(String[] args) &#123; UUID uuid = UUID.randomUUID(); System.out.println(uuid);&#125; 没错其实就是这么简单的一行就生成了。 打印一下： 1d57f476a-696e-416f-bbf8-48973a47c2b5 这就是唯一标志码。但显得冗长，不够友好。如果在URL后面做参数，更加不够友好。还有存储一个UUID要花费更多的空间。获取的时间倒不必考虑太多。看看有多糟心 从网上大牛那里找到的解决办法 1234567891011121314151617181920public static String[] chars = new String[] &#123; "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "A", "B", "C", "D", "E", "F", "G", "H", "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V","W", "X", "Y", "Z" &#125;; public static String getShortUuid() &#123; StringBuffer stringBuffer = new StringBuffer(); String uuid = UUID.randomUUID().toString().replace("-", ""); for (int i = 0; i &lt; 8; i++) &#123; // 32 -&gt; 8 String str = uuid.substring(i * 4, i * 4 + 4); // 16进制解数 int strInteger = Integer.parseInt(str, 16); System.out.println(strInteger); // 0x3E -&gt; 字典总数 62 stringBuffer.append(chars[strInteger % 0x3E]); &#125; return stringBuffer.toString(); &#125; 跑一下测试用例1000个。查重，没有。解决]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String s = new String("xyz") 创建了多少个String实例]]></title>
    <url>%2Fjava-jvm-String.html</url>
    <content type="text"><![CDATA[String有两种赋值方式： 第一种是通过“字面量”赋值。比如下面这行， 1String str = "Hello"; 第二种是通过new关键字创建新对象。比如下面这样， 1String str = new String("Hello"); 这两种方式到底有什么不同。程序执行的时候，内存里到底有几个实例？“实例”存在了内存的哪里？”字面量“又存在了哪里？”变量“又存在了哪里？概念很容易搞混。下面我们一个一个来讲。讲之前如果可以先回顾一下内存。 上图中，首先Heap堆分成“新生代”，“老年代”，先不用管它，这是GC垃圾回收时候的事。重要的是Stack栈区里的“局部变量表（Local Variables）”和“操作数栈（Operand Stack）”。因为栈是线程私有的，每个方法被执行的时候都会创建一个“栈帧（Stack Frame）”。而每个栈帧里对应的都维护着一个局部变量表和操作数栈。我们老说基本类型变量和对象引用存在栈里，其实就是存在局部变量表里。而操作数栈是线程实际的操作台。看下面这张图，做个加法100+98，局部变量表就是存数据的地方，一直不变，到加法做完再把和加进去。操作数栈就很忙了，先把两个数字压进去，再求和，算出来以后再弹出去。如图： 中间这个非堆（Non-Heap）可以粗略地理解为非堆里包含了永生代，而永生代里又包括了方法区。上面说了，每个类加载完之后，类的信息都存在方法区里。和String最相关的是里面的“运行时常量池（Run-time Constant Pool）”。它是每个类私有的。后面会说到，每个class文件里的“常量池”在类被加载器加载之后，就映射存放在这个地方。另外一个是“字符串常量池（String Pool）”。和运行时常量池不是一个概念。字符串常量池是全局共享的。位置就在第二张图里Interned String的位置，可以理解为在永生代里，方法区外面。后面会讲到，String.intern()方法，字符串驻留之后，引用就放在这个String Pool。心里有个内存的印象之后就可以开始说String了。 比如下面这个Test.java。在主线程方法main里声明了一个字面量是”Hello”的字符串str。 12345678class Test&#123; public void f(String s)&#123;...&#125;; public static void main(String[] args)&#123; String str = "Hello"; ... &#125;&#125; 编译成Test.class文件之后，如下图，除了版本、字段、方法、接口等描述信息外，还有一个也叫“常量池（Constant Pool Table）”的东西（淡绿色区块）。但这个常量池和内存里的常量池不是一个东西。class文件里的常量池主要存两个东西：“字面量（Literal）”和“符号引用量(Symbolic References)”。其中字面量就包括类中定义的一些常量，因为String是不可变的，由final关键字修饰过了，所以代码里的“Hello”字符串，就是作为字面量（常量）写在class的常量池里。 运行程序用到Test类的时候，Test.class文件的信息就会被解析到内存的方法区里。class文件里常量池里大部分数据会被加载到“运行时常量池”。但String不是。例子中的”Hello”的一个引用会被存到同样在Non Heap区的字符串常量池（String Pool）里。而“Hello”本体还是和所有对象一样，创建在Heap堆区。R大的文章里，测试的结果是在新生代的Eden区。但因为一直有一个引用驻留在字符串常量池，所以不会被GC清理掉。这个Hello对象会生存到整个线程结束。如下图所示，字符串.面。 ！注意：这只是在Test类被类加载器加载时候的情形。主线程中的str变量这时候都还没有被创建，但Hello的实例已经在Heap里了，对它的引用也已经在字符串常量池里了。 等主线程开始创建str变量的时候，虚拟机就会到字符串常量池里找，看有没有能equals(“Hello”)的String。如果找到了，就在栈区当前栈帧的局部变量表里创建str变量，然后把字符串常量池里对Hello对象的引用复制给str变量。找不到的话，才会在heap堆重新创建一个对象，然后把引用驻留到字符串常量区。然后再把引用复制栈帧的局部变量表。 如果我们当时定义了很多个值为”Hello”的String，比如像下面代码，有三个变量str1,str2,str3，也不会在堆上增加String实例。局部变量表里三个变量统一指向同一个堆内存地址。 12345678910class Test&#123; public void f(String s)&#123;...&#125;; public static void main(String[] args)&#123; String str1 = "Hello"; String str2 = "Hello"; String str3 = "Hello"; ... &#125;&#125; 上图中str1,str2,str3之间可以用==来连接。 但如果是用new关键字来创建字符串，情况就不一样了， 12345678910class Test&#123; public void f(String s)&#123;...&#125;; public static void main(String[] args)&#123; String str1 = "Hello"; String str2 = "Hello"; String str3 = new String("Hello"); ... &#125;&#125; 这时候，str1和str2还是和之前一样。但str3因为new关键字会在Heap堆申请一块全新的内存，来创建新对象。虽然字面还是”Hello”，但是完全不同的对象，有不同的内存地址。 当然String.intern()方法让我们能手动检查字符串常量池，把有新字面值的字符串地址，而不是new的字符串对象！驻留到常量池里。这样一些常用字符串在被频繁使用的时候就不需要在堆中重复申请空间了。==这句话是重点，好好理解就能想通！== 最后补充一下，JDK 7开始Hotspot把Interned String从PermGen挪到Heap堆，JDK 8又彻底取消了PermGen。但不管怎样，基本原理还是不变的。]]></content>
      <categories>
        <category>JVM 学习</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集算法]]></title>
    <url>%2Fjava-jvm-garbage-collector.html</url>
    <content type="text"><![CDATA[概述 垃圾收集即GC。经过半个多世纪的发展，目前内存的动态分配与内存回收技术已经相当成熟，一切看起来都进入了“自动化”时代，那我们为什么还要去了解GC和内存分配呢？答案很简单：当需要排查各种内存溢出，内存泄漏问题时，当垃圾手机成为系统达到更高并发的瓶颈时，我们就需要对这些“自动化”的技术实施必要的监控和调节。 GC瞄准谁 我们已知程序计数器，虚拟机栈以及本地方法栈都是随着线程而生，随着线程而亡。所以这部分跟随线程生死的运行时区域在线程结束时内存也自然的被回收了。这一部分的区域就不需要过多的考虑内存的回收的问题。而Java堆和方法区则不一样。一个接口中的多个实现类可能需要的内存相差很大，一个方法的多个分支需要的内存也可能不一样。我们只有在程序运行阶段才会知道会创建哪些对象，这部分的内存分配及回收都是动态的。垃圾收集器关注的也正是这部分内存。 哪些内存需要回收 引用计数算法给对象添加一个引用计数器，当有一个地方应用它时计数器加1；当引用失效时，计数器减1；任何时刻计数器为0的对象不可能再被使用。 优点： 实现简单，判定效率高。适用于大部分情况，但Java并没有选择其来管理内存。 缺点：很难解决对象间循环引用问题。 例子： 123456789101112131415161718192021222324252627public class ReferenceCountingGC &#123; public Object instance = null; private static final int _1MB = 1024 * 1024; private byte[] bigSize = new byte[2 * _1MB]; public static void testGC() &#123; ReferenceCountingGC objA = new ReferenceCountingGC(); ReferenceCountingGC objB = new ReferenceCountingGC(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; // 该程序是无意义的相互引用且不能再被访问 // 此处若发生GC，引用计数算法是无法通知GC收集器回收他们的 // 但在Java中会将他们回收，因为Java中并不是通过该算法来管理内存的 System.gc(); &#125; public static void main(String[] args) &#123; testGC(); &#125;&#125; 可达性分析算法通过一系列的称为“GC Root”的对象作为起始点，从这些节点开始向下搜索，搜索所走的路径称为引用链（Reference Chain）,当一个对象到GC Root不可达时，则证明这个对象是不可用的。如下图，对象object5、 object6、 object7，虽然相互有关联但是它们到GC Root不可达，所以它们被判定为是可回收的对象。 在Java语言中，可作为GC Root对象包括以下几种： 虚拟机栈（栈帧中的本地变量表）中的引用对象。 方法区中的静态属性或常量引用的对象。 本地方法栈中JNI(即一般说的Native方法)引用的对象。 后来Java又对引用的概念进行了扩充。引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）4种，这4种引用强度依次逐渐减弱。 强引用就是指在程序代码之中普遍存在的，类似“Object obj = new Object()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用是用来描述一些还有用但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK 1.2之后，提供了SoftReference类来实现软引用。 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在JDK 1.2之后，提供了WeakReference类来实现弱引用。 虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。在JDK 1.2之后，提供了PhantomReference类来实现虚引用。 非死不可吗？要真正宣告一个对象的死亡至少要经历两次标记过程。如果对象在进行可达性分析后发现没有与GC Roots相连接的引用连，那他将会被第一次标记并且进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖或者finalize()方法已经被虚拟机调用过，虚拟机将这两种情况都视为没有必要执行了。 如果该对象被判定为有必要执行finalize()方法。那么这个对象将会被放置在F-Quere队列之中。 并会被虚拟机创建的，低优先级的Finalizer线程去执行该对象的finalize()方法。但并不会等待它结束，因为对象在finalize()方法执行中如果出现执行缓慢或者发生死循环。将会导致F-Queue队列中其他对象永久处于等待。甚至导致整个内存回收系统崩溃。之后GC将会对F-Queue之中的对象进行第二次标记。如果在第二次标记前这些对象在自己的finalize()方法中可以拯救自己(重新与引用链上的任何一个对象建立关联即可)也是可以成功存活下来并被移除“即将回收”的集合的。 如果此时还没有逃脱，那就真的要被回收了。 虽然其有点儿C/C++中析构函数的意思，但其其实并不是，相反却是Java程序员期初为了更好的被C/C++程序员所接受而做的一种妥协。 注意：finalize()方法的运行代价高昂，不确定性大，无法保证各个对象的调用顺序。所以尽量使用try-finally来代替它。 几种垃圾收集算法 标记—清除算法算法分为标记和清除两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程就是使用可达性算法进行标记的。不足： 效率问题，标记和清除两个过程的效率都不高 空间问题，标记清除之后会产生大量不连续的内存碎片，导致以后分配较大对象时内存不足以至于不得不提前触发另一次垃圾收集动作。 复制算法复制算法：将可用内存按照容量分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另一块上面，然后把已使用过的内存空间一次清理掉。 内存分配时不用考虑内存碎片问题，只要一动堆顶指针，按顺序分配内存即可，实现简单，运行高效。代价是将内存缩小为原来的一半。 实际应用中将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中的一块Survivor。当回收时，将Eden和Survivor中还存活着的对象一次性复制到另一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。 Hotspot虚拟机中默认的Eden和Survivor的大小比例是8:1。 缺点： 在对象存活率较高的情况下，效率变低 有额外空间分配担保负担，无法应对被使用的内存100%对象存活的极端情况，致使老年代不能使用。 标记-整理算法标记整理算法（Mark-Compact），标记过程仍然和“标记-清除”一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活对象向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法根据对象存活周期的不同将内存分为几块。一般把Java堆分为新生代和老年代，根据各个年代的特点采用最合适的收集算法。在新生代中，每次垃圾收集时有大批对象死去，只有少量存活，可以选用复制算法。而老年代对象存活率高，使用标记清理或者标记整理算法。 什么时候回收？ 当这三个分代的堆空间比较紧张或者没有足够的空间来为新到的请求分配的时候，垃圾回收机制就会起作用。有两种类型的垃圾回收方式：次收集和全收集。当新生代堆空间满了的时候，会触发次收集将还存活的对象移到年老代堆空间。当年老代堆空间满了的时候，会触发一个覆盖全范围的对象堆的全收集。 次收集 当新生代堆空间紧张时会被触发 相对于全收集而言，收集间隔较短 全收集 当老年代或者持久代堆空间满了，会触发全收集操作 可以使用System.gc()方法来显式的启动全收集 全收集一般根据堆大小的不同，需要的时间不尽相同，但一般会比较长。不过，如果全收集时间超过3到5秒钟，那就太长了]]></content>
      <categories>
        <category>JVM 学习</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[马云热血励志演讲《最伟大的成功》]]></title>
    <url>%2Fstand-up.html</url>
    <content type="text"><![CDATA[当你乐观的时候，总是会有机会的。那么你可能要问了“机会在哪呢？”，你可能没有特别想实现的事，没有迫切要成功的欲望，没有勇攀高峰的决心，没有水滴石穿的毅力，也没有一颗所向披靡的强大心脏。那么，让来自马云的这段演讲来告诉你，你有什么。你有年轻的身体，你有奇妙的想法，你有乐观的心态，你有无限的可能性！ 喝下这口鸡汤之后，真的是有醍醐灌顶的感觉。它犹如一面镜子，映射出的却是我们每个人有什么和没有什么，我们常常抱怨自己没有别人的机会，没有别人的运气，甚至抱怨没有别人的出生。可是马云也没有，马云可能抱怨过，但他没有一直抱怨。我从他身上看到的从来都是他不服输的特点以及敢于尝试的态度。其实我们和那些成功的人相比，真正没有的是这两点吧。我们觉得这样就可以了，那个高度不是我能到达的，所以我们就止步于此并为自己开脱。我们怕失败，好面子，怕别人看不起自己。就不敢于尝试，不敢于接触自己不了解的东西。致使自己失去很多的机会失去很多的可能。不是吗？ 我想，当我们每个人迷茫的时候，投机取巧行动懒散的时候，我们甚至怀疑自己是否可以的时候，我们对自己的选择动摇的时候。是否是和马云所说的一样没有勇攀高峰的决心，没有水滴石穿的毅力，没有迫切想要成功的欲望以及一颗所向披靡的强大心脏？ 我想我们很少会有人有，但是没有不可怕，可怕的是我们一直意识不到自己比别人缺少的是什么。比那些成功的人同龄的时候差在哪里。现在，当你明白过来的时候。那就去尝试吧，尝试拥有他们那优秀的品质。无论最后是否会成功，是否一切如你所想。就算是为了自己的那份骄傲，就去尝试吧。不然你在骄傲什么呢？ 马云还曾经说过“今天很艰难，明天比今天更难，后天可能是美好的，但更多的人死在了明天”。是不是感觉说的就是自己？曾经的你多少次心血来潮，三分钟热度的去学习去努力的做一件事情甚至发出毒誓。但是没过两天甚至几分钟就忘得一干二净。可是上天给了你无数次机会，上天并没有让你死在明天，只是把你打倒了，它一次次打你，你一次次躺下。终于有一天它会让你死在某个明天，而你也欣然接受不是吗。这就是你，一次次倒下的你。 可我希望你逆天而行，选择那个你认为难走的路。走向自己的成功 最后，用马云视频中的一句话送给正是大三并为实习准备的自己。 You fall and you stand up.]]></content>
      <categories>
        <category>励志</category>
      </categories>
      <tags>
        <tag>励志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx速识]]></title>
    <url>%2Fnginx.html</url>
    <content type="text"><![CDATA[Nginx是什么Nginx是一款轻量级Web服务器，也是一款反向代理服务器。日常中用到的域名转发用的就是反向代理的功能。 Nginx能干什么 可直接支持Rails和PHP的程序 可以作为HTTP的反向代理服务器 作为负载均衡的服务器 作为邮件代理的服务器 帮助实现前段动静分离 Nginx的特点是什么 高稳定 高性能 资源占用少 功能丰富 模块化结构 支持热部署 Nginx常用命令测试配置文件1安装路径下的/nginx/sbin/nginx -t 启动命令 1安装路径下的/nginx/sbin/nginx 停止命令 123安装路径下的/nginx/sbin/nginx -s stopornginx -s quit 重启命令 1安装路径下的/nginx/sbin/nginx -s reload 查看进程的命令 1ps -ef|grep nginx 平滑重启 1killl -HUP [Nginx主进程号(即查看进程命令插到的PID)] 增加防火墙权限 12341. sudo vim /etc/sysconfig/iptables2. -A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT3. 保存退出4. 重启防火墙 sudo service iptables restart Nginx虚拟域名配置及测试验证 1231. sudo vim /user/local/nginx/conf/nginx.conf2. 增加include vhost/*.conf3. 保存退出]]></content>
      <categories>
        <category>Web服务器</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防火墙设置：虚拟机ping不通主机，但是主机可以ping通虚拟机（转载）]]></title>
    <url>%2Flinux-connection.html</url>
    <content type="text"><![CDATA[我在Windows7系统安装了虚拟机，通过虚拟机安装了Ubuntu13.04，我设置的主机与虚拟机的连接方式是桥接，安装好后，发现虚拟机ping不通主机，但是主机可以ping通虚拟机。 我的操作是：关闭防火墙，发现虚拟机可以ping通主机了。说明是Windows7防火墙阻止了。 现在存在的问题是：如果我一直关闭防火墙也不是个事啊？这样做会影响我的电脑安全的。于是我想我要先确定防火墙阻止了什么，导致需要关闭防火墙？ 于是我在网上查看资料，原来是Windows7的防火墙没有打开ICMPv4-in这个规则，那怎么打开呢： 打开WIN7防火墙 选择高级设置 入站规则 找到配置文件类型为“公用”的“文件和打印共享（回显请求 – ICMPv4-In）”规则，设置为允许。 虚拟机可以ping通主机了！ 本文出自 “chris” 博客，请务必保留此出处http://chris2013.blog.51cto.com/6931081/1209278]]></content>
      <categories>
        <category>Linux 学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS_7 桥接]]></title>
    <url>%2Flinux-centOS-bridging.html</url>
    <content type="text"><![CDATA[首先我是看的慕课网进行学习的，可是慕课网老师讲解的时候用的centOS版本是6.3版本。已经很很久之前的版本，最新的centOS已经更新到了7。所以会有一些列的怕配置不一致的问题出现，其中一些问题困扰了我很久。 这里附上慕课视频地址：XShell的安装和使用 网络配置一上来一步一步跟的老师的视频走，就发现怎么我的setup里没有网络配置呢？ 后来在讨论区里找到了答案，这里： 1nmtui 然后再后来又看了该作者对另一篇文章的解答，xshell连接centos 但是可能是自己比较笨，作者描述的不是“特别”的详细。所以我失败了 …… 查看本机 Ip1ipconfig/all 修改网卡ens33为eth0后来我注意到自己的网卡名称为ens33而不是老师视频上所示eth0。后来查询得知centOS7之后网卡名称改掉了，所以我也索性改掉了。 参考了博主： z_ycdqm：修改网卡ens33为eth0 防火墙及ssh服务器问题后来网卡名称也改了，网络也配置了，但是还是不行。就去网上各种百度，谷歌。很多人都在讨论防火墙和ssh协议端口开放问题，自己自然也跟着查了，发现还是都没有问题。但是学会了不少命令，这里记录一下，万一以后用得着呢。 参考博主： 功夫熊猫1： Xshell链接错误：Could notconnect to ‘192.168.18.128’ (port 22): Connection failed. 网卡ip配置参考博客： CentOS7网卡设置为桥接模式静态IP配置方法详解 主机桥接Centos7联网问题总结 ifcfg-eth0文件参数PREFIX 和 NETMASK的配置不一致问题 选择性参考完以上三位博主的博文之后，Xshell就可以成功的连接到虚拟机上了。可是后来又不知道怎么样崩掉了，后来我继续从网上找解决办法，最终从一位博主那里参考到了一个办法，我也和他出于懵逼状态不知道为什么这样可以，以后知道了会继续更新。 参考博文：虚拟机net模式可以上网，可是桥接模式不行 桥接和NAT模式的区别参考： Linux下的桥接模式和Nat模式的区别 关于虚拟机的两种上网方式（桥接模式和NAT模式）]]></content>
      <categories>
        <category>Linux 学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用命令]]></title>
    <url>%2Flinux-command-1.html</url>
    <content type="text"><![CDATA[Ubuntu 软件列表更新与系统更新1sudo apt-get update 会访问源列表里的每个网址，并读取软件列表，然后保存在本地电脑。 1sudo apt-get upgrade 会把本地已安装的软件，与刚下载的软件列表里对应软件进行对比，如果发现已安装的软件版本太低，就会提示你更新。 慎用。在保证服务器上的文件等不会因更新而被破坏时，再使用。因为如果软件源中有系统更新会直接把你系统更新掉，同时带来的问题就是之前安装过的很多软件可能无法使用。 Ubuntu 用户管理在Ubuntu下，$是普通管员，#是系统管理员;(系统管员权限&gt;普通管员) 新建用户（以test为例）：1234567有useradd和adduser两种；sudo useradd test //是一个ELF可执行程序；没有附加参数，用户没有同名主目录、密码和系统shellsudo adduser test //是一个perl脚本；有附加参数，会提示输入密码并创建同名目录 修改 test 用户的密码：passwd test //必须设置大于等于6位的密码sudo passwd test //不限制密码长度 新建用户组并加入用户（lebo用户组为例）：12sudo groupadd lebosudo adduser test lebo 给 test 用户创建自己的目录：12sudo mkdir /home/testchown test /home/test 给用户添加sudo权限1sudo usermod -aG sudo test 切换用户1su test 修改用户信息1usermod test 相关链接：https://cnzhx.net/blog/linux-add-user-to-group/ Ubuntu 文件管理12345678910111213141516tree / //查看全部文件（要先install tree）pwd //获取当前路径~ //当前用户主目录cd .. //上一级cd ~ //home目录（/开头是绝对路径；.开头是相对路径）mkdir mydir //新建目录mydirmkdir -p father/son/grandson //建多级目录cp test(此处可为路径) father/son/grandson //将当前目录下的test复制到grandson中rm //删除文件mv 旧名 新名 //重命名remove 'y/a-z/A-Z/' *.c //删文件cat test //查看文件test;-n显示行号file test //查看文件类型ls //查看当前目录下的文件ls -l 文件名称 //查看详细信息（文件夹将-l改为-ld）zip index.zip index -r //压缩index目录下的所有文件到index.zip(要先install zip) 文件权限说明： drwxr-xr-x 8 root root 4096 Apr 30 09:47 venv 文件属性 连接数 文件拥有者 所属群组 文件大小 文件修改时间 文件名 r可读，w可写，x 可执行，-不可读/写/执行 文件属性共10个位置 例如： d rwx r-x r-x 第一个字符指定了文件类型。如果第一个字符是横线，表示是一个非目录的文件。如果是d，表示是一个目录。 第二段是文件拥有者User的属性， 第三段是文件所属群组Group的属性， 第四段是对于其它用户Other的属性。 修改文件权限有两种方法，功能相同写法不同 方法一 1chmod abc file 其中a,b,c各为一个数字，分别表示User、Group、及Other的权限。 r=4，w=2，x=1 例子： 若要rwx属性则4+2+1=7； 若要rw-属性则4+2=6； 若要r-x属性则4+1=5。 示例代码： 12345sudo chmod 600 ××× （只有所有者有读和写的权限）sudo chmod 644 ××× （所有者有读和写的权限，组用户只有读的权限）sudo chmod 700 ××× （只有所有者有读和写以及执行的权限）sudo chmod 666 ××× （每个人都有读和写的权限）sudo chmod 777 ××× （每个人都有读和写以及执行的权限） 方法二 1chmod 用户 操作权限 文件名 用户参数：u–user; g–group; o–other; a–all(u+g+o) 操作方法：+添加权限 -取消权限 =取消旧权限赋予新权限） 操作参数：r可读，w可写，x 可执行，-不可读/写/执行， u 与文件属主拥有一样的权限； g 与和文件属主同组的用户拥有一样的权限； o 与其他用户拥有一样的权限. 示例代码： 1234chmod u+rw readme.txt //给用户增加读写权限chmod o-rwx readme.txt //不允许其他用户读写执行chmod g=rx readme.txt //只允许群组读取和执行chmod ug+x tigger //恢复群组权限 参考来源： Ubuntu下修改文件夹权限 Ubuntu更改文件夹及子文件夹权限 Ubuntu 更改文件夹权限及chmod详细用法 Ubuntu 搜索文件方法123456789101112131415161718通用格式:find pathname -options [-print -exec -ok]例子:find / -name filename 在根目录里面搜索文件名为filename的文件find /etc -name *s*在目录里面搜索带有s的文件find /etc -name *S 在目录里面搜索以s结尾的文件find /etc -name s*在目录里面搜索以s开头的文件find / -amin -10在系统中搜索最后１０分钟访问的文件find / -atime -2查找在系统中最后４８小时访问的文件find / -empty 查找在系统中为空的文件或者是文件夹find / -group groupname 查找在系统中属于groupname的文件find / -mmin -5查找在系统中最后５分钟修改过的文件find / -mtime -1查找在系统中最后２４小时修改过的文件find /－nouser查找在系统中属于费用户的文件find / -user username 查找在系统中属于username的文件find / -ctime -1查找在系统中最后２４小时被改变状态的文件find / -fstype type查找在系统中文件类型为？的文件find / -user user１name -or -useruser２name查找在系统中属于user1name或着属于user2name的文件find / -user user1name -and-user2name在系统中查找既属于user1name又属于user2name用户的文件 Ubuntu软件安装12sudo apt-get install 软件名 //最常用方法sudo dpkg -i package.deb //deb包安装方法 deb详解： 123456789dpkg -r package 删除包 dpkg -P package 删除包（包括配置文件） dpkg -L package 列出与该包关联的文件 dpkg -l packag 显示该包的版本e dpkg –unpack package.de 解开 deb 包的内容 dpkg -S keyword 搜索所属的包内容 dpkg -l 列出当前已安装的包 dpkg -c package.deb 列出 deb 包的内容 dpkg –configure package 配置包]]></content>
      <categories>
        <category>Linux 学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM(推荐)]]></title>
    <url>%2Fjava-jvm.html</url>
    <content type="text"><![CDATA[转载： 牧曦之晨：深入理解JVM 深入理解JVM 原文链接：http://www.cubrid.org/blog/dev-platform/understanding-jvm-internals 每个使用Java的开发者都知道Java字节码是在JRE中运行(JRE: Java 运行时环境)。JVM则是JRE中的核心组成部分，承担分析和执行Java字节码的工作，而Java程序员通常并不需要深入了解JVM运行情况就可以开发出大型应用和类库。尽管如此，如果你对JVM有足够了解，就会对Java有更好的掌握，并且能解决一些看起来简单但又尚未解决的问题。 所以，在本篇文章中，我将会介绍JVM工作原理，内部结构，Java字节码的执行及指令的执行顺序，并会介绍一些常见的JVM错误及其解决方案。最后会简单介绍下Java SE7带来的新特性。 虚拟机JRE由Java API和JVM组成，JVM通过类加载器(Class Loader)加类Java应用，并通过Java API进行执行。 虚拟机(VM: Virtual Machine)是通过软件模拟物理机器执行程序的执行器。最初Java语言被设计为基于虚拟机器在而非物理机器，重而实现WORA(一次编写，到处运行)的目的，尽管这个目标几乎被世人所遗忘。所以，JVM可以在所有的硬件环境上执行Java字节码而无须调整Java的执行模式。 JVM的基本特性： 基于栈(Stack-based)的虚拟机: 不同于Intel x86和ARM等比较流行的计算机处理器都是基于寄存器(register)架构，JVM是基于栈执行的。 符号引用(Symbolic reference): 除基本类型外的所有Java类型(类和接口)都是通过符号引用取得关联的，而非显式的基于内存地址的引用。 垃圾回收机制: 类的实例通过用户代码进行显式创建，但却通过垃圾回收机制自动销毁。 通过明确清晰基本类型确保平台无关性: 像C/C++等传统编程语言对于int类型数据在同平台上会有不同的字节长度。JVM却通过明确的定义基本类型的字节长度来维持代码的平台兼容性，从而做到平台无关。 网络字节序(Network byte order): Java class文件的二进制表示使用的是基于网络的字节序(network byte order)。为了在使用小端(little endian)的Intel x86平台和在使用了大端(big endian)的RISC系列平台之间保持平台无关，必须要定义一个固定的字节序。JVM选择了网络传输协议中使用的网络字节序，即基于大端(big endian)的字节序。 Sun 公司开发了Java语言，但任何人都可以在遵循JVM规范的前提下开发和提供JVM实现。所以目前业界有多种不同的JVM实现，包括Oracle Hostpot JVM和IBM JVM。Google公司使用的Dalvik VM也是一种JVM实现，尽管其并未完全遵循JVM规范。与基于栈机制的Java 虚拟机不同的是Dalvik VM是基于寄存器的，Java 字节码也被转换为Dalvik VM使用的寄存器指令集。 Java 字节码JVM使用Java字节码—一种运行于Java(用户语言)和机器语言的中间语言，以达到WORA的目的。Java字节码是部署Java程序的最小单元。 在介绍Java 字节码之前，我们先来看一下什么是字节码。下面涉及的案例是曾在一个真实的开发场景中遇到过的情境。 现象一个曾运行完好的程序在更新了类库后却不能再次运行，并抛出了如下异常： 123Exception in thread "main" java.lang.NoSuchMethodError: com.nhn.user.UserAdmin.addUser(Ljava/lang/String;)V at com.nhn.service.UserService.add(UserService.java:14) at com.nhn.service.UserService.main(UserService.java:19) 程序代码如下，并在更新类库之前未曾对这段代码做过变更： 12345// UserService.java…public void add(String userName) &#123; admin.addUser(userName);&#125; 类库中更新过的代码前后对比如下： 12345678910111213// UserAdmin.java - Updated library source code…public User addUser(String userName) &#123; User user = new User(userName); User prevUser = userMap.put(userName, user); return prevUser;&#125;// UserAdmin.java - Original library source code…public void addUser(String userName) &#123; User user = new User(userName); userMap.put(userName, user);&#125; 简单来说就是addUser()方法在更新之前返回void而在更新之后返回了User类型实例。而程序代码因为不关心addUser的返回值，所以在使用的过程中并未做过改变。 初看起来，com.mhn.user.UserAdmin.addUser()依然存在，但为什么会出现NoSuchMethodError？ 问题分析主要原因是程序代码在更新类库时并未重新编译代码，也就是说，虽然程序代码看起来依然是在调用addUser方法而不关心其返回值，而对编译的类文件来说，他是要明确知道调用方法的返回值类型的。 可以通过下面的异常信息说明这一点： 1java.lang.NoSuchMethodError: com.nhn.user.UserAdmin.addUser(Ljava/langString;)V NoSuchMethodError 是因为 “com.nhn.user.UserAdmin.addUser(Ljava/lang/String;)V” 方法找不到引起的。看一下”Ljava/lang/String;”和后面的”V”。在Java字节码表示中，”L;“表示类的实例。所以上面的addUser方法需要一个java/lang/String对象作为参数。就这个案例中，类库中的addUser()方法的参数未发生变化，所以参数是正常的。再看一下异常信息中最后面的”V”，它表示方法的返回值类型。在Java字节码表示中，”V”意味着该方法没有返回值。所以上面的异常信息就是说需要一个java.lang.String参数且没有任何返回值的com.nhn.user.UserAdmin.addUser方法找不到。 因为程序代码是使用之前版本的类库进编译的，class文件中定义的是应该调用返回”V”类型的方法。然而，在改变类库后，返回”V”类型的方法已不存在，取而代之的是返回类型为”Lcom/nhn/user/User;”的方法。所以便发生了上面看到的NoSuchMethodError。 注释 因为开发者未针对新类库重新编译程序代码，所以发生了错误。尽管如此，类库提供者却也要为此负责。因为之前没有返回值的addUser()方法既然是public方法，但后面却改成了会返回user实现，这意味着方法签名发生了明显的变化。这意味了该类库不能对之前的版本进行兼容，所以类库提供者必须事前对此进行通知。 我们重新回到Java 字节码，Java 字节码是JVM的基本元素，JVM本身就是一个用于执行Java字节码的执行器。Java编译器并不会把像C/C++那样把高级语言转为机器语言(CPU执行指令)，而是把开发者能理解的Java语言转为JVM理解的Java字节码。因为Java字节码是平台无关的，所以它可以在安装了JVM(准确的说，是JRE环境)的任何硬件环境执行，即使它们的CPU和操作系统各不相同(所以在Windows PC机上开发和编译的class文件在不做任何调整的情况下就可以在Linux机器上执行)。编译后文件的大小与源文件大小基本一致，所以比较容易通过网络传输和执行Java字节码。 Java class文件本身是基于二进制的文件，所以我们很难直观的理解其中的指令。为了管理这些class 文件， JVM提供了javap命令来对二进制文件进行反编译。执行javap得到的是直观的java指令序列。在上面的案例中，通过对程序代码执行javap -c就可得到应用中的UserService.add()方法的指令序列，如下： 1234567public void add(java.lang.String); Code: 0: aload_0 1: getfield #15; //Field admin:Lcom/nhn/user/UserAdmin; 4: aload_1 5: invokevirtual #23; //Method com/nhn/user/UserAdmin.addUser:(Ljava/lang/String;)V 8: return 在上面的Java指令中，addUser()方法是在第五行被调用，即”5: invokevirtual #23”。这句的意思是索引位置为23的方法会被调用，方法的索引位置是由javap程序标注的。invokevirtual是Java 字节码中最常用到的一个操作码，用于调用一个方法。另外，在Java字节码中有4个表示调用方法的操作码： invokeinterface_, invokespecial, invokestatic, _invokevirtual 。他们每个的含义如下： invokeinterface: 调用接口方法 invokespecial: 调用初始化方法、私有方法、或父类中定义的方法 invokestatic: 调用静态方法 invokevirtual: 调用实例方法 Java 字节码的指令集包含操作码(OpCode)和操作数(Operand)。像invokevirtual这样的操作码需要一个2字节长度的操作数。 对上面案例中的程序代码，如果在更新类库后重新编译程序代码，然后我们再反编译字节码将看到如下结果： 12345678public void add(java.lang.String); Code: 0: aload_0 1: getfield #15; //Field admin:Lcom/nhn/user/UserAdmin; 4: aload_1 5: invokevirtual #23; //Method com/nhn/user/UserAdmin.addUser:(Ljava/lang/String;)Lcom/nhn/user/User; 8: pop 9: return 如上我们看到#23对应的方法变成了具有返回值类型”Lcom/nhn/user/User;”的方法。 在上面的反编译结果中，代码前面的数字是具有什么含义？ 它是一个一字节数字，也许正因此JVM执行的代码被称为“字节码”。像 aload_0, getfield 和 invokevirtual 都被表示为一个单字节数字。(aload_0 = 0x2a, getfiled = 0xb4, invokevirtual = 0xb6)。因此Java字节码表示的最大指令码为256。 像aload_0和aload_1这样的操作码不需要任何操作数，因此aload_0的下一个字节就是下一个指令的操作码。而像getfield和invokevirtual这样的操作码却需要一个2字节的操作数，因此第一个字节里的第二个指令getfield指令的一下指令是在第4个字节，其中跳过了2个字节。通过16进制编辑器查看字节码如下： 12a b4 00 0f 2b b6 00 17 57 b1 在Java字节码中，类实例表示为”L;”，而void表示为”V”，类似的其他类型也有各自的表示。下表列出了Java字节码中类型表示。 表1: Java字节码里的类型表示 Java 字节码 类型 描述 B byte 单字节 C char Unicode字符 D double 双精度浮点数 F float 单精度浮点数 I int 整型 J long 长整型 L 引用 classname类型的实例 S short 短整型 Z boolean 布尔类型 [ 引用 一维数组 表2: Java代码的字节码示例 java 代码 Java 字节码表示 double d[][][] [[[D Object mymethod(int i, double d, Thread t) mymethod(I,D,Ljava/lang/Thread;)Ljava/lang/Object; 在《Java虚拟机技术规范第二版》的4.3 描述符(Descriptors)章节中有关于此的详细描述，在第6章”Java虚拟机指令集”中介绍了更多不同的指令。 类文件格式在解释类文件格式之前，先看一个在Java Web应用中经常发生的问题。 现象在Tomcat环境里编写和运行JSP时，JSP文件未被执行，并伴随着如下错误： 12Servlet.service() for servlet jsp threw exception org.apache.jasper.JasperException: Unable to compile class for JSP Generated servlet error:The code of method _jspService(HttpServletRequest, HttpServletResponse) is exceeding the 65535 bytes limit" 问题分析对于不同的Web应用容器，上面的错误信息会有些微差异，但核心信息是一致的，即65535字节的限制。这个限制是JVM定义的，用于规定方法的定义不能大于65535个字节。 下面我将先介绍65535个的字节限制，然后详细说明为什么要有这个限制。 Java字节码中，”goto”和”jsr”指令分别表示分支和跳转。 12goto [branchbyte1] [branchbyte2]jsr [branchbyte1] [branchbyte2] 这两个操作指令都跟着一个2字节的操作数，而2个字节能表示的最大偏移量只能是65535。然而为了支持更大范围的分支，Java字节码又分别定义了”goto_w” 和 “jsr_w” 用于接收4个字节的分支偏移量。 12goto_w [branchbyte1] [branchbyte2] [branchbyte3] [branchbyte4]jsr_w [branchbyte1] [branchbyte2] [branchbyte3] [branchbyte4] 受这两个指令所赐，分支能表示的最大偏移远远超过了65535，这么说来java 方法就不会再有65535个字节的限制了。然而，由于Java 类文件的各种其他限制，java方法的定义仍然不能够超过65535个字节的限制。下面我们通过对类文件的解释来看看java方法不能超过65535字节的其他原因。 Java类文件的大体结构如下： 1234567891011121314151617ClassFile &#123; u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count];&#125; 上面的文件结构出自《Java虚拟机技术规范第二版》的4.1节”类文件结构”。 之前讲过的UserService.class文件的前16个字节的16进制表示如下： 1ca fe ba be 00 00 00 32 00 28 07 00 02 01 00 1b 我们通过对这一段符号的分析来了解一个类文件的具体格式。 magic: 类文件的前4个字节是一组魔数，是一个用于区分Java类文件的预定义值。如上所看到的，其值固定为0xCAFEBABE。也就是说一个文件的前4个字节如果是0xCAFABABE，就可以认为它是Java类文件。”CAFABABE”是与”JAVA”有关的一个有趣的魔数。 minor_version, major_version: 接下来的4个字节表示类的版本号。如上所示，0x00000032表示的类版本号为50.0。由JDK 1.6编译而来的类文件的版本号是50.0，而由JDK 1.5编译而来的版本号则是49.0。JVM必须保持向后兼容，即保持对比其版本低的版本的类文件的兼容。而如果在一个低版本的JVM中运行高版本的类文件，则会出现java.lang.UnsupportedClassVersionError的发生。 constant_pool_count, constant_pool[]: 紧接着版本号的是类的常量池信息。这里的信息在运行时会被分配到运行时常量池区域，后面会有对内存分配的介绍。在JVM加载类文件时，类的常量池里的信息会被分配到运行时常量池，而运行时常量池又包含在方法区内。上面UserService.class文件的constant_pool_count为0x0028，所以按照定义contant_pool数组将有(40-1)即39个元素值。 access_flags: 2字节的类的修饰符信息，表示类是否为public, private, abstract或者interface。 this_class, super_class: 分别表示保存在constant_pool数组中的当前类及父类信息的索引值。 interface_count, interfaces[]: interface_count为保存在constant_pool数组中的当前类实现的接口数的索引值，interfaces[]即表示当前类所实现的每个接口信息。 fields_count, fields[]: 类的字段数量及字段信息数组。字段信息包含字段名、类型、修饰符以及在constant_pool数组中的索引值。 methods_count, methods[]: 类的方法数量及方法信息数组。方法信息包括方法名、参数的类型及个数、返回值、修饰符、在constant_pool中的索引值、方法的可执行代码以及异常信息。 attributes_count, attributes[]: attribute_info有多种不同的属性，分别被field_info, method_into使用。 javap程序把class文件格式以可阅读的方式输出来。在对UserService.class文件使用”javap -verbose”命令分析时，输出内容如下： 12345678910111213141516171819202122232425262728293031Compiled from "UserService.java"public class com.nhn.service.UserService extends java.lang.Object SourceFile: "UserService.java" minor version: 0 major version: 50 Constant pool:const #1 = class #2; // com/nhn/service/UserServiceconst #2 = Asciz com/nhn/service/UserService;const #3 = class #4; // java/lang/Objectconst #4 = Asciz java/lang/Object;const #5 = Asciz admin;const #6 = Asciz Lcom/nhn/user/UserAdmin;;// … omitted - constant pool continued …&#123;// … omitted - method information …public void add(java.lang.String); Code: Stack=2, Locals=2, Args_size=2 0: aload_0 1: getfield #15; //Field admin:Lcom/nhn/user/UserAdmin; 4: aload_1 5: invokevirtual #23; //Method com/nhn/user/UserAdmin.addUser:(Ljava/lang/String;)Lcom/nhn/user/User; 8: pop 9: return LineNumberTable: line 14: 0 line 15: 9 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Lcom/nhn/service/UserService; 0 10 1 userName Ljava/lang/String; // … Omitted - Other method information …&#125; 由于篇幅原因，上面只抽取了部分输出结果。在全部的输出信息中，会为你展示包括常量池和每个方法内容等各种信息。 方法的65535个字节的限制受到了结构体method_info的影响。如上面”javap -verbose”的输出所示，结构体method_info包括代码(Code)、行号表(LineNumberTable)以及本地变量表(LocalVariableTable)。其中行号表、本地变量表以及代码里的异常表(exception_table)的总长度为一个固定2字节的值。因此方法的大小不能超过行号表、本地变量表、异常表的长度，即不能超过65535个字节。 尽管很多人抱怨方法的大小限制，JVM规范也声称将会对此大小进行扩充，然而到目前为止并没有明确的进展。因为JVM技术规范里定义要把几乎整个类文件的内容都加载到方法区，因此如果方法长度将会对程序的向后兼容带来极大的挑战。 对于一个由Java编译器错误而导致的错误的类文件将发生怎样的情况？如果是在网络传输或文件复制过程中，类文件被损坏又将发生什么？ 为了应对这些场景，Java类加载器的加载过程被设计为一个非常严谨的处理过程。JVM规范详细描述了这个过程。 注释 我们如何验证JVM成功执行了类文件的验证过程？如何验证不同的JVM实现是否符合JVM规范？为此，Oracle提供了专门的测试工具：TCK(Technology Compatibility Kit)。TCK通过执行大量的测试用例(包括大量通过不同方式生成的错误类文件)来验证JVM规范。只有通过TCK测试的JVM才能被称作是JVM。 类似TCK，还有一个JCP(Java Community Process; http://jcp.org)，用于验证新的Java技术规范。对于一个JCP，必须具有详细的文档，相关的实现以及提交给JSR(Java Specification Request)的TCK测试。如果用户想像JSR一样使用新的Java技术，那他必须先从RI提供者那里得到许可，或者自己直接实现它并对之进行TCK测试。 JVM 结构Java程序的执行过程如下图所示： 图1: Java代码执行过程 类加载器把Java字节码载入到运行时数据区，执行引擎负责Java字节码的执行。 类加载Java提供了动态加载的特性，只有在运行时第一次遇到类时才会去加载和链接，而非在编译时加载它。JVM的类加载器负责类的动态加载过程。Java类加载器的特点如下： 层次结构：Java的类加载器按是父子关系的层次结构组织的。Boostrap类加载器处于层次结构的顶层，是所有类加载器的父类。 委派模式：基于类加载器的层次组织结构，类加载器之间是可以进行委派的。当一个类需要被加载，会先去请求父加载器判断该类是否已经被加载。如果父类加器已加载了该类，那它就可以直接使用而无需再次加载。如果尚未加载，才需要当前类加载器来加载此类。 可见性限制：子类加载器可以从父类加载器中获取类，反之则不行。 不能卸载： 类加载器可以载入类却不能卸载它。但是可以通过删除类加载器的方式卸载类。 每个类加载器都有自己的空间，用于存储其加载的类信息。当类加载器需要加载一个类时，它通过FQCN)(Fully Quanlified Class Name: 全限定类名)的方式先在自己的存储空间中检测此类是否已存在。在JVM中，即便具有相同FQCN的类，如果出现在了两个不同的类加载器空间中，它们也会被认为是不同的。存在于不同的空间意味着类是由不同的加载器加载的。 下图解释了类加载器的委派模型： 图2: 类加载器的委派模型 当JVM请示类加载器加载一个类时，加载器总是按照从类加载器缓存、父类加载器以及自己加载器的顺序查找和加载类。也就是说加载器会先从缓存中判断此类是否已存在，如果不存在就请示父类加载器判断是否存在，如果直到Bootstrap类加载器都不存在该类，那么当前类加载器就会从文件系统中找到类文件进行加载。 Bootstrap加载器：Bootstrap加载器在运行JVM时创建，用于加载Java APIs，包括Object类。不像其他的类加载器由Java代码实现，Bootstrap加载器是由native代码实现的。 扩展加载器(Extension class loader)：扩展加载器用于加载除基本Java APIs以外扩展类。也用于加载各种安全扩展功能。 系统加载器(System class loader)：如果说Bootstrap和Extension加载器用于加载JVM运行时组件，那么系统加载器加载的则是应用程序相关的类。它会加载用户指定的CLASSPATH里的类。 用户自定义加载器：这个是由用户的程序代码创建的类加载器。 像Web应用服务器(WAS: Web Application Server)等框架通过使用用户自定义加载器使Web应用和企业级应用可以隔离开在各自的类加载空间独自运行。也就是说可以通过类加载器的委派模式来保证应用的独立性。不同的WAS在自定义类加载器时会有略微不同，但都不外乎使用加载器的层次结构原理。 如果一个类加载器发现了一个未加载的类，则该类的加载和链接过程如下图： 图3: 类加载步骤 每一步的具体描述如下： 加载(Loading): 从文件中获取类并载入到JVM内存空间。 验证(Verifying): 验证载入的类是否符合Java语言规范和JVM规范。在类加载流程的测试过程中，这一步是最为复杂且耗时最长的部分。大部分JVM TCK的测试用例都用于检测对于给定的错误的类文件是否能得到相应的验证错误信息。 准备(Preparing): 根据内存需求准备相应的数据结构，并分别描述出类中定义的字段、方法以及实现的接口信息。 解析(Resolving): 把类常量池中所有的符号引用转为直接引用。 初始化(Initializing): 为类的变量初始化合适的值。执行静态初始化域，并为静态字段初始化相应的值。 JVM规范定义了规则，但也允许在运行时灵活处理。 运行时数据区 图4: 运行时数据区结构 运行时数据区是JVM程序运行时在操作系统上分配的内存区域。运行时数据区又可细分为6个部分，即：为每个线程分别创建的PC寄存器、JVM栈、本地方法栈和被所有线程共用的数据堆、方法区和运行时常量池。 PC 寄存器：每个线程都会有一个PC(Program Counter)寄存器，并跟随线程的启动而创建。PC寄存器中存有将执行的JVM指令的地址。 JVM 栈：每个线程都有一个JVM栈，并跟随线程的启动而创建。其中存储的数据元素称为栈帧(Stack Frame)，JVM会把栈桢压入栈或从其中弹出。如果有任何异常，printStackTrace()方法输出的栈跟踪信息的每一行就都是一个栈帧信息。 图5: JVM栈结构 123- 栈帧：在JVM中一旦有方法执行，JVM就会为之创建一个栈帧，并把其添加到当前线程的JVM栈中。当方法运行结束时，栈帧也会相应的从JVM栈中移除。栈帧中存放着对本地变量数组、操作数栈以及属于当前运行方法的运行时常量池的引用。本地变量数组和操作数栈的大小在编译时就已确定，所以属在运行时属于方法的栈帧大小是固定的。- 本地变量数组：本地变量数组的索引从0开始计数，其位置存储着对方法所属类实例的引用。从索引位置1开始的保存的是传递给该方法的参数。其后存储的就是真正的方法的本地变量了。- 操作数栈：是方法的实际运行空间。每个方法变换操作数栈和本地变量数组，并把调用其它方法的结果从栈中弹或压入。在编译时，编译器就能计算出操作数栈所需的内存窨，因此操作数栈的大小在编译时也是确定的。 本地方法栈：为非Java编写的本地代程定义的栈空间。也就是说它基本上是用于通过JNI(Java Native Interface)方式调用和执行的C/C++代码。根据具体情况，C栈或C++栈将会被创建。 方法区：方法区是被所有线程共用的内存空间，在JVM启动时创建。它存储了运行时常量池、字段和方法信息、静态变量以及被JVM载入的所有类和接口的方法的字节码。不同的JVM提供者在实现方法区时会通常有不同的形式。在Oracle的Hotspot JVM里方法区被称为Permanent Area(永久区)或Permanent Generation(PermGen， 永久代)。JVM规范并对方法区的垃圾回收未做强制限定，因此对于JVM实现者来说，方法区的垃圾回收是可选操作。 运行时常量池：一个存储了类文件格式中的常量池表的内存空间。这部分空间虽然存在于方法区内，但却在JVM操作中扮演着举足轻重的角色，因此JVM规范单独把这一部分拿出来描述。除了每个类或接口中定义的常量，它还包含了所有对方法和字段的引用。因此当需要一个方法或字段时，JVM通过运行时常量池中的信息从内存空间中来查找其相应的实际地址。 数据堆：堆中存储着所有的类实例或对象，并且也是垃圾回收的目标场所。当涉及到JVM性能优化时，通常也会提及到数据堆空间的大小设置。JVM提供者可以决定划分堆空间或者不执行垃圾回收。 我们再回到先前讨论的反编译过的字节码中： 12345678public void add(java.lang.String); Code: 0: aload_0 1: getfield #15; //Field admin:Lcom/nhn/user/UserAdmin; 4: aload_1 5: invokevirtual #23; //Method com/nhn/user/UserAdmin.addUser:(Ljava/lang/String;)Lcom/nhn/user/User; 8: pop 9: return 比较一下上面反编译过的字节码和我们常见的基于x86架构的机器码的区别，虽然它们着相似的格式、操作码，但有一个明显的区别：Java字节码中没有寄存器名称、内存地址或者操作数的偏移位置。正如前所述，JVM使用的是栈模型，因此它并不需要x86架构中使用的寄存器。因为JVM自己管理内存，所以Java字节码中使用像15、23这样的索引值而非直接的内存地址。上面的15和23指向的是当前类的常量池中的位置(即UserService类)。也就是JVM为每个类创建一个常量池，并在常量池中存储真实对象的引用。 上面每行代码的解释如下： aload_0: 把本地变量数组的0号元素添加到操作数栈。本地变量数组的0号元素始终是 this ，即当前类实例对象的引用。 getfield #15: 在当前类的常量池中，把15号元素添加到操作数栈。上面的15号元素是UserAdmin admin字段。因为admin是一个类实例对象，因此其引用被加入到操作数栈。 aload_1: 把本地变量数组的1号元素添加到操作数栈中。本地变量数组中从第1个位置开始的元素存储着方法的参数。因此调用add()方法传入的String userName参数的引用将会添加到操作数栈。 invokevirtual #23: 调用当前类常量池中的第23号元素所引用的方法，同时被aload_1和getField #15操作添加到操作数栈中的引用信息将被传给方法调用。当方法调用完成后，其结果将被添加到操作数栈。 pop: 把通过invokevirtual方法调用得到的结果从操作数栈中弹出。在前面讲述中使用之前类库时没有返回值，也就不需要把结果从操作数栈中弹出了。 return: 方法完成。 下图将帮忙容易理解上面的文字解释： 图6: 从运行时数据区加载Java字节码示例 作为示例，上面的方法中本地变量数组中的值未曾有任何改变，所以上图中我们只看到操作数栈的变化。实际上，在大多数场景中本地变量数组也是被发生变化的。数据通过加载指令(aload, iload)和存储指令(astore, istore)在本地变量数组和操作数栈之间发生变化和移动。 在本章节我们对运行时常量池和JVM栈作了清晰的介绍。在JVM运行时，每个类的实例被分配到数据堆上，类信息(包括User, UserAdmin, UserService, String)等被存储在方法区。 执行引擎JVM通过类加载器把字节码载入运行时数据区是由执行引擎执行的。执行引擎以指令为单位读入Java字节码，就像CPU一个接一个的执行机器命令一样。每个字节码命令包含一字节的操作码和可选的操作数。执行引擎读取一个指令并执行相应的操作数，然后去读取并执行下一条指令。 尽管如此，Java字节码还是以一种可以理解的语言编写的，而不像那些机器直接执行的无法读懂的语言。所以JVM的执行引擎必须要把字节码转换为能被机器执行的语言指令。执行引擎有两种常用的方法来完成这一工作： 解释器(Interpreter)：读取、解释并逐一执行每一条字节码指令。因为解释器逐一解释和执行指令，因此它能够快速的解释每一个字节码，但对解释结果的执行速度较慢。所有的解释性语言都有类似的缺点。叫做字节码的语言人本质上就像一个解释器一样运行。 即时编译器(JIT: Just-In-Time)：即时编译器的引入用来弥补解释器的不足。执行引擎先以解释器的方式运行，然后在合适的时机，即时编译器把整修字节码编译成本地代码。然后执行引擎就不再解释方法的执行而是通过使用本地代码直接执行。执行本地代码较逐一解释执行每条指令在速度上有较大的提升，并且通过对本地代码的缓存，编译后的代码能具有更快的执行速度。 然而，即时编译器在编译代码时比逐一解释和执行每条指令更耗时，所以如果代码只会被执行一次，解释执行可能会具有更好的性能。所以JVM通过检查方法的执行频率，然后只对达到一定频率的方法才会做即时编译。 图7: Java编译器和即时编译器 JVM规范中并未强行约束执行引擎如何运行。所以不同的JVM在实现各种的执行引擎时通过各种技术手段并引入多种即时编译器来提升性能。 大部分的即时编译器运行流程如下图： 图8: 即时编译器 即时编译器先把字节码转为一种中间形式的表达式(IR: Itermediate Representation)，并对之进行优化，然后再把这种表达式转为本地代码。 Oracel Hotspot VM使用的即时编译器称为Hotspot编译器。之所以称为Hotspot是因为Hotspot Compiler会根据分析找到具有更高编译优先级的热点代码，然后所这些热点代码转为本地代码。如果一个被编译过的方法不再被频繁调用，也即不再是热点代码，Hotspot VM会把这些本地代码从缓存中删除并对其再次使用解释器模式执行。Hotspot VM有Server VM和Client VM之后，它们所使用的即时编译器也有所不同。 图9: Hotspot ClientVM 和Server VM Client VM和Server VM使用相同的运行时环境，如上图所示，它们的区别在于使用了不同的即时编译器。Server VM通过使用多种更为复杂的性能优化技术从而具有更好的表现。 IBM VM在他的IBM JDK6中引入了AOT(Ahead-Of-Time) 编译器技术。通过此种技术使得多个JVM之间能通过共享缓存分享已编译的本地代码。也就是说通过AOT编译器编译的代码能被其他JVM直接使用而无须再次编译。另外IBM JVM通过使用AOT编译器把代码预编译为JXE(Java Executable)文件格式从而提供了一种快速执行代码的方式。 大多数的Java性能提升都是通过优化执行引擎的性能实现的。像即时编译等各种优化技术被不断的引入，从而使得JVM性能得到了持续的优化和提升。老旧的JVM与最新的JVM之间最大的差异其实就来自于执行引擎的提升。 Hotspot编译器从Java 1.3开始便引入到了Oracle Hotspot VM中，而即时编译器从Android 2.2开始便被引入到了Android Dalvik VM中。 注释 像其他使用了像字节码一样的中间层语言的编译语言，VM在执行中间层字节码时也像JVM执行字节码一样，引入了即时编译等技术来提高VM的执行效率。像Microsoft的.Net语言，其运行时的VM叫做CLR(Common Language Runtime)。CLR执行一种类似字节码的语言CIL(Common Intermediate Language)。CLR同时提供了AOT编译器和即时编译器。因为如果使用C#或VB.NET编写程序，编译器会把源码编译成CIL，CLR通过使用即时编译器来执行CIL。CLR也有垃圾回收，并且和JVM一样也是以基于栈的方式运行。 结束语虽然使用Java并不需要了解Java是如何被创造出来的，并且很多程序员在并没有深入研究JVM的情况下依然开发出了很多伟大的应用和类库。但是如果能够了解JVM，就能对Java 有更多深入的提高，并在解决文中案例问题场景时有所帮助。 除了上文所述，JVM还有很多特性和技术细节。JVM技术规范为JVM开发者提供了灵活的规范空间，以帮忙开发者能使用多种技术手段创造出具有更好性能的JVM实现。另外虽然垃圾回收手术已被很多具有类似VM能力的编程语言作为常用的性能提升的新手段，但因有很多对其详细介绍的资料，所以这里没有深入讲解。]]></content>
      <categories>
        <category>JVM 学习</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux vi/vim 复制剪切粘贴以及常用命令]]></title>
    <url>%2Flinux-vim-command.html</url>
    <content type="text"><![CDATA[复制剪切粘贴撤销复制 复制一行则：yy 复制三行则：3yy，即从当前光标+下两行 复制当前光标所在的位置到行尾：y$ 复制当前光标所在的位置到行首：y^ 剪切： 剪切一行：dd 前切三行：3dd，即从当前行+下两行被剪切了 剪切当前行光标所在的位置到行尾：d$ 剪切当前行光标所在的位置到行首：d^ 粘贴： 用v选中文本之后可以按y进行复制，如果按d就表示剪切，之后按p进行粘贴。 撤销与恢复： u : 撤销上一个编辑操作 ctrl + r : 恢复，即回退前一个命令 U : 行撤销，撤销所有在前一个编辑行上的操作 屏幕翻页 Ctrl+u ：向上翻半屏 Ctrl+f ：向上翻一屏 Ctrl+d ： 向下翻半屏 Ctrl＋b ： 向下翻一屏 移动光标指令移动光标普遍使用的是方向键，考虑兼容问题，vi 定义太多的方向指令，下面只是一小小部分（常用的几个）： space ：光标右移一个字符 Backspace ：光标左移一个字符 Enter ：光标下移一行 nG ：光标移至第n行首 n+ ：光标下移n行 n- ：光标上移n行 n ：光标移至第n行尾0:光标移至当前行首: 光标移至当前行尾 插入删除指令常用插入，删除指令如下： i：在当前光标前插入，光标后文本向后移 a：从当前光标后插入，光标后文本后移 I：在光标所在行首插入（第一个非空白字符前） A：从光标所在行末插入 o：在光标所在行下面新增一行（并进入输入模式） O：在光标所在行上方新增一行（并进入输入模式） x：删除光标所在字符，等同于[Delete]功能键 X：删除光标前字符，相当与[Backspace] dd：删除光标所在的行 r：修改光标所在字符 R：替换当前字符及其后的字符，直到按 [ESC] s：从当前光标位置处开始，以输入的文本替代指定数目的字符 S：删除指定数目的行，并以所输入文本代替之 do：删至行首 d$：删至行尾 退出退出输入模式，先按一下[ESC]键（有时要多按两下），然后执行：:w!:w ——保存当前文件:wq —— 存盘退出(与指令 :x 功能相同):q —— 直接退出，如已修改会提示是否保存:q! ——不保存直接退出 转载： 极客geek：Linux—vi/vim复制剪切粘贴以及常用命令小结]]></content>
      <categories>
        <category>Linux 学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 基础命令]]></title>
    <url>%2Flinxu-command.html</url>
    <content type="text"><![CDATA[基本文件和目录操作日常使用 新建文件和目录 1234$ mkdir dir$ touch file$ &gt;file #编辑文件$ vim file 复制文件和目录 12$ cp -r dir1 dir2$ cp file1 file2 移动文件和目录 1$ mv dir1 Desktop/dir1 #注意以目录形式书写移动到的路径 重命名文件和目录 12$ mv file1 file2$ mv dir1 dir2 删除文件和目录 12$ rm file$ rm -r dir 查看文件和目录 123456$ cat file #适合比较短的文件$ less file #有快捷键，可以看比较长的文件$ file file1 #查看文件类型$ file dir1 #查看文件夹类型$ du -k file #以KB为单位显示文件大小$ du -m file #以MB为单位显示文件大小 通配符12$ echo *.txt$ echo a* 文件打包123456$ unzip x.zip #zip格式$ zip -r x.zip x/$ tar zxvf xxx.tar.gz #tar.gz格式$ tar zcvf xxx.tar.gz xxx/$ tar jxvf xxx.tar.bz2 #tar.bz2格式$ tar jcvf xxx.tar.bz2 xxx/ 重定向重定向输出和输入123cat file1&gt;file2 #标准输出重定向，将file1中的内容重定向到file2中。file2中的内容全被file1覆盖cat file2&gt;&gt;file2 #追加内容 箭头指向右，为左面的内容添加到右面的内容中echo zifu #打印字符 zifu 管道线12| #传递命令ps aux|grep firefox #展示进程并利用正则搜寻并打印包含firefox字符的进程 权限修改文件模式123ls -l file #查看文件权限ls -ld dirchmod +x a.sh #为a.sh增加执行权限 chmod 的使用可参考：http://blog.csdn.net/qqxx6661/article/details/70223975 什么是执行权限： ​ 比如有一个文件a.sh，它的权限是rw-，你是无法 使用”./a.sh” 来运行的，会提示你没有权限，只能用sh a.sh的方式运行。 加上x权限，chmod u+x a.sh 之后，就可以以 ./a.sh 来执行这个脚本了。 进程获取进程号12$ ps aux #查看所有进程，aux为参数$ ps aux|grep vim #通过管道符传递grep查找命令 后台执行1firefox &amp; #启动并打印该firefox应用的进程 kill进程1$ kill 25409 #kill进程 其他命令vim编辑器12345i #进入编辑模式ESC #推出编辑模式ZZ #保存并退出 :wq #保存并退出./a.sh #执行a.sh脚本文件 快捷键12ctrl + alt + T - 终端ctrl + win + D - 桌面 参考：StormXing：Linux基础命令]]></content>
      <categories>
        <category>Linux 学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解Java虚拟机读书笔记 - Java运行时数据区域]]></title>
    <url>%2Fjava-jvm-ram-ware.html</url>
    <content type="text"><![CDATA[运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存区域划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则依赖用户线程的启动和结束而建立和销毁。 程序计数器是一块较小的内存空间。它可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令。 由于Java多线程是通过线程轮流切换并分配处理器执行时间来实现的。所以每条线程都有自己独立的程序计数器，这样多线程程序运行时才不会错乱。所以也称其为线程“私有”内存。 需要注意的是； Java方法：如果当前线程正在执行的是Java方法。这个计数器记录的是正在执行的虚拟机字节码指令的地址。 Native方法：如果执行Native方法，则计数器记录为空。所以是唯一一个不存在OutOfMemoryError情况的内存区域。 虚拟机栈(重要) 线程私有，生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型，每个方法执行都会创建一个栈帧。 栈帧(Stack Frame)：用于存储局部变量表、操作数栈、动态链接、方法出口等信息。局部变量表存放编译时的8中基本数据类型、引用类型和returnAddress类型（指向一条字节码指令地址）。 该区域有两种异常： 线程请求栈深度大于虚拟机栈深度，抛出StackOverflowError异常。 动态拓展时无法申请到足够内存，抛出OutOfMemoryError异常。 如果对栈帧所包含的概念不太清楚可以参考： 栈帧、局部变量表、操作数栈 JAVA内存结构之运行时栈帧结构 本地方法栈与虚拟机栈功能类似，但虚拟机栈为Java方法服务，而本地方法栈为Native方法服务。也有StackOverflowError和 OutOfMemoryError异常。 Java堆(重要) Java堆（Java Heap）是Java虚拟机管理的最大内存区域，虚拟机启动时创建，所有线程共享该内存。该内存唯一目的就是存放对象实例，几乎所有的对象实例都在此分配内存。 Java堆是垃圾收集器管理的主要区域，也被成为“GC堆”。Java堆可被细分为：新生代和老年代。 新生代： 用来存放生命周期较短的对象，而新生代又使用复制算法进行GC ，又将其按照8:1:1的比例分为一块较大的Eden空间和2个较小的From Survivor和To Survivor空间。 老年代：用来存放生命周期较长的对象。 Java堆可以处于物理上不连续内存区域，但需要逻辑上连续。 如果堆中没有内存进行实例分配，并且堆也无法再拓展时（通过-Xmx和-Xms控制），将会抛出OutOfMemoryError异常。 Xmx Java堆最大内存，默认值为物理内存的1/4，当可用的Java堆内存大于70%时，JVM会将内存调整至-Xms所指定的初始值 Xms Java堆初始内存，默认值为物理内存的1/64，当可用的Java堆内存小于40%时，JVM会将内存调整至-Xmx所允许的最大值 方法区(重要) 方法区和Java堆一样，是各个线程的共享的区域，是系统分配的一个内存逻辑区域，它用于存放已被虚拟机加载的类信息(类的描述信息)、常量、静态变量、即时编译器编译后的代码等数据。在HotSpot里也叫“永生代”。但两者不能等同。如上图，字符串池在永生代中却在方法区外。 可以处于物理上不连续内存区域，但需要逻辑上连续。 又叫静态区，方法区包含所有的class和static变量以及常量。 该区域的垃圾收集比较少见，主要针对常量池的回收和类型的卸载。 方法区无法满足内存分配需求时，会抛出OutOfMemoryError异常。 运行时常量池 属于方法区的一部分。每个类私有 存放 Class 文件中的常量池（存放编译期生成的各种字面量和符号引用）；翻译出来的直接引用；运行期间产生的新的常量（譬如 String 类的 intern() 方法）。 常量池无法申请到内存， 会抛出OutOfMemoryError异常。 直接内存 直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范定义中的内存区域。但这部分区域被频繁使用并可能引起OutOfMemoryError异常。 NIO（New Input/Output）类中 ，可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 java 堆里面的 DirectByteBuffer 对象作为这块内存的引用进行操作，避免了在 Java 堆和 Native 堆中来回复制数据。 不受 Java 堆大小的限制，但受本机总内存的大小及处理器寻址空间的限制，会抛出 OutOfMemoryError异常。 参考： 汉森X：JVM学习01——内存区域及内存溢出 付小德：JVM学习心得 胖胖：https://www.zhihu.com/question/22739143 Emanue：Java中几种常量池的区分]]></content>
      <categories>
        <category>JVM 学习</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu:The System is running in low-graphics mode 解决办法]]></title>
    <url>%2Flinux-error.html</url>
    <content type="text"><![CDATA[系统：ubuntu 16.04 系统提示： 参考了： super：Ubuntu更新出现 The system is running in low-graphics mode解决 由于我是在安装一个 ubuntu 风格界面的时候出现的该问题。可能是分配给 ubuntu 的显存不够导致 首先当出现上面界面的时候： 按 ctrl + alt + f1 然后依次输入 12345//机器上之前有一个老版本，请按照下面这些命令来做。Nvidia和ATI/AMD显卡的命令都一样。 sudo add-apt-repository ppa:ubuntu-x-swat/x-updates sudo apt-get update sudo apt-get upgrade 提示： sudo apt-get upgrade 执行时间较长约十几二十分钟 最后再给大家 指一条路，因为博主在找解决办法的时候连续找了好几个好评答案。逐个尝试，但是试到一半问题就解决了。另附一个好评博客是另一种方式，不知道管用不管用，如果这种方式解决不了你的问题。不妨尝试 maimang1001：虚拟机安装Ubuntu 12.04 出现提示“Ubuntu is running in low-graphics mode?”]]></content>
      <categories>
        <category>Linux 学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo d部署时报GIT错误 Connection timed out]]></title>
    <url>%2Ftool-git-pushError.html</url>
    <content type="text"><![CDATA[报错信息： 解决办法在.ssh目录下新建一个名叫config的文本文件。但是要去掉txt扩展名。 config 文件中内容123456Host github.comUser 个人邮箱Hostname ssh.github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsaPort 443 此时再在 Git Bash 中运行$ ssh -T git@github.com。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMwareTools 安装过程中遇到的Bug(安装正在进行)]]></title>
    <url>%2Flinux-VMware.html</url>
    <content type="text"><![CDATA[自己在安装 VMware Tools 的时候遇到了一个很奇怪的问题，就是按照别人的教程虚拟机外部点击了安装 VMware Tools。可是 ubuntu 内部的磁盘却没有任何显示。切到外面的 VMware 上一看，安装正在执行。后来试了半天玄学改法都没用，按照网上找到的很多办法也是没有解决。 后来中大脑中猛地窜出一个想法。决定先关闭 ubuntu 然后再在外部进行配置环境。结果果然有用，所以总结出一个道理，如果要对 VMware 进行一些配置的时候，最好先将你的 ubuntu 关机。 首先。ubuntu 关机。然后 ISO 映像文件这样设置。 然后开机。 此时再点开驱动就会发现VMwareTools…tar.gz这个文件。 然后就可以进行安装啦。安装细节这里就不再赘述了 推荐一个本人在安装时参考的博客：VMware Tools （ubuntu系统）安装详细过程与使用]]></content>
      <categories>
        <category>Linux 学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware下Ubuntu16.04LTS.64位不能上网的问题]]></title>
    <url>%2Flinux-bug.html</url>
    <content type="text"><![CDATA[Win 下输入 services.msc 先开启VMware NAT Service后开启VMware DHCP Service。]]></content>
      <categories>
        <category>Linux 学习</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中transient关键字]]></title>
    <url>%2Fjava-keywords-transient.html</url>
    <content type="text"><![CDATA[转载自: 敏敏Alexia：Java transient关键字使用小记 transient 的作用及使用方法​ 我们都知道一个对象只要实现了Serilizable接口，这个对象就可以被序列化，java的这种序列化模式为开发者提供了很多便利，我们可以不必关系具体序列化的过程，只要这个类实现了Serilizable接口，这个类的所有属性和方法都会自动序列化。 ​ 然而在实际开发过程中，我们常常会遇到这样的问题，这个类的有些属性需要序列化，而其他属性不需要被序列化，打个比方，如果一个用户有一些敏感信息（如密码，银行卡号等），为了安全起见，不希望在网络操作（主要涉及到序列化操作，本地序列化缓存也适用）中被传输，这些信息对应的变量就可以加上transient关键字。换句话说，这个字段的生命周期仅存于调用者的内存中而不会写到磁盘里持久化。 ​ 总之，java 的transient关键字为我们提供了便利，你只需要实现Serilizable接口，将不需要序列化的属性前添加关键字transient，序列化对象的时候，这个属性就不会序列化到指定的目的地中。 示例code如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.io.Serializable;/** * @description 使用transient关键字不序列化某个变量 * 注意读取的时候，读取数据的顺序一定要和存放数据的顺序保持一致 * * @author Alexia * @date 2013-10-15 */public class TransientTest &#123; public static void main(String[] args) &#123; User user = new User(); user.setUsername("Alexia"); user.setPasswd("123456"); System.out.println("read before Serializable: "); System.out.println("username: " + user.getUsername()); System.err.println("password: " + user.getPasswd()); try &#123; ObjectOutputStream os = new ObjectOutputStream( new FileOutputStream("C:/user.txt")); os.writeObject(user); // 将User对象写进文件 os.flush(); os.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; ObjectInputStream is = new ObjectInputStream(new FileInputStream( "C:/user.txt")); user = (User) is.readObject(); // 从流中读取User的数据 is.close(); System.out.println("\nread after Serializable: "); System.out.println("username: " + user.getUsername()); System.err.println("password: " + user.getPasswd()); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class User implements Serializable &#123; private static final long serialVersionUID = 8294180014912103005L; private String username; private transient String passwd; //getter / setter&#125; 输出为： 1234567read before Serializable: username: Alexiapassword: 123456read after Serializable: username: Alexiapassword: null 密码字段为null，说明反序列化时根本没有从文件中获取到信息。 transient 使用小结 一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。 transient关键字只能修饰变量，而不能修饰方法和类。 局部变量是不能被transient关键字修饰的。 变量如果是用户自定义类变量，则该类需要实现Serializable接口。 被transient关键字修饰的变量不再能被序列化，一个静态变量不管是否被transient修饰，均不能被序列化。 第三点可能有些人很迷惑，因为发现在User类中的username字段前加上static关键字后，程序运行结果依然不变，即static类型的username也读出来为“Alexia”了，这不与第三点说的矛盾吗？实际上是这样的：第三点确实没错（一个静态变量不管是否被transient修饰，均不能被序列化），反序列化后类中static型变量username的值为当前JVM中对应static变量的值，这个值是JVM中的不是反序列化得出的，不相信？好吧，下面我来证明： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.io.Serializable;/** * @description 使用transient关键字不序列化某个变量 * 注意读取的时候，读取数据的顺序一定要和存放数据的顺序保持一致 * * @author Alexia * @date 2013-10-15 */public class TransientTest &#123; public static void main(String[] args) &#123; User user = new User(); user.setUsername("Alexia"); user.setPasswd("123456"); System.out.println("read before Serializable: "); System.out.println("username: " + user.getUsername()); System.err.println("password: " + user.getPasswd()); try &#123; ObjectOutputStream os = new ObjectOutputStream( new FileOutputStream("C:/user.txt")); os.writeObject(user); // 将User对象写进文件 os.flush(); os.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; // 在反序列化之前改变username的值 User.username = "jmwang"; ObjectInputStream is = new ObjectInputStream(new FileInputStream( "C:/user.txt")); user = (User) is.readObject(); // 从流中读取User的数据 is.close(); System.out.println("\nread after Serializable: "); System.out.println("username: " + user.getUsername()); System.err.println("password: " + user.getPasswd()); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class User implements Serializable &#123; private static final long serialVersionUID = 8294180014912103005L; public static String username; private transient String passwd; // getter / setter&#125; 运行结果为： 1234567read before Serializable: username: Alexiapassword: 123456read after Serializable: username: jmwangpassword: null 这说明反序列化后类中static型变量username的值为当前JVM中对应static变量的值，为修改后jmwang，而不是序列化时的值Alexia。 transient 使用细节——被transient关键字修饰的变量真的不能被序列化吗？思考下面的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import java.io.Externalizable;import java.io.File;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;import java.io.ObjectInput;import java.io.ObjectInputStream;import java.io.ObjectOutput;import java.io.ObjectOutputStream;/** * @descripiton Externalizable接口的使用 * * @author Alexia * @date 2013-10-15 * */public class ExternalizableTest implements Externalizable &#123; private transient String content = "是的，我将会被序列化，不管我是否被transient关键字修饰"; @Override public void writeExternal(ObjectOutput out) throws IOException &#123; out.writeObject(content); &#125; @Override public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException &#123; content = (String) in.readObject(); &#125; public static void main(String[] args) throws Exception &#123; ExternalizableTest et = new ExternalizableTest(); ObjectOutput out = new ObjectOutputStream(new FileOutputStream( new File("test"))); out.writeObject(et); ObjectInput in = new ObjectInputStream(new FileInputStream(new File( "test"))); et = (ExternalizableTest) in.readObject(); System.out.println(et.content); out.close(); in.close(); &#125;&#125; content变量会被序列化吗？好吧，我把答案都输出来了，是的，运行结果就是： 1是的，我将会被序列化，不管我是否被transient关键字修饰 这是为什么呢，不是说类的变量被transient关键字修饰以后将不能序列化了吗？ ​ 我们知道在Java中，对象的序列化可以通过实现两种接口来实现，若实现的是Serializable接口，则所有的序列化将会自动进行，若实现的是Externalizable接口，则没有任何东西可以自动序列化，需要在writeExternal方法中进行手工指定所要序列化的变量，这与是否被transient修饰无关。因此第二个例子输出的是变量content初始化的内容，而不是null。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的深拷贝与浅拷贝]]></title>
    <url>%2Fjava-keywords-copy.html</url>
    <content type="text"><![CDATA[转载自: Benson：Java如何复制对象 复制原始数据类型假如说你想复制一个简单变量。很简单： 12int apples = 5; int pears = apples; 不仅仅是int类型，其它七种原始数据类型(boolean,char,byte,short,float,double.long)同样适用于该类情况。 但是如果你复制的是一个对象，情况就有些复杂了。 假设说我是一个beginner，我会这样写： 12345678910111213141516171819202122232425class Student &#123; private int number; public int getNumber() &#123; return number; &#125; public void setNumber(int number) &#123; this.number = number; &#125; &#125;public class Test &#123; public static void main(String args[]) &#123; Student stu1 = new Student(); stu1.setNumber(12345); Student stu2 = stu1; System.out.println("学生1:" + stu1.getNumber()); System.out.println("学生2:" + stu2.getNumber()); &#125;&#125; 打印结果： 12学生1:12345学生2:12345 这里我们自定义了一个学生类，该类只有一个 number 字段。 我们新建了一个学生实例，然后将该值赋值给stu2实例。(Student stu2 = stu1;) 再看看打印结果，作为一个新手，拍了拍胸腹，对象复制不过如此， 难道真的是这样吗？ 我们试着改变 stu2 实例的 number 字段，再打印结果看看： 1234stu2.setNumber(54321); System.out.println("学生1:" + stu1.getNumber()); System.out.println("学生2:" + stu2.getNumber()); 打印结果: 12学生1:54321 学生2:54321 这就怪了，为什么改变学生2的学号，学生1的学号也发生了变化呢？ 原因出在(stu2 = stu1) 这一句。该语句的作用是将stu1的引用赋值给stu2， 这样，stu1和stu2指向内存堆中同一个对象。如图： 浅拷贝那么，怎样才能达到复制一个对象呢？ 是否记得万类之王Object。它有11个方法，有两个protected的方法，其中一个为clone方法。 该方法的签名是： protected native Object clone() throws CloneNotSupportedException; 因为每个类直接或间接的父类都是Object，因此它们都含有clone()方法，但是因为该方法是protected，所以都不能在类外进行访问。 要想对一个对象进行复制，就需要对clone方法覆盖。 一般步骤是（浅复制）： 被复制的类需要实现Clonenable接口（不实现的话在调用clone方法会抛出CloneNotSupportedException异常) 该接口为标记接口(不含任何方法) 覆盖clone()方法，访问修饰符设为public。方法中调用super.clone()方法得到需要的复制对象，（native为本地方法) 下面对上面那个方法进行改造： 12345678910111213141516171819202122232425262728293031323334353637383940class Student implements Cloneable&#123; private int number; public int getNumber() &#123; return number; &#125; public void setNumber(int number) &#123; this.number = number; &#125; @Override public Object clone() &#123; Student stu = null; try&#123; stu = (Student)super.clone(); &#125;catch(CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return stu; &#125;&#125;public class Test &#123; public static void main(String args[]) &#123; Student stu1 = new Student(); stu1.setNumber(12345); Student stu2 = (Student)stu1.clone(); System.out.println("学生1:" + stu1.getNumber()); System.out.println("学生2:" + stu2.getNumber()); stu2.setNumber(54321); System.out.println("学生1:" + stu1.getNumber()); System.out.println("学生2:" + stu2.getNumber()); &#125;&#125; 打印结果： 1234学生1:12345 学生2:12345 学生1:12345 学生2:54321 如果你还不相信这两个对象不是同一个对象，那么你可以看看这一句： 1System.out.println(stu1 == stu2); // false 上面的复制被称为浅复制(Shallow Copy)，还有一种稍微复杂的深度复制(deep copy)： 深拷贝我们在学生类里再加一个Address类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162class Address &#123; private String add; public String getAdd() &#123; return add; &#125; public void setAdd(String add) &#123; this.add = add; &#125; &#125;class Student implements Cloneable&#123; private int number; private Address addr; public Address getAddr() &#123; return addr; &#125; public void setAddr(Address addr) &#123; this.addr = addr; &#125; public int getNumber() &#123; return number; &#125; public void setNumber(int number) &#123; this.number = number; &#125; @Override public Object clone() &#123; Student stu = null; try&#123; stu = (Student)super.clone(); &#125;catch(CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return stu; &#125;&#125;public class Test &#123; public static void main(String args[]) &#123; Address addr = new Address(); addr.setAdd("杭州市"); Student stu1 = new Student(); stu1.setNumber(123); stu1.setAddr(addr); Student stu2 = (Student)stu1.clone(); System.out.println("学生1:" + stu1.getNumber() + ",地址:" + stu1.getAddr().getAdd()); System.out.println("学生2:" + stu2.getNumber() + ",地址:" + stu2.getAddr().getAdd()); &#125;&#125; 打印结果： 12学生1:123,地址:杭州市学生2:123,地址:杭州市 乍一看没什么问题，真的是这样吗？ 我们在main方法中试着改变addr实例的地址。 1234addr.setAdd("西湖区"); System.out.println("学生1:" + stu1.getNumber() + ",地址:" + stu1.getAddr().getAdd()); System.out.println("学生2:" + stu2.getNumber() + ",地址:" + stu2.getAddr().getAdd()); 打印结果： 1234学生1:123,地址:杭州市 学生2:123,地址:杭州市 学生1:123,地址:西湖区 学生2:123,地址:西湖区 这就奇怪了，怎么两个学生的地址都改变了？ 原因是浅复制只是复制了addr变量的引用，并没有真正的开辟另一块空间，将值复制后再将引用返回给新对象。 所以，为了达到真正的复制对象，而不是纯粹引用复制。我们需要将Address类可复制化，并且修改clone方法，完整代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package abc;class Address implements Cloneable &#123; private String add; public String getAdd() &#123; return add; &#125; public void setAdd(String add) &#123; this.add = add; &#125; @Override public Object clone() &#123; Address addr = null; try&#123; addr = (Address)super.clone(); &#125;catch(CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return addr; &#125;&#125;class Student implements Cloneable&#123; private int number; private Address addr; public Address getAddr() &#123; return addr; &#125; public void setAddr(Address addr) &#123; this.addr = addr; &#125; public int getNumber() &#123; return number; &#125; public void setNumber(int number) &#123; this.number = number; &#125; @Override public Object clone() &#123; Student stu = null; try&#123; stu = (Student)super.clone(); //浅复制 &#125;catch(CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; stu.addr = (Address)addr.clone(); //深度复制 return stu; &#125;&#125;public class Test &#123; public static void main(String args[]) &#123; Address addr = new Address(); addr.setAdd("杭州市"); Student stu1 = new Student(); stu1.setNumber(123); stu1.setAddr(addr); Student stu2 = (Student)stu1.clone(); System.out.println("学生1:" + stu1.getNumber() + ",地址:" + stu1.getAddr().getAdd()); System.out.println("学生2:" + stu2.getNumber() + ",地址:" + stu2.getAddr().getAdd()); addr.setAdd("西湖区"); System.out.println("学生1:" + stu1.getNumber() + ",地址:" + stu1.getAddr().getAdd()); System.out.println("学生2:" + stu2.getNumber() + ",地址:" + stu2.getAddr().getAdd()); &#125;&#125; 打印结果： 1234学生1:123,地址:杭州市 学生2:123,地址:杭州市 学生1:123,地址:西湖区 学生2:123,地址:杭州市 这样结果就符合我们的想法了。 最后我们可以看看API里其中一个实现了clone方法的类： java.util.Date： 12345678910111213/** * Return a copy of this object. */ public Object clone() &#123; Date d = null; try &#123; d = (Date)super.clone(); if (cdate != null) &#123; d.cdate = (BaseCalendar.Date) cdate.clone(); &#125; &#125; catch (CloneNotSupportedException e) &#123;&#125; // Won't happen return d; &#125; 该类其实也属于深度复制。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java对象的序列化和反序列化]]></title>
    <url>%2Fjava-keywords-serializa.html</url>
    <content type="text"><![CDATA[转载自: 孤傲苍狼：Java对象的序列化和反序列化 另附一遍不错文章： 红黑联盟：Java序列化Serializable详解 序列化和反序列化的概念 序列化：把对象转换为字节序列的过程称为对象的序列化。 反序列化：把字节序列恢复为对象的过程称为对象的反序列化。 对象的序列化主要有两种用途： 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中 在网络上传送对象的字节序列。 在很多应用中，需要对某些对象进行序列化，让它们离开内存空间，入住物理硬盘，以便长期保存。比如最常见的是Web服务器中的Session对象，当有 10万用户并发访问，就有可能出现10万个Session对象，内存可能吃不消，于是Web容器就会把一些seesion先序列化到硬盘中，等要用了，再把保存在硬盘中的对象还原到内存中。 当两个进程在进行远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。发送方需要把这个Java对象转换为字节序列，才能在网络上传送；接收方则需要把字节序列再恢复为Java对象。 JDK类库中的序列化API​ java.io.ObjectOutputStream代表对象输出流，它的writeObject(Object obj)方法可对参数指定的obj对象进行序列化，把得到的字节序列写到一个目标输出流中。 java.io.ObjectInputStream代表对象输入流，它的readObject()方法从一个源输入流中读取字节序列，再把它们反序列化为一个对象，并将其返回。 只有实现了 Serializable 和 Externalizable 接口的类的对象才能被序列化。Externalizable 接口继承自 Serializable 接口，实现 Externalizable 接口的类完全由自身来控制序列化的行为，而仅实现 Serializable 接口的类可以 采用默认的序列化方式 。 对象序列化包括如下步骤： 创建一个对象输出流，它可以包装一个其他类型的目标输出流，如文件输出流； 通过对象输出流的writeObject()方法写对象。 对象反序列化的步骤如下： 创建一个对象输入流，它可以包装一个其他类型的源输入流，如文件输入流； 通过对象输入流的readObject()方法读取对象。 对象序列化和反序列范例： 定义一个Person类，实现Serializable接口 123456789101112131415161718192021import java.io.Serializable;/** * &lt;p&gt;ClassName: Person&lt;p&gt; * &lt;p&gt;Description:测试对象序列化和反序列化&lt;p&gt; * @author xudp * @version 1.0 V * @createTime 2014-6-9 下午02:33:25 */public class Person implements Serializable &#123; /** * 序列化ID */ private static final long serialVersionUID = -5809782578272943999L; private int age; private String name; private String sex; // getter/setter&#125; 序列化和反序列化Person类对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.text.MessageFormat;/** * &lt;p&gt;ClassName: TestObjSerializeAndDeserialize&lt;p&gt; * &lt;p&gt;Description: 测试对象的序列化和反序列&lt;p&gt; * @author xudp * @version 1.0 V * @createTime 2014-6-9 下午03:17:25 */public class TestObjSerializeAndDeserialize &#123; public static void main(String[] args) throws Exception &#123; SerializePerson();//序列化Person对象 Person p = DeserializePerson();//反序列Perons对象 System.out.println(MessageFormat.format("name=&#123;0&#125;,age=&#123;1&#125;,sex=&#123;2&#125;", p.getName(), p.getAge(), p.getSex())); &#125; /** * MethodName: SerializePerson * Description: 序列化Person对象 * @author xudp * @throws FileNotFoundException * @throws IOException */ private static void SerializePerson() throws FileNotFoundException, IOException &#123; Person person = new Person(); person.setName("gacl"); person.setAge(25); person.setSex("男"); // ObjectOutputStream 对象输出流，将Person对象存储到E盘的Person.txt文件中，完成对Person对象的序列化操作 ObjectOutputStream oo = new ObjectOutputStream(new FileOutputStream( new File("E:/Person.txt"))); oo.writeObject(person); System.out.println("Person对象序列化成功！"); oo.close(); &#125; /** * MethodName: DeserializePerson * Description: 反序列Perons对象 * @author xudp * @return * @throws Exception * @throws IOException */ private static Person DeserializePerson() throws Exception, IOException &#123; ObjectInputStream ois = new ObjectInputStream(new FileInputStream( new File("E:/Person.txt"))); Person person = (Person) ois.readObject(); System.out.println("Person对象反序列化成功！"); return person; &#125;&#125; 代码运行结果如下： 序列化 Person 成功后在E盘生成了一个 Person.txt 文件，而反序列化 Person 是读取E盘的 Person.txt 后生成了一个 Person 对象 serialVersionUID的作用serialVersionUID：字面意思上是序列化的版本号，凡是实现 Serializable 接口的类都有一个表示序列化版本标识符的静态变量 1private static final long serialVersionUID 实现 Serializable 接口的类如果类中没有添加 serialVersionUID，那么就会出现如下的警告提示 用鼠标点击就会弹出生成serialVersionUID的对话框，如下图所示： serialVersionUID有两种生成方式： 采用这种方式生成的serialVersionUID是1L，例如： 1private static final long serialVersionUID = 1L; 采用这种方式生成的serialVersionUID是根据类名，接口名，方法和属性等来生成的，例如： 1private static final long serialVersionUID = 4603642343377807741L; 添加了之后就不会出现那个警告提示了，如下所示： 扯了那么多，那么 serialVersionUID (序列化版本号)到底有什么用呢，我们用如下的例子来说明一下 serialVersionUID 的作用，看下面的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.io.Serializable;public class TestSerialversionUID &#123; public static void main(String[] args) throws Exception &#123; SerializeCustomer();// 序列化Customer对象 Customer customer = DeserializeCustomer();// 反序列Customer对象 System.out.println(customer); &#125; /** * MethodName: SerializeCustomer * Description: 序列化Customer对象 * @author xudp * @throws FileNotFoundException * @throws IOException */ private static void SerializeCustomer() throws FileNotFoundException, IOException &#123; Customer customer = new Customer("gacl",25); // ObjectOutputStream 对象输出流 ObjectOutputStream oo = new ObjectOutputStream(new FileOutputStream( new File("E:/Customer.txt"))); oo.writeObject(customer); System.out.println("Customer对象序列化成功！"); oo.close(); &#125; /** * MethodName: DeserializeCustomer * Description: 反序列Customer对象 * @author xudp * @return * @throws Exception * @throws IOException */ private static Customer DeserializeCustomer() throws Exception, IOException &#123; ObjectInputStream ois = new ObjectInputStream(new FileInputStream( new File("E:/Customer.txt"))); Customer customer = (Customer) ois.readObject(); System.out.println("Customer对象反序列化成功！"); return customer; &#125;&#125;/** * &lt;p&gt;ClassName: Customer&lt;p&gt; * &lt;p&gt;Description: Customer实现了Serializable接口，可以被序列化&lt;p&gt; * @author xudp * @version 1.0 V * @createTime 2014-6-9 下午04:20:17 */class Customer implements Serializable &#123; //Customer类中没有定义serialVersionUID private String name; private int age; public Customer(String name, int age) &#123; this.name = name; this.age = age; &#125; /* * @MethodName toString * @Description 重写Object类的toString()方法 * @author xudp * @return string * @see java.lang.Object#toString() */ @Override public String toString() &#123; return "name=" + name + ", age=" + age; &#125;&#125; 运行结果： 序列化和反序列化都成功了。 下面我们修改一下Customer类，添加多一个sex属性，如下： 12345678910111213141516171819202122232425262728293031class Customer implements Serializable &#123; //Customer类中没有定义serialVersionUID private String name; private int age; //新添加的sex属性 private String sex; public Customer(String name, int age) &#123; this.name = name; this.age = age; &#125; public Customer(String name, int age,String sex) &#123; this.name = name; this.age = age; this.sex = sex; &#125; /* * @MethodName toString * @Description 重写Object类的toString()方法 * @author xudp * @return string * @see java.lang.Object#toString() */ @Override public String toString() &#123; return "name=" + name + ", age=" + age; &#125;&#125; 然后执行反序列操作，此时就会抛出如下的异常信息： 1234Exception in thread "main" java.io.InvalidClassException: Customer; local class incompatible: stream classdesc serialVersionUID = -88175599799432325, local class serialVersionUID = -5182532647273106745 ​ 意思就是说，文件流中的 class 和 classpath 中的 class，也就是修改过后的 class，不兼容了，处于安全机制考虑，程序抛出了错误，并且拒绝载入。那么如果我们真的有需求要在序列化后添加一个字段或者方法呢？应该怎么办？那就是自己去指定 serialVersionUID。在 TestSerialversionUID 例子中，没有指定 Customer 类的 serialVersionUID 的，那么java编译器会自动给这个class进行一个摘要算法，类似于指纹算法，只要这个文件 多一个空格，得到的 UID 就会截然不同的，可以保证在这么多类中，这个编号是唯一的。所以，添加了一个字段后，由于没有显指定 serialVersionUID，编译器又为我们生成了一个UID，当然和前面保存在文件中的那个不会一样了，于是就出现了2个序列化版本号不一致的错误。因此，只要我们自己指定了 serialVersionUID，就可以在序列化后，去添加一个字段，或者方法，而不会影响到后期的还原，还原后的对象照样可以使用，而且还多了方法或者属性可以用。 下面继续修改 Customer 类，给 Customer 指定一个 serialVersionUID，修改后的代码如下： 12345678910111213141516171819202122232425262728293031323334class Customer implements Serializable &#123; /** * Customer类中定义的serialVersionUID(序列化版本号) */ private static final long serialVersionUID = -5182532647273106745L; private String name; private int age; //新添加的sex属性 //private String sex; public Customer(String name, int age) &#123; this.name = name; this.age = age; &#125; /*public Customer(String name, int age,String sex) &#123; this.name = name; this.age = age; this.sex = sex; &#125;*/ /* * @MethodName toString * @Description 重写Object类的toString()方法 * @author xudp * @return string * @see java.lang.Object#toString() */ @Override public String toString() &#123; return "name=" + name + ", age=" + age; &#125;&#125; 重新执行序列化操作，将 Customer 对象序列化到本地硬盘的 Customer.txt 文件存储，然后修改 Customer 类，添加 sex 属性，修改后的 Customer 类代码如下： 12345678910111213141516171819202122232425262728293031323334class Customer implements Serializable &#123; /** * Customer类中定义的serialVersionUID(序列化版本号) */ private static final long serialVersionUID = -5182532647273106745L; private String name; private int age; //新添加的sex属性 private String sex; public Customer(String name, int age) &#123; this.name = name; this.age = age; &#125; public Customer(String name, int age,String sex) &#123; this.name = name; this.age = age; this.sex = sex; &#125; /* * @MethodName toString * @Description 重写Object类的toString()方法 * @author xudp * @return string * @see java.lang.Object#toString() */ @Override public String toString() &#123; return "name=" + name + ", age=" + age; &#125;&#125; 执行反序列操作，这次就可以反序列成功了，如下所示： serialVersionUID的取值​ serialVersionUID的取值是Java运行时环境根据类的内部细节自动生成的。如果对类的源代码作了修改，再重新编译，新生成的类文件的serialVersionUID的取值有可能也会发生变化。 类的serialVersionUID的默认值完全依赖于Java编译器的实现，对于同一个类，用不同的Java编译器编译，有可能会导致不同的 serialVersionUID，也有可能相同。为了提高serialVersionUID的独立性和确定性，强烈建议在一个可序列化类中显示的定义serialVersionUID，为它赋予明确的值。 显式地定义serialVersionUID有两种用途： 在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID 在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA 下如何创建多Moudle工程]]></title>
    <url>%2Ftool-idea-moudel.html</url>
    <content type="text"><![CDATA[先在项目要放置的目录创建文件夹，然后IDEA import 导入，然后再创建 Moudle]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Java中的hashcode方法]]></title>
    <url>%2Fjava-keywords-hashcode-0.html</url>
    <content type="text"><![CDATA[转载自: 海 子：浅谈Java中的hashcode方法 另外再推荐一个博客也不错： 冯立彬： [Java中hashCode的作用] ​ 哈希表这个数据结构想必大多数人都不陌生，而且在很多地方都会利用到hash表来提高查找效率。在Java的Object类中有一个方法: 1public native int hashCode(); ​ 根据这个方法的声明可知，该方法返回一个int类型的数值，并且是本地方法，因此在Object类中并没有给出具体的实现。 为何Object类需要这样一个方法？它有什么作用呢？今天我们就来具体探讨一下hashCode方法。 hashCode方法的作用​ 对于包含容器类型的程序设计语言来说，基本上都会涉及到hashCode。在Java中也一样，hashCode方法的主要作用是为了配合基于散列的集合一起正常运行，这样的散列集合包括HashSet、HashMap以及HashTable。 为什么这么说呢？考虑一种情况，当向集合中插入对象时，如何判别在集合中是否已经存在该对象了？（注意：集合中不允许重复的元素存在） 也许大多数人都会想到调用equals方法来逐个进行比较，这个方法确实可行。但是如果集合中已经存在一万条数据或者更多的数据，如果采用equals方法去逐一比较，效率必然是一个问题。此时hashCode方法的作用就体现出来了，当集合要添加新的对象时，先调用这个对象的hashCode方法，得到对应的hashcode值，实际上在HashMap的具体实现中会用一个table保存已经存进去的对象的hashcode值，如果table中没有该hashcode值，它就可以直接存进去，不用再进行任何比较了；如果存在该hashcode值， 就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就散列其它的地址，所以这里存在一个冲突解决的问题，这样一来实际调用equals方法的次数就大大降低了，说通俗一点：Java中的hashCode方法就是根据一定的规则将与对象相关的信息（比如对象的存储地址，对象的字段等）映射成一个数值，这个数值称作为散列值。下面这段代码是java.util.HashMap的中put方法的具体实现： 12345678910111213141516171819public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); int hash = hash(key.hashCode()); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null; &#125; ​ put方法是用来向HashMap中添加新的元素，从put方法的具体实现可知，会先调用hashCode方法得到该元素的hashCode值，然后查看table中是否存在该hashCode值，如果存在则调用equals方法重新确定是否存在该元素，如果存在，则更新value值，否则将新的元素添加到HashMap中。从这里可以看出，hashCode方法的存在是为了减少equals方法的调用次数，从而提高程序效率。 ​ 如果对于hash表这个数据结构的朋友不清楚，可以参考这几篇博文; http://www.cnblogs.com/jiewei915/archive/2010/08/09/1796042.html http://www.cnblogs.com/dolphin0520/archive/2012/09/28/2700000.html http://www.java3z.com/cwbwebhome/article/article8/83560.html?id=4649 ​ 有些朋友误以为默认情况下，hashCode返回的就是对象的存储地址，事实上这种看法是不全面的，确实有些JVM在实现时是直接返回对象的存储地址，但是大多时候并不是这样，只能说可能存储地址有一定关联。下面是HotSpot JVM中生成hash散列值的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445static inline intptr_t get_next_hash(Thread * Self, oop obj) &#123; intptr_t value = 0 ; if (hashCode == 0) &#123; // This form uses an unguarded global Park-Miller RNG, // so it's possible for two threads to race and generate the same RNG. // On MP system we'll have lots of RW access to a global, so the // mechanism induces lots of coherency traffic. value = os::random() ; &#125; else if (hashCode == 1) &#123; // This variation has the property of being stable (idempotent) // between STW operations. This can be useful in some of the 1-0 // synchronization schemes. intptr_t addrBits = intptr_t(obj) &gt;&gt; 3 ; value = addrBits ^ (addrBits &gt;&gt; 5) ^ GVars.stwRandom ; &#125; else if (hashCode == 2) &#123; value = 1 ; // for sensitivity testing &#125; else if (hashCode == 3) &#123; value = ++GVars.hcSequence ; &#125; else if (hashCode == 4) &#123; value = intptr_t(obj) ; &#125; else &#123; // Marsaglia's xor-shift scheme with thread-specific state // This is probably the best overall implementation -- we'll // likely make this the default in future releases. unsigned t = Self-&gt;_hashStateX ; t ^= (t &lt;&lt; 11) ; Self-&gt;_hashStateX = Self-&gt;_hashStateY ; Self-&gt;_hashStateY = Self-&gt;_hashStateZ ; Self-&gt;_hashStateZ = Self-&gt;_hashStateW ; unsigned v = Self-&gt;_hashStateW ; v = (v ^ (v &gt;&gt; 19)) ^ (t ^ (t &gt;&gt; 8)) ; Self-&gt;_hashStateW = v ; value = v ; &#125; value &amp;= markOopDesc::hash_mask; if (value == 0) value = 0xBAD ; assert (value != markOopDesc::no_hash, "invariant") ; TEVENT (hashCode: GENERATE) ; return value;&#125; (这里本人没看懂 ······) ​ 该实现位于hotspot/src/share/vm/runtime/synchronizer.cpp文件下。 因此有人会说，可以直接根据hashcode值判断两个对象是否相等吗？肯定是不可以的，因为不同的对象可能会生成相同的hashcode值。虽然不能根据hashcode值判断两个对象是否相等，但是可以直接根据hashcode值判断两个对象不等，如果两个对象的hashcode值不等，则必定是两个不同的对象。如果要判断两个对象是否真正相等，必须通过equals方法。 也就是说对于两个对象，如果调用equals方法得到的结果为true，则两个对象的hashcode值必定相等； 如果equals方法得到的结果为false，则两个对象的hashcode值不一定不同； 如果两个对象的hashcode值不等，则equals方法得到的结果必定为false； 如果两个对象的hashcode值相等，则equals方法得到的结果未知。 equals方法和hashCode方法​ 在有些情况下，程序设计者在设计一个类的时候为需要重写equals方法，比如String类，但是千万要注意，在重写equals方法的同时，必须重写hashCode方法。为什么这么说呢？ 下面看一个例子： 12345678910111213141516171819202122232425262728293031323334353637383940package com.cxh.test1; import java.util.HashMap;import java.util.HashSet;import java.util.Set; class People&#123; private String name; private int age; public People(String name,int age) &#123; this.name = name; this.age = age; &#125; public void setAge(int age)&#123; this.age = age; &#125; @Override public boolean equals(Object obj) &#123; // TODO Auto-generated method stub return this.name.equals(((People)obj).name) &amp;&amp; this.age== ((People)obj).age; &#125;&#125; public class Main &#123; public static void main(String[] args) &#123; People p1 = new People("Jack", 12); System.out.println(p1.hashCode()); HashMap&lt;People, Integer&gt; hashMap = new HashMap&lt;People, Integer&gt;(); hashMap.put(p1, 1); System.out.println(hashMap.get(new People("Jack", 12))); &#125;&#125; ​ 在这里我只重写了equals方法，也就说如果两个People对象，如果它的姓名和年龄相等，则认为是同一个人。 这段代码本来的意愿是想这段代码输出结果为“1”，但是事实上它输出的是“null”。为什么呢？原因就在于重写equals方法的同时忘记重写hashCode方法。 虽然通过重写equals方法使得逻辑上姓名和年龄相同的两个对象被判定为相等的对象（跟String类类似），但是要知道默认情况下，hashCode方法是将对象的存储地址进行映射。那么上述代码的输出结果为“null”就不足为奇了。原因很简单，p1指向的对象和System.out.println(hashMap.get(new People(&quot;Jack&quot;, 12)));这句中的new People(&quot;Jack&quot;, 12)生成的是两个对象，它们的存储地址肯定不同。下面是HashMap的get方法的具体实现： 12345678910111213public V get(Object key) &#123; if (key == null) return getForNullKey(); int hash = hash(key.hashCode()); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) return e.value; &#125; return null; &#125; ​ 所以在hashmap进行get操作时，因为得到的hashcdoe值不同（注意，上述代码也许在某些情况下会得到相同的hashcode值，不过这种概率比较小，因为虽然两个对象的存储地址不同也有可能得到相同的hashcode值），所以导致在get方法中for循环不会执行，直接返回null。 到这里是博主原来的内容。可是当我按照博主的思路去查看 hashMap 的 get 方法的源码时，发现已不再是原来的模样，如下： 然后我按照现在的源码梳理了一下思路。为什么需要重写 hashcode 方法还是一目了然 因此如果想上述代码输出结果为“1”，很简单，只需要重写hashCode方法，让equals方法和hashCode方法始终在逻辑上保持一致性。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.cxh.test1; import java.util.HashMap;import java.util.HashSet;import java.util.Set; class People&#123; private String name; private int age; public People(String name,int age) &#123; this.name = name; this.age = age; &#125; public void setAge(int age)&#123; this.age = age; &#125; @Override public int hashCode() &#123; // TODO Auto-generated method stub return name.hashCode()*37+age; &#125; @Override public boolean equals(Object obj) &#123; // TODO Auto-generated method stub return this.name.equals(((People)obj).name) &amp;&amp; this.age== ((People)obj).age; &#125;&#125; public class Main &#123; public static void main(String[] args) &#123; People p1 = new People("Jack", 12); System.out.println(p1.hashCode()); HashMap&lt;People, Integer&gt; hashMap = new HashMap&lt;People, Integer&gt;(); hashMap.put(p1, 1); System.out.println(hashMap.get(new People("Jack", 12))); &#125;&#125; ​ 这样一来的话，输出结果就为“1”了。 下面这段话摘自Effective Java一书： 在程序执行期间，只要equals方法的比较操作用到的信息没有被修改，那么对这同一个对象调用多次，hashCode方法必须始终如一地返回同一个整数。 如果两个对象根据equals方法比较是相等的，那么调用两个对象的hashCode方法必须返回相同的整数结果。 如果两个对象根据equals方法比较是不等的，则hashCode方法不一定得返回不同的整数。 对于第二条和第三条很好理解，但是第一条，很多时候就会忽略。在《Java编程思想》一书中的P495页也有同第一条类似的一段话： ​ “设计hashCode()时最重要的因素就是：无论何时，对同一个对象调用hashCode()都应该产生同样的值。如果在讲一个对象用put()添加进HashMap时产生一个hashCdoe值，而用get()取出时却产生了另一个hashCode值，那么就无法获取该对象了。所以如果你的hashCode方法依赖于对象中易变的数据，用户就要当心了，因为此数据发生变化时，hashCode()方法就会生成一个不同的散列码”。 下面举个例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.cxh.test1; import java.util.HashMap;import java.util.HashSet;import java.util.Set; class People&#123; private String name; private int age; public People(String name,int age) &#123; this.name = name; this.age = age; &#125; public void setAge(int age)&#123; this.age = age; &#125; @Override public int hashCode() &#123; // TODO Auto-generated method stub return name.hashCode()*37+age; &#125; @Override public boolean equals(Object obj) &#123; // TODO Auto-generated method stub return this.name.equals(((People)obj).name) &amp;&amp; this.age== ((People)obj).age; &#125;&#125; public class Main &#123; public static void main(String[] args) &#123; People p1 = new People("Jack", 12); System.out.println(p1.hashCode()); HashMap&lt;People, Integer&gt; hashMap = new HashMap&lt;People, Integer&gt;(); hashMap.put(p1, 1); p1.setAge(13); System.out.println(hashMap.get(p1)); &#125;&#125; ​ 这段代码输出的结果为“null”，想必其中的原因大家应该都清楚了。 因此，在设计hashCode方法和equals方法的时候，如果对象中的数据易变，则最好在equals方法和hashCode方法中不要依赖于该字段。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hash表]]></title>
    <url>%2Fjava-structure-hashtable.html</url>
    <content type="text"><![CDATA[转载自: 海 子：Hash表 Hash表Hash表也称散列表，也有直接译作哈希表，Hash表是一种特殊的数据结构，它同数组、链表以及二叉排序树等相比较有很明显的区别，它能够快速定位到想要查找的记录，而不是与表中存在的记录的关键字进行比较来进行查找。这个源于Hash表设计的特殊性，它采用了函数映射的思想将记录的存储位置与记录的关键字关联起来，从而能够很快速地进行查找。 Hash表的设计思想 对于一般的线性表，比如链表，如果要存储联系人信息： 张三 13980593357李四 15828662334王五 13409821234张帅 13890583472 ​ 那么可能会设计一个结构体包含姓名，手机号码这些信息，然后把4个联系人的信息存到一张链表中。当要查找”李四 15828662334“这条记录是否在这张链表中或者想要得到李四的手机号码时，可能会从链表的头结点开始遍历，依次将每个结点中的姓名同”李四“进行比较，直到查找成功或者失败为止，这种做法的时间复杂度为O(n)。即使采用二叉排序树进行存储，也最多为O(logn)。假设能够通过”李四“这个信息直接获取到该记录在表中的存储位置，就能省掉中间关键字比较的这个环节，复杂度直接降到O(1)。Hash表就能够达到这样的效果。 Hash表采用一个映射函数 f : key —&gt; address 将关键字映射到该记录在表中的存储位置，从而在想要查找该记录时，可以直接根据关键字和映射关系计算出该记录在表中的存储位置，通常情况下，这种映射关系称作为Hash函数，而通过Hash函数和关键字计算出来的存储位置(注意这里的存储位置只是表中的存储位置，并不是实际的物理地址)称作为Hash地址。比如上述例子中，假如联系人信息采用Hash表存储，则当想要找到“李四”的信息时，直接根据“李四”和Hash函数计算出Hash地址即可。下面讨论一下Hash表设计中的几个关键问题。 Hash函数的设计​ Hash函数设计的好坏直接影响到对Hash表的操作效率。下面举例说明： 假如对上述的联系人信息进行存储时，采用的Hash函数为：姓名的每个字的拼音开头大写字母的ASCII码之和。 因此address(张三)=ASCII(Z)+ASCII(S)=90+83=173; address(李四)=ASCII(L)+ASCII(S)=76+83=159; address(王五)=ASCII(W)+ASCII(W)=87+87=174; address(张帅)=ASCII(Z)+ASCII(S)=90+83=173; 假如只有这4个联系人信息需要进行存储，这个Hash函数设计的很糟糕。首先，它浪费了大量的存储空间，假如采用char型数组存储联系人信息的话，则至少需要开辟174*12字节的空间，空间利用率只有4/174，不到5%；另外，根据Hash函数计算结果之后，address(张三)和address(李四)具有相同的地址，这种现象称作冲突，对于174个存储空间中只需要存储4条记录就发生了冲突，这样的Hash函数设计是很不合理的。所以在构造Hash函数时应尽量考虑关键字的分布特点来设计函数使得Hash地址随机均匀地分布在整个地址空间当中。通常有以下几种构造Hash函数的方法： 直接定址法 ​ 取关键字或者关键字的某个线性函数为Hash地址，即address(key)=a*key+b;如知道学生的学号从2000开始，最大为4000，则可以将address(key)=key-2000作为Hash地址。 平方取中法 ​ 对关键字进行平方运算，然后取结果的中间几位作为Hash地址。假如有以下关键字序列{421，423，436}，平方之后的结果为{177241，178929，190096}，那么可以取{72，89，00}作为Hash地址。 折叠法 ​ 将关键字拆分成几部分，然后将这几部分组合在一起，以特定的方式进行转化形成Hash地址。假如知道图书的ISBN号为8903-241-23，可以将address(key)=89+03+24+12+3作为Hash地址。 除留取余法 ​ 如果知道Hash表的最大长度为m，可以取不大于m的最大质数p，然后对关键字进行取余运算，address(key)=key%p。在这里p的选取非常关键，p选择的好的话，能够最大程度地减少冲突，p一般取不大于m的最大质数。 Hash表大小的确定​ Hash表大小的确定也非常关键，如果Hash表的空间远远大于最后实际存储的记录个数，则造成了很大的空间浪费，如果选取小了的话，则容易造成冲突。在实际情况中，一般需要根据最终记录存储个数和关键字的分布特点来确定Hash表的大小。还有一种情况时可能事先不知道最终需要存储的记录个数，则需要动态维护Hash表的容量，此时可能需要重新计算Hash地址。 冲突的解决在上述例子中，发生了冲突现象，因此需要办法来解决，否则记录无法进行正确的存储。通常情况下有2种解决办法： 开放定址法 ​ 即当一个关键字和另一个关键字发生冲突时，使用某种探测技术在Hash表中形成一个探测序列，然后沿着这个探测序列依次查找下去，当碰到一个空的单元时，则插入其中。比较常用的探测方法有线性探测法，比如有一组关键字{12，13，25，23，38，34，6，84，91}，Hash表长为14，Hash函数为address(key)=key%11，当插入12，13，25时可以直接插入，而当插入23时，地址1被占用了，因此沿着地址1依次往下探测(探测步长可以根据情况而定)，直到探测到地址4，发现为空，则将23插入其中。 链地址法 ​ 采用数组和链表相结合的办法，将Hash地址相同的记录存储在一张线性表中，而每张表的表头的序号即为计算得到的Hash地址。如上述例子中，采用链地址法形成的Hash表存储表示为： 虽然能够采用一些办法去减少冲突，但是冲突是无法完全避免的。因此需要根据实际情况选取解决冲突的办法。 Hash表的平均查找长度​ Hash表的平均查找长度包括查找成功时的平均查找长度和查找失败时的平均查找长度。 查找成功时的平均查找长度=表中每个元素查找成功时的比较次数之和/表中元素个数； 查找不成功时的平均查找长度相当于在表中查找元素不成功时的平均比较次数，可以理解为向表中插入某个元素，该元素在每个位置都有可能，然后计算出在每个位置能够插入时需要比较的次数，再除以表长即为查找不成功时的平均查找长度。 下面举个例子： 有一组关键字{23，12，14，2，3，5}，表长为14，Hash函数为key%11，则关键字在表中的存储如下： 地址 0 1 2 3 4 5 6 7 8 9 10 11 12 13 关键字 23 12 14 2 3 5 比较次数 1 2 1 3 3 2 因此查找成功时的平均查找长度为(1+2+1+3+3+2)/6=11/6； 查找失败时的平均查找长度为(1+7+6+5+4+3+2+1+1+1+1+1+1+1)/14=38/14； 这里有一个概念装填因子=表中的记录数/哈希表的长度，如果装填因子越小，表明表中还有很多的空单元，则发生冲突的可能性越小；而装填因子越大，则发生冲突的可能性就越大，在查找时所耗费的时间就越多。因此，Hash表的平均查找长度和装填因子有关。有相关文献证明当装填因子在0.5左右的时候，Hash的性能能够达到最优。因此，一般情况下，装填因子取经验值0.5。 Hash表的优缺点​ Hash表存在的优点显而易见，能够在常数级的时间复杂度上进行查找，并且插入数据和删除数据比较容易。但是它也有某些缺点，比如不支持排序，一般比用线性表存储需要更多的空间，并且记录的关键字不能重复。 代码实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081/*Hash表，采用数组实现，2012.9.28*/ #include&lt;stdio.h&gt;#define DataType int#define M 30 typedef struct HashNode &#123; DataType data; //存储值 int isNull; //标志该位置是否已被填充 &#125;HashTable;HashTable hashTable[M];void initHashTable() //对hash表进行初始化 &#123; int i; for(i = 0; i&lt;M; i++) &#123; hashTable[i].isNull = 1; //初始状态为空 &#125;&#125;int getHashAddress(DataType key) //Hash函数 &#123; return key % 29; //Hash函数为 key%29 &#125;int insert(DataType key) //向hash表中插入元素 &#123; int address = getHashAddress(key); if(hashTable[address].isNull == 1) //没有发生冲突 &#123; hashTable[address].data = key; hashTable[address].isNull = 0; &#125; else //当发生冲突的时候 &#123; while(hashTable[address].isNull == 0 &amp;&amp; address&lt;M) &#123; address++; //采用线性探测法，步长为1 &#125; if(address == M) //Hash表发生溢出 return -1; hashTable[address].data = key; hashTable[address].isNull = 0; &#125; return 0;&#125;int find(DataType key) //进行查找 &#123; int address = getHashAddress(key); while( !(hashTable[address].isNull == 0 &amp;&amp; hashTable[address].data == key &amp;&amp; address&lt;M)) &#123; address++; &#125; if( address == M) address = -1; return address;&#125;int main(int argc, char *argv[])&#123; int key[]=&#123;123,456,7000,8,1,13,11,555,425,393,212,546,2,99,196&#125;; int i; initHashTable(); for(i = 0; i&lt;15; i++) &#123; insert(key[i]); &#125; for(i = 0; i&lt;15; i++) &#123; int address; address = find(key[i]); printf("%d %d\n", key[i],address); &#125; return 0;&#125;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Java中的equals和==]]></title>
    <url>%2Fjava-keywords-equals_%E2%80%98%3D%3D%E2%80%99.html</url>
    <content type="text"><![CDATA[转载自: 海 子：浅谈Java中的equals和== 另外还有一篇博文对 equals 方法的讲解也很透彻： 孤傲苍狼：java基础学习总结——equals方法 在初学Java时，可能会经常碰到下面的代码： 12345String str1 = new String("hello");String str2 = new String("hello"); System.out.println(str1==str2);System.out.println(str1.equals(str2)); ​ ​ 为什么第4行和第5行的输出结果不一样？==和equals方法之间的区别是什么？如果在初学Java的时候这个问题不弄清楚，就会导致自己在以后编写代码时出现一些低级的错误。今天就来一起了解一下==和equals方法的区别之处。 一.关系操作符“==”到底比较的是什么？ 下面这个句话是摘自《Java编程思想》一书中的原话： “关系操作符生成的是一个boolean结果，它们计算的是操作数的值之间的关系”。 这句话看似简单，理解起来还是需要细细体会的。说的简单点，==就是用来比较值是否相等。下面先看几个例子： 12345678910111213141516171819202122232425public class Main &#123; /** * @param args */ public static void main(String[] args) &#123; // TODO Auto-generated method stub int n=3; int m=3; System.out.println(n==m); String str = new String("hello"); String str1 = new String("hello"); String str2 = new String("hello"); System.out.println(str1==str2); str1 = str; str2 = str; System.out.println(str1==str2); &#125;&#125; ​ 输出结果为 true false true n==m结果为true，这个很容易理解，变量n和变量m存储的值都为3，肯定是相等的。而为什么str1和str2两次比较的结果不同？要理解这个其实只需要理解基本数据类型变量和非基本数据类型变量的区别。 在Java中游8种基本数据类型： 浮点型：float(4 byte), double(8 byte) 整型：byte(1 byte), short(2 byte), int(4 byte) , long(8 byte) 字符型: char(2 byte) 布尔型: boolean(JVM规范没有明确规定其所占的空间大小，仅规定其只能够取字面值”true”和”false”) 对于这8种基本数据类型的变量，变量直接存储的是“值”，因此在用关系操作符==来进行比较时，比较的就是 “值” 本身。要注意浮点型和整型都是有符号类型的，而char是无符号类型的（char类型取值范围为0~2^16-1). 也就是说比如： int n=3; int m=3; 变量n和变量m都是直接存储的”3”这个数值，所以用==比较的时候结果是true。 而对于非基本数据类型的变量，在一些书籍中称作为 引用类型的变量。比如上面的str1就是引用类型的变量，引用类型的变量存储的并不是 “值”本身，而是于其关联的对象在内存中的地址。比如下面这行代码： String str1; 这句话声明了一个引用类型的变量，此时它并没有和任何对象关联。 而 通过new String(“hello”)来产生一个对象（也称作为类String的一个实例），并将这个对象和str1进行绑定： str1= new String(“hello”); 那么str1指向了一个对象（很多地方也把str1称作为对象的引用），此时变量str1中存储的是它指向的对象在内存中的存储地址，并不是“值”本身，也就是说并不是直接存储的字符串”hello”。这里面的引用和C/C++中的指针很类似。 因此在用==对str1和str2进行第一次比较时，得到的结果是false。因此它们分别指向的是不同的对象，也就是说它们实际存储的内存地址不同。 而在第二次比较时，都让str1和str2指向了str指向的对象，那么得到的结果毫无疑问是true。 二.equals比较的又是什么？​ equals方法是基类Object中的方法，因此对于所有的继承于Object的类都会有该方法。为了更直观地理解equals方法的作用，直接看Object类中equals方法的实现。 该类的源码路径为：C:\Program Files\Java\jdk1.6.0_14的src.zip 的java.lang路径下的Object.java（视个人jdk安装路径而定）。 下面是Object类中equals方法的实现： ​ 很显然，在Object类中，equals方法是用来比较两个对象的引用是否相等，即是否指向同一个对象。 但是有些朋友又会有疑问了，为什么下面一段代码的输出结果是true？ 1234567891011121314public class Main &#123; /** * @param args */ public static void main(String[] args) &#123; // TODO Auto-generated method stub String str1 = new String("hello"); String str2 = new String("hello"); System.out.println(str1.equals(str2)); &#125;&#125; ​ 要知道究竟，可以看一下String类的equals方法的具体实现，同样在该路径下，String.java为String类的实现。 下面是String类中equals方法的具体实现： ​ 可以看出，String类对equals方法进行了重写，用来比较指向的字符串对象所存储的字符串是否相等。 其他的一些类诸如Double，Date，Integer等，都对equals方法进行了重写用来比较指向的对象所存储的内容是否相等。 总结来说： 对于 ==，如果作用于基本数据类型的变量，则直接比较其存储的 “值”是否相等； 如果作用于引用类型的变量，则比较的是所指向的对象的地址 对于 equals 方法，注意：equals 方法不能作用于基本数据类型的变量 如果没有对 equals 方法进行重写，则比较的是引用类型的变量所指向的对象的地址； 诸如 String、Date 等类对 equals 方法进行了重写的话，比较的是所指向的对象的内容。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Integer与int的种种比较你知道多少？]]></title>
    <url>%2Fjava-keywords-integer-int.html</url>
    <content type="text"><![CDATA[转载自: 残剑：Integer与int的种种比较你知道多少？ 如果面试官问 Integer 与 int 的区别：估计大多数人只会说道两点，Ingeter 是 int 的包装类，int 的初值为 0，Ingeter 的初值为 null。但是如果面试官再问一下Integer i = 1;int ii = 1; i==ii为 true 还是为 false? 估计就有一部分人答不出来了，如果再问一下其他的，估计更多的人会头脑一片混乱。所以我对它们进行了总结，希望对大家有帮助。 首先看代码： 123456789101112131415161718192021222324252627282930313233public class TestInteger &#123; /** * @param args */ public static void main(String[] args) &#123; int i = 128; Integer i2 = 128; Integer i3 = new Integer(128); //Integer会自动拆箱为int，所以为true System.out.println(i == i2); // true System.out.println(i == i3); // true //java在编译的时候,被翻译成-&gt; Integer i5 = Integer.valueOf(127); Integer i5 = 127; Integer i6 = 127; System.out.println(i5 == i6);//true Integer i5 = 128; Integer i6 = 128; System.out.println(i5 == i6);//false i5 = 127; Integer ii5 = new Integer(127); System.out.println(i5 == ii5); //false Integer i7 = new Integer(128); Integer i8 = new Integer(123); System.out.println(i7 == i8); //false &#125;&#125; 首先，11行和12行输出结果都为 true，因为 Integer 和 int 比都会自动拆箱（jdk1.5以上）。 17行的结果为 true，而21行则为 false，很多人都不懂为什么。其实 Java 在编译Integer i5 = 127的时候,被翻译成-&gt;Integer i5 = Integer.valueOf(127);所以关键就是看valueOf()函数了。只要看看valueOf()函数的源码就会明白了。JDK 源码的 valueOf 函数式这样的： 123456public static Integer valueOf(int i) &#123; assert IntegerCache.high &gt;= 127; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 看一下源码大家都会明白，对于 -128 到 127 之间的数，会进行缓存，Integer i5 = 127时，会将 127 进行缓存，下次再写Integer i6 = 127时，就会直接从缓存中取，就不会 new 了。所以17行的结果为 true，而21行为 false。 对于25行和29行，因为对象不一样，所以为 false。 我对于以上的情况总结如下： 无论如何，Integer与 new Integer不会相等。不会经历拆箱过程，i3 的引用指向堆，而 i 指向专门存放他的内存（常量池），他们的内存地址不一样，所以为 false 两个都是非 new 出来的 Integer，如果数在 -128 到 127 之间且数值想等，则是 true，否则为 false java在编译Integer i2 = 128的时候,被翻译成-&gt; Integer i2 = Integer.valueOf(128);而valueOf()函数会对 -128 到 127 之间的数进行缓存 两个都是new出来的，都为 false int 和 Integer(无论 new 否)比，如果数值相同，都为 true，因为会把 Integer 自动拆箱为 int 再去比]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中native关键字]]></title>
    <url>%2Fjava-keywords-native.html</url>
    <content type="text"><![CDATA[转载自： xwdreamer： java native方法及JNI实例 这里需要提醒大家，这里为了精简，不长篇幅。只截取了能解决本人所困惑的内容，如要查看全部内容还请移步作者博客 😆 概述今天在看java多线程编程的时候，发现Thread这个类中有多个native方法，以前从来没有见过这种方法，因此对于比较好奇，查阅了一些资料，现在整理一下，以作备忘。（这里本人是在 Object 的 hashCode 方法中看到的，早就听过，随来了解一下） 1public native int hashCode(); native关键字用法 native是与C++联合开发的时候用的！ 使用native关键字说明这个方法是原生函数，也就是这个方法是用C/C++语言实现的，并且被编译成了DLL，由java去调用。 这些函数的实现体在DLL中，JDK的源代码中并不包含，你应该是看不到的。对于不同的平台它们也是不同的。这也是java的底层机制，实际上java就是在不同的平台上调用不同的native方法实现对操作系统的访问的。总而言之： native 是用做java 和其他语言（如c++）进行协作时使用的，也就是native 后的函数的实现不是用java写的。 既然都不是java，那就别管它的源代码了，我们只需要知道这个方法已经被实现即可。 native的意思就是通知操作系统， 这个函数你必须给我实现，因为我要使用。 所以native关键字的函数都是操作系统实现的， java只能调用。 java是跨平台的语言，既然是跨了平台，所付出的代价就是牺牲一些对底层的控制，而java要实现对底层的控制，就需要一些其他语言的帮助，这个就是native的作用了 JNI简介native方法是通过java中的JNI实现的。JNI是Java Native Interface的 缩写。从Java 1.1开始，Java Native Interface (JNI)标准成为java平台的一部分，它允许Java代码和其他语言写的代码进行交互。*JNI一开始是为了本地已编译语言，尤其是C和C++而设计 的，但是它并不妨碍你使用其他语言，只要调用约定受支持就可以了。*使用java与本地已编译的代码交互，通常会丧失平台可移植性。但是，有些情况下这样做是可以接受的，甚至是必须的，比如，使用一些旧的库，与硬件、操作系统进行交互，或者为了提高程序的性能。JNI标准至少保证本地代码能工作在任何Java 虚拟机实现下。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + Redis]]></title>
    <url>%2Fframe-springboot-redis.html</url>
    <content type="text"><![CDATA[GitHub 地址访问GitHub下载最新源码：https://github.com/JYG0723/SpringBootAction/tree/master/chapter4 Spring Boot 中除了对常用的关系型数据库提供了优秀的自动化支持之外，对于很多 NoSQL 数据库一样提供了自动化配置的支持，包括：Redis，MongoDB,，Elasticsearch,，Solr 和 Cassandra。 Redis Redis官网 Redis中文社区 Pom1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; Spring Boot提供的数据访问框架 Spring Data Redis 基于Jedis，源码： 1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; properties12345678910111213141516171819# REDIS (RedisProperties)# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=localhost# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=8# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0 其中spring.redis.database的配置通常使用0即可，Redis 在配置的时候可以设置数据库数量，默认为16，可以理解为数据库的 schema 因为有好多人曾问我是如何看源码的，(其实我不怎么看，偶尔瞟两眼)，然后这里我就简单说一下我是怎么过流程的。 看源码： 这里对着属性，CTRL + B 到了这里，我们就进入了源码的世界。 同样可以根据 CTRL + B 定位到我们的 Libraries 中类所在的位置。我经常定位到这里会看看引入的包的目录结构，或者随便点点看看该包下的其他相关类。 再对着 RedisProperties 类 CTRL + B。我们可以看到很多处引用到该 RedisProperties 类的地方，其中有包引入import ···，还有专门为该类开启关于@ConfigurationProperties注解的支持，@EnableConfigurationProperties。还有实例的声明，还有作为构造参数的注入，还有静态变量的引用，还有配置文件对应关系的指定。等等，会有很多作用处被检索到。我们需要根据自己感兴趣的内容点进去一探究竟。这里很明显我们进入了 RedisAutoConfiguration(看名字都知道是你)。 一进来就看到了很多的条件。众多的@ConditionalOnClass摆在面前。我们怎么样能知道这些被要求存在于 classpath 的类是否存在于 classpath 呢？ 很简单， 我们按住 CTRL 鼠标移到该类上方，就可以看到这一行详细信息，这一段信息向我们交代了它所被包含在 maven 的哪个包中。在什么包下，还顺带告诉了我们他继承了 AbstractRedisConnection 类。是不是很直观很清晰。下面我们还看到一个引用了的@ConditionalOnClass的配置 bean。我们还用刚才的小套路，发现咦不对，乍一看。如果我们对一些包依赖不清晰的话，以为自己没有在 maven 中引入这个依赖呢，虽然我们确实没有显示的依赖。但是我们不妨在右侧的 MavenProjects 栏下的树结构找一找看看是否真的没有引入该依赖呢。就这样，我们找到了它。原来 springboot 打包好的 starter-data-redis 下的 redis.clients:jedis 依赖已经为我们传递依赖引入了该 commons 依赖。 到这里，我们就可以确认这个 springboot 为我们自动配置的配置类可以作用了。同时它下面的静态内部类 RedisConnectionConfiguration 也可以起作用了。是不是很有感觉呢 ~ 到这里我们先暂停存档，待我们进行到后面继续带大家探索。 测试访问我们引入了各种依赖，也为其配置了属性，也走了一遍流程。我们觉得他应该是可以运作了。可是到底是可以了吗？我们也不确定，那就来写一个测试用例吧。 12345678910111213141516171819@RunWith(SpringRunner.class)@SpringBootTestpublic class Chapter4ApplicationTests &#123; @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void contextLoads() &#123; &#125; @Test public void test() throws Exception &#123; stringRedisTemplate.opsForValue().set("aaa", "111"); Assert.assertEquals("111", stringRedisTemplate.opsForValue().get("aaa")); &#125;&#125; 通过上面这段极为简单的测试案例演示了如何通过自动配置的StringRedisTemplate对象进行 Redis 的读写操作，该对象从命名中就可注意到支持的是 String 类型 StringRedisTemplate extends RedisTemplate&lt;String, String&gt;。如果有使用过spring-data-redis的开发者一定熟悉RedisTemplate&lt;K, V&gt;接口，StringRedisTemplate就相当于RedisTemplate&lt;String, String&gt;的实现。 除了 String 类型，实战中我们还经常会在 Redis 中存储对象，这时候我们就会想是否可以使用类似RedisTemplate&lt;String, User&gt;来初始化并进行操作。但是 Spring Boot 并不支持直接使用，需要我们自己实现RedisSerializer&lt;T&gt;接口来对传入对象进行序列化和反序列化，下面我们通过一个实例来完成对象的读写操作。 Po1234567891011121314151617181920212223242526272829public class User implements Serializable &#123; // 手动声明较好 private static final long serialVersionUID = -1L; private String username; private String password; public User(String username, String password) &#123; this.username = username; this.password = password; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125;&#125; 实现对象的序列化接口1234567891011121314151617181920212223242526272829303132333435public class RedisObjectSerializer implements RedisSerializer&lt;Object&gt; &#123; private Converter&lt;Object, byte[]&gt; serializer = new SerializingConverter(); private Converter&lt;byte[], Object&gt; deserializer = new DeserializingConverter(); static final byte[] EMPTY_ARRAY = new byte[0]; @Override public Object deserialize(byte[] bytes) &#123; if (isEmpty(bytes)) &#123; return null; &#125; try &#123; return deserializer.convert(bytes); &#125; catch (Exception ex) &#123; throw new SerializationException("Cannot deserialize", ex); &#125; &#125; @Override public byte[] serialize(Object object) &#123; if (object == null) &#123; return EMPTY_ARRAY; &#125; try &#123; return serializer.convert(object); &#125; catch (Exception ex) &#123; return EMPTY_ARRAY; &#125; &#125; private boolean isEmpty(byte[] data) &#123; return (data == null || data.length == 0); &#125;&#125; 到这里你可能会问，为什么你要配置这个呢？这个不急，我们后面详谈。 针对 User 的 RedisTemplate 实例1234567891011121314151617@Configurationpublic class RedisConfig &#123; @Bean JedisConnectionFactory jedisConnectionFactory() &#123; // 方法名即对象名 return new JedisConnectionFactory(); &#125; @Bean public RedisTemplate&lt;String, User&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory &#123; RedisTemplate&lt;String, User&gt; template = new RedisTemplate&lt;String, User&gt;(); template.setConnectionFactory(jedisConnectionFactory()); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(new RedisObjectSerializer()); return template; &#125;&#125; 到了这里。你肯定会问我，为什么要这样配？这样配好杂乱，我怎么样就可以记住它呢？别忘了我们相当于配置了一个 RedisTemplate 类的子类哦。既然同时其子类，为什么我们不参考那个被自动配置的 StringRedisTemplate 类呢？ 所以我们继续我们的源码： 是不是瞬间明白了我们前面为什么要创建 RedisObjectSerializer 类来实现对象的序列化接口。因为我们在实现 RedisTemplate 类的时候需要引用我们关于对象的序列化方式。既然要创建的序列化接口，就要去参谋一下别人的序列化接口是怎么实现的不是吗？所以来到 StringRedisSerizlizer 类。 照猫画虎我们也来一遍自己的实现。就 ok 了 StringRedisTemplate 类的第一个构造函数看完了。我们再来看一看第二个构造函数有什么要求。 它要求我们配置一个 RedisConnectionFactory 接口式的连接工厂。这里我们不用 RedisConnectionFactory 默认的实现。既然我们是 Java 应用 Redis。那就用我们依赖中包含的传递依赖 jedis (即 Java 语言来操作 Redis) 中的 JedisConnectionFactory 类来创建该链接工厂。同时该 JedisConnectionFactory 类也是专门针对 Java 语言对该RedisConnectionFactory 接口的实现类。由于 SpringBoot 为我们自动配置 JedisConnectionFactory 的要求是 classpath 中不包含 RedisConnectionFactory 。这里我们只有显示声明。同时也可以在 pom 文件中将其排除出去。 除此之外。原来在 StringRedisTemplate 中显示调用的 afterproperties() 方法这里由于我们实现了自己的实例化接口也不再显示调用。该方法由 RedisTemplate 进行了扩展，为我们键值以及 hashkey，hashvalue 判断如果为空则引用默认的实例化方案。由于首先调用了其父类的该方法，我们不妨进去看看。一目了然，利用断言确保我们配置了连接工厂而已。 到这里我们的源码探索就结束了。是不是觉得看源码其实也没有那么难？ 测试12345678910111213141516171819202122232425@RunWith(SpringRunner.class)@SpringBootTestpublic class UserSerializableTest &#123; @Autowired private RedisTemplate&lt;String, User&gt; redisTemplate; @Test public void test() throws Exception &#123; //保存对象 User user = new User("ji", 20); redisTemplate.opsForValue().set(user.getUsername(), user); user = new User("yong", 30); redisTemplate.opsForValue().set(user.getUsername(), user); user = new User("guang", 40); redisTemplate.opsForValue().set(user.getUsername(), user); Assert.assertEquals(20, redisTemplate.opsForValue().get("ji").getAge().longValue()); Assert.assertEquals(30, redisTemplate.opsForValue().get("yong").getAge().longValue()); Assert.assertEquals(40, redisTemplate.opsForValue().get("guang").getAge().longValue()); &#125;&#125; 可以看到我们三个对象已经成功序列化并存储到 Redis 中啦。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + SpringSecurity]]></title>
    <url>%2Fframe-springboot-springsecurity.html</url>
    <content type="text"><![CDATA[在编写 web 应用时。我们经常会对页面进行一系列的安全控制。比如一些页面对没有权限的用户不开放访问权限，此时会令该请求的用户跳转到登录页面。当然要实现访问控制的方法方式多种多样，可以通过过滤器，拦截器，Aop，甚至集成框架来实现。（如：Apache Shiro、Spring Security） Cfiguration1234567891011@Configurationpublic class MvcConfig extends WebMvcConfigurerAdapter &#123; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/index").setViewName("index"); registry.addViewController("/").setViewName("index"); registry.addViewController("/hello").setViewName("hello"); registry.addViewController("/login").setViewName("login"); &#125;&#125; index1234567891011&lt;!DOCTYPE html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org" xmlns:sec="http://www.thymeleaf.org/thymeleaf-extras-springsecurity3"&gt;&lt;head&gt; &lt;title&gt;Spring Security Example&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome!&lt;/h1&gt;&lt;p&gt;Click &lt;a th:href="@&#123;/hello&#125;"&gt;here&lt;/a&gt; to see a greeting.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; home12345678910111213&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Hello World!&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1 th:inline="text"&gt;Hello [[$&#123;#httpServletRequest.remoteUser&#125;]]!&lt;/h1&gt; &lt;form th:action="@&#123;/logout&#125;" method="post"&gt; &lt;input type="submit" value="注销"/&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; login1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org" xmlns:sec="http://www.thymeleaf.org/thymeleaf-extras-springsecurity3"&gt;&lt;head&gt; &lt;title&gt;Spring Security Example &lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:if="$&#123;param.error&#125;"&gt; Invalid username and password.&lt;/div&gt;&lt;div th:if="$&#123;param.logout&#125;"&gt; You have been logged out.&lt;/div&gt;&lt;form th:action="@&#123;/login&#125;" method="post"&gt; &lt;div&gt;&lt;label&gt; User Name : &lt;input type="text" name="username"/&gt; &lt;/label&gt;&lt;/div&gt; &lt;div&gt;&lt;label&gt; Password: &lt;input type="password" name="password"/&gt; &lt;/label&gt;&lt;/div&gt; &lt;div&gt;&lt;input ty&lt;/body&gt;&lt;/html&gt;pe="submit" value="Sign In"/&gt;&lt;/div&gt;&lt;/form&gt; Configuration123456789101112131415161718192021222324252627@Configuration@EnableWebSecurity // 开启Spring Security的功能public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers("/", "home").permitAll() .anyRequest().authenticated() .and() .formLogin() .loginPage("/login") .permitAll() .and() .logout() .permitAll(); &#125; @Autowired public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception &#123; auth .inMemoryAuthentication() .withUser("user").password("passowrd").roles("USER"); &#125;&#125; 本WebSecurityConfig类与注释@EnableWebSecurity，使Spring Security的网络安全支持，并提供了Spring MVC的整合。它还扩展WebSecurityConfigurerAdapter和覆盖了一些方法来设置Web安全配置的一些细节。 该configure(HttpSecurity)方法定义哪些URL路径应该被保护，哪些不应该。具体来说，“/”和“/ home”路径被配置为不需要任何身份验证。所有其他路径必须经过身份验证。 当用户成功登录时，它们将被重定向到先前请求的需要身份验证的页面。有一个自定义的“/登录”页面指定loginPage()，并且每个人都被允许查看它。 对于该configureGlobal(AuthenticationManagerBuilder)方法，它设置了具有单个用户的内存中用户存储。该用户的用户名为“user”，密码为“password”，角色为“USER”。 可以看到，这个 Thymeleaf 模板只是提供一个表单来捕获一个用户名和密码，并将它们发布到“/ login”。根据配置，Spring Security 提供了一个拦截该请求并验证用户的过滤器。如果用户无法验证，该页面将重定向到“/ login？error”，页面显示相应的错误消息。成功注销后，应用程序将发送到“/ login？logout”，页面显示相应的成功消息。 到这里，我们启用应用，并访问http://localhost:8080/，可以正常访问。但是访问http://localhost:8080/hello的时候被重定向到了http://localhost:8080/login页面，因为没有登录，用户没有访问权限，通过输入用户名user和密码password进行登录后，跳转到了Hello World页面，再也通过访问http://localhost:8080/login?logout，就可以完成注销操作。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>SpringSecurity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 如何有效地避免OOM：善于利用软引用和弱引用]]></title>
    <url>%2Fjava-keywords-reference.html</url>
    <content type="text"><![CDATA[转载自： 海 子：Java 如何有效地避免OOM：善于利用软引用和弱引用 想必很多朋友对OOM（OutOfMemory）这个错误不会陌生，而当遇到这种错误如何有效地解决这个问题呢？今天我们就来说一下如何利用软引用和弱引用来有效地解决程序中出现的OOM问题。 一.了解 强引用、软引用、弱引用、虚引用的概念​ 在Java中，虽然不需要程序员手动去管理对象的生命周期，但是如果希望某些对象具备一定的生命周期的话（比如内存不足时JVM就会自动回收某些对象从而避免OutOfMemory的错误）就需要用到软引用和弱引用了。 从Java SE2开始，就提供了四种类型的引用：强引用、软引用、弱引用和虚引用。Java中提供这四种引用类型主要有两个目的：第一是可以让程序员通过代码的方式决定某些对象的生命周期；第二是有利于JVM进行垃圾回收。下面来阐述一下这四种类型引用的概念： 1.强引用（StrongReference） 强引用就是指在程序代码之中普遍存在的，比如下面这段代码中的object和str都是强引用： 12Object object = new Object();String str = "hello"; 只要某个对象有强引用与之关联，JVM必定不会回收这个对象，即使在内存不足的情况下，JVM宁愿抛出OutOfMemory错误也不会回收这种对象。比如下面这段代码： 12345678910public class Main &#123; public static void main(String[] args) &#123; new Main().fun1(); &#125; public void fun1() &#123; Object object = new Object(); Object[] objArr = new Object[1000]; &#125;&#125; ​ 当运行至Object[] objArr = new Object[1000];这句时，如果内存不足，JVM会抛出OOM错误也不会回收object指向的对象。不过要注意的是，当fun1运行完之后，object和objArr都已经不存在了，所以它们指向的对象都会被JVM回收。 如果想中断强引用和某个对象之间的关联，可以显示地将引用赋值为null，这样一来的话，JVM在合适的时间就会回收该对象。 比如Vector类的clear方法中就是通过将引用赋值为null来实现清理工作的： 123456789101112131415161718192021222324/** * Removes the element at the specified position in this Vector. * Shifts any subsequent elements to the left (subtracts one from their * indices). Returns the element that was removed from the Vector. * * @throws ArrayIndexOutOfBoundsException if the index is out of range * (&#123;@code index &lt; 0 || index &gt;= size()&#125;) * @param index the index of the element to be removed * @return element that was removed * @since 1.2 */public synchronized E remove(int index) &#123; modCount++; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); Object oldValue = elementData[index]; int numMoved = elementCount - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--elementCount] = null; // Let gc do its work return (E)oldValue;&#125; 2.软引用（SoftReference） 软引用是用来描述一些有用但并不是必需的对象，在Java中用java.lang.ref.SoftReference类来表示。对于软引用关联着的对象，只有在内存不足的时候JVM才会回收该对象。因此，这一点可以很好地用来解决OOM的问题，并且这个特性很适合用来实现缓存：比如网页缓存、图片缓存等。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被JVM回收，这个软引用就会被加入到与之关联的引用队列中。下面是一个使用示例： 123456789import java.lang.ref.SoftReference; public class Main &#123; public static void main(String[] args) &#123; SoftReference&lt;String&gt; sr = new SoftReference&lt;String&gt;(new String("hello")); System.out.println(sr.get()); &#125;&#125; 3.弱引用（WeakReference） 弱引用也是用来描述非必需对象的，当JVM进行垃圾回收时，无论内存是否充足，都会回收被弱引用关联的对象。在java中，用java.lang.ref.WeakReference类来表示。下面是使用示例： 123456789101112import java.lang.ref.WeakReference; public class Main &#123; public static void main(String[] args) &#123; WeakReference&lt;String&gt; sr = new WeakReference&lt;String&gt;(new String("hello")); System.out.println(sr.get()); System.gc(); //通知JVM的gc进行垃圾回收 System.out.println(sr.get()); &#125;&#125; 输出结果为： 12hellonull ​ 第二个输出结果是null，这说明只要JVM进行垃圾回收，被弱引用关联的对象必定会被回收掉。不过要注意的是，这里所说的被弱引用关联的对象是指只有弱引用与之关联，如果存在强引用同时与之关联，则进行垃圾回收时也不会回收该对象（软引用也是如此）。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被JVM回收，这个弱引用就会被加入到与之关联的引用队列中。 4.虚引用（PhantomReference）​ 虚引用和前面的软引用、弱引用不同，它并不影响对象的生命周期。在java中用java.lang.ref.PhantomReference类表示。如果一个对象与虚引用关联，则跟没有引用与之关联一样，在任何时候都可能被垃圾回收器回收。 要注意的是，虚引用必须和引用队列关联使用，当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会把这个虚引用加入到与之 关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 1234567891011import java.lang.ref.PhantomReference;import java.lang.ref.ReferenceQueue; public class Main &#123; public static void main(String[] args) &#123; ReferenceQueue&lt;String&gt; queue = new ReferenceQueue&lt;String&gt;(); PhantomReference&lt;String&gt; pr = new PhantomReference&lt;String&gt;(new String("hello"), queue); System.out.println(pr.get()); &#125;&#125; 二.进一步理解软引用和弱引用 对于强引用，我们平时在编写代码时经常会用到。而对于其他三种类型的引用，使用得最多的就是软引用和弱引用，这2种既有相似之处又有区别。它们都是用来描述非必需对象的，但是被软引用关联的对象只有在内存不足时才会被回收，而被弱引用关联的对象在JVM进行垃圾回收时总会被回收。 在SoftReference类中，有三个方法，两个构造方法和一个get方法（WekReference类似）： 两个构造方法： 123456789public SoftReference(T referent) &#123; super(referent); this.timestamp = clock;&#125; public SoftReference(T referent, ReferenceQueue&lt;? super T&gt; q) &#123; super(referent, q); this.timestamp = clock;&#125; ​ get方法用来获取与软引用关联的对象的引用，如果该对象被回收了，则返回null。 在使用软引用和弱引用的时候，我们可以显示地通过System.gc()来通知JVM进行垃圾回收，但是要注意的是，虽然发出了通知，JVM不一定会立刻执行，也就是说这句是无法确保此时JVM一定会进行垃圾回收的。 三.如何利用软引用和弱引用解决OOM问题 前面讲了关于软引用和弱引用相关的基础知识，那么到底如何利用它们来优化程序性能，从而避免OOM的问题呢？ 下面举个例子，假如有一个应用需要读取大量的本地图片，如果每次读取图片都从硬盘读取，则会严重影响性能，但是如果全部加载到内存当中，又有可能造成内存溢出，此时使用软引用可以解决这个问题。 设计思路是：用一个HashMap来保存图片的路径 和 相应图片对象关联的软引用之间的映射关系，在内存不足时，JVM会自动回收这些缓存图片对象所占用的空间，从而有效地避免了OOM的问题。在Android开发中对于大量图片下载会经常用到。 下面这段代码是摘自博客： http://blog.csdn.net/arui319/article/details/8489451 12345678910111213141516171819202122232425262728293031323334353637383940.....private Map&lt;String, SoftReference&lt;Bitmap&gt;&gt; imageCache = new HashMap&lt;String, SoftReference&lt;Bitmap&gt;&gt;();....public void addBitmapToCache(String path) &#123; // 强引用的Bitmap对象 Bitmap bitmap = BitmapFactory.decodeFile(path); // 软引用的Bitmap对象 SoftReference&lt;Bitmap&gt; softBitmap = new SoftReference&lt;Bitmap&gt;(bitmap); // 添加该对象到Map中使其缓存 imageCache.put(path, softBitmap); &#125; public Bitmap getBitmapByPath(String path) &#123; // 从缓存中取软引用的Bitmap对象 SoftReference&lt;Bitmap&gt; softBitmap = imageCache.get(path); // 判断是否存在软引用 if (softBitmap == null) &#123; return null; &#125; // 取出Bitmap对象，如果由于内存不足Bitmap被回收，将取得空 Bitmap bitmap = softBitmap.get(); return bitmap; &#125; ​ 当然这里我们把缓存替换策略交给了JVM去执行，这是一种比较简单的处理方法]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中权限修饰符protected]]></title>
    <url>%2Fjava-keywords-protected.html</url>
    <content type="text"><![CDATA[private：可以定义方法或者属性，定义的方法和属性不能被外部的类所访问（包括子类），只能本类中访问。 default：可以在本包中的任意地方访问。划分点在是否在同一个包下 protected：保护，不同包中的非子类不能访问。(能访问的成员包括同包下的类以及该类的任意子类。) public：公共的，都可以访问，不受任何限制。 protectedprotected表示被其修饰的成员可以被本类以及本类同包下的所有类，以及本类的所有子类所访问。 被本类的所有子类访问很容易让人产生误解，我在进行测试时，第一反应就是在不同包下创建一个子类，在main 方法中 new 一个父类对象, 试图通过该对象.成员变量名 来调用 protected 的成员变量, 然而, 结果是 —— 》编译出错 查了一下资料才知道，protected 所谓的可以被子类访问, 是指可以被子类通过继承的方式直接拿来使用, 也就是说, 我需要new一个子类对象, 再调用父类的变量就没问题了。当然也就意味着，不同包的情况下，即便是子类，还是不可以调用其父类的 protected 变量或方法。只能通过 new子类对象的方式调用从父类继承来的protected变量和方法。 只有和父类同包下的子类，或其他类才可以通过new 父类对象的方式访问其peotected修饰的变量或方法。 转载自： Keep Moving：java中权限修饰符protected的使用注意事项]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中volatile关键字详解]]></title>
    <url>%2Fjava-keywords-volatile.html</url>
    <content type="text"><![CDATA[转载自： 海 子： Java并发编程：volatile关键字解析 这里需要提醒大家，如果看该作者的博文时遇到了不解的地方看评论第15条。相信你的不解和我是一样的 :happy: ​ volatile这个关键字可能很多朋友都听说过，或许也都用过。在Java 5之前，它是一个备受争议的关键字，因为在程序中使用它往往会导致出人意料的结果。在Java 5之后，volatile关键字才得以重获生机。 ​ volatile关键字虽然从字面上理解起来比较简单，但是要用好不是一件容易的事情。由于volatile关键字是与Java的内存模型有关的，因此在讲述volatile关键之前，我们先来了解一下与内存模型相关的概念和知识，然后分析了volatile关键字的实现原理，最后给出了几个使用volatile关键字的场景。 一.内存模型的相关概念​ 大家都知道，计算机在执行程序时，每条指令都是在CPU中执行的，而执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了高速缓存。 ​ 也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码： 1i = i + 1; 当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。 这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。本文我们以多核CPU为例。 比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？ 可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。 最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。 也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。 为了解决缓存不一致性问题，通常来说有以下2种解决方法： 通过在总线加LOCK#锁的方式 通过缓存一致性协议 这2种方式都是硬件层面上提供的方式。 在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。 但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。 所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。 二.并发编程中的三个概念 在并发编程中，我们通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。我们先看具体看一下这三个概念： 1.原子性原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 一个很经典的例子就是银行账户转账问题： 比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。 试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。 所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。 同样地反映到并发编程中会出现什么结果呢？ 举个最简单的例子，大家想一下假如为一个32位的变量赋值过程不具备原子性的话，会发生什么后果？ 1i = 9; ​ 假若一个线程执行到这个语句时，我暂且假设为一个32位的变量赋值包括两个过程：为低16位赋值，为高16位赋值。 那么就可能发生一种情况：当将低16位数值写入之后，突然被中断，而此时又有一个线程去读取i的值，那么读取到的就是错误的数据。 2.可见性可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 举个简单的例子，看下面这段代码： 123456//线程1执行的代码int i = 0;i = 10; //线程2执行的代码j = i; 假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。 此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10. 这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。 3.有序性有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码： 1234int i = 0; boolean flag = false;i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。 下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。 比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。 但是要注意，虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，那么它靠什么保证的呢？再看下面一个例子： 1234int a = 10; //语句1int r = 2; //语句2a = a + 3; //语句3r = a*a; //语句4 这段代码有4个语句，那么可能的一个执行顺序是： 那么可不可能是这个执行顺序呢： 语句2 语句1 语句4 语句3 不可能，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。 虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？下面看一个例子： 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。 从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。 也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。 三.Java内存模型​ 在前面谈到了一些关于内存模型以及并发编程中可能会出现的一些问题。下面我们来看一下Java内存模型，研究一下Java内存模型为我们提供了哪些保证以及在java中提供了哪些方法和机制来让我们在进行多线程编程时能够保证程序执行的正确性。 在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。 Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。 举个简单的例子：在java中，执行下面这个语句： 1i = 10; 执行线程必须先在自己的工作线程中对变量i所在的缓存行进行赋值操作，然后再写入主存当中。而不是直接将数值10写入主存当中。 那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？ 1.原子性在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 上面一句话虽然看起来简单，但是理解起来并不是那么容易。看下面一个例子i： 请分析以下哪些操作是原子性操作： 1234x = 10; //语句1y = x; //语句2x++; //语句3x = x + 1; //语句4 咋一看，有些朋友可能会说上面的4个语句中的操作都是原子性操作。其实只有语句1是原子性操作，其他三个语句都不是原子性操作。 语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。 语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。 同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。 所以上面4个语句只有语句1的操作具备原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 2.可见性对于可见性，Java提供了volatile关键字来保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 3.有序性 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 另外，Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。 下面就来具体介绍下happens-before原则（先行发生原则）： 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作 锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作 volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行 对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始 这8条原则摘自《深入理解Java虚拟机》。 这8条规则中，前4条规则是比较重要的，后4条规则都是显而易见的。 下面我们来解释一下前4条规则： 对于程序次序规则来说，我的理解就是一段程序代码的执行在单个线程中看起来是有序的。注意，虽然这条规则中提到“书写在前面的操作先行发生于书写在后面的操作”，这个应该是程序看起来执行的顺序是按照代码顺序执行的，因为虚拟机可能会对程序代码进行指令重排序。虽然进行重排序，但是最终执行的结果是与程序顺序执行的结果一致的，它只会对不存在数据依赖性的指令进行重排序。因此，在单个线程中，程序执行看起来是有序执行的，这一点要注意理解。事实上，这个规则是用来保证程序在单线程中执行结果的正确性，但无法保证程序在多线程中执行的正确性。 第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。 第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。 第四条规则实际上就是体现happens-before原则具备传递性。 四.深入剖析volatile关键字在前面讲述了很多东西，其实都是为讲述volatile关键字作铺垫，那么接下来我们就进入主题。 1.volatile关键字的两层语义一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义： 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。 禁止进行指令重排序。 先看一段代码，假如线程1先执行，线程2后执行： 12345678//线程1boolean stop = false;while(!stop)&#123; doSomething();&#125; //线程2stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是用volatile修饰之后就变得不一样了： 第一：使用volatile关键字会强制将修改的值立即写入主存； 第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）； 第三：由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。 那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。 那么线程1读取到的就是最新的正确的值。 2.volatile保证原子性吗？从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？ 下面看一个例子： 1234567891011121314151617181920212223public class Test &#123; public volatile int inc = 0; public void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 大家想一下这段程序的输出结果是多少？也许有些朋友认为是10000。但是事实上运行它会发现每次运行结果都不一致，都是一个小于10000的数字。 可能有的朋友就会有疑问，不对啊，上面是对变量inc进行自增操作，由于volatile保证了可见性，那么在每个线程中对inc自增完之后，在其他线程中都能看到修改后的值啊，所以有10个线程分别进行了1000次操作，那么最终inc的值应该是1000*10=10000。 这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。 在前面已经提到过，自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现： 假如某个时刻变量inc的值为10， 线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了； 然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。 然后线程1接着进行加1操作，由于已经读取了inc的值，注意此时在线程1的工作内存中inc的值仍然为10，所以线程1对inc进行加1操作后inc的值为11，然后将11写入工作内存，最后写入主存。 那么两个线程分别进行了一次自增操作后，inc只增加了1。 解释到这里，可能有朋友会有疑问，不对啊，前面不是保证一个变量在修改volatile变量时，会让缓存行无效吗？然后其他线程去读就会读到新的值，对，这个没错。这个就是上面的happens-before规则中的volatile变量规则，但是要注意，线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。 根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。 把上面的代码改成以下任何一种都可以达到效果： 采用synchronized： 1234567891011121314151617181920212223public class Test &#123; public int inc = 0; public synchronized void increase() &#123; inc++; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用Lock： 1234567891011121314151617181920212223242526272829public class Test &#123; public int inc = 0; Lock lock = new ReentrantLock(); public void increase() &#123; lock.lock(); try &#123; inc++; &#125; finally&#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 采用AtomicInteger： 1234567891011121314151617181920212223public class Test &#123; public AtomicInteger inc = new AtomicInteger(); public void increase() &#123; inc.getAndIncrement(); &#125; public static void main(String[] args) &#123; final Test test = new Test(); for(int i=0;i&lt;10;i++)&#123; new Thread()&#123; public void run() &#123; for(int j=0;j&lt;1000;j++) test.increase(); &#125;; &#125;.start(); &#125; while(Thread.activeCount()&gt;1) //保证前面的线程都执行完 Thread.yield(); System.out.println(test.inc); &#125;&#125; 在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。 3.volatile能保证有序性吗？在前面提到volatile关键字能禁止指令重排序，所以volatile能在一定程度上保证有序性。 volatile关键字禁止指令重排序有两层意思： 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行； 在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行。 可能上面说的比较绕，举个简单的例子： 12345678//x、y为非volatile变量//flag为volatile变量 x = 2; //语句1y = 0; //语句2flag = true; //语句3x = 4; //语句4y = -1; //语句5 由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。 并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。 那么我们回到前面举的一个例子： 123456789//线程1:context = loadContext(); //语句1inited = true; //语句2 //线程2:while(!inited )&#123; sleep()&#125;doSomethingwithconfig(context); 前面举这个例子的时候，提到有可能语句2会在语句1之前执行，那么久可能导致context还没被初始化，而线程2中就使用未初始化的context去进行操作，导致程序出错。 这里如果用volatile关键字对inited变量进行修饰，就不会出现这种问题了，因为当执行到语句2时，必定能保证context已经初始化完毕。 4.volatile的原理和实现机制前面讲述了源于volatile关键字的一些使用，下面我们来探讨一下volatile到底如何保证可见性和禁止指令重排序的。 下面这段话摘自《深入理解Java虚拟机》： “观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令” lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； 它会强制将对缓存的修改操作立即写入主存； 如果是写操作，它会导致其他CPU中对应的缓存行无效。 五.使用volatile关键字的场景synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件： 对变量的写操作不依赖于当前值 该变量没有包含在具有其他变量的不变式中 实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。 事实上，我的理解就是上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。 下面列举几个Java中使用volatile的几个场景。 1. 状态标记量123456789volatile boolean flag = false; while(!flag)&#123; doSomething();&#125; public void setFlag() &#123; flag = true;&#125; 12345678910volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context); 2. Double Check1234567891011121314151617class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; 至于为何需要这么写请参考： Java 中的双重检查（Double-Check） 单例模式与双重检测]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Aop的注解]]></title>
    <url>%2Fframe-spring-aop-annoation.html</url>
    <content type="text"><![CDATA[AopAop 为 Aspect Oriented Programming 的缩写，即面向切面编程。通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。他通过对已有程序定一个切入点，然后在其前后切入不同的执行内容。比如常见的有：打开数据库连接/关闭数据库连接、打开事务/关闭事务、记录日志等。基于AOP不会破坏原来程序逻辑，因此它可以很好的对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。 注解 @Aspect(切面):把当前类标识为一个切面类供容器读取 @Before:标识一个前置增强方法,，相当于BeforeAdvice @After:不管是抛出异常或者正常退出都会执行 @AfterThrowing:异常抛出增强，相当于ThrowsAdvice @AfterReturning:后置增强，相当于AfterReturningAdvice，方法正常退出时执行 @Around:环绕增强，相当于MethodInterceptor @DeclareParents:引介增强，相当于IntroductionInterceptor @Pointcut(切点):切面类中负责增强的方法，在实际操作中，实际负责增强的方法叫切入点。常与execution表达式一起用 JoinPoint(连接点):类里面的被增强的方法 @Order:一个 web 应用会配置多个切面，所以这时就有了先后顺序。@Order(value = )注解中的值越小优先级越高。执行顺序是这样的： 在@Before中优先执行@Order(5)的内容，再执行@Order(10)的内容 在@After和@AfterReturning中优先执行@Order(10)的内容，再执行@Order(5)的内容 execution 切点函数语法为： execution( 方法修饰符(可选) 返回类型 方法名 参数 异常模式(可选) ) execution(public * nuc.jyg.chapter9.controller.UserController.*(..)) 参数部分允许使用通配符： * 匹配任意字符，但只能匹配一个元素`(*)`` `..匹配任意字符，可以匹配任意多个元素，表示类时，必须和*联合使用。+必须跟在类名后面，如User+，表示类本身和继承或扩展指定类的所有类 所以以上表达式可以解析为： 名称 意义 方法修饰符 public 返回类型 *匹配任意数量字符，表示返回类型不限 方法名 nuc.jyg.chapter9.controller.UserController.*表示匹配UserController类下的所有方法 参数 (..)表示匹配任意数量和类型的输入参数 异常模式 不限 更多示例： void aop(String,int) 匹配目标类任意修饰符方法、返回void、方法名aop、带有一个String和一个int型参数的方法 public void aop(*) 匹配目标类public修饰、返回void、方法名aop、带有一个任意类型参数的方法 public String *o*(..) 匹配目标类public修饰、返回String类型、方法名中带有一个o字符、带有任意数量任意类型参数的方法 public void *o*(String,..) 匹配目标类public修饰、返回void、方法名中带有一个o字符、带有任意数量任意类型参数，但第一个参数必须有且为String型的方法 也可以指定类： public void nuc.jyg.chapter9.controller.UserController.*(..) 匹配UserController的public修饰、返回void、不限方法名、带有任意数量任意类型参数的方法 public void void nuc.jyg.chapter9.controller.*Controller.*(..) 匹配以Controller结尾的类中public修饰、返回void、不限方法名、带有任意数量任意类型参数的方法 指定包： public void nuc.jyg.chapter9.controller.*.aop(..) 匹配nuc.jyg.chapter9.controller包下所有类中public修饰、返回void、方法名aop、带有任意数量任意类型参数的方法 public void nuc.jyg..*.aop(..) 匹配nuc.jyg.包下和所有子包中的类中public修饰、返回void、方法名aop、带有任意数量任意类型参数的方法 更多切点函数除了execution()，Spring 中还支持其他多个函数，这里列出名称和简单介绍，以方便根据需要进行更详细的查询 annotation() 表示标注了指定注解的目标类方法 例如@annotation(org.springframework.transaction.annotation.Transactional) 表示标注了@Transactional的方法 args() 通过目标类方法的参数类型指定切点 例如args(String)表示有且仅有一个String型参数的方法 @args() 通过目标类参数的对象类型是否标注了指定注解指定切点 如@args(org.springframework.stereotype.Service)表示有且仅有一个标注了@Service的类参数的方法 within() 通过类名指定切点 如with(nuc.jyg.chapter9.controller.UserController)表示UserController的所有方法 target() 通过类名指定，同时包含所有子类 如target(nuc.jyg.chapter9.controller.UserController)且ManController extends UserController，则两个类的所有方法都匹配 @within() 匹配标注了指定注解的类及其所有子类 如@within(org.springframework.web.bind.annotation)给UserController加上@RestController标注，则UserController和ManController 的所有方法都匹配 @target() 所有标注了指定注解的类 如@target(org.springframework.stereotype.Service)表示所有标注了@Service的类的所有方法 this() 大部分时候和target()相同，区别是this是在运行时生成代理类后，才判断代理类与指定的对象类型是否匹配 逻辑运算符表达式可由多个切点函数通过逻辑运算组成 &amp;&amp;与操作，求交集，也可以写成and 例如execution(* aop(..)) &amp;&amp; target(User)表示User及其子类的aop方法 ||或操作，求并集，也可以写成or 例如execution(* aop(..)) || args(String)表示名称为aop的方法或者有一个String型参数的方法 !非操作，求反集，也可以写成not 例如execution(* aop(..)) and !args(String)表示名称为aop的方法但是不能是只有一个String型参数的方法]]></content>
      <categories>
        <category>Spring 学习</category>
      </categories>
      <tags>
        <tag>Spring,Aop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 之 小项目大思想]]></title>
    <url>%2Fframe-springboot-ProjectNotes.html</url>
    <content type="text"><![CDATA[Github地址：访问GitHub下载最新源码：https://github.com/JYG0723/SpringBootAction/tree/master/chapter9 简介：其实就是自己总结的一些套路。然后揉到了一起，其中包含 Spring 的 Aop 思想，GlobalExecptionHandle，ResultFul Api以及单元测试MockMvc的使用。 AopController12345678910111213141516171819202122232425262728293031323334353637383940@RestController@RequestMapping(value = "/user")public class UserController &#123; // 创建线程安全的Map static Map&lt;Integer, User&gt; users = Collections.synchronizedMap(new HashMap&lt;Integer, User&gt;()); @GetMapping(value = "/") public Result&lt;List&lt;User&gt;&gt; getUserList() &#123; List&lt;User&gt; userList = new ArrayList&lt;User&gt;(users.values()); return ResultUtil.success(userList); &#125; @GetMapping(value = "/&#123;id&#125;") public Result&lt;User&gt; getUser(@PathVariable Integer id) &#123; return ResultUtil.success(users.get(id)); &#125; @PostMapping(value = "/") public Result&lt;User&gt; saveUser(@Valid User user, BindingResult bindingResult) throws Exception&#123; if (bindingResult.hasErrors()) &#123; return ResultUtil.error(ResultEnum.UNKONW_ERROR.getCode(), bindingResult.getFieldError().getDefaultMessage()); &#125; return ResultUtil.success(users.put(user.getId(), user)); &#125; @PutMapping(value = "/&#123;id&#125;") public Result&lt;User&gt; updateUser(@PathVariable Integer id, @ModelAttribute User user) &#123; User u = new User(); u.setUsername(user.getUsername()); u.setPassword(user.getPassword()); return ResultUtil.success(users.put(id, u)); &#125; @DeleteMapping(value = "/&#123;id&#125;") public Result&lt;User&gt; removeUser(@PathVariable Integer id) &#123; return ResultUtil.success(users.remove(id)); &#125;&#125; 这里我使用了一个 Map 集合来模拟数据库操作。 Utils123456789101112131415161718192021public class ResultUtil &#123; public static Result success(Object object) &#123; Result result = new Result(); result.setCode(ResultEnum.SUCCESS.getCode()); result.setMsg(ResultEnum.SUCCESS.getMsg()); result.setData(object); return result; &#125; public static Result success() &#123; return success(null); &#125; public static Result error(Integer code, String msg) &#123; Result result = new Result(); result.setCode(code); result.setMsg(msg); return result; &#125;&#125; Dto12345678910111213@Data@NoArgsConstructorpublic class Result&lt;T&gt; implements Serializable &#123; /** 状态码. */ private Integer code; /** 提示信息 */ private String msg; /** 具体内容 */ private T data;&#125; 在写 Result 架构式的 http 请求时，想了一下想结合一下 Spring 的 aop 思想，在 Controller 层的访问前后用日志记录一下，方法的调用以及请求的响应情况。因为这是在生产环境中必然要做到的，时刻监听记录后台的请求情况。所以： Aspect1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Aspect@Componentpublic class HttpAspect &#123; private final static Logger logger = LoggerFactory.getLogger(HttpAspect.class); @Pointcut("execution(public * nuc.jyg.chapter9.controller.UserController.*(..))") public void log() &#123; &#125; @Before(value = "log()") public void doBefore(JoinPoint joinPoint) &#123; // request ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); // url logger.info("url=&#123;&#125;", request.getRequestURL()); // Request method logger.info("method=&#123;&#125;", request.getMethod()); // ip logger.info("ip=&#123;&#125;", request.getRemoteAddr()); // Class Method logger.info("class_method=&#123;&#125;", joinPoint.getSignature().getDeclaringTypeName() + "." + joinPoint .getSignature().getName()); // Args logger.info("args=&#123;&#125;", joinPoint.getArgs()); &#125; @After(value = "log()") public void doAfter() &#123; &#125; /** * returning. 返回结果绑定到的参数 */ @AfterReturning(returning = "object", pointcut = "log()") public void doAfterReturning(Object object) &#123; logger.info("response=&#123;&#125;", object.toString()); &#125;&#125; 注意： SpringBoot 工程中并不需要同 Spring 中一样使用@EnableAspectJAutoProx注解来启用。可以查看关于AOP的默认配置属性： 1234# AOPspring.aop.auto=true # Add @EnableAspectJAutoProxy.spring.aop.proxy-target-class=false # Whether subclass-based (CGLIB) proxies are to be created (true) asopposed to standard Java interface-based proxies (false). 当需要使用 CGLIB 来实现 AOP 的时候，需要配置spring.aop.proxy-target-class=true，不然默认使用的是标准 Java 的实现。 这样我们简单的 aop 思想揉合就完成了。很简单 GlobalExceptionHandle1234567891011121314151617@ControllerAdvicepublic class ExceptionHandle &#123; private static final Logger logger = LoggerFactory.getLogger(ExceptionHandle.class); @ExceptionHandler(value = Exception.class) @ResponseBody public Result handle(Exception e) &#123; if (e instanceof UserException) &#123; UserException userException = (UserException) e; return ResultUtil.error(userException.getCode(), userException.getMessage()); &#125; else &#123; logger.error(" [系统异常] &#123;&#125; ", e); return ResultUtil.error(ResultEnum.UNKONW_ERROR.getCode(), e.getMessage()); &#125; &#125;&#125; 首先通过@ControllerAdvice设置全局异常处理类，而因为默认的异常只接受msg，并且因为统一接口的原因，我们返回给前台的结果也应该是格式统一的，成功与失败各对应一种，所以这里我们定义了自定义的异常类UserException。 UserException12345678910@Datapublic class UserException extends RuntimeException &#123; private Integer code; public UserException(ResultEnum resultEnum) &#123; super(resultEnum.getMsg()); this.code = resultEnum.getCode(); &#125;&#125; 注意： Spring 只会对你抛出的是RuntimeException才会进行回滚。如果抛出的是Exception是不会进行回滚的。所以这里我们选择继承的是RuntimeException而不是Exception。 我们为其添加了code属性。然而紧接着新的问题也就出现了，我们后台 Service 层处理业务逻辑的时候，面对 Controller 传过来的部分数据需要进行验证已经逻辑判断，这时就会出现因参数或逻辑出现各种各样的异常： Service123456789101112131415@Servicepublic class UserService &#123; public void saveUser(Integer id) throws Exception &#123; User user = new User(); String username = user.getUsername(); String password = user.getPassword(); if ("".equals(username) || username == null) &#123; throw new UserException(ResultEnum.USERNAME_ILLEGALITY); &#125; else if ("".equals(password) || password == null) &#123; throw new UserException(ResultEnum.PASSWORD_ILLEGALITY); &#125; &#125;&#125; 用户名为空：ResultEnum.USERNAME_ILLEGALITY 密码为空：ResultEnum.PASSWORD_ILLEGALITY 而面对不同的异常我们也一定应该有其对应的异常状态码来与之对应，并且日后出现异常之后，我们通过log也能快速的定位，排查异常。 所以对应Result 的两个code，message属性，我们定义成了枚举统一管理。这样日后维护管理起来才会更方便 1234567891011121314151617181920212223public enum ResultEnum &#123; UNKONW_ERROR(-1, "未知错误"), SUCCESS(0, "成功"), USERNAME_ILLEGALITY(100, "用户名非法"), PASSWORD_ILLEGALITY(101, "密码非法"); private int code; private String msg; ResultEnum(int code, String mas) &#123; &#125; public int getCode() &#123; return code; &#125; public String getMsg() &#123; return msg; &#125;&#125; 枚举的使用都是直接用它的构造方法来创建。不必重新 Set 单元测试Controller12345678910111213@AutoConfigureMockMvcpublic class UserControllerTest extends Chapter9ApplicationTests&#123; private MockMvc mockMvc; @Test public void getUserList() throws Exception &#123; mockMvc.perform(MockMvcRequestBuilders.get("/user/")) .andExpect(MockMvcResultMatchers.status().isOk()) .andExpect(MockMvcResultMatchers.content().string("user")); // 示例错误信息 &#125;&#125; Service1234567891011121314151617public class UserServiceTest extends Chapter9ApplicationTests &#123; @Autowired UserService userService; @Test public void saveUser() throws Exception &#123; User user = new User(); user.setUsername("张三"); user.setPassword("zhangsan"); Integer userId = userService.saveUser(user); // service 层利用断言判断检测方法 Assert.assertEquals(new Integer(2), userId); &#125;&#125;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Aop</tag>
        <tag>Project</tag>
        <tag>MockMvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot 中的表单验证]]></title>
    <url>%2Fframe-springboot-data-binding.html</url>
    <content type="text"><![CDATA[Po1234567891011@Data@AllArgsConstructorpublic class User &#123; private long id; private String username; private String password; @Min(value = 18,message = "年龄太小") private int age;&#125; Controller12345678910111213@Controllerpublic class DataBindingController &#123; @PostMapping(value = "/&#123;id&#125;") @ResponseBody public User userAdd(@Valid User user, BindingResult bindingResult) &#123; if (bindingResult.hasErrors()) &#123; System.out.println(bindingResult.getFieldError().getDefaultMessage()); return null; &#125; return user; &#125;&#125; @Valid:该标签完成数据绑定的验证操作。根据 po 类中的约束来进行验证。绑定结果默认保存在BindingResult中。如果有误。那么通过FieldError类的getDefaultMessage方法可以访问到，设置的报出的错误信息。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 中 VO、 PO、DO、DTO、 BO、 QO、DAO、POJO 的概念]]></title>
    <url>%2Fjava-objectConcept.html</url>
    <content type="text"><![CDATA[PO(persistant object) 持久对象在 o/r 映射的时候出现的概念，如果没有 o/r 映射，没有这个概念存在了。通常对应数据模型 ( 数据库 ), 本身还有部分业务逻辑的处理。可以看成是与数据库中的表相映射的 java 对象。最简单的 PO 就是对应数据库中某个表中的一条记录，多个记录可以用 PO 的集合。 PO 中应该不包含任何对数据库的操作。 DO（Domain Object）领域对象就是从现实世界中抽象出来的有形或无形的业务实体。一般和数据中的表结构对应。 TO(Transfer Object) ，数据传输对象在应用程序不同 tie( 关系 ) 之间传输的对象 DTO（Data Transfer Object）数据传输对象这个概念来源于J2EE的设计模式，原来的目的是为了EJB的分布式应用提供粗粒度的数据实体，以减少分布式调用的次数，从而提高分布式调用的性能和降低网络负载，但在这里，我泛指用于展示层与服务层之间的数据传输对象。 VO(view object) 值对象视图对象，用于展示层，它的作用是把某个指定页面（或组件）的所有数据封装起来。 BO(business object) 业务对象从业务模型的角度看 , 见 UML 元件领域模型中的领域对象。封装业务逻辑的 java 对象 , 通过调用 DAO 方法 , 结合 PO,VO 进行业务操作。 business object: 业务对象 主要作用是把业务逻辑封装为一个对象。这个对象可以包括一个或多个其它的对象。 比如一个简历，有教育经历、工作经历、社会关系等等。 我们可以把教育经历对应一个 PO ，工作经历对应一个 PO ，社会关系对应一个 PO 。 建立一个对应简历的 BO 对象处理简历，每个 BO 包含这些 PO 。 这样处理业务逻辑时，我们就可以针对 BO 去处理。 POJO(plain ordinary java object) 简单无规则 java 对象纯的传统意义的 java 对象。就是说在一些 Object/Relation Mapping 工具中，能够做到维护数据库表记录的 persisent object 完全是一个符合 Java Bean 规范的纯 Java 对象，没有增加别的属性和方法。我的理解就是最基本的 Java Bean ，只有属性字段及 setter 和 getter 方法！ DAO(data access object) 数据访问对象是一个 sun 的一个标准 j2ee 设计模式， 这个模式中有个接口就是 DAO ，它负持久层的操作。为业务层提供接口。此对象用于访问数据库。通常和 PO 结合使用， DAO 中包含了各种数据库的操作方法。通过它的方法 , 结合 PO 对数据库进行相关的操作。夹在业务逻辑与数据库资源中间。配合 VO, 提供数据库的 CRUD 操作]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts2 + Interceptor]]></title>
    <url>%2Fframe-struts2-interceptor.html</url>
    <content type="text"><![CDATA[GitHub 地址访问GitHub下载最新源码：https://github.com/JYG0723/Struts2_Action 简介：环境与基本配置与上一篇一致。这里简单的利用一个拦截器拦截一个对 Aciton 的请求，计算了一下访问一次该 Action 所花费的时间。拦截器的作用还请自行百度 第一个拦截器实例：访问 Action 时间记录TimerAction1234567891011public class TimerAction extends ActionSupport &#123; @Override public String execute() throws Exception &#123; for (int i = 0; i &lt; 10000; i++) &#123; System.out.println("I LOVE IMOOC"); &#125; return SUCCESS; &#125;&#125; TimerInteceptor123456789101112131415161718public class TimerInterceptor extends AbstractInterceptor &#123; // 执行 Action 的时候，会自动调用该方法 public String intercept(ActionInvocation actionInvocation) throws Exception &#123; // 执行 Action 之前，获取当前系统时间 long start = System.currentTimeMillis(); // 执行下一个拦截器，如果已经是最后一个拦截器，则执行目标 Action String result = actionInvocation.invoke(); // 执行 Action 之后，获取当前系统时间 long end = System.currentTimeMillis(); System.out.println("执行Action花费的时间: " + (end - start)); return result; &#125;&#125; struts.xml123456789101112&lt;package name="default" namespace="/" extends="struts-default"&gt; &lt;!-- 注册拦截器 --&gt; &lt;interceptors&gt; &lt;interceptor name="timerInterceptor" class="interceptor.TimerInterceptor"&gt;&lt;/interceptor&gt; &lt;/interceptors&gt; &lt;action name="timer" class="action.TimerAction"&gt; &lt;!-- 引用拦截器 --&gt; &lt;interceptor-ref name="timerInterceptor"&gt;&lt;/interceptor-ref&gt; &lt;result&gt;/success.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; index.jsp1&lt;a href="timer"&gt;点击计算访问一次 Action 所花费的时间&lt;/a&gt; Struts2 内建拦截器 params 拦截器 负责将请求参数设置为 Action 属性 staticParams 拦截器 将配置文件中 action 元素的子元素 param 参数设置为 Action 属性 servletConfig 拦截器 将源于 Servlet API 的各种对象注入到 Action，必须实现对应接口 fileUpload 拦截器 对文件上传提供支持，将文件和元数据设置到对应的 Action 属性中 exception 拦截器 捕获 Struts2 中发生的异常， 并且将异常映射到用户自定义的页面 validation 拦截器 调用验证框架进行数据验证 struts-default.xml1234567891011121314151617181920212223242526272829303132333435&lt;interceptor name="alias" class="com.opensymphony.xwork2.interceptor.AliasInterceptor"/&gt;&lt;interceptor name="autowiring" class="com.opensymphony.xwork2.spring.interceptor.ActionAutowiringInterceptor"/&gt;&lt;interceptor name="chain" class="com.opensymphony.xwork2.interceptor.ChainingInterceptor"/&gt;&lt;interceptor name="conversionError" class="org.apache.struts2.interceptor.StrutsConversionErrorInterceptor"/&gt;&lt;interceptor name="cookie" class="org.apache.struts2.interceptor.CookieInterceptor"/&gt;&lt;interceptor name="cookieProvider" class="org.apache.struts2.interceptor.CookieProviderInterceptor"/&gt;&lt;interceptor name="clearSession" class="org.apache.struts2.interceptor.ClearSessionInterceptor" /&gt;&lt;interceptor name="createSession" class="org.apache.struts2.interceptor.CreateSessionInterceptor" /&gt;&lt;interceptor name="debugging" class="org.apache.struts2.interceptor.debugging.DebuggingInterceptor" /&gt;&lt;interceptor name="execAndWait" class="org.apache.struts2.interceptor.ExecuteAndWaitInterceptor"/&gt;&lt;interceptor name="exception" class="com.opensymphony.xwork2.interceptor.ExceptionMappingInterceptor"/&gt;&lt;interceptor name="fileUpload" class="org.apache.struts2.interceptor.FileUploadInterceptor"/&gt;&lt;interceptor name="i18n" class="org.apache.struts2.interceptor.I18nInterceptor"/&gt;&lt;interceptor name="logger" class="com.opensymphony.xwork2.interceptor.LoggingInterceptor"/&gt;&lt;interceptor name="modelDriven" class="com.opensymphony.xwork2.interceptor.ModelDrivenInterceptor"/&gt;&lt;interceptor name="scopedModelDriven" class="com.opensymphony.xwork2.interceptor.ScopedModelDrivenInterceptor"/&gt;&lt;interceptor name="params" class="com.opensymphony.xwork2.interceptor.ParametersInterceptor"/&gt;&lt;interceptor name="actionMappingParams" class="org.apache.struts2.interceptor.ActionMappingParametersInteceptor"/&gt;&lt;interceptor name="prepare" class="com.opensymphony.xwork2.interceptor.PrepareInterceptor"/&gt;&lt;interceptor name="staticParams" class="com.opensymphony.xwork2.interceptor.StaticParametersInterceptor"/&gt;&lt;interceptor name="scope" class="org.apache.struts2.interceptor.ScopeInterceptor"/&gt;&lt;interceptor name="servletConfig" class="org.apache.struts2.interceptor.ServletConfigInterceptor"/&gt;&lt;interceptor name="timer" class="com.opensymphony.xwork2.interceptor.TimerInterceptor"/&gt;&lt;interceptor name="token" class="org.apache.struts2.interceptor.TokenInterceptor"/&gt;&lt;interceptor name="tokenSession" class="org.apache.struts2.interceptor.TokenSessionStoreInterceptor"/&gt;&lt;interceptor name="validation" class="org.apache.struts2.interceptor.validation.AnnotationValidationInterceptor"/&gt;&lt;interceptor name="workflow" class="com.opensymphony.xwork2.interceptor.DefaultWorkflowInterceptor"/&gt;&lt;interceptor name="store" class="org.apache.struts2.interceptor.MessageStoreInterceptor" /&gt;&lt;interceptor name="checkbox" class="org.apache.struts2.interceptor.CheckboxInterceptor" /&gt;&lt;interceptor name="datetime" class="org.apache.struts2.interceptor.DateTextFieldInterceptor" /&gt;&lt;interceptor name="profiling" class="org.apache.struts2.interceptor.ProfilingActivationInterceptor" /&gt;&lt;interceptor name="roles" class="org.apache.struts2.interceptor.RolesInterceptor" /&gt;&lt;interceptor name="annotationWorkflow" class="com.opensymphony.xwork2.interceptor.annotations.AnnotationWorkflowInterceptor" /&gt;&lt;interceptor name="multiselect" class="org.apache.struts2.interceptor.MultiselectInterceptor" /&gt;&lt;interceptor name="noop" class="org.apache.struts2.interceptor.NoOpInterceptor" /&gt; 可以看到 Struts2 的内建拦截器有很多。当然有的我们会用到，有的不会用到。但其还为我们声明了许多的拦截器栈，方便我们以组合的形式来使用。默认的，只要你的struts.xml文件中的package标签的extends=&quot;struts-default&quot;。那么下面的defaultStack默认拦截器栈已经被你这个包下的所有 Action 所使用。 defaultStack12345678910111213141516171819202122232425&lt;interceptor-stack name="defaultStack"&gt; &lt;interceptor-ref name="exception"/&gt; &lt;interceptor-ref name="alias"/&gt; &lt;interceptor-ref name="servletConfig"/&gt; &lt;interceptor-ref name="i18n"/&gt; &lt;interceptor-ref name="prepare"/&gt; &lt;interceptor-ref name="chain"/&gt; &lt;interceptor-ref name="scopedModelDriven"/&gt; &lt;interceptor-ref name="modelDriven"/&gt; &lt;interceptor-ref name="fileUpload"/&gt; &lt;interceptor-ref name="checkbox"/&gt; &lt;interceptor-ref name="datetime"/&gt; &lt;interceptor-ref name="multiselect"/&gt; &lt;interceptor-ref name="staticParams"/&gt; &lt;interceptor-ref name="actionMappingParams"/&gt; &lt;interceptor-ref name="params"/&gt; &lt;interceptor-ref name="conversionError"/&gt; &lt;interceptor-ref name="validation"&gt; &lt;param name="excludeMethods"&gt;input,back,cancel,browse&lt;/param&gt; &lt;/interceptor-ref&gt; &lt;interceptor-ref name="workflow"&gt; &lt;param name="excludeMethods"&gt;input,back,cancel,browse&lt;/param&gt; &lt;/interceptor-ref&gt; &lt;interceptor-ref name="debugging"/&gt;&lt;/interceptor-stack&gt; 注意： 需要注意的就是，当为包中的某个 Action 显示的指定了某个拦截器，则默认的拦截器将不再起作用。 struts.xml1234567&lt;action name="timer" class="action.TimerAction"&gt; &lt;!--在拦截器调用的时候，配置的先后顺序决定了该 Action 的拦截器的调用顺序，一般先调用默认的拦截器栈--&gt; &lt;interceptor-ref name="defaultStack"&gt;&lt;/interceptor-ref&gt; &lt;!-- 引用拦截器 --&gt; &lt;interceptor-ref name="timerInterceptor"&gt;&lt;/interceptor-ref&gt; &lt;result&gt;/success.jsp&lt;/result&gt;&lt;/action&gt; 第二个拦截器实例：权限验证LoginAction1234567891011121314151617181920212223242526public class LoginAction extends ActionSupport implements SessionAware &#123; private String username; private String password; // 封装了 session 的 Map 集合，需要实现 SessionAware 接口 private Map&lt;String, Object&gt; session; public void setSession(Map&lt;String, Object&gt; session) &#123; this.session = session; &#125; // getter/setter /** * 处理登录请求 */ public String login() &#123; if ("admin".equals(username) &amp;&amp; "admin".equals(password)) &#123; session.put("loginInfo", username); return SUCCESS; &#125; else &#123; session.put("loginError", "用户名和密码不正确"); return ERROR; &#125; &#125;&#125; AuthInterceptor123456789101112131415public class AuthInterceptor extends AbstractInterceptor &#123; public String intercept(ActionInvocation actionInvocation) throws Exception &#123; ActionContext actionContext = ActionContext.getContext(); Map&lt;String, Object&gt; session = actionContext.getSession(); if (session.get("loginInfo") != null) &#123; String result = actionInvocation.invoke(); return result; &#125; else &#123; return "login"; &#125; &#125;&#125; struts.xml12345678910111213141516171819202122232425262728293031&lt;struts&gt; &lt;constant name="struts.enable.DynamicMethodInvocation" value="false"&gt;&lt;/constant&gt; &lt;constant name="struts.devMode" value="true"&gt;&lt;/constant&gt; &lt;package name="default" namespace="/" extends="struts-default"&gt; &lt;interceptors&gt; &lt;interceptor name="auth" class="interceptor.AuthInterceptor"&gt;&lt;/interceptor&gt; &lt;!-- 自定义拦截器栈，组合了 auth Inteceptor 和 defaultStack --&gt; &lt;interceptor-stack name="myStack"&gt; &lt;interceptor-ref name="defaultStack"&gt;&lt;/interceptor-ref&gt; &lt;interceptor-ref name="auth"&gt;&lt;/interceptor-ref&gt; &lt;/interceptor-stack&gt; &lt;/interceptors&gt; &lt;!-- 通过该 Action 访问后台管理页面，需要判断用户是否已登录，如果未登录则跳转到登录页面 --&gt; &lt;action name="auth"&gt; &lt;!-- 这里没有实现类，会默认调用 ActionSupport 类,则结果一定返回 `success`,但经过拦截器就会被修改规则判定如果没有登录则返回 `login` --&gt; &lt;interceptor-ref name="myStack"&gt;&lt;/interceptor-ref&gt; &lt;result&gt;/WEB-INF/page/admin.jsp&lt;/result&gt; &lt;result name="login"&gt;/login.jsp&lt;/result&gt; &lt;/action&gt; &lt;!-- 通过该 Action 处理表单登录验证，如果用户名和密码有误则跳转到登录页面 --&gt; &lt;action name="login" class="action.LoginAction" method="login"&gt; &lt;result&gt;/WEB-INF/page/admin.jsp&lt;/result&gt; &lt;result name="error"&gt;/login.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; login.jsp123456$&#123;loginError&#125;&lt;form action="login.action" method="post"&gt; 用户名: &lt;input type="text" name="username"&gt; 密码: &lt;input type="password" name="password"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts InitCode]]></title>
    <url>%2Fframe-struts2-initCode.html</url>
    <content type="text"><![CDATA[GitHub 地址访问GitHub下载最新源码：https://github.com/JYG0723/Struts2_Action 执行流程图 系统环境IDE：InterliJ IDEA 2017.2.3jdk 版本：1.8Maven 版本：3.5 构建 构建好项目之后，maven 自动在webapp目录下生成的东西，除了web.xml全删。同时把web.xml删除到只剩xsd约束。 Pom12345&lt;dependency&gt; &lt;groupId&gt;org.apache.struts&lt;/groupId&gt; &lt;artifactId&gt;struts2-core&lt;/artifactId&gt; &lt;version&gt;2.5.13&lt;/version&gt;&lt;/dependency&gt; web.xml123456789&lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; Action123456789public class HelloWorldAction extends ActionSupport &#123; @Override public String execute() throws Exception &#123; System.out.println("执行Action"); // url: http://127.0.0.1:8080/struts2/helloworld.action return SUCCESS; // = "success" &#125;&#125; struts.xml 123456789&lt;struts&gt; &lt;package name="default" namespace="/" extends="struts-default"&gt; &lt;action name="helloworld" class="action.HelloWorldAction"&gt; &lt;result&gt;/result.jsp&lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; 注意： 出现的选项全勾 这样简单的 Struts2 的一个 Action 就配置完成了。自己编写一个登录实例，就可以进行测试了。 url: http://127.0.0.1:8080/struts2/helloworld.action]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts2 的 xml 及 properties 配置文件]]></title>
    <url>%2Fframe-struts2-configFile.html</url>
    <content type="text"><![CDATA[GitHub 地址访问GitHub下载最新源码：https://github.com/JYG0723/Struts2_Action struts.xml该文件也是 Struts2 框架自动加载的文件，在这个文件中可以定义一些自己的action，interceptor，package等，该文件的package通常继承struts-default包。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!--下面指定Struts 2.1配置文件的DTD信息--&gt;&lt;!DOCTYPE struts PUBLIC "-//Apache SoftwareFoundation//DTD Struts Configuration 2.1//EN" "http://struts.apache.org/dtds/struts-2.1.dtd"&gt;&lt;!-- struts是Struts 2配置文件的根元素--&gt;&lt;struts&gt; &lt;!--下面元素可以出现零次，也可以出现无数次--&gt; &lt;constant name="" value="" /&gt; &lt;!--下面元素可以出现零次，也可以出现无数次--&gt; &lt;bean type="" name="" class="" scope="" static=""optional="" /&gt; &lt;!--下面元素可以出现零次，也可以出现无数次--&gt; &lt;include file="" /&gt; &lt;!-- package元素是Struts配置文件的核心，该元素可以出现零次，或者无数次--&gt; &lt;package name="必填的包名" extends="" namespace="" abstract="" externalReferenceResolver&gt; &lt;!--该元素可以出现，也可以不出现，最多出现一次--&gt; &lt;result-types&gt; &lt;!--该元素必须出现，可以出现无数次--&gt; &lt;result-type name=""class="" default="true|false"&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* &lt;/result-type&gt; &lt;/result-types&gt; &lt;!--该元素可以出现，也可以不出现，最多出现一次--&gt; &lt;interceptors&gt; &lt;!--该元素的interceptor元素和interceptor-stack至少出现其中之一，也可以二者都出现--&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;interceptor name="" class=""&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* &lt;/interceptor&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;interceptor-stack name=""&gt; &lt;!--该元素必须出现，可以出现无数次--&gt; &lt;interceptor-ref name=""&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* &lt;/interceptor-ref&gt; &lt;/interceptor-stack&gt; &lt;/interceptors&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;default-interceptor-ref name=""&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* &lt;/default-interceptor-ref&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;default-action-ref name=""&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* &lt;/default-action-ref&gt;? &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;global-results&gt; &lt;!--该元素必须出现，可以出现无数次--&gt; &lt;result name="" ype=""&gt; &lt;!--该字符串内容可以出现零次或多次--&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* ---- (映射资源) &lt;/result&gt; &lt;/global-results&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;global-exception-mappings&gt; &lt;!--该元素必须出现，可以出现无数次--&gt; &lt;exception-mapping name=""exception="" result=""&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* ---- (异常处理资源) &lt;/exception-mapping&gt; &lt;/global-exception-mappings&gt; &lt;action name=""class="" method="" converter=""&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;result name="" type=""&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* --- (映射资源) &lt;/result&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;interceptor-ref name=""&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* &lt;/interceptor-ref&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;exception-mapping name=""exception="" result=""&gt; &lt;!--下面元素可以出现零次，也可以无数次--&gt; &lt;param name="参数名"&gt;参数值&lt;/param&gt;* ---- (异常处理资源) &lt;/exception-mapping&gt; &lt;/action&gt; &lt;/package&gt;* &lt;!-- unknown-handler-stack元素可出现零次或1次--&gt; &lt;unknown-handler-stack&gt; &lt;!-- unknown-handler-ref元素可出现零次或多次--&gt; &lt;unknown-handler-ref name=" "&gt;...&lt;/unknown-handler-ref&gt;* &lt;/unknown-handler-stack&gt;?&lt;struts&gt; struts.properties文件这个文件是 Struts2 框架的全局属性文件，也是自动加载的文件。该文件包含了系列的key-value对。该文件完全可以配置在struts.xml文件中，使用constant标签元素。下面是这个文件中一些常见的配置项及说明。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114### 指定加载struts2配置文件管理器，默认为org.apache.struts2.config.DefaultConfiguration### 开发者可以自定义配置文件管理器，该类要实现Configuration接口，可以自动加载struts2配置文件。# struts.configuration=org.apache.struts2.config.DefaultConfiguration### 设置默认的locale和字符编码# struts.locale=en_USstruts.i18n.encoding=UTF-8### 指定struts的工厂类# struts.objectFactory = spring### 指定spring框架的装配模式### 装配方式有: name, type, auto, and constructor (name 是默认装配模式)struts.objectFactory.spring.autoWire = name### 该属性指定整合spring时，是否对bean进行缓存，值为true or false,默认为true.struts.objectFactory.spring.useClassCache = true### 指定类型检查#struts.objectTypeDeterminer = tiger#struts.objectTypeDeterminer = notiger### 该属性指定处理 MIME-type multipart/form-data，文件上传# struts.multipart.parser=cos# struts.multipart.parser=pellstruts.multipart.parser=jakarta# 指定上传文件时的临时目录，默认使用 javax.servlet.context.tempdir struts.multipart.saveDir=struts.multipart.maxSize=2097152### 加载自定义属性文件 (不要改写struts.properties!)# struts.custom.properties=application,org/apache/struts2/extension/custom### 指定请求url与action映射器，默认为org.apache.struts2.dispatcher.mapper.DefaultActionMapper#struts.mapper.class=org.apache.struts2.dispatcher.mapper.DefaultActionMapper### 指定action的后缀，默认为actionstruts.action.extension=action### 被 FilterDispatcher使用### 如果为 true 则通过jar文件提供静态内容服务. ### 如果为 false 则静态内容必须位于 &lt;context_path&gt;/strutsstruts.serve.static=true### 被 FilterDispatcher使用### 指定浏览器是否缓存静态内容，测试阶段设置为false，发布阶段设置为true.struts.serve.static.browserCache=true### 设置是否支持动态方法调用，true为支持，false不支持.struts.enable.DynamicMethodInvocation = true### 设置是否可以在action中使用斜线，默认为false不可以，想使用需设置为true.struts.enable.SlashesInActionNames = false### 是否允许使用表达式语法，默认为true.struts.tag.altSyntax=true### 设置当struts.xml文件改动时，是否重新加载.### - struts.configuration.xml.reload = true### 设置struts是否为开发模式，默认为false,测试阶段一般设为true.struts.devMode = false### 设置是否每次请求，都重新加载资源文件，默认值为false.struts.i18n.reload=false###标准的UI主题### 默认的UI主题为xhtml,可以为simple,xhtml或ajaxstruts.ui.theme=xhtml###模板目录struts.ui.templateDir=template#设置模板类型. 可以为 ftl, vm, or jspstruts.ui.templateSuffix=ftl###定位velocity.properties 文件. 默认 velocity.propertiesstruts.velocity.configfile = velocity.properties### 设置velocity的context.struts.velocity.contexts =### 定位toolbox.struts.velocity.toolboxlocation=### 指定web应用的端口.struts.url.http.port = 80### 指定加密端口struts.url.https.port = 443### 设置生成url时，是否包含参数.值可以为: none, get or allstruts.url.includeParams = get### 设置要加载的国际化资源文件，以逗号分隔.# struts.custom.i18n.resources=testmessages,testmessages2### 对于一些web应用服务器不能处理HttpServletRequest.getParameterMap()### 像 WebLogic, Orion, and OC4J等，须设置成true,默认为false.struts.dispatcher.parametersWorkaround = false### 指定freemarker管理器#struts.freemarker.manager.classname=org.apache.struts2.views.freemarker.FreemarkerManager### 设置是否对freemarker的模板设置缓存### 效果相当于把template拷贝到 WEB_APP/templates.struts.freemarker.templatesCache=false### 通常不需要修改此属性.struts.freemarker.wrapper.altMap=true### 指定xslt result是否使用样式表缓存.开发阶段设为true,发布阶段设为false.struts.xslt.nocache=false### 设置struts自动加载的文件列表.struts.configuration.files=struts-default.xml,struts-plugin.xml,struts.xml### 设定是否一直在最后一个slash之前的任何位置选定namespace.struts.mapper.alwaysSelectFullNamespace=false]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts2 学习笔记 (二)]]></title>
    <url>%2Fframe-struts2-depth.html</url>
    <content type="text"><![CDATA[GitHub 地址访问GitHub下载最新源码：https://github.com/JYG0723/Struts2_Action 访问 Servlet ApiStruts2 不再与 Servlet Api 进行耦合，但任提供了三种方式去访问 Servlet Api ActionContext ：上下文的类，通过它获取相关的对象。Map 方式 Aware ：实现 Aware 接口。 ServletActionContex：与 ActionContext 类似。 Action 的搜索顺序 url：http://127.0.0.1:8080/struts2/path1/path2/student.action 首先根据 url 路径判断namespace为/path1/path2的 package 是否存在。 存在：判断 action 是否存在，如果不存在则去默认namespace的 package 里寻找。及namespace为/的 package 下。如果还不存在则报错。 不存在：检查上一级路径的 package 是否存在(直到默认 namespace)，即 namespace为path1的 package。如果没有报错。 动态方法调用动态方法调用为了解决一个 Action 对应多个请求的处理。以免 Action 太多，Struts2 对其有三种实现方式： 指定method属性。容易出现太多 xml文件中出现太多 action，不推荐 感叹号方式。官方不推荐，这里不写例子了。(请求写的和屎一样) 需要配置常量。并且配置 package 标签的strict-method-invocation=&quot;false&quot; 通配符方式，相比较而言推荐 需要配置 package 标签的strict-method-invocation=&quot;false&quot; 指定method属性struts.xml123456789101112&lt;package name="default" namespace="/" extends="struts-default"&gt; &lt;action name="helloworld" class="action.HelloWorldAction"&gt; &lt;!-- action 的 method 属性默认 execute --&gt; &lt;!-- result 的 name 属性默认 success --&gt; &lt;result&gt;/result.jsp&lt;/result&gt; &lt;/action&gt; &lt;action name="add" class="action.HelloWorldAction" method="add"&gt; &lt;!-- result 的 name 属性默认 success --&gt; &lt;result&gt;/add.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; HelloWorldAction123456789101112public class HelloWorldAction extends ActionSupport &#123; public String add() &#123; return SUCCESS; &#125; @Override public String execute() throws Exception &#123; System.out.println("执行Action"); return SUCCESS; // = "success" &#125;&#125; url：http://localhost:8080/struts2/add.action 通配符方式struts.xml12345678&lt;package name="default" namespace="/" extends="struts-default" strict-method-invocation="false"&gt; &lt;action name="helloworld_*" method="&#123;1&#125;" class="action.HelloWorldAction"&gt; &lt;!-- 默认 success --&gt; &lt;result&gt;/result.jsp&lt;/result&gt; &lt;result name="add"&gt;/&#123;1&#125;.jsp&lt;/result&gt; &lt;result name="update"&gt;&#123;1&#125;.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; HelloWorldAction12345678910111213141516public class HelloWorldAction extends ActionSupport &#123; public String add() &#123; return "add"; &#125; public String update() &#123; return "update"; &#125; @Override public String execute() throws Exception &#123; System.out.println("执行Action"); return SUCCESS; // = "success" &#125;&#125; url：http://localhost:8080/struts2/helloworld_update.action 多配置文件helloworld.xml1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE struts PUBLIC "-//Apache Software Foundation//DTD Struts Configuration 2.5//EN" "http://struts.apache.org/dtds/struts-2.5.dtd"&gt;&lt;struts&gt; &lt;package name="default" namespace="/" extends="struts-default" strict-method-invocation="false"&gt; &lt;action name="helloworld_*" method="&#123;1&#125;" class="action.HelloWorldAction"&gt; &lt;!-- 默认 success --&gt; &lt;result&gt;/result.jsp&lt;/result&gt; &lt;result name="add"&gt;/&#123;1&#125;.jsp&lt;/result&gt; &lt;result name="update"&gt;/&#123;1&#125;.jsp&lt;/result&gt; &lt;/action&gt; &lt;!-- &lt;action name="add" class="action.HelloWorldAction" method="add"&gt; &lt;result&gt;/add.jsp&lt;/result&gt; &lt;/action&gt; --&gt; &lt;/package&gt;&lt;/struts&gt; struts.xml12345678910&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE struts PUBLIC "-//Apache Software Foundation//DTD Struts Configuration 2.5//EN" "http://struts.apache.org/dtds/struts-2.5.dtd"&gt;&lt;struts&gt; &lt;include file="helloworld.xml"&gt;&lt;/include&gt;&lt;/struts&gt; 默认 Action默认 Action，即如果用户输入的路径有误，找不到对应的 Action，就可以用该 Action 来向用户展示默认页面。防止出现 404 影响用户体验。 123456789&lt;package name="default" namespace="/" extends="struts-default" strict-method-invocation="false"&gt; &lt;default-action-ref name="index"&gt;&lt;/default-action-ref&gt; &lt;action name="index"&gt; &lt;!-- 默认 success --&gt; &lt;result&gt;/error.jsp&lt;/result&gt; &lt;/action&gt;&lt;/package&gt; url：http://localhost:8080/struts2/***.action Struts2 后缀struts.xml1234567&lt;struts&gt; &lt;include file="helloworld.xml"&gt;&lt;/include&gt; &lt;constant name="struts.action.extension" value="html"&gt;&lt;/constant&gt; &lt;/struts&gt; url：http://localhost:8080/struts2/helloworld_add.html 12345&lt;struts&gt; &lt;include file="helloworld.xml"&gt;&lt;/include&gt; &lt;/struts&gt; url：http://localhost:8080/struts2/helloworld_add 注意： 比较有趣的一点是。默认 Struts2 访问 Action 不加.action后缀也是可以根据名称访问到对应 Action 的。但是如果配置了该struts.action.extension常量，并且 value 设值了，那么不添加后缀是访问不到的。如果该 value 没有设值，那么任然可以继续不带尾缀访问对应 Action。说明 struts2 源码实现中是会判断该常量的值是否存在的，如果存在就使用自定义的后缀，如果不存在，那么默认走的是以action为后缀的。但是当用户请求的时候也会判断，是否带了后缀，如果没带，就给用户一个默认的action后缀。如果带了直接向下进行 struts.propertis12### 指定后缀为 .action 形式的请求可被 Struts2 处理，默认为action。可配置多个请求后缀，用 , 隔开struts.action.extension=action,do,struts2, web.xml12345678&lt;filter&gt; &lt;filter-name&gt;struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;struts.action.extension&lt;/param-name&gt; &lt;param-value&gt;do&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt; 接受参数Struts2 的 Action 是如何接收参数的： 使用 Action 的属性接收参数 使用 DomainModel 接受参数 使用 ModelDriven 接受参数 Action 的属性接收LoginAction123456789101112public class LoginAction extends ActionSupport &#123; private String username; private String password; public String login() &#123; System.out.println(username + ":" + password); return SUCCESS; &#125; // getter/setter&#125; struts.xml1234&lt;action name="LoginAction" method="login" class="action.LoginAction"&gt; &lt;!-- 默认 success --&gt; &lt;result&gt;/success.jsp&lt;/result&gt;&lt;/action&gt; login.jsp1234&lt;form action="LoginAction.action" method="post"&gt; 用户名: &lt;input type="text" name="username"&gt; 密码: &lt;input type="password" name="password"&gt;&lt;/form&gt; DomainModel 接受LoginAction1234567891011121314151617public class LoginAction extends ActionSupport &#123; private User user; public String login() &#123; System.out.println(user.getUsername()+ ":" + user.getPassword()); return SUCCESS; &#125; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125;&#125; User1234567public class User &#123; private String username; private String password; getter/setter&#125; login.jsp12345&lt;form action="LoginAction.action" method="post"&gt; 用户名: &lt;input type="text" name="user.username"&gt; 密码: &lt;input type="password" name="user.password"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; ModelDriven 方式接收LoginAction1234567891011121314public class LoginAction extends ActionSupport implements ModelDriven&lt;User&gt;&#123; private User user = new User(); public String login() &#123; System.out.println(user.getUsername()+ ":" + user.getPassword()); return SUCCESS; &#125; @Override public User getModel() &#123; return user; &#125;&#125; login.jsp12345&lt;form action="LoginAction.action" method="post"&gt; 用户名: &lt;input type="text" name="username"&gt; 密码: &lt;input type="password" name="password"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; 复杂参数请求User12345678public class User &#123; private String username; private String password; private List&lt;User&gt; userList; // getter/setter&#125; login.jsp12345678&lt;form action="LoginAction.action" method="post"&gt; 用户名: &lt;input type="text" name="username"&gt; 密码: &lt;input type="password" name="password"&gt; 用户名1:&lt;input type="text" name="userList[0].username"&gt; 用户名2:&lt;input type="text" name="userList[1].username"&gt; 用户名3:&lt;input type="text" name="userList[2].username"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; LoginAction12345678910111213141516public class LoginAction extends ActionSupport implements ModelDriven&lt;User&gt; &#123; private User user = new User(); public String login() &#123; System.out.println(user.getUsername() + ":" + user.getPassword() + ": 用户名1:" + user.getUserList().get(0).getUsername() + ": 用户名2:" + user.getUserList().get(1).getUsername()); return SUCCESS; &#125; @Override public User getModel() &#123; return user; &#125;&#125; 处理结果类型LoginAction1234public class LoginAction extends ActionSupport&#123; ···&#125; ActionSupport1234public class ActionSupport implements Action, Validateable, ValidationAware, TextProvider, LocaleProvider, Serializable &#123; ···&#125; Action1234567891011package com.opensymphony.xwork2;public interface Action &#123; String SUCCESS = "success"; String NONE = "none"; String ERROR = "error"; String INPUT = "input"; String LOGIN = "login"; String execute() throws Exception;&#125; SUCCESS：Action 正确的执行完成。返回相应的视图，success 是 name 属性默认值 NONE：表示 Action 正确的执行完成，但并不返回任何视图 ERROR：表示 Action 执行失败，返回到错误处理视图 LOGIN：Action 因为用户没有登录的原因没有正确执行，将返回该登录视图，要求用户进行登录验证 INPUT ：Action 的执行，需要从前段页面获取参数，INPUT 就是代表这个参数输入的界面，一般在应用中，会对这些参数进行验证，如果验证没有通过，将自动返回到该视图。 INPUT 用法示例struts.xml12345&lt;action name="LoginAction" method="login" class="action.LoginAction"&gt; &lt;!-- 默认 success --&gt; &lt;result&gt;/success.jsp&lt;/result&gt; &lt;result name="input"&gt;/login.jsp&lt;/result&gt;&lt;/action&gt; login.jsp123456789101112&lt;%@ taglib prefix="s" uri="/struts-tags" %&gt;&gt;···&lt;form action="LoginAction.action" method="post"&gt; 用户名: &lt;input type="text" name="username"&gt;&lt;s:fielderror name="username"&gt;&lt;/s:fielderror&gt; 密码: &lt;input type="password" name="password"&gt; 用户名1:&lt;input type="text" name="userList[0].username"&gt; 用户名2:&lt;input type="text" name="userList[1].username"&gt; 年龄:&lt;input type="text" name="age"&gt; &lt;input type="submit" value="提交"&gt;&lt;/form&gt; LoginAction1234567891011public class LoginAction extends ActionSupport implements ModelDriven&lt;User&gt; &#123; ··· @Override public void validate() &#123; if (user.getUsername() == null || "".equals(user.getUsername())) &#123; this.addFieldError("username", "用户名不能为空"); &#125; &#125;&#125; 注意： 这里的addFieldError方法的username参数对应 jsp 页面&lt;S:&gt;标签的 name 属性。 result 标签&lt;result name = &quot;&quot; type = &quot;&quot;&gt; &lt;/result&gt; 这里的 type 属性默认是 dispatcher 即转发。页面是通过请求转发调度过去，支持 jsp 引擎。 12345678910111213&lt;result-types&gt; &lt;result-type name="chain" class="com.opensymphony.xwork2.ActionChainResult"/&gt; &lt;result-type name="dispatcher" class="org.apache.struts2.result.ServletDispatcherResult" default="true"/&gt; &lt;result-type name="freemarker" class="org.apache.struts2.views.freemarker.FreemarkerResult"/&gt; &lt;result-type name="httpheader" class="org.apache.struts2.result.HttpHeaderResult"/&gt; &lt;result-type name="redirect" class="org.apache.struts2.result.ServletRedirectResult"/&gt; &lt;result-type name="redirectAction" class="org.apache.struts2.result.ServletActionRedirectResult"/&gt; &lt;result-type name="stream" class="org.apache.struts2.result.StreamResult"/&gt; &lt;result-type name="velocity" class="org.apache.struts2.result.VelocityResult"/&gt; &lt;result-type name="xslt" class="org.apache.struts2.views.xslt.XSLTResult"/&gt; &lt;result-type name="plainText" class="org.apache.struts2.result.PlainTextResult" /&gt; &lt;result-type name="postback" class="org.apache.struts2.result.PostbackResult" /&gt;&lt;/result-types&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Struts2 学习笔记 (一)]]></title>
    <url>%2Fframe-struts2-principle.html</url>
    <content type="text"><![CDATA[GitHub 地址访问GitHub下载最新源码：https://github.com/JYG0723/Struts2_Action 简介由于学校框架学习学的是 Struts2，而我之前学习的是Spring MVC。虽然曾经在大一暑假的时候接触过 Struts2，可是当时学的并不仔细，而且早已经忘记。所以决定重新学习一遍，记录下来自己在学习时觉得重要的知识点。 Struts2 的执行流程 客户端HttpServletRequest发送请求 请求经过过滤器ActionContextCleanUp--&gt;StrutsPrepareAndExecuteFilter(核心过滤器 ) 请求到达ActionMapper，通过它来决定调用哪个A ction 当决定调用某个 Action 后，请求又会通过核心过滤器，核心过滤器把请求的处理交给ActionProxy ActionProxy通过ConfigurationManage询问配置文件Struts.xml，找到要调用的 Action 类。 StrutsPrepareAndExecuteFilter 等同于 Spring MVC 中的 DispatcherServlet。前段请求接收器，负责根据各 action 分发用户请求。 这其实两个 Filter，Prepare(准备)和Execute(执行)。他的前身是 FilterDispatcher，后来因为该 Filter 不允许在视图和该过滤器之间添加自己的过滤器所以被改进。转变成了现在的StrutsPrepareAndExecuteFilter 这个过滤器只会过滤和自己相关的请求，即以.action为路径后缀的请求。.html，.jsp会放行结尾的则会放行。 web.xml中配置了该过滤器之后，web 应用上下文被加载成功之后便会加载该过滤器，只要改过滤器被加载那么他将会加载 Struts2 框架。 struts.xmlstruts2 的核心配置文件。主要负责管理各 Action 的映射，以及该 Action 对应的 Result 的定义。 struts.xml 文件中包含： 全局属性 各用户请求和响应 Action 之间的对应关系。 Action 可能用到的参数和返回结果 各种拦截器配置 标签 include：可以将每个功能模块独立到一个 xml 配置文件中，然后用 include 标签进行引入。 package：配置文件中可以有多个包，但是包的名称是唯一的。 name：包名 extend：继承的父类的包，默认是 struts-default。 abstract：设置该 package 的属性为抽象的。抽象的 package 不能定义 action。但可以在其中定义一些全局的属性或者拦截器。然后供其他包进行引用或者继承。 namespace：定义 package 的命名空间。该命名空间影响到该 package 下定义的 action 的访问的 url 路径。 如果 namespace 定义成 &quot;/&quot;，那么访问该 package 下的 action 只需要直接根据该 action 的名字访问就可以了。http://localhost:8080/struts2/XX.action interceptors：拦截器的定义在该标签中，可以在 interceptors 标签下定义我们自己的拦截器。 interceptor ：拦截器。其中该 interceptor 标签有两个属性，一个 name(拦截器名称)，一个 class(类名)。 interceptor-stack：拦截器栈。 default-interceptor -ref：可以通过该标签来引用一个拦截器成为默认的拦截器。即任意一个 Action 都会引用该拦截器。 global-results：全局的结果集。可以自己在其中进行定义，定义好之后该包之中的所有的 action 都可以对其进行引用。&lt;result name = &quot;error&quot;&gt;/error.jsp&lt;/result&gt; action：每个包中可以定义多个 action。 属性 &lt;action name = &quot;hello&quot; class = &quot;nuc.jyg.struts2.Action.LoginAction&quot;&gt;&lt;/action&gt; name：该 action 的名称。对应访问该 action 的 url 映射。http://localhost:8080/ProjectName/NameSpace/hello.action。 class：对应类的路径。 method：调用 Action 的方法名。可以指定该 Action 调用它的哪个方法。 内部标签 interceptor-ref：可以定义该 Action 的拦截器。 result：可以定义该 Action 的结果集，通过 method 属性的结果来对应。选择哪个结果集对应的视图进行展示。&lt;result name = &quot;success&quot; type = &quot;dispatcher&quot;&gt;/success.jsp&lt;/result&gt;。这里 type 属性有很多种。 param：Action 的参数。在对应的 Action 中通过 set/get 方法可以访问到。&lt;param name = &quot;url&quot;&gt;http://www.jiyongguang.xin&lt;/param&gt; constant：常量标签。在struts.xml文件中定义该标签。可以省去配置struts.properties文件。 &lt;constant name = &quot;struts.i18n.reload&quot; value = &quot;true&quot;&gt;&lt;/constant&gt; 具体的struts.xml和struts.properties可以参考：Struts2 的 xml及properties 配置文件]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Struts2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thymeleaf 语法 (持续更新)]]></title>
    <url>%2FTemplateEngine-Thymeleaf-grammar.html</url>
    <content type="text"><![CDATA[简介这里总结的是我自己在学习时用到的一些语法。由于是用到才会去查，因为太多我记不住。所以是记录式学习，会持续更新 标签th:actionForm 表单1&lt;form th:action="@&#123;'/book/'+$&#123;book.id&#125;&#125;"&gt;&lt;/form&gt; th:valueInput 标签1&lt;input th:value="$&#123;book.id&#125;"/&gt; th:hrefa 标签1&lt;a th:href="@&#123;'/book/'+$&#123;book.id&#125;&#125;"&gt;&lt;/a&gt; th:eachtable 表格1&lt;tr th:each="book: $&#123;books&#125;"&gt;&lt;/tr&gt; th:texttable 表格1&lt;td th:text="$&#123;book.id&#125;"&gt;&lt;/td&gt; th:ifdiv 体展示1&lt;div th:if="$&#123;books != null&#125;"&gt;&lt;/div&gt; th:src静态资源引入1&lt;script th:src="@&#123;/resources/js/jquery/jquery.json-2.4.min.js&#125;" th:object表单数据对象的绑定用于表单数据对象绑定，将表单绑定到后台controller的一个JavaBean参数。常与th:field一起使用进行表单数据绑定。 123456public class LoginBean implements Serializable&#123;...&#125;&#123;&#125; @RequestMapping(value = "/login", method = RequestMethod.POST) public String login(@ModelAttribute(value = "loginBean") LoginBean loginBean，ModelMap model)&#123; ... &#125;&#125; 1&lt;form id="login-form" th:action="@&#123;/login&#125;" th:object="$&#123;loginBean&#125;"&gt;...&lt;/form&gt; th:field表单字段绑定，属性绑定、集合绑定。注意操作符是 * 12345678910111213141516171819public class LoginBean implements Serializable &#123; private String username; private List&lt;User&gt; user;...&#125;---public class User implements Serializable &#123; private String username;;&#125;---@RequestMapping(value = "/login", method = RequestMethod.POST)public String login(@ModelAttribute(value = "loginBean") LoginBean loginBean，ModelMap model) &#123; &#125; 1234&lt;form id="login-form" th:action="@&#123;/login&#125;" th:object="$&#123;loginBean&#125;"&gt; &lt;input type="text" value="" th:field="*&#123;username&#125;"&gt;&lt;/input&gt; &lt;input type="text" value="" th:field="*&#123;user[0].username&#125;"&gt;&lt;/input&gt;&lt;/form&gt; th:iddiv id声明1&lt;div class="student" th:id = "stu+($&#123;rowStat.index&#125;+1)"&gt;&lt;/div&gt; th:fragment声明定义该属性的div为模板片段。常用与头文件，页尾文件的引入。常与th:include，th:replace一起使用 声明模板片段 /WEBINF/templates/footer. html 123&lt;div th: fragment="copy" &gt; © 2011 The Good Thymes Virtual Grocery&lt;/div&gt; 引入模板片段 12&lt;div th: include=" /templates/footer : : copy" &gt;&lt;/div&gt;&lt;div th: replace=" /templates/footer : : copy" &gt;&lt;/div&gt; th:inline[[…]]之间的表达式在 Thymeleaf 被认为是内联表达式，在其中您可以使用任何类型的表达式，也会有效th:text属性。 1&lt;p&gt;Hello, [[$&#123;session.user.name&#125;]]!&lt;/p&gt; 等同于： 1&lt;p&gt;Hello, &lt;span th:text="$&#123;session.user.name&#125;"&gt;Sebastian&lt;/span&gt;!&lt;/p&gt; 为了让内联工作，必须激活它使用th:inline 属性，它有三个可能的值或模式(text, javascript 和 none)。 1&lt;p th:inline="text"&gt;Hello, [[$&#123;session.user.name&#125;]]!&lt;/p&gt; 如果不使用th:inline=&quot;text&quot;,则会被当做字符串显示。th:inline=&quot;javascript&quot;表示能在 js 中使用[ [] ]取值。 参考：thymeleaf中的内联[ [ ] ]]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Thymeleaf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + Swagger2]]></title>
    <url>%2Fframe-springboot-swagger2.html</url>
    <content type="text"><![CDATA[Swagger 常用注解 @Api：用在类上，说明该类的作用 @ApiOperation：用在方法上，说明方法的作用 @ApiImplicitParams：用在方法上包含一组参数说明 @ApiImplicitParam：用在@ApiImplicitParams注解中，指定一个请求参数的各个方面 paramType：参数放在哪个地方 header–&gt;请求参数的获取：@RequestHeader query–&gt;请求参数的获取：@RequestParam path（用于restful接口）–&gt;请求参数的获取：@PathVariable body（不常用） form（不常用） name：参数名 dataType：参数类型 required：参数是否必须传 value：参数的意思 defaultValue：参数的默认值 @ApiResponses：用于表示一组响应 @ApiResponse：用在@ApiResponses中，一般用于表达一个错误的响应信息 code：数字，例如400 message：信息，例如”请求参数没填好” response：抛出异常的类 @ApiModel：描述一个Model的信息（这种一般用在post创建的时候，使用@RequestBody这样的场景，请求参数无法使用@ApiImplicitParam注解进行描述的时候） @ApiModelProperty：描述一个model的属性 这是我自己学习时总结的。后来还找到一篇比我总结的更详细，更具体的文章。Swagger2常用注解 Swagger In SpringBootPom12345678910&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt;&lt;/dependency&gt; Configuration123456789101112131415161718192021222324@Configuration@EnableSwagger2public class Swagger2 &#123; @Bean public Docket createRestApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage("http://www.jiyongguang.xin")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title("Spring Boot中使用Swagger2构建RESTful APIs") .description("Spring Boot相关文章请关注：http://www.jiyongguang.xin") .termsOfServiceUrl("http://www.jiyongguang.xin") .contact("洛雨男铃") .version("1.0") .build(); &#125;&#125; Controller1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@RestController@RequestMapping(value="/users") // 通过这里配置使下面的映射都在/users下，可去除public class UserController &#123; static Map&lt;Long, User&gt; users = Collections.synchronizedMap(new HashMap&lt;Long, User&gt;()); @ApiOperation(value="获取用户列表", notes="") @RequestMapping(value=&#123;""&#125;, method=RequestMethod.GET) public List&lt;User&gt; getUserList() &#123; List&lt;User&gt; r = new ArrayList&lt;User&gt;(users.values()); return r; &#125; @ApiOperation(value="创建用户", notes="根据User对象创建用户") @ApiImplicitParam(name = "user", value = "用户详细实体user", required = true, dataType = "User") @RequestMapping(value="", method=RequestMethod.POST) public String postUser(@RequestBody User user) &#123; users.put(user.getId(), user); return "success"; &#125; @ApiOperation(value="获取用户详细信息", notes="根据url的id来获取用户详细信息") @ApiImplicitParam(name = "id", value = "用户ID", required = true, dataType = "Long") @RequestMapping(value="/&#123;id&#125;", method=RequestMethod.GET) public User getUser(@PathVariable Long id) &#123; return users.get(id); &#125; @ApiOperation(value="更新用户详细信息", notes="根据url的id来指定更新对象，并根据传过来的user信息来更新用户详细信息") @ApiImplicitParams(&#123; @ApiImplicitParam(name = "id", value = "用户ID", required = true, dataType = "Long"), @ApiImplicitParam(name = "user", value = "用户详细实体user", required = true, dataType = "User") &#125;) @RequestMapping(value="/&#123;id&#125;", method=RequestMethod.PUT) public String putUser(@PathVariable Long id, @RequestBody User user) &#123; User u = users.get(id); u.setName(user.getName()); u.setAge(user.getAge()); users.put(id, u); return "success"; &#125; @ApiOperation(value="删除用户", notes="根据url的id来指定删除对象") @ApiImplicitParam(name = "id", value = "用户ID", required = true, dataType = "Long") @RequestMapping(value="/&#123;id&#125;", method=RequestMethod.DELETE) public String deleteUser(@PathVariable Long id) &#123; users.remove(id); return "success"; &#125;&#125;]]></content>
      <categories>
        <category>SpringBoot 学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Swagger2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见注解，Bean 解析]]></title>
    <url>%2Fframe-annotation.html</url>
    <content type="text"><![CDATA[整理博客的原因：因为自己经常在看别人源码的时候，或者自己在看源码以及一些文档的时候看到一些注解，或者对象不太了解其中的实现。经常当时百度了过不久就会忘记，后来还得再去查，这样下来不但费时，关键经常一些优秀的博客会丢失。所以这里我进行了一些对我可能用到的注解讲解的好的，或者我在学习时遇到的不理解的地方百度到的对我有作用的博客进行了整理。 SpringSpring高级话题-@Enable*注解的工作原理 @Enable*注解的工作原理参考：http://blog.csdn.net/qq_26525215/article/details/53524844 Spring MVCModel、ModelMap和ModelAndView的区别和用法 Model，ModelMap和ModelAndView的区别和用法参考：http://blog.csdn.net/qq_20282263/article/details/52831398 其实这个网上找了很多资源之后都没有找到我想要的结果，上面给的链接也不是我想要的，但是对于这三个对象的使用描述的很清晰，以后也可以当做模板来用一下。我一直想区分的其实是这三个在返回视图对象的时候都可以用，我也都用到过，可是他们三个有什么区别呢？性能上哪个又更好呢，什么场景更适合用哪个呢？可是网上找了好多之后并没有找到我想要的文章。 迫不得已，大概扫了一下源码之后(看不懂，美滋滋，哈哈~)。ModelAndView是一个单独的类，其实包含 一个ModelMap座位其属性。而ModelMap是继承了LinkedHashMap的一个子类，而Model则是一个接口(一看到接口就感觉凉了)。所以我感觉ModelMap可能最好用。 拦截器执行流程 拦截器执行流程参考：http://www.jianshu.com/p/f14ed6ca4e56 异常：今天在学习 Spring Boot 中 Web 应用的统一异常处理时。发现自己竟然对throws Exception和throw new Exception(&quot;发生错误&quot;);的理解还不是很清楚。该文章有些地方读起来有点儿问题，可能笔者写错了。但笔者的意思我是大概了解了 解惑文章：http://blog.csdn.net/wy5612087/article/details/47861077]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>常见</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + Untertow]]></title>
    <url>%2Fframe-springboot-undertow.html</url>
    <content type="text"><![CDATA[为什么是 Untertow 而不是 TomcatTomcat和Undertow并发性能 ，这篇文章详细测试了 Spring Boot 应用在两种容器下的性能和内存使用，证明了Undertow在性能和内存使用上是最好的 Pom1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Untertow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 学习笔记]]></title>
    <url>%2Ftool-git.html</url>
    <content type="text"><![CDATA[Git命令速查表 我最喜欢的图 版本控制系统集中式：(SVN，CVS) 工作前都需要把最新代码从中央库 Pull 下来。工作完成然后再 Push 到中央库中，意味着必须联网。受网络限制，并且不安全 分布式：(Git，BitKeeper) 每一台终端都是一个中央服务器。代码保存在本地，十分灵活。 时光穿梭工作区和暂存区 命令组 意义 git add file 文件添加到暂存区 git commit -m “提交说明” -m后面输入的是本次提交的说明 git status 查看当前仓库的状态 git diff 查看修改内容 管理修改 命令组 意义 git log (–pretty=oneline) 当前文件所有历史版本 cat file 查看文件内容 git reflog 查看每一次提交的id git reset –hard [版本号] 回到某一版本。HEAD 就是当前版本 撤销修改 命令组 意义 git checkout – file 丢弃工作区修改。回到最近一次git commit或git add时的状态 git reset HEAD file 把暂存区的修改撤销掉 删除文件 命令组 意义 git rm file 删除文件。删除后可以借助git checkout恢复文件到版本库中存在的文件的最新版本 远程仓库添加远程仓库 命令组 意义 git remote add origin [url] 关联一个远程库 git push -u origin master 第一次推送本地master分支的内容到远程，添加-u参数完成初始化 git push -u -f origin master 遇到报错时可以选择覆盖远程master，强制提交 git push origin master 第一次之后每次推送最新修改。推送master分支内容到远程master分支 从远程仓库克隆 命令组 意义 git clone [url] https协议克隆一个仓库。速度慢 git clone git@github.com:[用户名]/[仓库名].git ssh支持的原生git协议。克隆一个仓库 提交代码到远程仓库 命令组 意义 git pull origin master 下载远程仓库的最新内容 git push origin master 上传到分支 分支管理创建与合并分支 命令组 意义 git checkout -b [分支名称] 创建加切换到分支 git branch [分支名称] 创建分支 git checkout [分支名称] 切换到分支 git branch 查看分支 git merge [分支名称] 合并指定分支到当前分支 git branch -d [分支名称] 删除指定分支(确保当前不在此分支上) 解决冲突双方修改同一文件的不同地方不会触发。相反修改同一文件的同一地方才会触发。各自修改提交后，合并时就会出现冲突。我们切换到主分支下，对文件进行最终修改后。再进行提交即可 12CONFLICT (content): Merge conflict in [文件名称]Automatic merge failed; fix conflicts and then commit the result. 命令组 意义 git log –graph 可以看到分支合并图 分支管理策略 命令组 意义 git merge –no-ff -m “描述” [分支名称] 合并分支时，强制禁用Fast forward模式。此时Git就会在merge时生成一个新的commit。所以需要加上-m参数 加上--no-ff参数就可以用普通模式合并，合并后的历史有分支，能看出来曾经做过合并，而Fast Forward合并看不出来曾经做过合并。 分支策略： master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活。干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本。你和你的团队每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。所以团队合作看起来就像这样： Bug 分支当某一天你在工作时，你的Boss告诉你你之前的代码出现了bug。需要你在一个小时内改完，可是你当前在dev上进行的工作暂时还没有完成没办法提交。预计还有很久的时间，可又必须在一个小时内改完bug。该怎么办： 命令组 意义 git stash 可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作 git stash apply [stash@{0}] 恢复指定的工作现场。stash内容并不删除 git stash drop [stash@{0}] 删除指定 stash git stash pop 恢复到前一工作现场。并删除该stash 注意： 首先确定要在哪个分支上修复 bug，假定需要在master分支上修复，就从master创建临时分支issue-101。修复完成后，再切换回master分支进行合并。最后删除issue-101分支。在不同分支上进行修复，工作区中看到的代码不一定是相同的，需要确保这一点。并且在不同分支上进行修复后，最后会合并到该分支上。如果代码要最终发布，你需要再将你分之上的代码merge到master分支上。 多人协作注意： 合作开发新功能时，最好在一个新的分支上进行新功能的开发，而不去污染主分支。当该功能开发好之后再去合并到主分支即可。 命令组 意义 git remote -v 查看远程库的详细信息。( fetch，push 抓取和推送的origin的地址 ) git push origin [分支名称] 推送该分支的本地内容到远程库的分支上。 注意： 这里还有一个学问就是，并不是一定要把本地分支往远程推送，那么，哪些分支需要推送，哪些不需要呢？ master分支是主分支，因此要时刻与远程同步 dev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步 多人协作时，大家都会往master和dev分支上推送各自的修改。 bug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug feature分支是否推到远程，取决于你是否和你的同班合作在上面开发 命令组 意义 git checkout -b branch-name origin/branch-name 在本地创建和远程分支对应的分支 git branch –set-upstream branch-name origin/branch-name 建立本地分支和远程分支的关联 git push origin branch-name 本地新建的分支如果不推送到远程，对其他人就是不可见的， 从本地推送分支到远程(会让你输github的用户名和密码)。 多人协作的工作模式通常是这样： 首先从远程库clone下项目，然后在本地创建远程origin的dev分支到本地。然后就可以在dev分支上提交修改 然后可以试图用git push origin branch-name推送自己的修改 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull拉取下来最新的提交，如果拉取失败则是因为远程的分支与本地的分支没有建立链接。设置好后再git pull进行合并 如果合并有冲突，则解决冲突，并在本地提交 没有冲突或者解决掉冲突后，再用git push origin branch-name推送就能成功 错误： 12fatal: Cannot update paths and switch to branch &apos;dev&apos; at the same time.Did you intend to checkout &apos;origin/dev&apos; which can not be resolved as commit? 解决： 1234git remote show origingit remote updategit fetchgit checkout -b local-name origin/remote-name 对应多个远程库 (码云，GitHub) 命令集 意义 git remote -v 查看远程库信息 git remote rm [远程库名] 删除已关联的远程库 git remote add [远程库别名] git@github.com:michaelliao/learngit.git 关联GitHub的远程库，可以给远程库起个别名，这样可以一个本地库关联多个远程库而不会出现名称冲突的问题 git push [远程库名称] master 将master分支代码推送到名称对应的远程库上 最后送上一本书据说很牛逼的关于Git的书，我看了两眼觉得牛逼，但实在没空看完它有空会去看的。点击这里 推荐： Acey：Git指南 - 3个小时搞定git stormzhang：从0开始学习 GitHub 系列之「Git 进阶」]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC Demo(四) 博文管理]]></title>
    <url>%2Fframe-springmvc-demo-4.html</url>
    <content type="text"><![CDATA[访问GitHub下载最新源码：https://github.com/JYG0723/springmvc BlogRepoistory123@Repositorypublic interface BlogRepository extends JpaRepository&lt;BlogEntity, Integer&gt; &#123;&#125; 查看所有博文BlogController1234567891011121314151617181920@Controller@RequestMapping(value = "/admin/blogs")public class BlogController &#123; @Autowired BlogRepository blogRepository; /** * 博文管理页面 * * @param modelMap * @return */ @RequestMapping(value = "", method = RequestMethod.GET) public String showBlogs(ModelMap modelMap) &#123; List&lt;BlogEntity&gt; blogList = blogRepository.findAll(); modelMap.addAttribute("blogList", blogList); return "/admin/blog/blogs"; &#125;&#125; 添加博客BlogController 加入123456789101112@RequestMapping(value = "/addPage", method = RequestMethod.GET)public String addBlogPage(ModelMap modelMap) &#123; List&lt;UserEntity&gt; userList = userRepository.findAll(); modelMap.addAttribute("userList", userList); return "admin/blog/addBlog";&#125;@RequestMapping(value = "/addBlog", method = RequestMethod.POST)public String addBlogPost(@ModelAttribute("blog") BlogEntity blogEntity) &#123; blogRepository.saveAndFlush(blogEntity); return "redirect:/admin/blogs";&#125; addBlog.jsp 添加博文页面1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;%@ taglib prefix="form" uri="http://www.springframework.org/tags/form" %&gt;&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt; &lt;!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ --&gt; &lt;title&gt;SpringMVC 添加博客&lt;/title&gt; &lt;!-- 新 Bootstrap 核心 CSS 文件 --&gt; &lt;link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"&gt; &lt;!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src="//cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/respond.js/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="container"&gt; &lt;h1&gt;SpringMVC 添加博客&lt;/h1&gt; &lt;hr/&gt; &lt;%--@elvariable id="blog" type="model.BlogEntity"--%&gt; &lt;form:form action="/admin/blogs/addBlog" method="post" commandName="blog" role="form"&gt; &lt;div class="form-group"&gt; &lt;label for="title"&gt;Title:&lt;/label&gt; &lt;input type="text" class="form-control" id="title" name="title" placeholder="Enter Title:"/&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label for="userByUserId.id"&gt;Author:&lt;/label&gt; &lt;select class="form-control" id="userByUserId.id" name="userByUserId.id"&gt; &lt;c:forEach items="$&#123;userList&#125;" var="user"&gt; &lt;option value="$&#123;user.id&#125;"&gt;$&#123;user.nickname&#125;, $&#123;user.firstName&#125; $&#123;user.lastName&#125;&lt;/option&gt; &lt;/c:forEach&gt; &lt;/select&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label for="content"&gt;Content:&lt;/label&gt; &lt;textarea class="form-control" id="content" name="content" rows="3" placeholder="Please Input Content"&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label for="pubDate"&gt;Publish Date:&lt;/label&gt; &lt;input type="date" class="form-control" id="pubDate" name="pubDate"/&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;button type="submit" class="btn btn-sm btn-success"&gt;提交&lt;/button&gt; &lt;/div&gt; &lt;/form:form&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 需要通过 blog 的外键来定位到所选择的作者。而在其选项组 option 中，使用user.id来进行赋值，对应blogEntity对象中的private UserEntity userByUserId属性，对应数据库中的user_id INT(11) 这样就能把blog和user表相关联。 查看博文详情BlogController 加入123456@RequestMapping(value = "/show/&#123;id&#125;", method = RequestMethod.GET)public String showBlog(@PathVariable("id") Integer id, ModelMap modelMap) &#123; BlogEntity blogEntity = blogRepository.findOne(id); modelMap.addAttribute("blog", blogEntity); return "admin/blogDetail";&#125; blogDetail.jsp - 博客详情页面使用了 jstl 的 fmt 标签来格式化输出时间。代码中需要在顶部引入 1&lt;%@ taglib prefix="fmt" uri="http://java.sun.com/jsp/jstl/fmt" %&gt; 修改博文BlogRepository 加入1234@Modifying@Transactional@Query("update BlogEntity blog set blog.title = :title,blog.content = :content,blog.userByUserId.id = :userId,blog.pubDate = :pubDate where blog.id = :blogId")public void updateBole(@Param("title") String title, @Param("content") String content, @Param("pubDate") Date pubDate,@Param("userId") Integer userId, @Param("blogId") Integer id); BlogController 加入123456789101112131415@RequestMapping(value = "/update/&#123;id&#125;", method = RequestMethod.GET)public String updateBlogPage(@PathVariable("id") Integer id, ModelMap modelMap) &#123; BlogEntity blogEntity = blogRepository.findOne(id); List&lt;UserEntity&gt; userList = userRepository.findAll(); modelMap.addAttribute("userList", userList); modelMap.addAttribute("blog", blogEntity); return "admin/blog/updateBlog";&#125;@RequestMapping(value = "/updatePut", method = RequestMethod.PUT)public String updateBlog(@ModelAttribute("blog") BlogEntity blogEntity) &#123; blogRepository.updateBole(blogEntity.getTitle(), blogEntity.getContent(), blogEntity.getPubDate(), blogEntity.getUserByUserId().getId(), blogEntity.getId()); blogRepository.flush(); return "redirect:/admin/blogs";&#125; 删除博客BlogController 加入1234567@RequestMapping(value = "/delete/&#123;id&#125;", method = RequestMethod.DELETE)@ResponseBodypublic String deleteBlog(@PathVariable("id") Integer id) &#123; blogRepository.delete(id); blogRepository.flush(); return JsonUtil.getJsonString(JsonUtil.REQUEST_SUCCESS);&#125; blogs.jsp 加入1234567891011121314151617181920212223function deleteBlog(node) &#123; var url = node.id; $.ajax(&#123; url: url, type: "DELETE", success: function (restlt) &#123; if (restlt.code = 1) &#123; window.location.href = "/admin/blogs"; &#125; else &#123; alert("删除失败！") &#125; &#125; &#125;);&#125;······&lt;td&gt; &lt;a href="/admin/blogs/show/$&#123;blog.id&#125;" type="button" class="btn btn-sm btn-success"&gt;详情&lt;/a&gt; &lt;a href="/admin/blogs/update/$&#123;blog.id&#125;" type="button" class="btn btn-sm btn-warning"&gt;修改&lt;/a&gt; &lt;a id="/admin/blogs/delete/$&#123;blog.id&#125;" type="button" class="btn btn-sm btn-danger" onclick="deleteBlog(this)"&gt;删除&lt;/a&gt;&lt;/td&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>AJAX</tag>
        <tag>BootStrap</tag>
        <tag>Restful</tag>
        <tag>MariaDB</tag>
        <tag>Project</tag>
        <tag>SpringMVC</tag>
        <tag>Spring</tag>
        <tag>Spring Data JPA</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[REST架构中的PUT、DELETE请求如何实现?]]></title>
    <url>%2Fframe-rest-put.html</url>
    <content type="text"><![CDATA[web.xml123456789&lt;!-- 将POST请求转化为DELETE或者是PUT 要用_method指定真正的请求参数 --&gt;&lt;filter&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; html12&lt;form:form action="/admin/users/update" method="post" commandName="user" role="form"&gt; &lt;input type="hidden" name="_method" value="put"/&gt; Controller1@RequestMapping(value = "/update", method = RequestMethod.PUT)]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Restful</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC 的 @ModelAttribute 注解]]></title>
    <url>%2Fframe-springmvc-modelattribute.html</url>
    <content type="text"><![CDATA[@ModelAttribute123456@RequestMapping("/save") public String save(@ModelAttribute User user) &#123; user.setUsername("U love me"); userService.save(user); return "result"; &#125; 此方法会先从 model 去获取 key 为 “user” 的对象，如果获取不到会通过反射实例化一个 User 对象，再从 request 里面拿值set 到这个对象，然后把这个 User 对象添加到 model (其中 key 为 “user” ) 使用了@ModelAttribute可修改这个 key，不一定是 “user” ，此情况下用与不用@ModelAttribute没有区别 参考：springmvc的ModelAttribute注解]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC Demo(三) 用户管理]]></title>
    <url>%2Fframe-springmvc-demo-3.html</url>
    <content type="text"><![CDATA[访问GitHub下载最新源码：https://github.com/JYG0723/springmvc UserRepository123@Repositorypublic interface UserRepository extends JpaRepository&lt;UserEntity,Integer&gt;&#123;&#125; MainController12345678@Controllerpublic class MainController &#123; @RequestMapping(value = "/", method = RequestMethod.GET) public String index() &#123; return "index"; &#125;&#125; 用户管理页面的访问与添加用户功能实现UserController 加入123456789101112131415161718192021222324252627282930/*** 添加用户页面** @return*/@RequestMapping(value = "/addPage", method = RequestMethod.GET) public String addUserPage() &#123; return "admin/addUser";&#125; /** * 添加有用户操作 * * @param userEntity * @return */ @RequestMapping(value = "/addUser", method = RequestMethod.POST) public String addUserPost(@ModelAttribute("user") UserEntity userEntity) &#123; // 注意此处，post请求传递过来的是一个UserEntity对象，里面包含了该用户的信息 // 通过@ModelAttribute()注解可以获取传递过来的封装了前台信息的'user'实例，并创建这个对象 // 数据库中添加一个用户，该步暂时不会刷新缓存 //userRepository.save(userEntity); // 数据库中添加一个用户，并立即刷新缓存 userRepository.saveAndFlush(userEntity); // 重定向到用户管理页面，方法为 redirect:url return "redirect:/admin/users/"; &#125; users.jsp - 用户管理页面12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN"&gt;&lt;head&gt; &lt;meta charset="utf-8"/&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"/&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"/&gt; &lt;title&gt;SpringMVC 用户管理&lt;/title&gt; &lt;!-- 新 Bootstrap 核心 CSS 文件 --&gt; &lt;link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"&gt; &lt;!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src="//cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/respond.js/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="container"&gt; &lt;h1&gt;SpringMVC 博客系统-用户管理&lt;/h1&gt; &lt;hr/&gt; &lt;h3&gt;所有用户 &lt;a href="/admin/users/add" type="button" class="btn btn-primary btn-sm"&gt;添加&lt;/a&gt;&lt;/h3&gt; &lt;!-- 如果用户列表为空 --&gt; &lt;c:if test="$&#123;empty userList&#125;"&gt; &lt;div class="alert alert-warning" role="alert"&gt; &lt;span class="glyphicon glyphicon-info-sign" aria-hidden="true"&gt;&lt;/span&gt;User表为空，请&lt;a href="/admin/users/add" type="button" class="btn btn-primary btn-sm"&gt;添加&lt;/a&gt; &lt;/div&gt; &lt;/c:if&gt; &lt;!-- 如果用户列表非空 --&gt; &lt;c:if test="$&#123;!empty userList&#125;"&gt; &lt;table class="table table-bordered table-striped"&gt; &lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;昵称&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;密码&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;c:forEach items="$&#123;userList&#125;" var="user"&gt; &lt;tr&gt; &lt;td&gt;$&#123;user.id&#125;&lt;/td&gt; &lt;td&gt;$&#123;user.nickname&#125;&lt;/td&gt; &lt;td&gt;$&#123;user.firstName&#125; $&#123;user.lastName&#125;&lt;/td&gt; &lt;td&gt;$&#123;user.password&#125;&lt;/td&gt; &lt;td&gt; &lt;a href="/admin/users/show/$&#123;user.id&#125;" type="button" class="btn btn-sm btn-success"&gt;详情&lt;/a&gt; &lt;a href="/admin/users/update/$&#123;user.id&#125;" type="button" class="btn btn-sm btn-warning"&gt;修改&lt;/a&gt; &lt;a href="/admin/users/delete/$&#123;user.id&#125;" type="button" class="btn btn-sm btn-danger"&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;/table&gt; &lt;/c:if&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; addUser.jsp - 添加用户页面1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;%@ taglib prefix="form" uri="http://www.springframework.org/tags/form" %&gt;&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN"&gt;&lt;head&gt; &lt;meta charset="utf-8"/&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"/&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"/&gt; &lt;!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ --&gt; &lt;title&gt;SpringMVC 添加用户&lt;/title&gt; &lt;!-- 新 Bootstrap 核心 CSS 文件 --&gt; &lt;link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"&gt; &lt;!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src="//cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/respond.js/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="container"&gt; &lt;h1&gt;SpringMVC 添加用户&lt;/h1&gt; &lt;hr/&gt; &lt;%--@elvariable id="user" type="model"--%&gt; &lt;form:form action="/admin/users/addUser" method="post" commandName="user" role="form"&gt; &lt;div class="form-group"&gt; &lt;label for="firstName"&gt;Nickname:&lt;/label&gt; &lt;input type="text" class="form-control" id="nickname" name="nickname" placeholder="Enter Nickname:"/&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label for="firstName"&gt;First Name:&lt;/label&gt; &lt;input type="text" class="form-control" id="firstName" name="firstName" placeholder="Enter FirstName:"/&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label for="lastName"&gt;Last Name:&lt;/label&gt; &lt;input type="text" class="form-control" id="lastName" name="lastName" placeholder="Enter LastName:"/&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label for="password"&gt;Password:&lt;/label&gt; &lt;input type="text" class="form-control" id="password" name="password" placeholder="Enter Password:"/&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;button type="submit" class="btn btn-sm btn-success"&gt;提交&lt;/button&gt; &lt;/div&gt; &lt;/form:form&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 注意： &lt;form:form&gt;标签：使用 Spring 的 form 标签，可以方便的收集整块数据，commondName=“user”说明 form 内的内容都保存在这个 user 实例中，然后将整个 user 实例传递给 Usercontroller 处理。在所有的 input 标签中，name 一定要与 UserEntity中的属性名相同，不然无法找到。 用户详情查看的功能实现UserController 加入12345678910111213/*** 用户详情页面** @param userId* @param modelMap* @return*/@RequestMapping(value = "/show/&#123;id&#125;", method = RequestMethod.GET)public String showUserDetail(@PathVariable("id") Integer userId, ModelMap modelMap) &#123; UserEntity userEntity = userRepository.findOne(userId); modelMap.addAttribute("user", userEntity); return "admin/userDetail";&#125; userDetail.jsp - 用户详情页面12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt; &lt;!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ --&gt; &lt;title&gt;SpringMVC 用户详情&lt;/title&gt; &lt;!-- 新 Bootstrap 核心 CSS 文件 --&gt; &lt;link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"&gt; &lt;!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src="//cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/respond.js/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="container"&gt; &lt;h1&gt;SpringMVC 用户详情&lt;/h1&gt; &lt;hr/&gt; &lt;table class="table table-bordered table-striped"&gt; &lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;td&gt;$&#123;user.id&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;Nickname&lt;/th&gt; &lt;td&gt;$&#123;user.nickname&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;First Name&lt;/th&gt; &lt;td&gt;$&#123;user.firstName&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;Last Name&lt;/th&gt; &lt;td&gt;$&#123;user.lastName&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;Password&lt;/th&gt; &lt;td&gt;$&#123;user.password&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 用户更改功能的实现UserController 加入12345678910111213141516171819202122232425/*** 更新用户页面** @return*/@RequestMapping(value = "/update/&#123;id&#125;", method = RequestMethod.GET)public String updateUserPut(@PathVariable("id") Integer userId, ModelMap modelMap) &#123; UserEntity userEntity = userRepository.findOne(userId); modelMap.addAttribute("user", userEntity); return "admin/updateUser";&#125;/*** 更新用户操作** @param userEntity* @return*/@RequestMapping(value = "/update", method = RequestMethod.PUT)public String updateUserPut(@ModelAttribute("user") UserEntity userEntity) &#123; userRepository.updateUser(userEntity.getNickname(), userEntity.getFirstName(), userEntity.getLastName(), userEntity.getPassword(), userEntity.getId()); userRepository.flush(); return "redirect:/admin/users";&#125; UserRepository 加入 - 自定义 update 方法123456@Modifying @Transactional // 加入事务控制@Query("update UserEntity ue set ue.nickname=:nickname,ue.firstName=:firstName,ue.lastName=:lastName,ue.password=:password where ue.id=:id") public void updateUser(@Param("nickname") String nickname, @Param("firstName") String firstName, @Param("lastName") String lastName, @Param("password") String password, @Param("id") Integer id); updateUser.jsp - 用户更改页面1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;%@ taglib prefix="form" uri="http://www.springframework.org/tags/form" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;!DOCTYPE html&gt;&lt;html lang="zh-CN"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt; &lt;!-- 上述3个meta标签*必须*放在最前面，任何其他内容都*必须*跟随其后！ --&gt; &lt;title&gt;SpringMVC Demo 更新用户&lt;/title&gt; &lt;!-- 新 Bootstrap 核心 CSS 文件 --&gt; &lt;link rel="stylesheet" href="//cdn.bootcss.com/bootstrap/3.3.5/css/bootstrap.min.css"&gt; &lt;!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries --&gt; &lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt; &lt;!--[if lt IE 9]&gt; &lt;script src="//cdn.bootcss.com/html5shiv/3.7.2/html5shiv.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/respond.js/1.4.2/respond.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt; &lt;script src="//cdn.bootcss.com/jquery/1.11.3/jquery.min.js"&gt;&lt;/script&gt; &lt;script src="//cdn.bootcss.com/bootstrap/3.3.5/js/bootstrap.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;div class="container"&gt; &lt;h1&gt;SpringMVC 更新用户信息&lt;/h1&gt; &lt;hr/&gt; &lt;form:form action="/admin/users/update" method="post" commandName="user" role="form"&gt; &lt;input type="hidden" name="_method" value="put"/&gt; &lt;div class="form-group"&gt; &lt;label for="firstName"&gt;Nickname:&lt;/label&gt; &lt;input type="text" class="form-control" id="nickname" name="nickname" placeholder="Enter Nickname:" value="$&#123;user.nickname&#125;"/&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label for="firstName"&gt;First Name:&lt;/label&gt; &lt;input type="text" class="form-control" id="firstName" name="firstName" placeholder="Enter FirstName:" value="$&#123;user.firstName&#125;"/&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label for="lastName"&gt;Last Name:&lt;/label&gt; &lt;input type="text" class="form-control" id="lastName" name="lastName" placeholder="Enter LastName:" value="$&#123;user.lastName&#125;"/&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;label for="password"&gt;Password:&lt;/label&gt; &lt;input type="text" class="form-control" id="password" name="password" placeholder="Enter Password:" value="$&#123;user.password&#125;"/&gt; &lt;/div&gt; &lt;!-- 把 id 一并写入 userP 中 --&gt; &lt;input type="hidden" id="id" name="id" value="$&#123;user.id&#125;"/&gt; &lt;div class="form-group"&gt; &lt;button type="submit" class="btn btn-sm btn-success"&gt;提交&lt;/button&gt; &lt;/div&gt; &lt;/form:form&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 用户删除功能的实现UserController 加入12345678@RequestMapping(value = "/delete/&#123;id&#125;", method = RequestMethod.DELETE)@ResponseBodypublic String deleteUser(@PathVariable("id") Integer userId) &#123; userRepository.delete(userId); userRepository.flush();// return "redirect:/admin/users"; return JsonUtil.getJsonString(JsonUtil.REQUEST_SUCCESS);&#125; users.jsp 修改123456789101112131415161718192021222324252627&lt;script type="text/javascript"&gt; function deleteUser(node) &#123; var url = node.id; $.ajax(&#123; type: "DELETE", url: url, success: function (result) &#123; if (result.code = 1) &#123; window.location.href = "/admin/users"; &#125; else &#123; alert("删除失败") &#125; &#125; &#125;) ; &#125;&lt;/script&gt;······&lt;td&gt; &lt;a href="/admin/users/show/$&#123;user.id&#125;" type="button" class="btn btn-sm btn-success"&gt;详情&lt;/a&gt; &lt;a href="/admin/users/update/$&#123;user.id&#125;" type="button" class="btn btn-sm btn-warning"&gt;修改&lt;/a&gt; &lt;a id="/admin/users/delete/$&#123;user.id&#125;" type="button" class="btn btn-sm btn-danger" onclick="deleteUser(this)"&gt;删除&lt;/a&gt;&lt;/td&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>AJAX</tag>
        <tag>BootStrap</tag>
        <tag>Restful</tag>
        <tag>MariaDB</tag>
        <tag>Project</tag>
        <tag>SpringMVC</tag>
        <tag>Spring</tag>
        <tag>Spring Data JPA</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Heidisql 建表字段]]></title>
    <url>%2Fide-heidisql-field.html</url>
    <content type="text"><![CDATA[Intrinsic column flags PK: primary key (column is part of a pk) 主键 NN: not null (column is nullable) 非空 UQ: unique (column is part of a unique key) 唯一 AI: auto increment (the column is auto incremented when rows are inserted) 自增 additional data type flags, depend on used data type BIN: binary (if dt is a blob or similar, this indicates that is binary data, rather than text) 二进制(比text更大的二进制数据) UN: unsigned (for integer types, see docs: “10.2. Numeric Types”) 整数 ZF: zero fill (rather a display related flag, see docs: “10.2. Numeric Types”)值中最有意义的字节总为0，并且不保存。 MySQL外键设置中的的 Cascade、NO ACTION、Restrict、SET NULL NULL、RESTRICT、NO ACTION 删除：从表记录不存在时，主表才可以删除。删除从表，主表不变 更新：从表记录不存在时，主表才可以更新。更新从表，主表不变 CASCADE 删除：删除主表时自动删除从表。删除从表，主表不变 更新：更新主表时自动更新从表。更新从表，主表不变 SET NULL 删除：删除主表时自动更新从表值为NULL。删除从表，主表不变 更新：更新主表时自动更新从表值为NULL。更新从表，主表不变]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>MariaDB</tag>
        <tag>HeidiSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC Demo(二) 数据库配置]]></title>
    <url>%2Fframe-springmvc-demo-2.html</url>
    <content type="text"><![CDATA[访问GitHub下载最新源码：https://github.com/JYG0723/springmvc 创建数据库123456789101112131415161718192021222324252627DROP DATABASE IF EXISTS `springdemo`;CREATE DATABASE IF NOT EXISTS `springdemo` /*!40100 DEFAULT CHARACTER SET utf8 */;USE `springdemo`;-- 导出 表 springdemo.blog 结构DROP TABLE IF EXISTS `blog`;CREATE TABLE IF NOT EXISTS `blog` ( `id` int(11) NOT NULL AUTO_INCREMENT, `title` varchar(100) NOT NULL, `content` varchar(255) DEFAULT NULL, `user_id` int(11) NOT NULL, `pub_date` date NOT NULL, PRIMARY KEY (`id`), KEY `user_id` (`user_id`), CONSTRAINT `user_id` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`) ON DELETE NO ACTION ON UPDATE NO ACTION) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- 导出 表 springdemo.user 结构DROP TABLE IF EXISTS `user`;CREATE TABLE IF NOT EXISTS `user` ( `id` int(1) NOT NULL AUTO_INCREMENT, `nickname` varchar(45) NOT NULL, `password` varchar(45) NOT NULL, `first_name` varchar(45) DEFAULT NULL, `last_name` varchar(45) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8; Intellij 自动生成 Model 右键项目，选择Add Framework Support 下拉选择JavaEE Persistence，右边 provider 选择Hibernate 此时resources里面生成了persistence.xml配置文件。同时左下角出现了persistence边框 右键项目名，选择Generate Persistence Mapping，再选择By Database Schema 打开model包，可以看到生成了两个Java Bean，在SpringMVC中称为两个实体，它们对应了数据库的两张表。 将persistence.xml文件移除（过于陈旧）。把数据库配置移到mvc-dispatcher-servlet.xml中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:jpa="http://www.springframework.org/schema/data/jpa" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt; &lt;!--指明 controller 所在包，并扫描其中的注解--&gt; &lt;context:component-scan base-package="controller"/&gt; &lt;!-- 静态资源(js、image等)的访问 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 开启注解 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!--ViewResolver 视图解析器--&gt; &lt;!--用于支持Servlet、JSP视图解析--&gt; &lt;bean id="jspViewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView"/&gt; &lt;property name="prefix" value="/WEB-INF/pages/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; &lt;!-- 表示JPA Repository所在的包 --&gt; &lt;jpa:repositories base-package="repository"/&gt; &lt;bean id="entityManagerFactory" class="org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean"&gt; &lt;property name="persistenceUnitName" value="defaultPersistenceUnit"/&gt; &lt;property name="packagesToScan" value="model" /&gt; &lt;property name="jpaVendorAdapter"&gt; &lt;bean class="org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter"/&gt; &lt;/property&gt; &lt;property name="jpaProperties"&gt; &lt;props&gt; &lt;prop key="hibernate.connection.driver_class"&gt;org.mariadb.jdbc.Driver&lt;/prop&gt; &lt;prop key="hibernate.connection.url"&gt;jdbc:mysql://localhost:3306/springdemo?useSSL=false&lt;/prop&gt; &lt;prop key="hibernate.connection.username"&gt;root&lt;/prop&gt; &lt;prop key="hibernate.connection.password"&gt;root&lt;/prop&gt; &lt;prop key="hibernate.show_sql"&gt;false&lt;/prop&gt; &lt;prop key="hibernate.connection.useUnicode"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.connection.characterEncoding"&gt;UTF-8&lt;/prop&gt; &lt;prop key="hibernate.format_sql"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.use_sql_comments"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.hbm2ddl.auto"&gt;update&lt;/prop&gt; &lt;prop key="hibernate.connection.autoReconnect"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.dialect"&gt;org.hibernate.dialect.MySQL5Dialect&lt;/prop&gt; &lt;prop key="connection.autoReconnectForPools"&gt;true&lt;/prop&gt; &lt;prop key="connection.is-connection-validation-required"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.c3p0.validate"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.connection.provider_class"&gt;org.hibernate.service.jdbc.connections.internal.C3P0ConnectionProvider&lt;/prop&gt; &lt;prop key="hibernate.c3p0.min_size"&gt;5&lt;/prop&gt; &lt;prop key="hibernate.c3p0.max_size"&gt;600&lt;/prop&gt; &lt;prop key="hibernate.c3p0.timeout"&gt;1800&lt;/prop&gt; &lt;prop key="hibernate.c3p0.max_statements"&gt;50&lt;/prop&gt; &lt;prop key="hibernate.c3p0.preferredTestQuery"&gt;SELECT 1;&lt;/prop&gt; &lt;prop key="hibernate.c3p0.testConnectionOnCheckout"&gt;true&lt;/prop&gt; &lt;prop key="hibernate.c3p0.idle_test_period"&gt;3000&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 事务管理 --&gt; &lt;bean id="transactionManager" class="org.springframework.orm.jpa.JpaTransactionManager"&gt; &lt;property name="entityManagerFactory" ref="entityManagerFactory"/&gt; &lt;/bean&gt; &lt;!-- 开启事务管理注解 --&gt; &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt;&lt;/beans&gt; jpa:repositories：这一部分涉及到数据库的接口 entityManagerFactory：实体管理器工厂，读取persistence.xml配置 transactionManager：事务管理器，利用entityManager进行事务管理 tx:annotation-driven：打开事务管理器的注解驱动，可以使用注解的方法操纵数据库。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>AJAX</tag>
        <tag>BootStrap</tag>
        <tag>Restful</tag>
        <tag>MariaDB</tag>
        <tag>Project</tag>
        <tag>SpringMVC</tag>
        <tag>Spring</tag>
        <tag>Spring Data JPA</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IntelliJ IDEA 源值1.5已过时，将在未来所有版本中删除]]></title>
    <url>%2Fide-intellij-java.html</url>
    <content type="text"><![CDATA[###原因 IDEA默认把项目的源代码版本设置为jdk1.5，目标代码设置为jdk1.5，编译时jdk版本为jdk1.5 解决方案 修改Maven的settings.xml文件添加如下内容 1234567891011121314&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;jdk-1.8&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 打开项目配置，设置Modules的Language Level为“8” 最后点击Default Settings修改全局配置文件，搜索”Java Compiler”，将默认jdk和当前modual的jdk版本切换为1.8即可]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
        <tag>ERROR</tag>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC Demo(一) 框架搭建]]></title>
    <url>%2Fframe-springmvc-demo-1.html</url>
    <content type="text"><![CDATA[访问GitHub下载最新源码：https://github.com/JYG0723/springmvc Pom.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;properties&gt; &lt;spring.version&gt;4.3.10.RELEASE&lt;/spring.version&gt; &lt;hibernate.version&gt;5.2.10.Final&lt;/hibernate.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!--dependency&gt; &lt;groupId&gt;nuc.jyg&lt;/groupId&gt; &lt;artifactId&gt;[the artifact id of the block to be mounted]&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency--&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.data/spring-data-jpa --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.11.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;$&#123;hibernate.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-c3p0&lt;/artifactId&gt; &lt;version&gt;$&#123;hibernate.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 停更 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.mchange&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 停更 --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;6.0.6&lt;/version&gt; &lt;/dependency&gt; Web.xml1234567891011121314151617181920212223242526272829303132333435&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"&gt; &lt;display-name&gt;SpringMvcPractice Web Application&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;mvc-dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;filter&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 其中encoding用来设置编码格式，forceEncoding用来设置是否理会request.getCharacterEncoding()方法，设置为 true 则强制覆盖之前的编码格式。 ###Controller 12345678@Controllerpublic class MainController &#123; @RequestMapping(value = "/", method = RequestMethod.GET) public String index() &#123; return "index"; &#125;&#125; mvc-dispatcher-servlet.xml 创建的 SpringMVC 的配置文件 mvc-dispatcher-servlet.xml（-servlet前面是在servlet里面定义的servlet名）。 123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;!--指明 controller 所在包，并扫描其中的注解--&gt; &lt;context:component-scan base-package="controller"/&gt; &lt;!-- 静态资源(js、image等)的访问 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 开启springmvc注解 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- ViewResolver 视图解析器--&gt; &lt;!--用于支持Servlet、JSP视图解析--&gt; &lt;bean id="jspViewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView"/&gt; &lt;property name="prefix" value="/WEB-INF/pages/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt;&lt;/beans&gt; 首先加入component-scan标签，指明controller所在的包，并扫描其中的注解 再进行js、image、css等静态资源访问的相关配置，这样，SpringMVC 才能访问网站内的静态资源 再开启 springmvc 注解模式，利用注解方法来进行相关定义，可以省去很多的配置 再进行视图解析器的相关配置 ViewResolver Controller如何找到视图文件： 在 controller 的一个方法中，返回的字符串定义了所需访问的jsp的名字（如上面的index）。在jspViewResolver中，有两个属性，一个是prefix，定义了所需访问的文件路径前缀，另一是suffix，表示要访问的文件的后缀，这里为 .jsp。那么，如果返回字符串是 xxx ，SpringMVC就会找到 /WEB-INF/pages/xxx.jsp 文件。 项目结构]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>AJAX</tag>
        <tag>BootStrap</tag>
        <tag>Restful</tag>
        <tag>MariaDB</tag>
        <tag>Project</tag>
        <tag>SpringMVC</tag>
        <tag>Spring</tag>
        <tag>Spring Data JPA</tag>
        <tag>Hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBootTest[1.4+]]]></title>
    <url>%2Fframe-springboot-test.html</url>
    <content type="text"><![CDATA[前言测试在 SpringBoot 1.4 版本之后进行了改进，Testing improvements in Spring Boot 1.4。由于 Spring Boot 1.4 之前的测试方式均属于集成测试。一个单纯的单元测试不应该创建和加载 Spring 的上下文。在 1.4 版本之前想要使用单元测试测试一个带有@Autowired注解的外部 services 的 controller 而不用去加载Spring上下文，是不可能的。 简介Spring Boot 1.4 解决的另外一个问题是，可以测试一段代码。不用启动服务器。并且不用启动整个Spring上下文，Spring Boot 1.4 通过新的Test Slicing的特性 就可以完成，这个特性被设计成可以至启动一小片的Spring上下文。这时的测试单个的代码片段更加容易了。你可以这样去测试你的应用中的特定代码片段 MVC 片段： 通过@WebMvcTest注解测试Controller代码 JPA 片段： 通过@DataJpaTest注解测试Spring Data JPA repository代码 JSON 片段： 通过@JsonTest注解JSON序列化代码 解决的问题；大型的应用要测试的话，如果它启动Spring上下文，会很耗费时间 SpringBoot 1.4-12345@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = Application.class)public class ApplicationTests &#123;&#125; Or 12345@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = Application.class)public class ApplicationTests &#123;&#125; SpringBoot 1.4+12345@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT, classes = Application.class)public class ApplicationTests &#123;&#125; 注解 @RunWith(SpringRunner.class) 告诉Spring运行使用的JUnit测试支持。SpringRunner是SpringJUnit4ClassRunner的新名字，这个名字只是让名字看起来简单些。 @SpringBootTest意思是“带有Spring Boot支持的引导程序”（例如，加载应用程序、属性，为我们提供Spring Boot的所有精华部分）。 webEnvironment属性允许为测试配置特定的“网络环境”。 MOCK：提供一个Mock的Servlet环境，内置的Servlet容器并没有真实的启动，主要搭配使用@AutoConfigureMockMvc RANDOM_PORT： 提供一个真实的Servlet环境，也就是说会启动内置容器，然后使用的是随机端口 DEFINED_PORT：这个配置也是提供一个真实的Servlet环境，使用的默认的端口，如果没有配置就是8080 NONE：这是个神奇的配置，跟Mock一样也不提供真实的Servlet环境。 classes如果想要加载一个特定的配置，可以用@SpringBootTest的classes属性。在这个实例中，省略classes就意味着测试要首次尝试从任意一个inner-classes中加载@configuration，如果这个尝试失败了，它会在你主要的@SpringBootApplicationclass中进行搜索。 实例单例测试123456789101112131415161718@RunWith(SpringRunner.class)@WebMvcTest(controllers = HelloController.class)@AutoConfigureWebMvcpublic class HelloControllerTest &#123; @Autowired private MockMvc mockMvc; @Test public void index() throws Exception &#123; this.mockMvc.perform(get("/hello")) .andExpect(status().isOk()) .andExpect(content().contentType("application/json;charset=UTF-8"))// .andExpect(view().name("index")) .andExpect(content().string(Matchers.containsString("Hello World"))) .andDo(print()); &#125;&#125; 与@SpringBootTest注解不同@WebMvcTest注解会把自动配置给禁用掉。 @WebMvcTest只会将 Spring MVC 的基础架构自动配置，并且仅对使用@Controller,@ControllerAdvice,@JsonComponent注解的bean ，以及Filter、WebMvcConfigurer和HandlerMethodArgumentResolver类型的bean进行扫描。此时@Component、@Service 或 @Repository注解的bean将不会被扫描到 集成测试1234567891011121314151617181920212223@RunWith(SpringRunner.class)//@WebMvcTest(controllers = HelloController.class)//@AutoConfigureWebMvcpublic class HelloControllerTest extends C1ApplicationTests &#123;// @Autowired private MockMvc mockMvc; @Before public void setUp() throws Exception &#123; mockMvc = MockMvcBuilders.standaloneSetup(new HelloController()).build(); &#125; @Test public void index() throws Exception &#123; this.mockMvc.perform(get("/hello")) .andExpect(status().isOk()) .andExpect(content().contentType("application/json;charset=UTF-8"))// .andExpect(view().name("index")) .andExpect(content().string(Matchers.containsString("Hello World"))) .andDo(print()); &#125;&#125; 12345@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT, classes = C1Application.class)public class C1ApplicationTests &#123; &#125; 如果想要加载所有的应用配置并且使用 MockMVC，就应该使用@SpringBootTest注解并且加上 @AutoConfigureMockMvc注解，而不是使用@WebMvcTest注解。 MockMvc 通过模拟 Spring MVC 来测试 MVC 网页应用。可以向一个controller发送模拟的HTTP请求，这样不再需要启动应用服务器。可以通过 MockMvcBuilders 来获取 MockMvc 的实例。 (推荐)standaloneSetup()：注册一个或多个@Controller实例，并且允许通过编程去配置 Spring MVC 的基础架构 从而来构造一个 MockMvc 的实例。 这跟普通的单元测试很相似，同时也使得一次仅关注一个controller的测试成为可能。 webAppContextSetup()： 使用完全被初始化（并且刷新过）了的 WebApplicationContext 来构建一个MockMvc实例。这样使Spring可以加载你的控制层以及它们的所有依赖，从而进行一个完整的集成测试。 方法解析： perform：执行一个RequestBuilder请求，会自动执行 SpringMVC 的流程并映射到相应的控制器执行处理； get：声明发送一个get请求的方法。MockHttpServletRequestBuilder get(String urlTemplate, Object... urlVariables)：根据uri模板和uri变量值得到一个 GET 请求方式的。另外提供了其他的请求的方法，如：post、put、delete等。 param：添加request的参数，假如使用需要发送json数据格式的时将不能使用这种方式，可见后面被@ResponseBody注解参数的解决方法 andExpect：添加ResultMatcher验证规则，验证控制器执行完成后结果是否正确（对返回的数据进行的判断）； andDo：添加ResultHandler结果处理器，比如调试时打印结果到控制台（对返回的数据进行的判断）； andReturn：最后返回相应的MvcResult；然后进行自定义验证/进行下一步的异步处理（对返回的数据进行的判断）； 控制台12345678910111213141516171819202122232425262728293031323334MockHttpServletRequest: HTTP Method = GET Request URI = /hello Parameters = &#123;&#125; Headers = &#123;&#125;Handler: Type = nuc.jyg.c1.web.HelloController Method = public java.lang.String nuc.jyg.c1.web.HelloController.index()Async: Async started = false Async result = nullResolved Exception: Type = nullModelAndView: View name = null View = null Model = nullFlashMap: Attributes = nullMockHttpServletResponse: Status = 200 Error message = null Headers = &#123;Content-Type=[application/json;charset=UTF-8], Content-Length=[11]&#125; Content type = application/json;charset=UTF-8 Body = Hello World Forwarded URL = null Redirected URL = null Cookies = [] 扩展事物回滚12@TransactionConfiguration(transactionManager = "transactionManager", defaultRollback = true)@Transactional 上面两句的作用是，让我们对数据库的操作会事务回滚，如对数据库的添加操作，在方法结束之后，会撤销我们对数据库的操作。 为什么要事务回滚? 测试过程对数据库的操作，会产生脏数据，影响数据的正确性 不方便循环测试，即假如这次将一个记录删除了，下次就无法再进行这个Junit测试了，因为该记录已经删除，将会报错。 如果不使用事务回滚，需要在代码中显式的对增删改数据库操作进行恢复，将多很多和测试无关的代码 这里需要注意，如果使用了事物回滚。那么有些时候对数据库内容进行修改操作后你将不能直观的看到变化。如何判断是否成功了，可以在返回的数据中带上data字段，将修改的数据存进去传向前台。 使用andExpect方法对返回的数据进行判断，用“$.属性”获取里面的数据，如要获取返回数据中的”data.name”，可以写成”$.data.name”。下面的例子是判断返回的 data.name = “测试”。 1MockHttpServletRequestBuilder.andExpect(jsonPath("$.data.name", is("##")))) ####不同环境的测试 @ActiveProfiles(profiles = &quot;test&quot;) 在测试类上面指定profiles，可以改变当前spring 的profile，来达到多环境的测试]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>MockMvc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + Mybatis]]></title>
    <url>%2Fframe-springboot-mybatis.html</url>
    <content type="text"><![CDATA[Pom12345678910111213141516171819202122232425262728293031323334&lt;!-- 移除 tomcat-jdbc, Spring Boot 将会自动使用 HikariCP --&gt;&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;2.6.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 数据库选用 Mariadb --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mariadb.jdbc&lt;/groupId&gt; &lt;artifactId&gt;mariadb-java-client&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.mybatis.spring.boot/mybatis-spring-boot-starter --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;!-- 移除 Tomcat 的jdbc连接池，使用 HikariCP --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;6.0.6&lt;/version&gt;&lt;/dependency&gt; MyBatis-Spring-Boot-Starter依赖将会： 自动检测现有的DataSource 将创建并注册SqlSessionFactory的实例，该实例使用SqlSessionFactoryBean将该DataSource作为输入进行传递 将创建并注册从SqlSessionFactory中获取的SqlSessionTemplate的实例。 自动扫描mappers，将它们链接到SqlSessionTemplate并将其注册到Spring上下文，以便将其注入到你的bean中。 就是说，使用了该Starter之后，只需要定义一个DataSource即可（application.properties中可配置），它会自动创建使用该DataSource的SqlSessionFactoryBean以及SqlSessionTemplate。会自动扫描你的Mappers，连接到SqlSessionTemplate，并注册到Spring上下文中。 自定义数据源12345678910111213141516171819202122232425@SpringBootApplicationpublic class SbmybatisApplication &#123; @Autowired Environment environment; public static void main(String[] args) &#123; SpringApplication.run(SbmybatisApplication.class, args); &#125; @Bean(destroyMethod = "shutdown") public DataSource dataSource() &#123; HikariDataSource hikariDataSource = new HikariDataSource(); hikariDataSource.setJdbcUrl(environment.getProperty("spring.datasource.hikari.jdbc-url")); hikariDataSource.setUsername(environment.getProperty("spring.datasource.hikari.username")); hikariDataSource.setPassword(environment.getProperty("spring.datasource.hikari.password")); hikariDataSource.setMaximumPoolSize(Integer.parseInt(environment.getProperty("spring.datasource.hikari.maximum-pool-size"))); hikariDataSource.setMinimumIdle(Integer.parseInt(environment.getProperty("spring.datasource.hikari.minimum-idle"))); hikariDataSource.setConnectionTestQuery(environment.getProperty("spring.datasource.hikari.connection-test-query")); hikariDataSource.setIdleTimeout(Long.parseLong(environment.getProperty("spring.datasource.hikari.idle-timeout"))); hikariDataSource.setMaxLifetime(Long.parseLong(environment.getProperty("spring.datasource.hikari.max-lifetime"))); hikariDataSource.setConnectionTimeout(Long.parseLong(environment.getProperty("spring.datasource.hikari.connection-timeout"))); return hikariDataSource; &#125;&#125; 初始化脚本1234567891011121314DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `id` bigint(11) NOT NULL, `username` varchar(9) NOT NULL, `password` varchar(10) NOT NULL, `uri` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- ------------------------------ Records of user-- ----------------------------INSERT INTO `user` VALUES (&apos;1&apos;, &apos;冀永光&apos;, &apos;jyg0723&apos;, &apos;http://www.jiyongguang.xin/&apos;);INSERT INTO `user` VALUES (&apos;2&apos;, &apos;李亚男&apos;, &apos;lyn0723&apos;, &apos;http://www.jiyongguang.xin/&apos;); Model123456789@Data@AllArgsConstructorpublic class User &#123; private long id; private String username; private String password; private String uri;&#125; Controller123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Controller@Log4j2@RequestMapping(path = "/user")public class UserController &#123; @Autowired UserService userService; @RequestMapping(path = "/query", method = RequestMethod.GET, produces = "application/json;charset=UTF-8") @ResponseBody public String queryAllUser() &#123; log.info("UserController -/ queryAllUser"); String userString = userService.queryAllUser().toString(); log.info("userList", userService.queryAllUser()); return JsonUtil.getJsonString(JsonUtil.REQUEST_SUCCESS, userString); &#125; @RequestMapping(path = "/add", method = RequestMethod.POST) @ResponseBody public String addUser(@RequestParam String username, @RequestParam String password, @RequestParam String uri) &#123; log.info("UserController -/ addUser"); log.info("username:" + username + " - password:" + password + " - uri:" + uri); return JsonUtil.getJsonString(userService.addUser(username, password, uri)); &#125; @RequestMapping(path = "/update", method = RequestMethod.POST) @ResponseBody public String updateUser(@RequestParam String username, @RequestParam String password, @RequestParam String uri, @RequestParam long id) &#123; log.info("UserController -/ updateUser"); log.info("username:" + username + " - password:" + password + " - uri:" + uri + " - id:" + id); return JsonUtil.getJsonString(userService.updateUser(username, password, uri, id)); &#125; @RequestMapping(path = "/delete", method = RequestMethod.POST) @ResponseBody public String deleteUser(@RequestParam String id) &#123; log.info("UserController -/ deleteUser - id: " + id, id); return JsonUtil.getJsonString(userService.deleteUser(Long.parseLong(id))); &#125; @RequestMapping(path = "/queryone", method = RequestMethod.GET) public String queryUserById(@RequestParam String id, Model model) &#123; log.info("UserController -/ queryUserById - id: " + id, id); User user = userService.queryUserById(Long.parseLong(id)); model.addAttribute("user", user); return "update"; &#125;&#125; 注解方式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263@Mapper@Component@SuppressWarnings("ALL")public interface UserDao &#123; @Select("select * from user where id = #&#123;id&#125;") User queryUserById(@Param("id") Long id); @Select("select * from user") @Results(id = "userList", value = &#123; @Result(id = true, column = "id", property = "id", javaType = Long.class, jdbcType = JdbcType.BIGINT), @Result(column = "username", property = "username", javaType = String.class, jdbcType = JdbcType.VARCHAR), @Result(column = "password", property = "password", javaType = String.class, jdbcType = JdbcType.VARCHAR), @Result(column = "uri", property = "uri", javaType = String.class, jdbcType = JdbcType.VARCHAR) &#125;) List&lt;User&gt; queryAllUser(); // 模糊查询 @SelectProvider(type = UserSqlBuilder.class, method = "queryUserByParams") List&lt;User&gt; queryUserByCondition(Map&lt;String, Object&gt; params); @Insert("insert into user(username,password,uri) values(#&#123;username&#125;,#&#123;password&#125;,#&#123;uri&#125;) ") Integer addUser(@Param("username") String username, @Param("password") String password, @Param("uri") String uri); @Update("update user set username=#&#123;username&#125;,password=#&#123;password&#125;,uri=#&#123;uri&#125; where id = #&#123;id&#125;") Integer updateUser(@Param("username") String username, @Param("password") String password, @Param("uri") String uri, @Param("id") Long id); @Delete("delete from user where id = #&#123;id&#125;") Integer deleteUser(@Param("id") Long id); @DeleteProvider(type = UserSqlBuilder.class, method = "deleteUserById") Integer deleteUserById(@Param("ids") String[] ids); @Log4j2 class UserSqlBuilder &#123; public String queryUserByParams(final Map&lt;String, Object&gt; params) &#123; StringBuilder sql = new StringBuilder("select * from user where 1=1"); if (!StringUtils.isEmpty((String) params.get("username"))) &#123; sql.append("and username like '%").append((String) params.get("username")).append("'%"); &#125; else if (!StringUtils.isEmpty((String) params.get("uti"))) &#123; sql.append("and uri like '%").append((String) params.get("uri")).append("%'"); &#125; log.info("查询的sql语句：" + sql.toString()); return sql.toString(); &#125; public String deleteUserById(final String[] ids) &#123; StringBuilder sql = new StringBuilder("delete from user where id in("); for (int i = 0; i &lt; ids.length; ++i) &#123; if (i == ids.length - 1) &#123; sql.append(ids[i]); &#125; else &#123; sql.append(ids[i]).append(","); &#125; &#125; sql.append(")"); log.info("删除的sql语句：" + sql.toString()); return sql.toString(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>HikariCP</tag>
        <tag>MariaDB</tag>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + JdbcTemplate]]></title>
    <url>%2Fframe-springboot-jdbctemplate.html</url>
    <content type="text"><![CDATA[pom.xml12345678910111213141516171819202122232425&lt;!-- 移除 Tomcat 的jdbc连接池，使用 HikariCP --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 移除 tomcat-jdbc, Spring Boot 将会自动使用 HikariCP --&gt;&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;2.6.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 数据库选用 Mariadb --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mariadb.jdbc&lt;/groupId&gt; &lt;artifactId&gt;mariadb-java-client&lt;/artifactId&gt; &lt;version&gt;2.0.3&lt;/version&gt;&lt;/dependency&gt; application.properties12345678910111213141516171819### 数据源信息spring.datasource.hikari.driver-class-name=spring.datasource.hikari.jdbc-url=spring.datasource.hikari.username=spring.datasource.hikari.password=#等待连接池分配连接的最大时长（毫秒）spring.datasource.hikari.connection-timeout=#初始化时建立连接的个数spring.datasource.hikari.connection-init-sql=#最大连接池数量spring.datasource.hikari.maximum-pool-size=#最小连接池数量spring.datasource.hikari.minimum-idle=-#检测连接是否有效的sqlspring.datasource.hikari.connection-test-query=#一个连接idle状态的最大时长（毫秒）超时则被释放（retired）缺省:10分钟spring.datasource.hikari.idle-timeout=#一个连接的生命时长（毫秒），超时而且没被使用则被释放（retired），缺省:30分钟spring.datasource.hikari.max-lifetime= 自定义DataSource1234567891011121314@Bean(destroyMethod = "shutdown")public DataSource dataSource() &#123; HikariDataSource hikariDataSource = new HikariDataSource(); hikariDataSource.setJdbcUrl(environment.getProperty("spring.datasource.hikari.jdbc-url")); hikariDataSource.setUsername(environment.getProperty("spring.datasource.hikari.username")); hikariDataSource.setPassword(environment.getProperty("spring.datasource.hikari.password")); hikariDataSource.setMaximumPoolSize(Integer.parseInt(environment.getProperty("spring.datasource.hikari.maximum-pool-size"))); hikariDataSource.setMinimumIdle(Integer.parseInt(environment.getProperty("spring.datasource.hikari.minimum-idle"))); hikariDataSource.setConnectionTestQuery(environment.getProperty("spring.datasource.hikari.connection-test-query")); hikariDataSource.setIdleTimeout(Long.parseLong(environment.getProperty("spring.datasource.hikari.idle-timeout"))); hikariDataSource.setMaxLifetime(Long.parseLong(environment.getProperty("spring.datasource.hikari.max-lifetime"))); hikariDataSource.setConnectionTimeout(Long.parseLong(environment.getProperty("spring.datasource.hikari.connection-timeout"))); return hikariDataSource;&#125; 这里注意，并不需要指定DriverClassName，除非系统无法自动识别。 脚本初始化1234567891011121314DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `id` bigint(11) NOT NULL, `username` varchar(9) NOT NULL, `password` varchar(10) NOT NULL, `uri` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- ------------------------------ Records of user-- ----------------------------INSERT INTO `user` VALUES (&apos;1&apos;, &apos;冀永光&apos;, &apos;jyg0723&apos;, &apos;http://www.jiyongguang.xin/&apos;);INSERT INTO `user` VALUES (&apos;2&apos;, &apos;李亚男&apos;, &apos;lyn0723&apos;, &apos;http://www.jiyongguang.xin/&apos;); JdbcTemplateSpring的JdbcTemplate是自动配置的，你可以直接使用@Autowired来注入到你自己的bean中来使用。 1234567891011121314151617181920212223242526@Repositorypublic class UserDaoImp implements UserDao &#123; @Autowired JdbcTemplate jdbcTemplate; @Override public List&lt;User&gt; queryUserList() &#123; return jdbcTemplate.queryForObject("SELECT * FROM user WHERE username = ?", List.class); // required Type &#125; @Override public Integer addUser(String username, String passowrd, String uri) &#123; return jdbcTemplate.update("INSERT INTO user(username,password,uri) VALUES(?,?,?)", username, passowrd, uri); &#125; @Override public Integer updateUser(String username, String passowrd, String uri, long id) &#123; return jdbcTemplate.update("UPDATE user SET usernmae=?,password=?,uri=? WHERE id = ?", username, passowrd, uri, id); &#125; @Override public Integer deleteUserById(long id) &#123; return jdbcTemplate.update("DELETE FROM user WHERE id=?", id); &#125;&#125;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>HikariCP</tag>
        <tag>MariaDB</tag>
        <tag>JdbcTemplate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot默认日志logback配置解析]]></title>
    <url>%2Fframe-springboot-log.html</url>
    <content type="text"><![CDATA[默认日志LogbackLogback是log4j框架的作者开发的新一代日志框架，它效率更高、能够适应诸多的运行环境，同时天然支持SLF4J。 默认情况下，Spring Boot会用Logback来记录日志，并用INFO级别输出到控制台。所以并不需要我们手动添加依赖 Spring Boot为我们提供了很多默认的日志配置，所以，只要将spring-boot-starter-logging作为依赖加入到当前应用的classpath，则”开箱即用”。 日志输出内容元素具体如下： 时间日期：精确到毫秒 日志级别：ERROR，WARN，INFO，DEBUG，TRACE 进程ID 分隔符：--- 标识实际日志的开始 线程名：方括号括起来（可能会截断控制台输出） Logger名：通常使用源代码的类名 日志内容 控制台输出日志级别从低到高分为TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL，如果设置为WARN，则低于WARN的信息都不会输出。 Spring Boot中默认配置ERROR、WARN和INFO级别的日志输出到控制台。还可以通过启动应用程序–debug标志来启用“调试”模式（开发的时候推荐开启）。以下两种方式皆可： 在运行命令后加入--debug标志，如：$ java -jar springTest.jar --debug 在application.properties中配置debug=true，该属性置为true的时候，核心Logger（包含嵌入式容器、hibernate、spring）会输出更多内容，但是你自己应用的DEBUG级别的日志并不会输出。 文件输出默认情况下，Spring Boot将日志输出到控制台，不会写到日志文件。如果要编写除控制台输出之外的日志文件，则需在application.properties中设置logging.file或logging.path属性。 logging.file：设置文件，可以是绝对路径，也可以是相对路径。如：logging.file=my.log 如果只配置 logging.file，会在项目的根路径下生成一个 my.log 日志文件。 如果只配置 logging.path，在 /config/log文件夹生成一个日志文件为 spring.log。 二者不能同时使用，如若同时使用，则只有logging.file生效 默认情况下，日志文件的大小达到10MB时会切分一次，产生新的日志文件，默认级别为：ERROR、WARN、INFO 级别控制所有支持的日志记录系统都可以在Spring环境中设置记录级别（application.properties） 格式为：logging.level.* = LEVEL （规定什么路径下输出什么级别日志） 自定义日志配置由于日志服务一般都在ApplicationContext创建前就初始化了，它并不是必须通过Spring的配置文件控制。因此通过系统属性和传统的Spring Boot外部配置文件依然可以很好的支持日志控制和管理。 根据不同的日志系统，你可以按如下规则组织配置文件名，并且放在src/main/resources目录下面即可。就能被正确加载： Logback：logback-spring.xml, logback-spring.groovy, logback.xml, logback.groovy Log4j：log4j-spring.properties, log4j-spring.xml, log4j.properties, log4j.xml Log4j2：log4j2-spring.xml, log4j2.xml JDK (Java Util Logging)：logging.properties Spring Boot官方推荐优先使用带有-spring的文件名作为你的日志配置（如使用logback-spring.xml，而不是logback.xml），命名为logback-spring.xml的日志配置文件，spring boot可以为它添加一些spring boot特有的配置项。 logback-spring.xml12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration scan="true" scanPeriod="60 seconds" debug="false"&gt; &lt;contextName&gt;logback&lt;/contextName&gt; &lt;property name="log.path" value="E:\\test\\logback.log"/&gt; &lt;!--输出到控制台--&gt; &lt;appender name="console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;!-- &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;/filter&gt;--&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--输出到文件--&gt; &lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;log.path&#125;&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;logback.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="info"&gt; &lt;appender-ref ref="console"/&gt; &lt;appender-ref ref="file"/&gt; &lt;/root&gt; &lt;!-- logback为java中的包 --&gt; &lt;logger name="nuc.jyg.controller"/&gt; &lt;!--logback.LogbackDemo：类的全路径 --&gt; &lt;logger name="nuc.jyg.controller.ThymeleafController" level="WARN" additivity="false"&gt; &lt;appender-ref ref="console"/&gt; &lt;/logger&gt;&lt;/configuration&gt; 根节点包含的属性 scan:当此属性设置为true时，配置文件如果发生改变，将会被重新加载，默认值为true。 scanPeriod:设置监测配置文件是否有修改的时间间隔，如果没有给出时间单位，默认单位是毫秒。当scan为true时，此属性生效。默认的时间间隔为1分钟。 debug:当此属性设置为true时，将打印出logback内部日志信息，实时查看logback运行状态。默认值为false。 属性：设置上下文名称&lt;contextName&gt;每个logger都关联到logger上下文，默认上下文名称为“default”。但可以使用设置成其他名字，用于区分不同应用程序的记录。一旦设置，不能修改,可以通过%contextName来打印日志上下文名称。 1&lt;contextName&gt;logback&lt;/contextName&gt; 属性：设置变量&lt;property&gt;用来定义变量值的标签， 有两个属性，name和value；其中name的值是变量的名称，value的值时变量定义的值。通过定义的值会被插入到logger上下文中。定义变量后，可以使“${}”来使用变量。 1&lt;property name="log.path" value="C:\Users\ASUS-\Desktop\\logback.log" /&gt; 子节点一&lt;appender&gt;appender用来格式化日志输出节点，有俩个属性name和class，class用来指定哪种输出策略，常用就是控制台输出策略和文件输出策略。 控制台输出ConsoleAppender：123456789&lt;!--输出到控制台--&gt;&lt;appender name="console" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; &lt;encoder&gt;表示对日志进行编码： %d{HH: mm:ss.SSS}——日志输出时间 %thread——输出日志的进程名字，这在Web应用以及异步任务处理中很有用 %-5level——日志级别，并且使用5个字符靠左对齐 %logger{36}——日志输出者的名字 %msg——日志消息 %n——平台的换行符 ThresholdFilter为系统定义的拦截器，例如我们用ThresholdFilter来过滤掉ERROR级别以下的日志不输出到文件中。如果不用记得注释掉，不然低于ERROR级别的日志都不会输出。 输出到文件RollingFileAppender另一种常见的日志输出到文件，随着应用的运行时间越来越长，日志也会增长的越来越多，将他们输出到同一个文件并非一个好办法。RollingFileAppender用于切分文件日志： 123456789101112&lt;!--输出到文件--&gt;&lt;appender name="file" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;log.path&#125;&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;logback.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; %contextName [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt;&lt;/appender&gt; 其中重要的是rollingPolicy的定义，上例中&lt;fileNamePattern&gt;logback.%d{yyyy-MM-dd}.log&lt;/fileNamePattern&gt;定义了日志的切分方式——把每一天的日志归档到一个文件中，&lt;maxHistory&gt;30&lt;/maxHistory&gt;表示只保留最近30天的日志，以防止日志填满整个磁盘空间。同理，可以使用%d{yyyy-MM-dd_HH-mm}来定义精确到分的日志切分方式。&lt;totalSizeCap&gt;1GB&lt;/totalSizeCap&gt;用来指定日志文件的上限大小，例如设置为1GB的话，那么到了这个值，就会删除旧的日志。 子节点&lt;root&gt;root节点是必选节点，用来指定最基础的日志输出级别，只有一个level属性。 level：用来设置打印级别，大小写无关：TRACE，DEBUG，INFO，WARN，ERROR，ALL 和 OFF。默认是DEBUG。可以包含零个或多个元素，标识这个appender将会添加到这个loger。 1234&lt;root level="debug"&gt; &lt;appender-ref ref="console" /&gt; &lt;appender-ref ref="file" /&gt;&lt;/root&gt; 子节点&lt;loger&gt;&lt;loger&gt;用来设置某一个包或者具体的某一个类的日志打印级别、以及指定&lt;appender&gt;。&lt;loger&gt;仅有一个name属性，一个可选的level和一个可选的addtivity属性。 name:用来指定受此loger约束的某一个包或者具体的某一个类。 level:用来设置打印级别，大小写无关：TRACE，DEBUG，INFO，WARN，ERROR，ALL 和 OFF，还有一个特俗值INHERITED或同义词NULL代表强制执行上级的级别。如果未设置此属性，那么当前loger将会继承上级的级别。 addtivity:是否向上级loger传递打印信息。默认是true。 多环境日志输出据不同环境（prod:生产环境，test:测试环境，dev:开发环境）来定义不同的日志输出，在 logback-spring.xml 中使用 springProfile 节点来定义，方法如下： 文件名称不是logback.xml，想使用spring扩展profile支持，要以logback-spring.xml命名。（前面提到的springboot扩展） 12345678&lt;!-- 测试环境+开发环境. 多个使用逗号隔开. --&gt;&lt;springProfile name="test,dev"&gt; &lt;logger name="com.dudu.controller" level="info" /&gt;&lt;/springProfile&gt;&lt;!-- 生产环境. --&gt;&lt;springProfile name="prod"&gt; &lt;logger name="com.dudu.controller" level="ERROR" /&gt;&lt;/springProfile&gt; 可以启动服务的时候指定 profile （如不指定使用默认），如指定prod 的方式为： application.properties： 12# 基于配置#spring.profiles.active=prod 代码：1private Logger logger = LoggerFactory.getLogger(this.getClass()); 推荐 自定义一套喜欢的logback-spring.xml来配置，并以logback-spring.xml来命名。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Json解析]]></title>
    <url>%2Ftool-json.html</url>
    <content type="text"><![CDATA[Json 优势JSON 比 XML 更小、更快，更易解析。 什么是 JSON ？ JSON 指的是 JavaScript 对象表示法（JavaScript Object Notation） JSON 是轻量级的文本数据交换格式 JSON - 转换为 JavaScript 对象JavaScript 程序能够使用内建的 eval() 函数，用 JSON 数据来生成原生的 JavaScript 对象。 相比 XML 的不同之处 没有结束标签 更短 读写的速度更快 能够使用内建的 JavaScript eval() 方法进行解析 使用数组 不使用保留字 代码： 12345var employees = [ &#123;"firstName": "Bill", "lastName": "Gates"&#125;, &#123;"firstName": "George", "lastName": "Bush"&#125;, &#123;"firstName": "Thomas", "lastName": "Carter"&#125;]; 123456789101112var JsonObject = &#123; "username": "jyg", "password": "jyg", "city": "us", "birthday": "723", "phone": employees&#125;;document.getElementById("name").innerHTML = JsonObject.usernamedocument.getElementById("password").innerHTML = JsonObject.passworddocument.getElementById("city").innerHTML = JsonObject.citydocument.getElementById("birthday").innerHTML = JsonObject.birthday// document.getElementById("phone").innerHTML = JsonObject.phone JSON 文件 JSON 文件的文件类型是 “.json” JSON 文本的 MIME 类型是 “application/json”]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Json</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fiddler抓包]]></title>
    <url>%2Ftool-fiddler.html</url>
    <content type="text"><![CDATA[什么是 FiddlerFiddler是一个好用的抓包工具，可以将网络传输发送与接受的数据包进行截获、重发、编辑、转存等操作。 Fiddler 抓包简介Fiddler是位于客户端和服务器端的HTTP代理，也是目前最常用的http抓包工具之一 。 它能够记录客户端和服务器之间的所有 HTTP请求，可以针对特定的HTTP请求，分析请求数据、设置断点、修改请求的数据，甚至可以修改服务器返回的数据，功能非常强大，是web调试的利器。 既然是代理，也就是说：客户端的所有请求都要先经过Fiddler，然后转发到相应的服务器，反之，服务器端的所有响应，也都会先经过Fiddler然后发送到客户端。使用了Fiddler之后，web客户端和服务器的请求如下所示： 在打开Fiddler的那一瞬间，它就已经设置好了浏览器的代理了。当你关闭的时候，它又帮你把代理还原了 字段说明Capture Traffic 开启Fiddler想要抓到数据包，要确保Capture Traffic是开启，在 File –&gt; Capture Traffic。开启后再左下角会有显示，也可以直接点击左下角的图标来关闭/开启抓包功能。 请求字段及图标含义解析Fiddler开始工作了，抓到的数据包就会显示在列表里面，下面总结了这些都是什么意思： 名称 含义 # 抓取HTTP Request的顺序，从1开始，以此递增 Result HTTP状态码 Protocol 请求使用的协议，如HTTP/HTTPS/FTP等 Host 请求地址的主机名 URL 请求资源的位置 Body 该请求的大小 Caching 请求的缓存过期时间或者缓存控制值 Content-Type 请求响应的类型 Process 发送此请求的进程：进程ID Comments 允许用户为此回话添加备注 Custom 允许用户设置自定义值 图标 含义 请求已经发往服务器 已从服务器下载响应结果 请求从断点处暂停 响应从断点处暂停 请求使用 HTTP 的 HEAD 方法，即响应没有内容（Body） 请求使用 HTTP 的 POST 方法 请求使用 HTTP 的 CONNECT 方法，使用 HTTPS 协议建立连接隧道 响应是 HTML 格式 响应是一张图片 响应是脚本格式 响应是 CSS 格式 响应是 XML 格式 响应是 JSON 格式 响应是一个音频文件 响应是一个视频文件 响应是一个 SilverLight 响应是一个 FLASH 响应是一个字体 普通响应成功 响应是 HTTP/300、301、302、303 或 307 重定向 响应是 HTTP/304（无变更）：使用缓存文件 响应需要客户端证书验证 服务端错误 会话被客户端、Fiddler 或者服务端终止 Statistics 请求的性能数据分析随意点击一个请求，就可以看到Statistics关于HTTP请求的性能以及数据分析了。 名称 含义 Request Count 选中的session数 Unique Hosts 流量流向的独立目标主机数。如果所有选中的流量都发送到相同的服务器上，则不会显示该字段 Bytes sent HTTP请求头和请求体中向外发送的字节总数。后面括号中分别给出了头和body各自的字节数 Bytes received HTTP请求头和请求体中接收到的所有字节数。在全部计数后面的括号中给出了请求头和请求体各自的字节数 Requests started at Fiddler接收到的第一个请求的第一个字节的时间点 Responses completed at Fiddler发送到客户端的最后一个响应的最后一个字节的时间点 Sequence(clock) duration 第一个请求开始到最后一个响应结束之间的 “时钟时间” Aggregate session duration 所有选中的session从请求到响应之间的时间的和 DNS Lookup time 所有选中的session解析DNS所花费的时间的总和 TCP/IP Connect duration 所有选中session建立TCP/IP连接所花费的时间总和 HTTPS Handshake duration 所有选中session在HTTPS握手上所花费的时间总和 Response Codes 选中session中各个HTTP响应码的计数 Response Bytes by content-type 选中session中响应的各个Content-Type的字节数 Estimated Performance 选中的流量在不同语种(local)地区和连接方式下所需时间的初步估计 Inspectors 查看数据内容Inspectors是用于查看会话的内容，可以详细查看请求的 Headers、Cookies，并且可以对请求体格式化，以 WebForms、JSON、Raw 等方式查看。具体每种方式的区别可以自己感受一下。一般来说，想要查看请求的参数的话，WebForms 的方式就挺直观的。点击Raw就能看到原始的请求头部信息。上半部分是请求的内容，下半部分是响应的内容： AutoResponder 允许拦截指定规则的请求AutoResponder允许你拦截指定规则的请求，并返回本地资源或Fiddler资源，从而代替服务器响应。 字符串匹配（默认）：只要包含指定字符串（不区分大小写），全部认为是匹配 字符串匹配（baidu） 是否匹配 http://www.baidu.com 匹配 http://pan.baidu.com 匹配 http://tieba.baidu.com 匹配 正则表达式匹配：以“regex:”开头，使用正则表达式来匹配，这个是区分大小写的 字符串匹配（regex:.+.(jpg \ gif \ bmp ) $） 是否匹配 http://bbs.fishc.com/Path1/query=foo.bmp&amp;bar 不匹配 http://bbs.fishc.com/Path1/query=example.gif 匹配 http://bbs.fishc.com/Path1/query=example.bmp 匹配 http://bbs.fishc.com/Path1/query=example.Gif 不匹配 这样在Fiddler中设置拦截规则之后，再访问baidu就会被劫持。这里需要注意的是，当我访问www.baidu.com的时候，该网站是基于https协议的。所以看不到请求报文，要想看到需要在fiddler上进行一些配置。这里我为了简单直接访问了http://tieba.baidu.com。还有就是，测试完之后记得将该拦截规则关闭。 反向代理参考：反向代理参考 Composer 自定义请求发送服务器 Composer允许自定义请求发送到服务器，可以手动创建一个新的请求，也可以在会话表中，拖拽一个现有的请求 Parsed模式下你只需要提供简单的URL地址即可（如下图，也可以在RequestBody定制一些属性，如模拟浏览器User-Agent） Filters 请求过滤规则Fiters 是过滤请求用的，左边的窗口不断的更新，当你想看你系统的请求的时候，你刷新一下浏览器，一大片不知道哪来请求，看着碍眼，它还一直刷新你的屏幕。这个时候可以通过过滤规则来过滤掉那些不想看到的请求。 勾选左上角的Use Filters开启过滤器，这里有两个最常用的过滤条件：Zone和Host Zone 指定只显示内网（Intranet）或互联网（Internet）的内容： Host 指定显示某个域名下的会话： Timeline 请求响应时间在左侧会话窗口点击一个或多个请求，Timeline 便会显示指定内容从服务端传输到客户端的时间： Fiddler 设置解密HTTPS的网络数据Fiddler可以通过伪造CA证书来欺骗浏览器和服务器。大概原理就是在浏览器面前Fiddler伪装成一个HTTPS服务器，而在真正的HTTPS服务器面前Fiddler又装成浏览器，从而实现解密HTTPS数据包的目的。 解密HTTPS需要手动开启： Tools - Fiddler Options - HTTPS - Decrypt HTTPS Traffic。一路 ok，yes 下来 此时基于HTTPS协议的请求我们就可以拦截到了，并且我们刚才设置劫持的含有baidu关键字的网站https://www.baidu.com/，也可以访问了。 Fiddler 内置命令与断点FIddler断点功能就是将请求截获下来，但是不发送，这个时候你可以干很多事情，比如说，把包改了，再发送给服务器君。等等 ~ 当茫茫多请求存在在请求列表中时如何快速检索你想要的命令呢。 命令 对应请求项 介绍 示例 ? All 问号后边跟一个字符串，可以匹配出包含这个字符串的请求 ?imooc &gt; Body 大于号后面跟一个数字，可以匹配出请求大小，大于这个数字请求 &gt;1000 &lt; Body 小于号跟大于号相反，匹配出请求大小，小于这个数字的请求 &lt;100 = Result 等于号后面跟数字，可以匹配HTTP返回码 =200 @ Host @后面跟Host，可以匹配域名 @www.baidu.com select Content-Type select后面跟响应类型，可以匹配到相关的类型 select image cls All 清空当前所有请求 cls dump All 将所有请求打包成saz压缩包，保存到“我的文档\Fiddler2\Captures”目录下 dump start All 开始监听请求 start stop All 停止监听请求 stop 断点命令 bpafter All bpafter后边跟一个字符串，表示中断所有包含该字符串的请求 bpafter baidu（输入bpafter解除断点） bpu All 跟bpafter差不多，只不过这个是收到请求了，但是中断响应 bpu baidu（输入bpu解除断点） bps Result 后面跟状态吗，表示中断所有是这个状态码的请求 bps 200（输入bps解除断点） bpv / bpm HTTP方法 只中断HTTP方法的命令，HTTP方法如POST、GET bpv get（输入bpv解除断点） g / Go All 放行所有中断下来的请求 g QuickExec 官网介绍 输入help会带你到命令行的帮助页，上面列举了所有可用的命令。不是很多，而且都很直观。 断点可以直接点击Fiddler下图的图标位置，就可以设置全部请求的断点，断点的命令可以精确设置需要截获那些请求。如下示例： Response乱码时的处理方法有时候看到Response中的HTML是乱码的， 这是因为HTML被压缩了，可以通过两种方法去解压缩。 方法一：点击红框内容“Response body is encouded.Click to decode.” 方法二：选中工具栏中的”Decode”。这样会自动解压缩。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Fiddler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTPP请求方法Get与Post解析]]></title>
    <url>%2Fjava-web-get-post.html</url>
    <content type="text"><![CDATA[两种 HTTP 请求方法：GET 和 POST在客户机和服务器之间进行请求-响应时，两种最常被用到的方法是：GET 和 POST。 GET - 从指定的资源请求数据。 POST - 向指定的资源提交要被处理的数据 GET 方法get方法查询字符串（K/V对）是在 get 请求的 URL 中连带发送的： 1/test/demo_form.asp?name1=value1&amp;name2=value2 有关 GET 请求的其他一些注释： GET 请求可被缓存 GET 请求保留在浏览器历史记录中 GET 请求可被收藏为书签 GET 请求不应在处理敏感数据时使用 GET 请求有长度限制 GET 请求只应当用于取回数据 POST 方法post方法查询字符串（K/V对）是在 post 请求的 HTTP 消息主体中发送的： 123POST /test/demo_form.asp HTTP/1.1Host: w3schools.comname1=value1&amp;name2=value2 有关 POST 请求的其他一些注释： POST 请求不会被缓存 POST 请求不会保留在浏览器历史记录中 POST 不能被收藏为书签 POST 请求对数据长度没有要求 比较 GET 与 POST GET POST 后退按钮/刷新 无害 数据会被重新提交（浏览器应该告知用户数据会被重新提交）。 书签 可收藏为书签 不可收藏为书签 缓存 能被缓存 不能缓存 编码类型 application/x-www-form-urlencoded application/x-www-form-urlencoded 或 multipart/form-data。为二进制数据使用多重编码。 历史 参数保留在浏览器历史中。 参数不会保存在浏览器历史中。 对数据长度的限制 是的。当发送数据时，GET 方法向 URL 添加数据；URL 的长度是受限制的（URL 的最大长度是 2048 个字符）。 无限制。 对数据类型的限制 只允许 ASCII 字符。 没有限制。也允许二进制数据。 安全性 与 POST 相比，GET 的安全性较差，因为所发送的数据是 URL 的一部分。在发送密码或其他敏感信息时绝不要使用 GET ！ POST 比 GET 更安全，因为参数不会被保存在浏览器历史或 web 服务器日志中。 可见性 数据在 URL 中对所有人都是可见的。 数据不会显示在 URL 中。 其他 HTTP 请求方法 方法 描述 HEAD 与 GET 相同，但只返回 HTTP 报头，不返回文档主体。 PUT 上传指定的 URI 表示。 DELETE 删除指定资源。 OPTIONS 返回服务器支持的 HTTP 方法。 CONNECT 把请求连接转换到透明的 TCP/IP 通道。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jQuery ajax - ajax() 方法]]></title>
    <url>%2Fframe-jquery-ajax.html</url>
    <content type="text"><![CDATA[通过 AJAX 加载一段文本：jQuery 代码： 123456789$(document).ready(function () &#123; $("#button").click(function () &#123; htmlobj = $.ajax(&#123; url: "/jquery/test1.txt", async: false &#125;); $("#div").html(htmlobj.responseText); &#125;);&#125;); HTML 代码： 12&lt;div id="div"&gt;&lt;h2&gt;Let AJAX change this text&lt;/h2&gt;&lt;/div&gt;&lt;button id="button" type="button"&gt;Change Content&lt;/button&gt; 定义和用法 ajax() 方法通过 HTTP 请求加载远程数据。 该方法是 jQuery 底层 AJAX 实现。简单易用的高层实现见\$.get, \$.post 等。\$.ajax() 返回其创建的 XMLHttpRequest 对象。大多数情况下你无需直接操作该函数，除非你需要操作不常用的选项，以获得更多的灵活性。 最简单的情况下，\$.ajax() 可以不带任何参数直接使用。 注意：所有的选项都可以通过 $.ajaxSetup() 函数来全局设置。 语法1jQuery.ajax([settings]) 参数 描述 settings 可选。用于配置 Ajax 请求的键值对集合。可以通过 $.ajaxSetup() 设置任何选项的默认值。 参数type 类型：String 默认值: “GET”)。请求方式 (“POST” 或 “GET”)， 默认为 “GET”。注意：其它 HTTP 请求方法，如 PUT 和 DELETE 也可以使用，但仅部分浏览器支持。 url 类型：String 默认值: 当前页地址。发送请求的地址。 data 类型：String 发送到服务器的数据。将自动转换为请求字符串格式。GET 请求中将附加在 URL 后。查看 processData 选项说明以禁止此自动转换。必须为 Key/Value 格式。如果为数组，jQuery 将自动为不同值对应同一个名称。如 {foo:[“bar1”, “bar2”]} 转换为 ‘&amp;foo=bar1&amp;foo=bar2’。 processData 类型：Boolean 默认值: true。默认情况下，通过data选项传递进来的数据，如果是一个对象(技术上讲只要不是字符串)，都会处理转化成一个查询字符串，以配合默认内容类型 “application/x-www-form-urlencoded”。如果要发送 DOM 树信息或其它不希望转换的信息，请设置为 false。 dataType 类型：String 预期服务器返回的数据类型。如果不指定，jQuery 将自动根据 HTTP 包 MIME 信息来智能判断，比如 XML MIME 类型就被识别为 XML。在 1.4 中，JSON 就会生成一个 JavaScript 对象，而 script 则会执行这个脚本。随后服务器端返回的数据会根据这个值解析后，传递给回调函数。可用值: “xml”: 返回 XML 文档，可用 jQuery 处理。 “html”: 返回纯文本 HTML 信息；包含的 script 标签会在插入 dom 时执行。 “script”: 返回纯文本 JavaScript 代码。不会自动缓存结果。除非设置了 “cache” 参数。注意：在远程请求时(不在同一个域下)，所有 POST 请求都将转为 GET 请求。（因为将使用 DOM 的 script标签来加载） “json”: 返回 JSON 数据 。 “jsonp”: JSONP 格式。使用 JSONP 形式调用函数时，如 “myurl?callback=?” jQuery 将自动替换 ? 为正确的函数名，以执行回调函数。 “text”: 返回纯文本字符串 success 类型：Function 请求成功后的回调函数。 参数：由服务器返回，并根据 dataType 参数进行处理后的数据；描述状态的字符串。 这是一个 Ajax 事件。 其余更多参数的使用可参考：jQuery ajax - ajax() 方法]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Jquery</tag>
        <tag>AJAX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jQuery 与 AJAX]]></title>
    <url>%2Fframe-jquery.html</url>
    <content type="text"><![CDATA[什么是 AJAX？AJAX = 异步 JavaScript 和 XML（Asynchronous JavaScript and XML）。 简短地说，在不重载整个网页的情况下，AJAX 通过后台加载数据，并在网页上进行显示。 使用 AJAX 的应用程序案例：谷歌地图、腾讯微博、优酷视频、人人网等等。 关于 jQuery 与 AJAXjQuery 提供多个与 AJAX 有关的方法。 通过 jQuery AJAX 方法，您能够使用 HTTP Get 和 HTTP Post 从远程服务器上请求文本、HTML、XML 或 JSON - 同时您能够把这些外部数据直接载入网页的被选元素中。 jQuery load() 方法jQuery load() 方法是简单但强大的 AJAX 方法。 load() 方法从服务器加载数据，并把返回的数据放入被选元素中。 语法： 1$(selector).load(URL,data,callback); 必需的 URL 参数规定您希望加载的 URL。 可选的 data 参数规定与请求一同发送的查询字符串键/值对集合。 可选的 callback 参数是 load() 方法完成后所执行的函数名称。 123$("#div1").load("demo_test.txt"); ···$("#div1").load("demo_test.txt #p1"); 可选的 callback 参数规定当 load() 方法完成后所要允许的回调函数。回调函数可以设置不同的参数： responseTxt - 包含调用成功时的结果内容 statusTXT - 包含调用的状态 xhr - 包含 XMLHttpRequest 对象 12345678$("button").click(function() &#123; $("div").load("demo_text.txt", function(responstTXT, statusTxt, xhr) &#123; if (statusTxt == "success") alert("A"); if (statusTxt == "false") alert("B" + xhr.statusText); &#125;);&#125;); 这里需要注意的是：回调函数先执行完，元素中的内容才会进行替换。 完整的 jQuery AJAX 参考手册 jQuery - AJAX get() 和 post() 方法 jQuery get() 和 post() 方法用于通过 HTTP GET 或 POST 请求从服务器请求数据。 HTTP 请求：GET vs POST两种在客户端和服务器端进行请求-响应的常用方法是：GET 和 POST。GET - 从指定的资源请求数据POST - 向指定的资源提交要处理的数据GET 基本上用于从服务器获得（取回）数据。注释：GET 方法可能返回缓存数据。POST 也可用于从服务器获取数据。不过，POST 方法不会缓存数据，并且常用于连同请求一起发送数据。 参考：HTTP 方法 - GET 对比 POST。 jQuery $.get() 方法 $.get() 方法通过 HTTP GET 请求从服务器上请求数据。 语法： 1$.get(URL,callback); 必需的 URL 参数规定您希望请求的 URL。 可选的 callback 参数是请求成功后所执行的函数名。 下面的例子使用 $.get() 方法从服务器上的一个文件中取回数据： 12345$("button").click(function() &#123; $.get("demo_text.jsp", function(data, status) &#123; alert("Data:" + data + "\nStatus:" + status); &#125;);&#125;); 关于回调函数的参数： 第一个回调参数存有被请求页面的内容。 第二个回调参数存有请求的状态。 JSP 文件 (“demo_test.jsp”) 类似这样： 123&lt;% response.getWrite.printf("This is some text from an external JSP file.");%&gt; printf 函数输出的内容即为回调参数 data 中所存的内容。 jQuery $.post() 方法 $.post() 方法通过 HTTP POST 请求从服务器上请求数据。 语法： 1$.post(URL,data,callback); 必需的 URL 参数规定您希望请求的 URL。 可选的 data 参数规定连同请求发送的数据。 可选的 callback 参数是请求成功后所执行的函数名。 下面的例子使用 $.post() 连同请求一起发送数据： 123456789$("button").click(function() &#123; $.post("demo_text.jsp", &#123; name: "jiyongguang", password: "jiyongguang" &#125;, function(data, status) &#123; alert("Data:" + data + "\nStatus:" + status) &#125;);&#125;); $.post() 的第一个参数是希望请求的 URL (“demo_text.jsp”)。 然后连同请求（name 和 password）一起发送数据。 “demo_text.jsp” 中的 JSP 脚本读取这些参数，对它们进行处理，然后返回结果。 第三个参数是回调函数。第一个回调参数存有被请求页面的内容，而第二个参数存有请求的状态。 JSP 文件 (“demo_text.jsp”) 类似这样： 123456&lt;% name = request.getParameter("name"); password = request.getParameter("password"); response.getWrite.printf("Dear name " + name); response.getWrite.printf("Your password is " + password);%&gt; 更多jQuery Ajax 操作函数。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Jquery</tag>
        <tag>AJAX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot自定义配置以及拦截器配置]]></title>
    <url>%2Fframe-springboot-staticAndInterceptor.html</url>
    <content type="text"><![CDATA[在进行 SpringBoot 项目开发的过程中，对于 SpringBoot 自带的默认配置我们难免有自己不喜欢的地方。或者你认为更合理更想要的处理方式，这种时候你就可以选择配置自己的处理逻辑。 如果Spring Boot提供的Sping MVC不符合要求，则可以通过一个配置类（注解有@Configuration的类）加上@EnableWebMvc注解来实现完全自己控制的MVC配置。 12345@EnableWebMvc@Configurationpublic class TestMvc &#123; ···&#125; 通常情况下，Spring Boot的自动配置是符合我们大多数需求的。在你既需要保留Spring Boot提供的便利，有需要增加自己的额外的配置的时候，可以定义一个配置类并继承WebMvcConfigurerAdapter,无需使用@EnableWebMvc注解。 1234@Configurationpublic class TestMvc extends WebMvcConfigurerAdapter&#123; ···&#125; 这里我们提到这个WebMvcConfigurerAdapter这个类，重写这个类中的方法可以让我们增加额外的配置，常用的有如下几个。 自定义资源映射 addResourceHandlers如果想自定义静态资源映射目录的话，只需重写WebMvcConfigurerAdapter类的addResourceHandlers方法即可。 12345678910111213141516171819202122232425262728293031/*** &#123;@inheritDoc&#125;* &lt;p&gt;This implementation is empty.** @param registry*/@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler("/illuos1ion/**").addResourceLocations("classpath:/illuos1ion/"); super.addResourceHandlers(registry); &#125;/ ========================================================================================= / // WebMvcAutoConfiguration public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if(!this.resourceProperties.isAddMappings()) &#123; logger.debug("Default resource handling disabled"); &#125; else &#123; Integer cachePeriod = this.resourceProperties.getCachePeriod(); if(!registry.hasMappingForPattern("/webjars/**")) &#123; this.customizeResourceHandlerRegistration(registry.addResourceHandler(new String[]&#123;"/webjars/**"&#125;).addResourceLocations(new String[]&#123;"classpath:/META-INF/resources/webjars/"&#125;).setCachePeriod(cachePeriod)); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if(!registry.hasMappingForPattern(staticPathPattern)) &#123; this.customizeResourceHandlerRegistration(registry.addResourceHandler(new String[]&#123;staticPathPattern&#125;).addResourceLocations(this.resourceProperties.getStaticLocations()).setCachePeriod(cachePeriod)); &#125; &#125;&#125; 通过addResourceHandler添加映射路径，然后通过addResourceLocations来指定资源文件路径。 访问自定义illuos1ion文件夹中的 item-video.png 图片的地址为 http://localhost:8080/illuos1ion/item-video.png 如果想指定外部的文件目录也很简单，直接通过addResourceLocations方法指定即可： 12345@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler("/my/**").addResourceLocations("file:E:/illuos1ion/"); super.addResourceHandlers(registry);&#125; addResourceLocations 指的是文件放置的目录，addResoureHandler 指的是对外暴露的访问路径 页面跳转 addViewControllers重写 WebMvcConfigurerAdapter 中的 addViewControllers 方法即可达到你想要的处理效果： 12345678910/** * 过去要访问一个页面需要先创建个Controller控制类，再写方法跳转到页面 * 在这里配置后就不需要那么麻烦了，直接访问http://localhost:8080/toLogin就跳转到login.jsp页面了 * @param registry */@Overridepublic void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/toLogin").setViewName("login"); super.addViewControllers(registry);&#125; 需要注意的是，在这里重写addViewControllers方法，并不会覆盖WebMvcAutoConfiguration中的addViewControllers（在此方法中，Spring Boot将“/”映射至index.html），这也就意味着我们自己的配置和Spring Boot的自动配置同时有效。 拦截器addInterceptors拦截器在项目中经常使用的，这里介绍下最简单的判断是否登录的使用。要实现拦截器功能需要完成2个步骤： 创建自己的拦截器类并实现 HandlerInterceptor 接口 重写WebMvcConfigurerAdapter类中的addInterceptors方法把自定义的拦截器类添加进来即可 拦截器代码：12345678910111213141516171819202122232425@Componentpublic class LoginInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; boolean flag; User user = (User) request.getSession().getAttribute("user"); if (user == null) &#123; response.sendRedirect("/login"); flag = false; &#125; else &#123; flag = true; &#125; return flag; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 这里简单实现了根据session中是否有User对象来判断是否登录，为空就跳转到登录页，不为空就通过。 接着，重写WebMvcConfigurerAdapter类中的addInterceptors方法： Web配置代码：123456789101112131415@Configurationpublic class WebMvcConfiguration extends WebMvcConfigurerAdapter&#123; @Autowired LoginInterceptor loginInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) &#123; // addPathPatterns 用于添加拦截规则 // excludePathPatterns 用户排除拦截 // 映射为 user 的控制器下的所有映射 registry.addInterceptor(loginInterceptor).addPathPatterns("/login/home").excludePathPatterns("/index", "/"); super.addInterceptors(registry); &#125;&#125; 拦截器执行流程参考：http://www.jianshu.com/p/f14ed6ca4e56 addPathPatterns(&quot;/login/home&quot;)对/login/home请求拦截，但是排除了/index和/请求的拦截。 Html登录代码：123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"/&gt; &lt;title&gt;Login&lt;/title&gt; &lt;link rel="stylesheet" href="/webjars/bootstrap/3.3.7-1/css/bootstrap.min.css"/&gt; &lt;script type="text/javascript" src="/webjars/jquery/3.2.1/jquery.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form class="form-horizontal" role="form" method="post" action="/login/process"&gt; &lt;div class="form-group"&gt; &lt;!--&lt;span class="input-group-addon"&gt;用户名&lt;/span&gt;--&gt; &lt;label class="control-label col-sm-2" for="username"&gt;用户名:&lt;/label&gt; &lt;div class="col-sm-10"&gt; &lt;input type="text" id="username" name="username" class="form-control" placeholder="Username"/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;!--&lt;span class="input-group-addon"&gt;密码&lt;/span&gt;--&gt; &lt;label class="control-label col-sm-2" for="password"&gt;密 码:&lt;/label&gt; &lt;div class="col-sm-10"&gt; &lt;input type="text" id="password" name="password" class="form-control" placeholder="Password"/&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="form-group"&gt; &lt;div class="col-sm-offset-2 col-sm-10"&gt; &lt;button type="submit" class="btn btn-info"&gt;登 录&lt;/button&gt; &lt;button type="submit" class="btn btn-info"&gt;注 册&lt;/button&gt; &lt;/div&gt; &lt;/div&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 控制器代码：12345678910111213141516171819202122232425262728@Controller@RequestMapping(path = "/login")public class LoginController &#123; @RequestMapping(path = "/process", method = RequestMethod.POST) public String login(@RequestParam String username, @RequestParam String password, HttpServletRequest request) &#123; if (username.equals("admin") &amp;&amp; password.equals("admin")) &#123; User user = new User(username, password, "http://www.jiyongguang.xin"); request.getSession().setAttribute("user", user); return "redirect:/login/home"; &#125; return "redirect:/"; &#125; @RequestMapping(path = "/home", method = RequestMethod.GET) public String home(Model model) &#123; List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); User user = new User("jyg", "jyg", "http://www.jiyongguang.xin"); userList.add(user); user = new User("lyn", "lyn", "http://www.jiyongguang.xin"); userList.add(user); model.addAttribute("userList", userList); return "home"; &#125;&#125; 或者可以通过Jquery封装好的AJAX方法来执行一套请求。效果是一样的 1234567891011121314151617181920$(document).ready(function () &#123; $("#login").click(function () &#123; $.ajax(&#123; type: "POST", url: "/login/process", data: &#123; username: $("#username").val(), password: $("#password").val() &#125;, dataType: "json", success: function (data) &#123; if (data.code == 1) &lt;!-- 当前页面打开URL页面 --&gt; window.location.href = "/login/home"; else alert("账号密码不能为空！"); &#125; &#125;); &#125;);&#125;); 控制器代码： 1234567891011121314@RequestMapping(value = "/process", method = RequestMethod.POST)@ResponseBodypublic String index(@RequestParam String username, @RequestParam String password, HttpServletRequest request) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;(); if (username.equals("admin") &amp;&amp; password.equals("admin")) &#123; User user = new User(username, password, "http://www.jiyongguang.xin"); request.getSession().setAttribute("user", user); return JsonUtil.getJsonString(JsonUtil.REQUEST_SUCCESS); &#125; else &#123; return JsonUtil.getJsonString(JsonUtil.REQUEST_Fail, "用户名或密码错误"); &#125;&#125; 这样访问/login/home的时候，如果未登录就会跳转到login.html页面(注意缓存)，而访问http://localhost:8080/index和http://localhost:8080不会被拦截。 更多配置可以查看WebMvcConfigurerAdapter的类的API。因其是WebMvcConfigurer接口的实现，所以WebMvcConfigurer的API方法也可以用来配置MVC。只是实现这个接口的话，要实现所有的方法，这个就比较麻烦了。所以还是推荐使用继承WebMvcConfigurerAdapter类来处理。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>AJAX</tag>
        <tag>SpringBoot</tag>
        <tag>Interceptor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot集成Webjar管理前端文件]]></title>
    <url>%2Fframe-springboot-webjar.html</url>
    <content type="text"><![CDATA[今天在使用bootstrap搭建前台模板的时候还像过去文件引用方式引用bootstrap的css和js文件发现都没有用。 静态资源目录结构如下： 代码如下： 12345&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;BRACKETS 入门&lt;/title&gt; &lt;link rel="stylesheet" href="/css/bootstrap.min.css"&gt;&lt;/head&gt; 经过网上一番查阅之后看到，暂时仍旧没有找到原因。(找到原因会写出来)，后来我果断摒弃了这种做法。选用webjar来管理前台资源文件，因为通过手工进行管理，容易导致文件混乱、版本不一致等问题。而WebJars是将这些通用的Web前端资源打包成Java的Jar包，然后借助Maven工具对其管理，保证这些web资源版本唯一性，升级也比较容易。 关于webjars资源，有一个专门的网站http://www.webjars.org/，我们可以到这个网站上找到自己需要的资源，在自己的工程中添加入maven依赖，即可直接使用这些资源了。 Pom.xml 12345678910111213141516 &lt;!-- https://mvnrepository.com/artifact/org.webjars/webjars-locator --&gt;&lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;webjars-locator&lt;/artifactId&gt; &lt;version&gt;0.32-1&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;bootstrap&lt;/artifactId&gt; &lt;version&gt;3.3.7-1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.2.1&lt;/version&gt;&lt;/dependency&gt; webjars-locator 包的作用是省略 webjar 的版本。比如对于请求 http://localhost:8080/webjars/jquery/3.1.0/jquery.js省略版本号 3.2.1 直接使用http://localhost:8080/webjars/jquery/jquery.js也可访问。 Html 页面引用资源文件 原： 1&lt;link rel="stylesheet" href="/css/bootstrap.min.css"/&gt; 现： 1&lt;link rel="stylesheet" href="/webjars/bootstrap/css/bootstrap.min.css"/&gt; 其他资源文件引用方式：cdn加速服务 1&lt;link href="https://cdn.bootcss.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet"&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>BootStrap</tag>
        <tag>SpringBoot</tag>
        <tag>CSS</tag>
        <tag>JavaScript</tag>
        <tag>JQuery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bootstrap中data-toggle与data-target]]></title>
    <url>%2Fframe-bootstrap-data.html</url>
    <content type="text"><![CDATA[data-toggle data-toggle 指以什么事件触发，常用的如 modal，popover，tooltips，dropdown 等 data-target data-target 指事件的目标，一起使用就是代表 data-target 所指的元素以 data-toggle 指定的形式显示 aria-label图标的可访问性： 现代的辅助技术能够识别并朗读由 CSS 生成的内容和特定的 Unicode 字符。为了避免 屏幕识读设备抓取非故意的和可能产生混淆的输出内容（尤其是当图标纯粹作为装饰用途时），我们为这些图标设置了 aria-hidden=”true” 属性。 如果你使用图标是为了表达某些含义（不仅仅是为了装饰用），请确保你所要表达的意思能够通过被辅助设备识别，例如，包含额外的内容并通过 .sr-only 类让其在视觉上表现出隐藏的效果。 如果你所创建的组件不包含任何文本内容（例如， &lt;button&gt;内只包含了一个图标），你应当提供其他的内容来表示这个控件的意图，这样就能让使用辅助设备的用户知道其作用了。这种情况下，你可以为控件添加 aria-label 属相。 control-label Bootstrap 默认情况下，control-label 的文本采用右对齐方式。这种方式在Form中如果含有checkbox等控件情况下，实际对齐方式很难看。我们可以将其修改为左对齐方式。具体在bootstrap的css文件中，搜索.form-horizontal .control-label sr-only .sr-only是 除了屏幕阅读器外，其他设备上隐藏该元素，这个是用于屏幕阅读器的，帮助残障人士更好的访问网站。 xmlns 定义了一个命名空间，浏览器会将此命名空间用于该属性所在元素内的所有内容。 例如，如果需要使用符合 XML 规范的 XHTML 文档，则应该在文档中的 标签中至少使用一个 xmlns 属性，以指定整个文档所使用的主要命名空间： 1&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt; 如果需要在一个 div 元素中显示一串数学公式，则可以为该 div 元素定义一个数学命名空间。比如这样： 1&lt;div xmlns="http://www.w3.org/1999/Math/MathMl"&gt;x3/x&lt;/div&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>BootStrap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中专业词汇]]></title>
    <url>%2Fjava-keywords-set.html</url>
    <content type="text"><![CDATA[响应式布局 响应式布局是Ethan Marcotte在2010年5月份提出的一个概念，简而言之，就是一个网站能够兼容多个终端——而不是为每个终端做一个特定的版本。这个概念是为解决移动互联网浏览而诞生的。 CDNCDN的全称是Content Delivery Network，即内容分发网络。其基本思路是尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度 组件 一个网站，一个App或者一个系统的构建 一些零件的组合 Dom DOM 全称是 Document Object Model，也就是文档对象模型。 以编程的方法操作这个 HTML 的内容（比如添加某些元素、修改元素的内容、删除某些元素），我们把这个 HTML 看做一个对象树（DOM树），它本身和里面的所有东西比如 这些标签都看做一个对象，每个对象都叫做一个节点（node），节点可以理解为 DOM 中所有 Object 的父类。 DOM 的作用： 为了操作 HTML 中的元素，比如说我们要通过 JS 把这个网页的标题改了，直接这样就可以了： 1document.title = 'how to make love'; 这个 API 使得在网页被下载到浏览器之后改变网页的内容成为可能。 DOM 是为了操作文档出现的 API，document 是其的一个对象。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot开发Web应用集成Thymeleaf(官方推荐)]]></title>
    <url>%2Fframe-springboot-thymeleaf.html</url>
    <content type="text"><![CDATA[spring-boot-starter-webSpring Boot提供了spring-boot-starter-web为Web开发予以支持，spring-boot-starter-web为我们提供了嵌入的Tomcat以及Spring MVC的依赖。 Spring MVC自动配置Spring Boot为Spring MVC提供适用于多数应用的自动配置功能。在Spring默认基础上，自动配置添加了以下特性： 引入ContentNegotiatingViewResolver和BeanNameViewResolver beans。 对静态资源的支持，包括对WebJars的支持。 自动注册Converter，GenericConverter，Formatter beans。 对HttpMessageConverters的支持。 自动注册MessageCodeResolver。 对静态index.html的支持。 对自定义Favicon的支持。 如果想要自己完全控制WebMVC配置，就需要在@Configuration注解的配置类上增加@EnableWebMvc注解。增加该注解以后WebMvcAutoConfiguration中配置就不会生效，你需要自己来配置需要的每一项。这种情况下的配置还是要多看一下WebMvcAutoConfiguration类(上面7个默认配置就在此处设定)。 12345@EnableWebMvc@Configurationpublic class TestMvc &#123; ···&#125; 如果想保留Spring Boot MVC的特性(应用默认配置)，并只是添加自定义的MVC配置(拦截器，formatters，视图控制器等)，你可以自定义一个配置类并继承WebMvcConfigurerAdapter类。在类中通过配置@Bean方法来注册自己想要的bean甚至是自定义的bean。或重写父类某一方法实现自己的处理逻辑 123456789101112131415161718192021222324@Configurationpublic class CustomizeWebMvcConfiguration extends WebMvcConfigurerAdapter &#123; ··· @Bean public BeanNameViewResolver beanNameViewResolver () &#123; return new BeanNameViewResolver(); // 示例代码 &#125; /* 一个道理 &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="viewClass" value="org.springframework.web.servlet.view.JstlView"/&gt; &lt;property name="prefix" value="/WEB-INF/jsp/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; */ @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; registry.addResourceHandler("/webjar/**").addResourceLocations("classpath:/webjar/"); super.addResourceHandlers(registry); &#125; ···&#125; 当你使用@EnableWebMvc来配置spring mvc时，会把WebMvcConfigurationSupport当成配置文件来用，将其中所有标识有@Bean注解的方法配置成bean，这就成了Spring mvc的默认配置 123public class WebMvcConfigurationSupport implements ApplicationContextAware, ServletContextAware &#123; ····&#125; 各个组件都是可以定制化的，在WebMvcConfigurationSupport是通过模板方法模式来实现的，在各个发布成Bean的方法中(@Bean)，都调用了自定义组件的抽象方法，所以可以在其在子类中对这些组件进行覆盖，如： 对HandlerAdapter组件，有addInterceptors(InterceptorRegistry registry)可以添加自己的拦截器； 对conversionService组件，有addFormatters(FormatterRegistry registry)可以添加自己的类型转换器； ··· 从而实现定制化。 上面提到子类，Spring mvc提供的默认实现是DelegatingWebMvcConfiguration，覆盖父类的方法之前，它会寻找容器中所有的WebMvcConfigurer实现类，将所有WebMvcConfigurer实现类中的配置组合起来，组成一个超级配置，再对WebMvcConfigurationSupport中对应的发布成Bean的方法进行覆盖。这样，WebMvcConfigurationSupport中的bean配置发布时，就会把这所有自定义配置都带上了。 1234@Configurationpublic class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123; ···&#125; 总的来说就是，WebMvcConfigurationSupport负责bean的发布。分派自己的子类DelegatingWebMvcConfiguration去寻找用户所有实现了WebMvcConfigurer接口的实现类。并将用户所有发布成Bean的方法组合起来。交还给WebMvcConfigurationSupport统一发布并配置。 参考：Spring mvc注解配置的背后 静态文件 默认情况下，Spring Boot从classpath下一个叫/static（/public，/resources或/META-INF/resources）的文件夹或从ServletContext根目录提供静态内容。(这几个都是静态资源的映射路径，优先级顺序为：META-INF/resources &gt; resources &gt; static &gt; public) 对应的配置文件配置如下： 1234# 默认映射，默认值为 /**spring.mvc.static-path-pattern=# 默认值为 classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/spring.resources.static-locations=这里设置要指向的路径，多个使用英文逗号隔开 可以通过修改spring.mvc.static-path-pattern来修改默认的映射，例如改成/thymeleaf/**,那运行的时候访问 http://lcoalhost:8080/thymeleaf/index.html 才对应到index.html页面。 这使用了Spring MVC的ResourceHttpRequestHandler，所以你可以通过添加自己的WebMvcConfigurerAdapter并覆写addResourceHandlers方法来改变这个行为（加载静态文件）。 在一个单独的web应用中，容器默认的servlet是开启的，如果Spring决定不处理某些请求，默认的servlet作为一个回退（降级）将从ServletContext根目录加载内容。大多数时候，这不会发生（除非你修改默认的MVC配置），因为Spring总能够通过DispatcherServlet处理请求。 此外，上述标准的静态资源位置有个例外情况是Webjars内容。任何在/webjars/**路径下的资源都将从jar文件中提供，只要它们以Webjars的格式打包。 注：如果你的应用将被打包成jar，那就不要使用src/main/webapp文件夹。尽管该文件夹是一个共同的标准，但它仅在打包成war的情况下起作用，并且如果产生一个jar，多数构建工具都会静悄悄的忽略它 默认实现类： 123456789class WebMvcConfigurerComposite implements WebMvcConfigurer &#123; ··· @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; for (WebMvcConfigurer delegate : this.delegates) &#123; delegate.addResourceHandlers(registry); &#125; ···&#125; 1234567891011121314151617181920212223public class WebMvcConfigurationSupport implements ApplicationContextAware, ServletContextAware &#123; ··· @Bean public HandlerMapping resourceHandlerMapping() &#123; ResourceHandlerRegistry registry = new ResourceHandlerRegistry(this.applicationContext, this.servletContext, mvcContentNegotiationManager()); // 关键代码 addResourceHandlers(registry); AbstractHandlerMapping handlerMapping = registry.getHandlerMapping(); if (handlerMapping != null) &#123; handlerMapping.setPathMatcher(mvcPathMatcher()); handlerMapping.setUrlPathHelper(mvcUrlPathHelper()); handlerMapping.setInterceptors(new ResourceUrlProviderExposingInterceptor(mvcResourceUrlProvider())); handlerMapping.setCorsConfigurations(getCorsConfigurations()); &#125; else &#123; handlerMapping = new EmptyHandlerMapping(); &#125; return handlerMapping; &#125; ···&#125; 扩展类： 1234567public abstract class WebMvcConfigurerAdapter implements WebMvcConfigurer &#123; ··· @Override public void addResourceHandlers(ResourceHandlerRegistry registry) &#123; &#125; ···&#125; 模板引擎Spring Boot支持多种模版引擎包括： FreeMarker Groovy Thymeleaf(官方推荐) JSP技术Spring Boot官方是不推荐的： Tomcat 只支持war的打包方式，不支持可执行的jar。 Jetty 嵌套的容器不支持jsp Undertow 创建自定义error.jsp页面不会覆盖错误处理的默认视图，而应该使用自定义错误页面 当你使用上述模板引擎中的任何一个，它们默认的模板配置路径为：src/main/resources/templates。 Thymeleaf模板引擎Thymeleaf是一款用于渲染XML/XHTML/HTML5内容的模板引擎。类似JSP，Velocity，FreeMaker等，它也可以轻易的与Spring MVC等Web框架进行集成作为Web应用的模板引擎。与其它模板引擎相比，Thymeleaf最大的特点是能够直接在浏览器中打开并正确显示模板页面，而不需要启动整个Web应用。它的功能特性如下： Spring MVC中@Controller中的方法可以直接返回模板名称，接下来Thymeleaf模板引擎会自动进行渲染 模板中的表达式支持Spring表达式语言（Spring EL) 表单支持，并兼容Spring MVC的数据绑定与验证机制 国际化支持 引入依赖12345&lt;!--thymeleaf模板引擎 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 需要注意的是： spring-boot-starter-thymeleaf会自动包含spring-boot-starter-web，所以我们就不需要单独引入web依赖了。 Model123456@Data@AllArgsConstructorpublic class User &#123; private String username; private String password;&#125; Controller12345678910111213141516@Controller@RequestMapping(value = "/thymeleaf")public class ThymeleafController &#123; @RequestMapping(path = "/", method = RequestMethod.GET) public ModelAndView index() &#123; List&lt;User&gt; userList = new ArrayList&lt;User&gt;(); User user = new User("jyg", "jyg"); userList.add(user); user = new User("lyn", "lyn"); userList.add(user); ModelAndView modelAndView = new ModelAndView("index.html"); modelAndView.addObject("userList", userList); return modelAndView; &#125;&#125; Html 首先通过xmlns:th=”http://www.thymeleaf.org“ 命名 thymeleaf 空间，将静态页面转换为动态的视图，需要进行动态处理的元素将使用“th:”前缀。 1xmlns:th="http://www.thymeleaf.org" 代码： 123456789101112131415&lt;body&gt;&lt;h1&gt;Thymeleaf&lt;/h1&gt;&lt;hr/&gt; &lt;table class="table table-striped table-bordered table-hover"&gt; &lt;tr class="info"&gt; &lt;td&gt;用户名&lt;/td&gt; &lt;td&gt;密码&lt;/td&gt; &lt;/tr&gt; &lt;!--/*@thymesVar id="userList" type=""*/--&gt; &lt;tr th:each="user : $&#123;userList&#125;" class="success"&gt; &lt;td th:text="$&#123;user.username&#125;"&gt;冀永光&lt;/td&gt; &lt;td th:text="$&#123;user.password&#125;"&gt;jiyongguang.&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/body&gt; Thymeleaf 做到了什么直接访问 index.html ： 访问 http://localhost:8080/thymeleaf/： Thymeleaf 做到了不破坏 Html 自身内容的数据逻辑分离。 Thymeleaf的默认参数配置12345678910111213141516171819202122232425# THYMELEAF (ThymeleafAutoConfiguration)#开启模板缓存（默认值：true）spring.thymeleaf.cache=true #Check that the template exists before rendering it.spring.thymeleaf.check-template=true #检查模板位置是否正确（默认值:true）spring.thymeleaf.check-template-location=true#Content-Type的值（默认值：text/html）spring.thymeleaf.content-type=text/html#开启MVC Thymeleaf视图解析（默认值：true）spring.thymeleaf.enabled=true#模板编码spring.thymeleaf.encoding=UTF-8#要被排除在解析之外的视图名称列表，用逗号分隔spring.thymeleaf.excluded-view-names=#要运用于模板之上的模板模式。另见StandardTemplate-ModeHandlers(默认值：HTML5)spring.thymeleaf.mode=HTML5#在构建URL时添加到视图名称前的前缀（默认值：classpath:/templates/）spring.thymeleaf.prefix=classpath:/templates/#在构建URL时添加到视图名称后的后缀（默认值：.html）spring.thymeleaf.suffix=.html#Thymeleaf模板解析器在解析器链中的顺序。默认情况下，它排第一位。顺序从1开始，只有在定义了额外的TemplateResolver Bean时才需要设置这个属性。spring.thymeleaf.template-resolver-order=#可解析的视图名称列表，用逗号分隔spring.thymeleaf.view-names=]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Thymeleaf</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中static关键字详解]]></title>
    <url>%2Fjava-keywords-static.html</url>
    <content type="text"><![CDATA[static关键字的含义?static表示“全局”或者“静态”的意思，用来修饰成员变量和成员方法，也可以形成静态static代码块，但是Java语言中没有全局变量的概念。 什么是static变量？ 被static修饰的成员变量和成员方法独立于该类的任何对象。也就是说，它不依赖类特定的实例，被类的所有实例共享。只要这个类被加载，Java虚拟机就能根据类名在运行时数据区的方法区内定找到他们。因此，static对象可以在它的任何对象创建之前访问，无需引用任何对象。 用public修饰的static成员变量和成员方法本质是全局变量和全局方法，当声明类的对象时，不生成static变量的副本，而是类的所有实例共享同一个static变量。 static变量可以在静态方法中使用，也可以在非静态成员方法中使用。 static表示不要实例化就可以使用 static变量与实例变量​ 按照是否静态的对类成员变量进行分类可分两种：一种是被static修饰的变量，叫静态变量或类变量。另一种是没有被static修饰的变量，叫实例变量。两者的区别是： 对于静态变量在内存中只有一个拷贝（节省内存），JVM只为静态分配一次内存，在加载类的过程中完成静态变量的内存分配，可用类名直接访问（方便），当然也可以通过对象来访问（但是这是不推荐的）。 对于实例变量，每创建一个实例，就会为实例变量分配一次内存，实例变量可以在内存中有多个拷贝，互不影响（灵活）。 static方法 静态方法可以直接通过类名调用，任何的实例也都可以调用，因此静态方法中不能用this和super关键字。 不能直接访问所属类的实例变量和实例方法(就是不带static的成员变量和成员成员方法)，只能访问所属类的静态成员变量和成员方法。因为实例成员与特定的对象关联 因为static方法独立于任何实例，因此static方法必须被实现，而不能是抽象的abstract。 static代码块 static代码块也叫静态代码块，是在类中独立于类成员的static语句块。 可以有多个，位置可以随便放，它不在任何的方法体内，JVM加载类时会执行这些静态的代码块，如果static代码块有多个，JVM将按照它们在类中出现的先后顺序依次执行它们，每个代码块只会被执行一次。 利用静态代码块可以对一些static变量进行赋值 static和final一块用表示什么static final用来修饰成员变量和成员方法，可简单理解为全局常量 对于变量，表示一旦给值就不可修改，并且通过类名可以访问。 对于方法，表示不可覆盖，并且可以通过类名直接访问。 特别要注意一个问题： ​ 对于被static和final修饰过的实例常量，实例本身不能再改变了，但对于一些容器类型（比如，ArrayList、HashMap）的实例变量，不可以改变容器变量本身，但可以修改容器中存放的对象。 12private static final ArrayList&lt;String&gt; alStaticFinalVar = new ArrayList&lt;String&gt;(); alStaticFinalVar.add("aaa"); // 正确，容器变量本身没有变化，但存放内容发生了变化。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中final关键字详解]]></title>
    <url>%2Fjava-keywords-final.html</url>
    <content type="text"><![CDATA[前言今天在看BlockingQueue的一段演示代码的时候看到了这样一段代码：123456public static void main(String[] args) &#123; final BlockingQueue queue = new ArrayBlockingQueue(3); for(int i=0;i&lt;2;i++)&#123; new Thread()&#123; &#125; ······ 省略后序代码 final BlockingQueue queue = new ArrayBlockingQueue(3); 对这里初始化的BlockingQueue对象不太清楚为什么要用final关键字来进行修饰。看来自己对final关键字的认识还是不够。所以去研究了一下 基本概念 当final关键字用于修饰变量时表示该变量的值不可变；静态变量、实例成员变量、形式参数和局部变量都可以被final修饰。 修饰变量的final关键字可以为两种： 1. final修饰基本类型变量：表示该变量的值不能改变，即不能重新赋值，是“编译时常量”（compile-time constant） 2. final修饰引用类型：表示该变量的引用地址不能改变，而引用地址里的内容可以变，是“运行时不变量”（runtime immutable variable） 海子的文章 海子：浅析Java中的final关键字 谈到final关键字，想必很多人都不陌生，在使用匿名内部类的时候可能会经常用到final关键字。另外，Java中的String类就是一个final类，那么今天我们就来了解final这个关键字的用法。下面是本文的目录大纲： final关键字的基本用法 深入理解final关键字 final关键字的基本用法在Java中，final关键字可以用来修饰类、方法和变量（包括成员变量和局部变量），甚至参数。下面就从这几个方面来了解一下final关键字的基本用法。 final修饰类当用final修饰一个类时，表明这个类不能被继承。也就是说，如果一个类你永远不会让他被继承，就可以用final进行修饰。final类中的成员变量可以根据需要设为final，但是要注意final类中的所有成员方法都会被隐式地指定为final方法。 在使用final修饰类的时候，要注意谨慎选择，除非这个类真的在以后不会用来继承或者出于安全的考虑，尽量不要将类设计为final类。 final修饰方法下面这段话摘自《Java编程思想》第四版第143页： “使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升。在最近的Java版本中，不需要使用final方法进行这些优化了。“ 我们对过往final修饰方法的优势大概了解一下。 因此，如果只有在想明确禁止该方法在子类中被覆盖的情况下才将方法设置为final的。 注：类的private方法会隐式地被指定为final方法。 修饰变量修饰变量是final用得最多的地方，也是本文接下来要重点阐述的内容。首先了解一下final变量的基本语法： 对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。 举个例子： 上面的一段代码中，对变量i和obj的重新赋值都报错了。 深入理解final关键字在了解了final关键字的基本用法之后，这一节我们来看一下final关键字容易混淆的地方。 类的final变量和普通变量有什么区别？当用final作用于类的成员变量时，成员变量（注意是类的成员变量，局部变量只需要保证在使用之前被初始化赋值即可）必须在定义时或者构造器中进行初始化赋值，而且final变量一旦被初始化赋值之后，就不能再被赋值了。 那么final变量和普通变量到底有何区别呢？下面请看一个例子： 1234567891011public class Test &#123; public static void main(String[] args) &#123; String a = "hello2"; final String b = "hello"; String d = "hello"; String c = b + 2; String e = d + 2; System.out.println((a == c)); System.out.println((a == e)); &#125;&#125; 结果:12truefalse 大家可以先想一下这道题的输出结果。为什么第一个比较结果为true，而第二个比较结果为fasle。这里面就是final变量和普通变量的区别了，当final变量是基本数据类型以及String类型时，如果在编译期间能知道它的确切值，则编译器会把它当做编译期常量使用。 也就是说在用到该final变量的地方，相当于直接访问的这个常量，不需要在运行时确定。这种和C语言中的宏替换有点像。因此在上面的一段代码中，由于变量b被final修饰，因此会被当做编译器常量，所以在使用到b的地方会直接将变量b 替换为它的 值。而对于变量d的访问却需要在运行时通过链接来进行。想必其中的区别大家应该明白了，不过要注意，只有在编译期间能确切知道final变量值的情况下，编译器才会进行这样的优化 ，比如下面的这段代码就不会进行优化： 12345678910111213public class Test &#123; public static void main(String[] args) &#123; String a = "hello2"; final String b = getHello();// 函数经过掉过才能知道确切的返回值 String c = b + 2; System.out.println((a == c)); &#125; public static String getHello() &#123; return "hello"; &#125;&#125; 这段代码的输出结果为false。因为getHello函数的返回值只有在经过调用才能确定。 被final修饰的引用变量指向的对象内容可变吗？在上面提到被final修饰的引用变量一旦初始化赋值之后就不能再指向其他的对象，那么该引用变量指向的对象的内容可变吗？看下面这个例子： 1234567891011public class Test &#123; public static void main(String[] args) &#123; final MyClass myClass = new MyClass(); System.out.println(++myClass.i); &#125;&#125; class MyClass &#123; public int i = 0;&#125; 这段代码可以顺利编译通过并且有输出结果，输出结果为1。这说明引用变量被final修饰之后，虽然不能再指向其他对象，但是它指向的对象的内容是可变的。 final和static很多时候会容易把static和final关键字混淆，static作用于成员变量用来表示只保存一份副本，而final的作用是用来保证变量不可变。看下面这个例子：12345678910111213141516public class Test &#123; public static void main(String[] args) &#123; MyClass myClass1 = new MyClass(); MyClass myClass2 = new MyClass(); System.out.println(myClass1.i); System.out.println(myClass1.j); System.out.println(myClass2.i); System.out.println(myClass2.j); &#125;&#125; class MyClass &#123; public final double i = Math.random(); public static double j = Math.random();&#125; 运行这段代码就会发现，每次打印的两个j值都是一样的，而i的值却是不同的。从这里就可以知道final和static变量的区别了。 匿名内部类中使用的外部局部变量为什么只能是final变量？这个问题请参见上一篇博文中《Java内部类详解》中的解释，在此处不再赘述。 关于final参数的问题关于网上流传的”当你在方法中不需要改变作为参数的对象变量时，明确使用final进行声明，会防止你无意的修改而影响到调用方法外的变量“这句话，我个人理解这样说是不恰当的。 因为无论参数是基本数据类型的变量还是引用类型的变量，使用final声明都不会达到上面所说的效果。 看这个例子就清楚了： 上面这段代码好像让人觉得用final修饰之后，就不能在方法中更改变量i的值了。殊不知，方法changeValue和main方法中的变量i根本就不是一个变量，因为java参数传递采用的是值传递，对于基本类型的变量，相当于直接将变量进行了拷贝。所以即使没有final修饰的情况下，在方法内部改变了变量i的值也不会影响方法外的i。 再看下面这段代码： 123456789101112131415public class Test &#123; public static void main(String[] args) &#123; MyClass myClass = new MyClass(); StringBuffer buffer = new StringBuffer("hello"); myClass.changeValue(buffer); System.out.println(buffer.toString()); &#125;&#125; class MyClass &#123; void changeValue(final StringBuffer buffer) &#123; buffer.append("world"); &#125;&#125; 运行这段代码就会发现输出结果为helloworld。很显然，用final进行修饰并没有阻止在changeValue中改变buffer指向的对象的内容。有人说假如把final去掉了，万一在changeValue中让buffer指向了其他对象怎么办。有这种想法的朋友可以自己动手写代码试一下这样的结果是什么，如果把final去掉了，然后在changeValue中让buffer指向了其他对象，也不会影响到main方法中的buffer，原因在于java采用的是值传递，对于引用变量，传递的是引用的值，也就是说让实参和形参同时指向了同一个对象，因此让形参重新指向另一个对象对实参并没有任何影响。 所以关于网上流传的final参数的说法，我个人不是很赞同。 重点： Java值传递。 至于方法形参上用final修饰的作用就是防止形参变量指向在函数内发生更改。可参考： 浅谈方法中参数加上final hebaodan的文章 - 更清晰hebaodan：Java关键字final理解 修饰类时：表示该类不允许被继承 修饰方法时：表示该方法在派生类里不允许被覆写（override） 修饰变量时表示该变量的值不可变；静态变量、实例成员变量、形式参数和局部变量都可以被final修饰。修饰变量的final关键字可以为两种: 修饰基本类型变量：表示该变量的值不能改变，即不能重新赋值，是“编译时常量” 修饰引用类型：表示该变量的引用地址不能改变，而引用地址里的内容可以变，是“运行时不变量” 编译时常量 编译时常量：在编译阶段已经可以确定其值的变量 12345678910111213141516171819202122232425/** * @author chenxin * @time 2017-05-06-11:25 */public class FinalTest &#123; public final int a = 1; // 编译时常量 public static final int b = 2; // 编译时常量 public static final Integer c = 3; // 非编译时常量 public static final Type TYPE = Type.D; // 非编译时常量 public final int j; // 非编译时常量 public static final long k = b - 1; // 编译时常量 FinalTest(int j)&#123; this.j = j; &#125; static&#123; System.out.println("触发类初始化"); &#125;&#125; 解释在上述代码中，变量c,TYPE不是基本类型，变量j需要在对象实例化的时候初始化值，为运行时不变量。 实验：12345678910111213141516171819public class FinalMain &#123; public static void main(String[] args) &#123; System.out.println(FinalTest.b); System.out.println(FinalTest.k); System.out.println(FinalTest.c); System.out.println(FinalTest.TYPE); &#125;&#125;运行结果：21触发类初始化3D 说明：由程序执行结果看，在访问变量c,TYPE时触发了类的初始化，验证它们不是编译时常量。 问题：为什么触发类的初始化就不是编译时常量呢，那变量a为何又是呢？(重点) 先看变量a，它虽然没有被static修饰，但通过javap -c FinalTest查看字节码，常量1已经赋值给a了。然而，这么写代码是不优雅的，因为a作为成员变量，每次实例化对象都会在常量池分配内存，导致浪费。所以 ：对于编译时常量，它就需要使用 static 关键字修饰，这样就是类的所有实例共享了。 为何触发类的初始化就不是编译时常量呢？因为编译时常量存在于常量池，也会直接把值嵌入在字节码中,也就是Java虚拟机会将常量直接保存到类文件中。访问时是不需要进行类的初始化(下文解释)的。 编译时常量只有可能是基本类型和String类型，而不可能是任何的引用类型，包括枚举，基本类型的包装类型(因为引用类型如果要做编译时常量必然需要运行时动态确定其引用。而这又与其是编译时常量相矛盾，所以只能是运行时常量) 小测试 public static final int m = new Random().nextInt(); 属于编译时常量吗？ 不属于，值在编译时无法确定。对方法调用获得的值不属于编译时常量。 为什么使用final 定义为常量，在多线程环境下进行共享，一定程度上解决某些并发安全问题。切记需要与static连用 JVM对常量有缓存 方法内部类连本方法的成员变量都不可访问，它只能访问本方法的final型成员,一个典型的示例就是用Spring的transactionTemplate.execute，如下：b,c在方法内必须定义为final类型 1234567891011private void method()&#123; final Object b = new Object; final Object c = new Object; transactionTemplate.execute(new TransactionCallbackWithoutResult() &#123; @Override protected void doInTransactionWithoutResult(TransactionStatus transactionStatus) &#123; a.update(b); a.update(c); &#125; &#125;);&#125; 对编译时常量的运算JIT会进行常量折叠，如下： 12345static int foo2() &#123; final int a = 2; // 声明常量a final int b = 3; // 声明常量b return a + b; // 常量表达式&#125; 实际代码编译后运行的效果如下：123static int foo3() &#123; return 5;&#125; JAVA局部变量加final修饰的好处参考：https://blog.csdn.net/gdscp/article/details/72901063]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见的错误]]></title>
    <url>%2Fjava-problem.html</url>
    <content type="text"><![CDATA[Error 注入类没有写入容器。 接口的实现类添加带有 @Component 元注解的注解 Description: Field dbConnector in nuc.jyg.controller.ProfileController required a bean of type ‘nuc.jyg.service.DBConnector’ that could not be found. Action: Consider defining a bean of type ‘nuc.jyg.service.DBConnector’ in your configuration. 这个问题之前遇到是因为自己疏漏忘记添加@Component注解，后来发现我的实现类带了@Component注解这个错误还是出现了。原来是因为我的接口有两个实现类，而两个实现类分别作用于不同环境下。而我在properties文件中把 spring.profiles.active 属性注释了。导致Controller中调用服务方法的时候会找不到接口的实现类。就会报类似这样的错 Log： 12345678Description:Field dbConnector in nuc.jyg.controller.ProfileController required a bean of type 'nuc.jyg.service.DBConnector' that could not be found.Action:Consider defining a bean of type 'nuc.jyg.service.DBConnector' in your configuration. application.properties： 123···# spring.profiles.active=testdb··· Interface： 1234public interface DBConnector &#123; public void configure();&#125; achieveClass： 12345678@Component@Profile("testdb")// 测试环境使用 取决于application.properties配置文件的spring.profiles.active属性的配置public class TestDBConnector implements DBConnector &#123; @Override public void configure() &#123; System.out.println("testdb"); &#125;&#125; 12345678@Component@Profile("devdb") // 生产环境使用 取决于application.properties配置文件的spring.profiles.active属性的配置public class DevDBConnector implements DBConnector &#123; @Override public void configure() &#123; System.out.println("devdb"); &#125;&#125; Error 注入类没有写入容器。 移除dependency，重新下载 Cannot resolve symbol ‘log’ 404 看打包发布的jar包中是否包含访问页面。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>常见</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot集成lombok让代码更简洁]]></title>
    <url>%2Fframe-springboot-lombok.html</url>
    <content type="text"><![CDATA[话不多说，先上图： IDEA安装lombok插件 IntelliJ IDEA 定位到 File &gt; Settings &gt; Plugins 点击 Browse repositories… 搜索 Lombok Plugin 点击 Install plugin 重启 IDEA Spring Boot项目中使用lombok 添加lombok依赖 1234567&lt;!-- lombok代码简化 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.16&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 编写一个实体类进行测试 123456@Datapublic class ConfigBean &#123; private String name; private String think;&#125; 编写一个控制类进行访问测试 1234@RequestMapping(path = "/properties", method = RequestMethod.GET)public String configProperties() &#123; return configBean.getName() + ":" + configBean.getThink();&#125; lombok 支持的注解： valFinally! Hassle-free final local variables. @NonNullor: How I learned to stop worrying and love the NullPointerException. @CleanupAutomatic resource management: Call your close() methods safely with no hassle. @Getter/@SetterNever write public int getFoo() {return foo;} again. @ToStringNo need to start a debugger to see your fields: Just let lombok generate a toString for you! @EqualsAndHashCodeEquality made easy: Generates hashCode and equals implementations from the fields of your object.. @NoArgsConstructor, @RequiredArgsConstructor and @AllArgsConstructor Constructors made to order: Generates constructors that take no arguments, one argument per final / non-nullfield, or one argument for every field. @DataAll together now: A shortcut for @ToString, @EqualsAndHashCode, @Getter on all fields, and @Setter on all non-final fields, and @RequiredArgsConstructor! @ValueImmutable classes made very easy. @Builder… and Bob’s your uncle: No-hassle fancy-pants APIs for object creation! @SneakyThrowsTo boldly throw checked exceptions where no one has thrown them before! @Synchronizedsynchronized done right: Don’t expose your locks. @Getter(lazy=true)Laziness is a virtue! @LogCaptain’s Log, stardate 24435.7: “What was that line again?” 官网资料： https://projectlombok.org/features/all 另附两篇中文释意不错的文章： http://blog.csdn.net/ghsau/article/details/52334762 http://himichaelchu.iteye.com/blog/2124409]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解析 SpringBoot 项目的 pom.xml]]></title>
    <url>%2Fframe-springboot-starter.html</url>
    <content type="text"><![CDATA[1. Spring Boot父级依赖123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt; 这块配置就是Spring Boot父级依赖，有了这个，当前的项目就是Spring Boot项目了，spring-boot-starter-parent是一个特殊的starter,它用来提供相关的Maven默认依赖，使用它之后，常用的包依赖可以省去version标签。使用父级依赖提供的默认version。关于Spring Boot提供了哪些jar包的依赖，可查看C:\Users\用户.m2\repository\org\springframework\boot\spring-boot-dependencies\1.5.1.RELEASE\spring-boot-dependencies-1.5.1.RELEASE.pom 123456789101112131415161718&lt;properties&gt; &lt;!-- Dependency versions --&gt; &lt;activemq.version&gt;5.14.3&lt;/activemq.version&gt; &lt;antlr2.version&gt;2.7.7&lt;/antlr2.version&gt; &lt;appengine-sdk.version&gt;1.9.48&lt;/appengine-sdk.version&gt; &lt;artemis.version&gt;1.5.2&lt;/artemis.version&gt; &lt;aspectj.version&gt;1.8.9&lt;/aspectj.version&gt; &lt;assertj.version&gt;2.6.0&lt;/assertj.version&gt; &lt;atomikos.version&gt;3.9.3&lt;/atomikos.version&gt; &lt;bitronix.version&gt;2.1.4&lt;/bitronix.version&gt; &lt;caffeine.version&gt;2.3.5&lt;/caffeine.version&gt; &lt;cassandra-driver.version&gt;3.1.3&lt;/cassandra-driver.version&gt; &lt;classmate.version&gt;1.3.3&lt;/classmate.version&gt; &lt;commons-beanutils.version&gt;1.9.3&lt;/commons-beanutils.version&gt; &lt;commons-collections.version&gt;3.2.2&lt;/commons-collections.version&gt; &lt;spring-data-releasetrain.version&gt;Ingalls-RELEASE&lt;/spring-data-releasetrain.version&gt; ......&lt;/properties&gt; 如果你不想使用某个依赖默认的版本，您还可以通过覆盖自己的项目中的属性来覆盖各个依赖项。如下： 1234567891011&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;version&gt;1.5.3.RELEASE&lt;/version&gt;&lt;/dependency&gt; 2. 起步依赖 spring-boot-starter-xxSpring Boot提供了很多”开箱即用“的依赖模块，都是以spring-boot-starter-xx作为命名的。举个例子来说明一下这个起步依赖的好处，比如组装台式机和品牌机，自己组装的话需要自己去选择不同的零件，最后还要组装起来，期间有可能会遇到零件不匹配的问题。耗时又消力，而品牌机就好一点，买来就能直接用的，后续想换零件也是可以的。相比较之下，后者带来的效果更好点（这里就不讨论价格问题哈），起步依赖就像这里的品牌机，自动给你封装好了你想要实现的功能的依赖。就比如我们之前要实现web功能，引入了spring-boot-starter-web这个起步依赖。我们来看看spring-boot-starter-web到底依赖了哪些，如下图： 看来依赖如此之多，如果让我自己弄估计要调半天，所以Spring Boot通过提供众多起步依赖降低项目依赖的复杂度。起步依赖本质上是一个Maven项目对象模型（Project Object Model，POM），定义了对其他库的传递依赖，这些东西加在一起即支持某项功能。很多起步依赖的命名都暗示了它们提供的某种或者某类功能。 3. Spring Boot Maven插件12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 上面的配置就是Spring Boot Maven插件，Spring Boot Maven插件提供了许多方便的功能： 把项目打包成一个可执行的超级JAR（uber-JAR）,包括把应用程序的所有依赖打入JAR文件内，并为JAR添加一个描述文件，其中的内容能让你用java -jar来运行应用程序。 搜索public static void main()方法来标记为可运行类。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA下maven的正确使用]]></title>
    <url>%2Fjava-idea-maven.html</url>
    <content type="text"><![CDATA[IDEA 下 SpringBoot 项目的运行SpringBoot 项目可以使用命令 mvn spring-boot:run 在命令行启动该应用，IDEA 中该命令在如下位置： 运行之后： 当看到如下命令，并且控制台没有任何异常信息。就可以在浏览器中对 SpringBoot 项目进行访问了。 命令行下 SpringBoot 项目的运行先在 maven 命令中运行 clean 命令，然后再运行 package 命令打包。IDEA 中命令在如下位置： 运行结果：BUILD SUCCESS 运行 mvn package 进行打包时，会打包成一个可以直接运行的 JAR 文件，使用 java -jar 命令就可以直接运行： 没有任何异常信息，运行成功之后就可以对 SpringBoot 项目进行访问了。 Maven有如下几种依赖范围：在引入dependency时，对一些依赖的作用范围梳理不清。 compile:编译依赖范围。如果没有指定，就会默认使用该依赖范围。使用此依赖范围的Maven依赖，对于编译、测试、运行三种classpath都有效。典型的例子是spring-code,在编译、测试和运行的时候都需要使用该依赖。 test: 测试依赖范围。使用次依赖范围的Maven依赖，只对于测试classpath有效，在编译主代码或者运行项目的使用时将无法使用此依赖。典型的例子是Jnuit,它只有在编译测试代码及运行测试的时候才需要。 provided:已提供依赖范围。使用此依赖范围的Maven依赖，对于编译和测试classpath有效，但在运行时候无效。典型的例子是servlet-api,编译和测试项目的时候需要该依赖，但在运行项目的时候，由于容器以及提供，就不需要Maven重复地引入一遍。(测试时不会启动容器，所以用不到容器默认提供的servlet-api，但是测试代码 又需要用到，所以在引入依赖时需要在标签中带上provided)。在项目运行时该依赖就不会起作用]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Java</tag>
        <tag>IDEA</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cookie和Session有什么区别？]]></title>
    <url>%2Fjava-web-cookie-session.html</url>
    <content type="text"><![CDATA[来自知乎：https://www.zhihu.com/question/19786827 cookie保存在客户端，session保存在服务器端cookie目的可以跟踪会话，也可以保存用户喜好或者保存用户名密码session用来跟踪会话 当我们登录网站勾选保存用户名和密码的时候，一般保存的都是cookie，将用户名和密码的cookie保存到硬盘中，这样再次登录的时候浏览器直接将cookie发送到服务端验证，直接username和password保存到客户端，当然这样不安全，浏览器也可以加密解密这样做，每个浏览器都可以有自己的加密解密方式，这样方便了用户，再比如用户喜欢的网页背景色，比如QQ空间的背景，这些信息也是可以通过cookie保存到客户端的，这样登录之后直接浏览器直接就可以拿到相应的偏好设置。 跟踪会话，比如某些网站中网页有不同的访问权限，有只能登录的用户访问的网页或者用户级别不同不能访问的，但是http请求是无状态的，每次访问服务端是不知道是否是登录用户，很自然的想到在http请求报文中加入登录标识就可以了，这个登录标识就可以是cookie，这样的cookie服务端要保存有所有登录用户的cookie，这样请求报文来了之后拿到登录标识cookie，在服务端进行比较久可以了。再比如购物网站，多次点击添加商品到购物车客户端很容易知道哪些物品在购物车中，但是服务端怎么知道每次添加的物品放到哪个登录用户的购物车中呢？也需要请求报文中带着cookie才行（在不登陆的情况下京东也是可以不断添加商品的，推测应该是登录的时候一并创建cookie并且发送物品信息），这些cookie都是为了跟踪会话用的，所以客户端有，服务端也有，并且服务端有全部的会话cookie。 后面衍生出session技术,session技术是要使用到cookie的，之所以出现session技术，主要是为了安全。 http是无状态的协议，客户每次读取web页面时，服务器都打开新的会话，而且服务器也不会自动维护客户的上下文信息，那么要怎么才能实现网上商店中的购物车呢，session就是一种保存上下文信息的机制，它是针对每一个用户的，变量的值保存在服务器端，通过SessionID来区分不同的客户,session是以cookie或URL重写为基础的，默认使用cookie来实现，系统会创造一个名为JSESSIONID的输出cookie，我们叫做session cookie,以区别persistent cookies,也就是我们通常所说的cookie,注意session cookie是存储于浏览器内存中的，并不是写到硬盘上的，这也就是我们刚才看到的JSESSIONID，我们通常情是看不到JSESSIONID的，但是当我们把浏览器的cookie禁止后，web服务器会采用URL重写的方式传递Sessionid，我们就可以在地址栏看到 sessionid=KWJHUG6JJM65HS2K6之类的字符串。 大家请看在HTTP请求报文头的最后一行有cookie，不过是JSessionID的cookie值 Cookie: $Version=1; Skin=new;jsessionid=5F4771183629C9834F8382E23BE13C4C 比如前两个值，应该属于偏好设置之类的。 服务端是怎么知道客户端的多个请求是隶属于一个Session呢？注意到后台的那个jsessionid=5F4771183629C9834F8382E23BE13C4C木有？原来就是通过HTTP请求报文头的Cookie属性的jsessionid的值关联起来的！（当然也可以通过重写URL的方式将会话ID附带在每个URL的后面哦）。​ 明白了原理，我们就可以很容易的分辨出persistent cookies和session cookie的区别了，网上那些关于两者安全性的讨论也就一目了然了，session cookie针对某一次会话而言，会话结束session cookie也就随着消失了，而persistent cookie只是存在于客户端硬盘上的一段文本（通常是加密的），而且可能会遭到cookie欺骗以及针对cookie的跨站脚本攻击，自然不如 session cookie安全了。 通常session cookie是不能跨窗口使用的，当你新开了一个浏览器窗口进入相同页面时，系统会赋予你一个新的sessionid，这样我们信息共享的目的就达不到了，此时我们可以先把sessionid保存在persistent cookie中，然后在新窗口中读出来，就可以得到上一个窗口SessionID了，这样通过session cookie和persistent cookie的结合我们就实现了跨窗口的session tracking（会话跟踪）。 在一些web开发的书中，往往只是简单的把Session和cookie作为两种并列的http传送信息的方式，session cookies位于服务器端，persistent cookie位于客户端，可是session又是以cookie为基础的，明白的两者之间的联系和区别，我们就不难选择合适的技术来开发web service了。 部分参考自：session与cookie的区别** 举个QQ空间的例子： 当我们登录QQ空间的时候，可以选择保存用户名和密码，这样下次登录的时候浏览器可以自动填充或者自动登陆，此时使用的是cookie技术，将于 http://qzone.qq.com/ 域名对应的cookie保存到硬盘中，下次访问的时候浏览器查找保存在硬盘中的与该域名对应的cookie填充。 登录之后，我们可能做些操作，比如删除日志，发表说说，这些只有登录用户才能做的事情可以使用cookie也可以使用session进行会话跟踪 空间的喜好设置可以保存到硬盘cookie当中。 其实说白了session就是用来保存会话的cookie。下面介绍下Java中Servlet的session管理 http://lavasoft.blog.51cto.com/62575/275589 深入理解HTTP Session session在web开发中是一个非常重要的概念，这个概念很抽象，很难定义，也是最让人迷惑的一个名词，也是最多被滥用的名字之一，在不同的场合，session一次的含义也很不相同。这里只探讨HTTP Session。 为了说明问题，这里基于Java Servlet理解Session的概念与原理，这里所说Servlet已经涵盖了JSP技术，因为JSP最终也会被编译为Servlet，两者有着相同的本质。 在Java中，HTTP的Session对象用javax.servlet.http.HttpSession来表示。 概念：Session代表服务器与浏览器的一次会话过程，这个过程是连续的，也可以时断时续的。在Servlet中，session指的是HttpSession类的对象，这个概念到此结束了，也许会很模糊，但只有看完本文，才能真正有个深刻理解。 Session创建的时间是： 一个常见的误解是以为session在有客户端访问时就被创建，然而事实是直到某server端程序调用 HttpServletRequest.getSession(true)这样的语句时才被创建，注意如果JSP没有显示的使用 &lt;% @page session=”false”%&gt; 关闭session，则JSP文件在编译成Servlet时将会自动加上这样一条语句 HttpSession session = HttpServletRequest.getSession(true);这也是JSP中隐含的 session对象的来历。由于session会消耗内存资源，因此，如果不打算使用session，应该在所有的JSP中关闭它。 引申： 访问*.html的静态资源因为不会被编译为Servlet，也就不涉及session的问题。 当JSP页面没有显式禁止session的时候，在打开浏览器第一次请求该jsp的时候，服务器会自动为其创建一个session，并赋予其一个sessionID，发送给客户端的浏览器。以后客户端接着请求本应用中其他资源的时候，会自动在请求头上添加： Cookie:JSESSIONID=客户端第一次拿到的session ID 这样，服务器端在接到请求时候，就会收到session ID，并根据ID在内存中找到之前创建的session对象，提供给请求使用。这也是session使用的基本原理—-搞不懂这个，就永远不明白session的原理。下面是两次请求同一个jsp，请求头信息： 通过图可以清晰发现，第二次请求的时候，已经添加session ID的信息。 Session删除的时间是： Session超时：超时指的是连续一定时间服务器没有收到该Session所对应客户端的请求，并且这个时间超过了服务器设置的Session超时的最大时间。 程序调用HttpSession.invalidate() 服务器关闭或服务停止 session存放在哪里： 服务器端的内存中。不过session可以通过特殊的方式做持久化管理。 session的id是从哪里来的，sessionID是如何使用的：当客户端第一次请求session对象时候，服务器会为客户端创建一个session，并将通过特殊算法算出一个session的ID，用来标识该session对象，当浏览器下次（session继续有效时）请求别的资源的时候，浏览器会偷偷地将sessionID放置到请求头中，服务器接收到请求后就得到该请求的sessionID，服务器找到该id的session返还给请求者（Servlet）使用。一个会话只能有一个session对象，对session来说是只认id不认人。 session会因为浏览器的关闭而删除吗？ 不会，session只会通过上面提到的方式去关闭。 同一客户端机器多次请求同一个资源，session一样吗？ 一般来说，每次请求都会新创建一个session。 其实，这个也不一定的，总结下：对于多标签的浏览器（比如360浏览器）来说，在一个浏览器窗口中，多个标签同时访问一个页面，session是一个。对于多个浏览器窗口之间，同时或者相隔很短时间访问一个页面，session是多个的，和浏览器的进程有关。对于一个同一个浏览器窗口，直接录入url访问同一应用的不同资源，session是一样的。 session是一个容器，可以存放会话过程中的任何对象。 session因为请求（request对象）而产生，同一个会话中多个request共享了一session对象，可以直接从请求中获取到session对象。 其实，session的创建和使用总在服务端，而浏览器从来都没得到过session对象。但浏览器可以请求Servlet（jsp也是Servlet）来获取session的信息。客户端浏览器真正紧紧拿到的是session ID，而这个对于浏览器操作的人来说，是不可见的，并且用户也无需关心自己处于哪个会话过程中。 比如下面一段使用session的代码 123456789101112131415161718192021222324252627282930public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException&#123; response.setContentType("text/html"); response.setCharacterEncoding("utf-8"); PrintWriter out = response.getWriter(); // 得到用户名和密码，验证 String u = request.getParameter("username"); String p = request.getParameter("password"); UserBeanBO ubb = new UserBeanBO(); if (ubb.checkUser(u, p)) &#123; // 1.把成功登陆的用户所有信息放入session UserBean ub = ubb.getUserBean(u); request.getSession().setAttribute("userInfo", ub); // 2.把购物车的信息取出 MyCartBO mcb = (MyCartBO)request.getSession().getAttribute("mycart"); ArrayList al = mcb.showMyCart(); // 把al放入request request.setAttribute("mycartInfo", al); // 用户合法 request.getRequestDispatcher("success.jsp").forward(request,response); &#125; else &#123; // 用户不合法 request.getRequestDispatcher("error.jsp").forward(request, response); &#125;&#125; 12345678910HttpSession javax.servlet.http.HttpServletRequest.getSession()Returns the current session associated with this request, or if the request does not have a session, creates one.Returns: the HttpSession associated with this requestSee Also:getSession(boolean) javax.servlet.http.HttpServletRequest.getSession() 将会返回当前request相关联的HttpSession对象，如果不存在，将会创建一个。 翻译一下，当一个浏览器请求来到之后，Servlet处理程序（Servlet容器内部实现）将会主动检查请求信息Cookie当中是否有JSESSIONID，若有，找到对应JSESSION的HttpSession对象，如果没有，创建一个，具体的机制在Servlet容器的实现当中。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Illuos1ion-picture]]></title>
    <url>%2FIlluos1ion-picture.html</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[Illuos1ion-picture-nan]]></title>
    <url>%2FIlluos1ion-picture-nan.html</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java 单例模式]]></title>
    <url>%2FdesignPatterns-singleton.html</url>
    <content type="text"><![CDATA[Java中单例模式是一种常见的设计模式，单例模式总共有7种写法。 懒汉，线程不安全 懒汉，线程安全 饿汉 饿汉，变种 静态内部类 枚举 双重校验锁 这里针对常用的单例模式的实现方式主要介绍两种：懒汉式(饱汉式)单例、饿汉式单例。若对其他几种实现方式感兴趣可以移步这里 首先单例模式有以下特点： 1、单例类只能有一个实例。2、单例类必须自己创建自己的唯一实例。3、单例类必须给所有其他对象提供这一实例的访问权限。 单例模式确保某个类只有一个实例，而且自行实例化并向整个系统提供这个实例。在计算机系统中，线程池、缓存、日志对象、对话框、打印机、显卡的驱动程序对象常被设计成单例。这些应用都或多或少具有资源管理器的功能。每台计算机可以有若干个打印机，但只能有一个Printer Spooler，以避免两个打印作业同时输出到打印机中。每台计算机可以有若干通信端口，系统应当集中管理这些通信端口，以避免一个通信端口同时被两个请求同时调用。总之，选择单例模式就是为了避免不一致状态，避免政出多头。 懒汉式单例123456789101112131415//懒汉式单例类.在第一次调用的时候才实例化自己 public class Singleton &#123; private Singleton() &#123; &#125; private static Singleton single = null; //静态工厂方法 public static Singleton getInstance() &#123; if (single == null) &#123; single = new Singleton(); &#125; return single; &#125;&#125; 该方式的优点是： 写起来比较简单，当类SingletonTest被加载的时候，静态变量static的single未被创建并分配内存空间，当getInstance方法第一次被调用时，初始化single变量，并分配内存，因此在某些特定条件下会节约了内存； 缺点是： 并发环境下很可能出现多个SingletonTest实例。没有考虑线程安全问题，它是线程不安全的 要实现线程安全，有以下三种方式，都是对getInstance这个方法改造，保证了懒汉式单例的线程安全。 第一种方法，在getInstance方法上加synchronized关键字，实现同步。但同步方法反复调用的时候效率较低123456public static synchronized Singleton getInstance() &#123; if (single == null) &#123; single = new Singleton(); &#125; return single;&#125; 第二种方法，双重检查锁定。同步代码块，方法的判断代码中对Singleton类上锁。这种方式是单例模式的最佳实现。内存占用低，效率高，线程安全，多线程操作原子性。12345678910public static Singleton getInstance()&#123; if(singleton==null)&#123; synchronized (Singleton.class)&#123; if(singleton==null)&#123; singleton=new Singleton(); &#125; &#125; &#125; return singleton;&#125; 第三种方法，静态内部类。利用了classloder的机制来保证初始化INSTANCE时只有一个线程123456789101112public class Singleton &#123; private static class LazyHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton() &#123; &#125; public static final Singleton getInstance() &#123; return LazyHolder.INSTANCE; &#125;&#125; 饿汉式123456789101112131415public class SingletonTest &#123; // 定义一个私有的构造方法 private SingletonTest() &#123; &#125; // 将自身的实例对象设置为一个属性,并加上Static和final修饰符 private static final SingletonTest singleton = new SingletonTest(); // 静态方法返回该类的实例 public static SingletonTest getInstancei() &#123; return singleton; &#125;&#125; 该方式的优点是：写起来比较简单，而且不存在多线程同步问题，避免了synchronized所造成的性能问题； 缺点是：当类SingletonTest被加载的时候，会初始化static的singleton，静态变量被创建并分配内存空间，从这以后，这个static的singleton对象便一直占着这段内存（即便你还没有用到这个实例），当类被卸载时，静态变量被摧毁，并释放所占有的内存，因此在某些特定条件下会耗费内存。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 抽象工厂模式]]></title>
    <url>%2FdesignPatterns-abstractFactory.html</url>
    <content type="text"><![CDATA[例子背景：随着Ipone手机的销售火热。同时在组装Ipone手机的时候我们需要考虑到手机壳，手机其他配件等其他配件的匹配组装。于是这个工厂开始生产手机壳和其余手机配件，用来组装手机。这时候工厂有两个系列的产品:手机壳和其余配件。Iphone7系列配置A型号手机壳和A型号其余配件，Iphone8系列配置B型号手机壳和B型号其余配件。 概念：抽象工厂模式是工厂方法模式的升级版本，他用来创建一组相关或者相互依赖的对象。比如Iphone7系列使用A型号手机壳和A型号其余配件，而Iphone8系列使用B型号手机壳和B型号其余配件。那么使用抽象工厂模式，在为Iphone7系列生产相关配件时，就无需制定配件的型号，它会自动根据手机型号生产对应的配件型号A。 当每个抽象产品都有多于一个的具体子类的时候（手机壳有型号A和B两种，其余手机配件也有型号A和B两种），工厂角色怎么知道实例化哪一个子类呢？比如每个抽象产品角色都有两个具体产品（产品手机壳有两个具体产品手机壳A和手机壳B）。抽象工厂模式提供两个具体工厂角色（Iphone7系列工厂和Iphone8系列工厂），分别对应于这两个具体产品角色，每一个具体工厂角色只负责某一个产品角色的实例化。每一个具体工厂类只负责创建抽象产品的某一个具体子类的实例。 产品类：123456789101112131415161718192021222324252627282930313233//手机壳以及型号 public interface PhoneCase &#123;&#125;public class PhoneCaseA implements PhoneCase &#123; public PhoneCaseA() &#123; System.out.println("制造--&gt;PhoneCase"); &#125;&#125;public class PhoneCaseB implements PhoneCase &#123; public PhoneCaseB() &#123; System.out.println("制造--&gt;PhoneCaseB"); &#125;&#125;//其余手机配件以及型号 public interface Debris &#123;&#125;public class DebrisA implements Debris &#123; public DebrisA() &#123; System.out.println("制造--&gt;DebrisA"); &#125;&#125;public class DebrisB implements Debris &#123; public DebrisB() &#123; System.out.println("制造--&gt;DebrisB"); &#125;&#125; 工厂类：12345678910111213141516171819202122232425262728293031323334353637//创建工厂的接口 public interface AbstractFactory &#123; //制造手机壳 public PhoneCase createPhoneCase(); //制造其余配件 public Debris createDebris();&#125;//为Iphone7系列生产配件 public class FactoryIphone7 implements AbstractFactory &#123; @Override public PhoneCase createPhoneCase() &#123; return new PhoneCaseA(); &#125; @Override public Debris createDebris() &#123; return new DebrisA(); &#125;&#125;//Iphone8系列 public class FactoryIphone8 implements AbstractFactory &#123; @Override public PhoneCase createPhoneCase() &#123; return new PhoneCaseB(); &#125; @Override public Debris createDebris() &#123; return new DebrisB(); &#125;&#125; 客户类：12345678910111213public class Customer &#123; public static void main(String[] args) &#123; //生产Iphone7系列配件 FactoryIphone7 factoryIphone7 = new FactoryIphone7(); factoryIphone7.createPhoneCase(); factoryIphone7.createDebris(); //生产Iphone8系列配件 FactoryIphone8 factoryIphone8 = new FactoryIphone8(); factoryIphone8.createPhoneCase(); factoryIphone8.createDebris(); &#125;&#125; 总结：在使用时，经常你会发现，明明使用的工厂方法模式，当新需求来临，稍加修改，加入了一个新方法后，由于类中的产品构成了不同等级结构中的产品族，它就变成抽象工厂模式了；而对于抽象工厂模式，当减少一个方法使得提供的产品不再构成产品族之后，它就演变成了工厂方法模式。 所以，在使用工厂模式时，只需要关心降低耦合度的目的是否达到了。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 工厂模式]]></title>
    <url>%2FdesignPatterns-Factory.html</url>
    <content type="text"><![CDATA[一、工厂模式主要是为创建对象提供过渡接口，以便将创建对象的具体过程屏蔽隔离起来，达到提高灵活性的目的。 1.首先我们应该简单明确Java代码规范的开闭原则： 对扩展开放；对修改封闭 在明确了java的规范之后，来看所谓的工厂模式。 2.工厂模式在很多地方区分不同，有些地方把它严格区分为三类，简单工厂模式，工厂方法模式，(抽象工厂模式)。大部分时候我们将他们区分为两类，即工厂方法模式，抽象工厂模式。原因看完即懂 1）简单工厂模式（Simple Factory）：不利于产生系列产品、违背了开闭原则、该模式下的工厂类我们一般称它为上帝类或者全能类； 2）工厂方法模式（Factory Method）：又称为多形性工厂、符合开闭原则、但不适合产品中类非常多的情况下，因为会出现大量与之对应的工厂对象。 3）抽象工厂模式（Abstract Factory）：又称为工具箱，产生产品族，但不利于产生新的产品； 这三种模式从上到下逐步抽象，并且更具一般性。 简单工厂模式1）简单工厂模式，属于类的创新型模式，又叫静态工厂方法模式,是通过专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类，或实现了统一的接口。 2）简单工厂模式就是通过一个”全能类”，根据外界传递的信息来决定创建哪个具体类的对象。 产品类：12345678910111213141516171819abstract class Iphone &#123; public Iphone() &#123; &#125;&#125;public class Iphone7 extends Iphone &#123; public Iphone7() &#123; System.out.println("制造--&gt;Iphone7"); &#125;&#125;public class Iphone8 extends Iphone &#123; public Iphone8() &#123; System.out.println("制造--&gt;Iphone8"); &#125;&#125; 工厂类：1234567891011121314151617public class Factory &#123; public Iphone createIphone(int type) &#123; switch (type) &#123; case 7: return new Iphone7(); case 8: return new Iphone8(); default: break; &#125; return null; &#125;&#125; 客户类：1234567public class Customer &#123; public static void main(String[] args) &#123; Factory factory = new Factory(); Iphone iphone7 =factory.createIphone(7); Iphone iphone8 =factory.createIphone.(8); &#125;&#125; 总结： 由以上简单的几行代码可以看出，简单工厂模式严重违背了“开闭原则”，并且难以拓展，所以由此产生了工厂方法模式。 工厂方法模式1）工厂方法模式，是对简单工厂模式进行了抽象化，符合“开闭原则”，实现了可扩展。 2）工厂方法模式的意义是定义一个创建产品对象的工厂接口，将实际创建工作推迟到子类当中。核心工厂类不再负责产品的创建，这样核心类成为一个抽象工厂角色，仅负责具体工厂子类必须实现的接口，这样进一步抽象化的好处是使得工厂方法模式可以使系统在不修改具体工厂角色的情况下引进新的产品。 3）工厂方法模式组成： 抽象工厂角色： 这是工厂方法模式的核心，它与应用程序无关。是具体工厂角色必须实现的接口或者必须继承的父类。在java中它由抽象类或者接口来实现。 具体工厂角色：它含有和具体业务逻辑有关的代码。由应用程序调用以创建对应的具体产品的对象。 抽象产品角色：它是具体产品继承的父类或者是实现的接口。在java中一般有抽象类或者接口来实现。 具体产品角色：具体工厂角色所创建的对象就是此角色的实例。在java中由具体的类来实现。 4）工厂方法模式使用继承自抽象工厂角色的多个子类来代替简单工厂模式中的“上帝类”。正如上面所说，这样便分担了对象承受的压力；而且这样使得结构变得灵活 起来——当有新的产品产生时，只要按照抽象产品角色、抽象工厂角色提供的合同来生成，那么就可以被客户使用，而不必去修改任何已有 的代码。可以看出工厂角色的结构也是符合开闭原则的！ 5）工厂方法模式使用场景： 如组装手机的代工厂。从手机原料工厂获取外壳、显示屏、主板、按键、电池等配件进行组装。组装手机工厂只负责手机的装配，而不负责配件的生产，也不需要关心从手机原料工厂出来的配件是否改变，只要手机各个配置衔接的接口不变就行。比如原料工厂显示屏从TFT 的换成了UFB的显示屏，对于组装手机的代工厂来说，只要接口没变，只需要继续装配就行。 产品类：123456789101112131415abstract class Iphone &#123; public Iphone()&#123; &#125; &#125; public class Iphone7 extends Iphone &#123; public Iphone7() &#123; System.out.println("制造--&gt;Iphone7"); &#125; &#125; public class Iphone8 extends Iphone&#123; public Iphone8()&#123; System.out.println("制造--&gt;Iphone8"); &#125; &#125; 创建工厂类：12345678910111213141516171819interface FactoryIphone &#123; Iphone createIphone();&#125;public class FactoryIphone7 implements FactoryIphone &#123; @Override public Iphone7 createIphone() &#123; return new Iphone7(); &#125;&#125;public class FactoryIphone8 implements FactoryIphone &#123; @Override public Iphone8 createIphone() &#123; return new Iphone8(); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 客户类：123456789public class Customer &#123; public static void main(String[] args) &#123; FactoryIphone7 factoryIphone7 = new FactoryIphone7(); Iphone7 iphone7 = factoryIphone7.createIphone(); FactoryIphone8 factoryIphone8 = new FactoryIphone8(); Iphone8 iphone8 = factoryIphone8.createIphone(); &#125; &#125; 总结：工厂模式的好处就在于提供创建的产品接口给使用者就行，无论产品的类型如何变化，只要根据接口创建的产品的功能没有变化，使用者就无须做任何变动。 工厂方法模式仿佛已经很完美的对对象的创建进行了包装，使得客户程序中仅仅处理抽象产品角色提供的接口，但使得对象的数量成倍增长。当产品种类非常多时，会出现大量的与之对应的工厂对象，这不是我们所希望的。 以上就是简单工厂模式，工厂方法模式，抽象工厂模式在这里。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + HiKariCP]]></title>
    <url>%2Fframe-springboot-HiKariCP.html</url>
    <content type="text"><![CDATA[HiKariCP是数据库连接池的一个后起之秀，号称性能最好，可以完美地PK掉其他连接池。总的来说就一个字，快！ 该项目托管于github： 官网地址：github:https://github.com/brettwooldridge/HikariCP 为什么HikariCP被号称为性能最好的Java数据库连接池，如何配置使用： 原文地址：http://blog.csdn.net/clementad/article/details/46928621 数据库连性池性能测试(hikariCP,druid,tomcat-jdbc,dbcp,c3p0)： 原文地址： http://www.tuicool.com/articles/qayayiM pom.xml： 123456789101112131415161718&lt;!-- 移除 Tomcat 连接池，使用 HikariCP --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-jdbc&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 移除 tomcat-jdbc, Spring Boot 将会自动使用 HikariCP --&gt;&lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>HikariCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + MariaDB]]></title>
    <url>%2Fframe-springboot-MariaDB.html</url>
    <content type="text"><![CDATA[首先来看维基上对MariaDB的描述： MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可。开发这个分支的原因之一是：甲骨文公司收购了MySQL后，有将MySQL闭源的潜在风险，因此社区采用分支的方式来避开这个风险。 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，10.0.9版起使用XtraDB（名称代号为Aria&amp;action=edit&amp;redlink=1)）来代替MySQL的InnoDB。 过去一年中，大型互联网用户以及Linux发行商纷纷抛弃MySQL，转投MariaDB阵营。MariaDB是目前最受关注的MySQL数据库衍生版，也被视为开源数据库MySQL的替代品。 MariaDB虽然被视为MySQL数据库的替代品，但它在扩展功能、存储引擎以及一些新的功能改进方面都强过MySQL。而且从MySQL迁移到MariaDB也是非常简单的： 数据和表定义文件（.frm）是二进制兼容的 所有客户端API、协议和结构都是完全一致的 所有文件名、二进制、路径、端口等都是一致的 所有的MySQL连接器，比如PHP、Perl、Python、Java、.NET、MyODBC、Ruby以及MySQL C connector等在MariaDB中都保持不变 mysql-client包在MariaDB服务器中也能够正常运行 共享的客户端库与MySQL也是二进制兼容的 也就是说，在大多数情况下，你完全可以卸载MySQL然后安装MariaDB，然后就可以像之前一样正常的运行。 如下是支持MariaDB的客户端工具： DBEdit 一个免费的MariaDB数据库和其他数据库管理应用程序。 Navicat 一系列Windows、Mac OS X、Linux下专有数据库管理应用程序。 HeidiSQL 一个Windows上自由和开放源码的MySQL客户端。它支持MariaDB的5.2.7版本和以后的版本。(在用) phpMyAdmin 一个基于网络的MySQL数据库管理应用程序 pom.xml： 123456&lt;!-- Mariadb 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mariadb.jdbc&lt;/groupId&gt; &lt;artifactId&gt;mariadb-java-client&lt;/artifactId&gt; &lt;version&gt;1.5.9&lt;/version&gt; &lt;/dependency&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>MariaDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot启动原理解析]]></title>
    <url>%2Fframe-springboot-run.html</url>
    <content type="text"><![CDATA[启动类：123456@SpringBootApplicationpublic class SpringbootInitialApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootInitialApplication.class, args); &#125;&#125; 接下来着重分析两点： @SpringBootApplication SpringApplication.run SpringBootApplication123456789101112@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123;...&#125; 这里实际重要的只有三个注解： @Configuration（@SpringBootConfiguration点开查看发现里面还是应用了@Configuration） @EnableAutoConfiguration @ComponentScan 所以，如果使用如下的SpringBoot启动类，与之前的启动类功能一致： 12345678@Configuration@EnableAutoConfiguration@ComponentScanpublic class SpringbootInitialApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootInitialApplication.class, args); &#125;&#125; 当然我选择比较懒的方式。推荐使用@SpringBootApplication。 @Configuration @Configuration对我们来说不陌生，它就是JavaConfig形式的Spring Ioc容器的配置类使用的那个@Configuration，SpringBoot社区推荐使用基于JavaConfig的配置形式，所以，这里的启动类标注了@Configuration之后，本身其实也是一个IOC容器的配置类。 简单回顾下，XML跟config配置方式的区别： 表达形式层面 基于XML配置的方式是这样： 1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd" default-lazy-init="true"&gt; &lt;!--bean定义--&gt;&lt;/beans&gt; 基于JavaConfig的配置方式是这样： 1234@Configurationpublic class MockConfiguration&#123; //bean定义&#125; 任何一个标注了@Configuration的Java类定义都是一个JavaConfig配置类。 注册bean定义层面 基于XML的配置形式是这样： 123&lt;bean id="mockService" class="..MockServiceImpl"&gt; ...&lt;/bean&gt; 基于JavaConfig的配置形式是这样： 1234567@Configurationpublic class MockConfiguration&#123; @Bean public MockService mockService()&#123; return new MockServiceImpl(); &#125;&#125; 任何一个标注了@Bean的方法，其返回值将作为一个bean定义注册到Spring的IOC容器(返回值对应xml配置文形式中的class属性)，方法名将默认成该bean定义的id。 表达依赖注入关系层面 为了表达bean与bean之间的依赖关系，在XML形式中一般是这样： 12345&lt;bean id="mockService" class="..MockServiceImpl"&gt; &lt;propery name ="dependencyService" ref="dependencyService" /&gt;&lt;/bean&gt;&lt;bean id="dependencyService" class="DependencyServiceImpl"&gt;&lt;/bean&gt; 基于JavaConfig的配置形式是这样的： 123456789101112@Configurationpublic class MockConfiguration&#123; @Bean public MockService mockService()&#123; return new MockServiceImpl(dependencyService());// 这里直接向MockServiceImpl的构造方法中调用依赖bean的创建方法即可 &#125; @Bean public DependencyService dependencyService()&#123; return new DependencyServiceImpl(); &#125;&#125; 如果一个bean的定义依赖其他bean,则直接调用对应的JavaConfig类中依赖的bean的创建方法就可以了。 @ComponentScan @ComponentScan这个注解在Spring中很重要，它对应XML配置中的元素，@ComponentScan的功能其实就是自动扫描并加载符合条件的组件（比如@Component和@Repository等）或者bean定义，最终将这些bean定义加载到IoC容器中。 我们可以通过basePackages等属性来细粒度的定制@ComponentScan自动扫描的范围，如果不指定，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。 注：所以SpringBoot的启动类最好是放在root package下，因为默认不指定basePackages。 @EnableAutoConfigurationSpring框架提供了各种名字为@Enable开头的Annotation定义。比如@EnableScheduling，@EnableCaching，@EnableMBeanExport等，@EnableAutoConfiguration的理念和做事方式其实一脉相承，简单概括一下就是：借助@Import的支持，收集和注册特定场景相关的bean。 @EnableScheduling是通过@Import将Spring调度框架相关的bean定义都加载到IOC容器。 @EnableMBeanExport是通过@Import将JMX相关的bean定义加载到IOC容器。 而@EnableAutoConfiguration也是借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IOC容器，仅此而已！ @EnableAutoConfiguration作为一个复合Annotation,其自身定义关键信息如下： 12345678910@SuppressWarnings("deprecation")@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(EnableAutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; ...&#125; @Import其中，最关键的是@Import(EnableAutoConfigurationImportSelector.class)： 借助EnableAutoConfigurationImportSelector类，@EnableAutoConfiguration可以帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot项目创建并使用的IOC容器。(注入作用) 就像一只“八爪鱼”一样。借助于Spring框架原有的一个工具类：SpringFactoriesLoader的支持，@EnableAutoConfiguration可以智能的自动配置功效才得以大功告成！(扫描作用) SpringFactoriesLoader SpringFactoriesLoader属于Spring框架私有的一种扩展方案，其主要功能就是从指定的配置文件META-INF/spring.factories加载配置。 1234567891011public abstract class SpringFactoriesLoader &#123; // factoryClass public static &lt;T&gt; List&lt;T&gt; loadFactories(Class&lt;T&gt; factoryClass, ClassLoader classLoader) &#123; ... &#125; // factoryClass public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123; .... &#125;&#125; 配合@EnableAutoConfiguration使用的话，它更多是提供一种配置查找的功能支持，即根据@EnableAutoConfiguration的完整类名org.springframework.boot.autoconfigure.EnableAutoConfiguration作为查找的Key,获取对应的一组@Configuration类 上图就是从SpringBoot的autoconfigure依赖包中的META-INF/spring.factories配置文件中摘录的一段内容，可以很好地说明问题。 所以，@EnableAutoConfiguration自动配置就变成了：从classpath中搜寻所有的META-INF/spring.factories配置文件，并将其中org.springframework.boot.autoconfigure.EnableutoConfiguration对应的配置项通过反射（Java Refletion）实例化为对应的标注了@Configuration的JavaConfig形式的IOC容器配置类，然后汇总为一个并加载到IOC容器。 SpringApplication执行流程SpringApplication的run方法实现流程： 如果我们使用的是SpringApplication的静态run方法，那么，这个方法里面首先要创建一个SpringApplication对象实例，然后调用这个创建好的SpringApplication的实例方法。在SpringApplication实例初始化的时候，它会提前做几件事情： 根据classpath里面是否存在某个特征类（org.springframework.web.context.ConfigurableWebApplicationContext）来决定是否应该创建一个为Web应用使用的ApplicationContext类型。 使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationContextInitializer。 使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationListener。 推断并设置main方法的定义类。 SpringApplication实例初始化完成并且完成设置后，就开始执行run方法的逻辑了，方法执行伊始，首先遍历执行所有通过SpringFactoriesLoader可以查找到并加载的SpringApplicationRunListener。调用它们的started()方法，告诉这些SpringApplicationRunListener，SpringBoot应用要开始执行了。(启动监听器) 创建并配置当前Spring Boot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）。将配置文件中的配置信息应用到SpringBoot的上下文中 123456private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123; // 关键代码 ConfigurableEnvironment environment = this.getOrCreateEnvironment(); this.configureEnvironment((ConfigurableEnvironment)environment, applicat ··· &#125; 遍历调用所有SpringApplicationRunListener的environmentPrepared()的方法，告诉他们：当前SpringBoot应用使用的Environment准备好了。(函数回调) 123456private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners, ApplicationArguments applicationArguments) &#123;// 回调函数 ··· // 关键代码 listeners.environmentPrepared((ConfigurableEnvironment)environment); ··· &#125; 如果SpringApplication的showBanner属性被设置为true，则打印banner。 根据用户是否明确设置了applicationContextClass类型以及初始化阶段的推断结果，决定该为当前SpringBoot应用创建什么类型的ApplicationContext并创建完成。 ​ 123456789101112protected ConfigurableApplicationContext createApplicationContext() &#123; Class&lt;?&gt; contextClass = this.applicationContextClass; if(contextClass == null) &#123; try &#123; contextClass = Class.forName(this.webEnvironment?"org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext":"org.springframework.context.annotation.AnnotationConfigApplicationContext"); &#125; catch (ClassNotFoundException var3) &#123; throw new IllegalStateException("Unable create a default ApplicationContext, please specify an ApplicationContextClass", var3); &#125; &#125; return (ConfigurableApplicationContext)BeanUtils.instantiate(contextClass);&#125; 然后根据条件决定是否使用自定义的ResourceLoader， 决定是否使用自定义的BeanNameGenerator， 决定是否添加ShutdownHook， 最重要的，将之前准备好的Environment设置给创建好的ApplicationContext使用。 ApplicationContext创建好之后，SpringApplication会再次借助SpringFactoriesLoader，查找并加载classpath中所有可用的ApplicationContextInitializer，然后遍历调用这些ApplicationContextInitializer的initialize（applicationContext）方法来对已经创建好的ApplicationContext进行进一步的处理。 遍历调用所有SpringApplicationRunListener的contextPrepared()方法。 最核心的一步，将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的IOC容器配置加载到已经准备完毕的ApplicationContext。 遍历调用所有SpringApplicationRunListener的contextLoaded()方法。 调用ApplicationContext的refresh()方法，完成IOC容器可用的最后一道工序。 查找当前ApplicationContext中是否注册有CommandLineRunner，如果有，则遍历执行它们。 正常情况下，遍历执行SpringApplicationRunListener的finished()方法、（如果整个过程出现异常，则依然调用所有SpringApplicationRunListener的finished()方法，只不过这种情况下会将异常信息一并传入处理） 去除事件通知点后，整个流程如下： 总结：SpringBoot的核心组件完成了基本的解析，综合来看，大部分都是Spring框架背后的一些概念和实践方式，SpringBoot只是在这些概念和实践上对特定的场景事先进行了固化和升华，而也恰恰是这些固化让我们开发基于Sping框架的应用更加方便高效。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + log4j2]]></title>
    <url>%2Fframe-springboot-log4j2.html</url>
    <content type="text"><![CDATA[浅谈Log4j和Log4j2的区别： 原文链接：http://blog.csdn.net/fangaohua200/article/details/53561718 pom.xml： 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- 日志 Log4j2 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;version&gt;1.5.3.RELEASE&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot + Devtools(热部署)]]></title>
    <url>%2Fframe-springboot-devtools.html</url>
    <content type="text"><![CDATA[技术介绍devtools：是boot的一个热部署工具，当我们修改了classpath下的文件（包括类文件、属性文件、页面等）时，会重新启动应用（由于其采用的双类加载器机制，这个启动会非常快，如果发现这个启动比较慢，可以选择使用jrebel） 双类加载器机制：boot使用了两个类加载器来实现重启（restart）机制：base类加载器（简称bc）+restart类加载器（简称rc）。 bc：用于加载不会改变的jar（eg.第三方依赖的jar） rc：用于加载我们正在开发的jar（eg.整个项目里我们自己编写的类）。当应用重启后，原先的rc被丢掉、重新new一个rc来加载这些修改过的东西，而bc却不需要动一下。这就是devtools重启速度快的原因。 thymeleaf：boot推荐的模板引擎，这里做简要的介绍，用来介绍devtools对页面的热部署。 项目结构： pom.xml 说明：如果仅仅使用thymeleaf，只需要引入thymeleaf；如果需要使用devtools，只需要引入devtools。 注意：maven中的optional=true表示依赖不会传递。即此处引用的devtools不会传递到依赖myboot项目的项目中。 仅仅加入devtools在我们的IDEA中还不起作用，这时候还需要对之前添加的spring-boot-maven-plugin做一些修改，如下： 即添加了fork:true 对IDEA配置进行修改： CTRL + SHIFT + A –&gt; 查找make project automatically –&gt; 选中 CTRL + SHIFT + A –&gt; 查找Registry –&gt; 找到并勾选compiler.automake.allow.when.app.running 倘若发现还未生效： Chrome禁用缓存 F12(或Ctrl+Shift+J或Ctrl+Shift+I) –&gt; NetWork –&gt; Disable Cache ThymeleafController123456789101112131415161718192021222324package nuc.jyg.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;/** * @Author Nuc YongGuang Ji * Created by JiYongGuang on 2017/4/18. */@Controller@RequestMapping("/thymeleaf")public class ThymeleafController &#123; @RequestMapping(path = &#123;"/interview"&#125;, method = &#123;RequestMethod.GET&#125;) public String interview(@RequestParam(name = "name", required = false, defaultValue = "interview") String name,Model model) &#123; model.addAttribute("templateName",name); return "interview"; &#125;&#125; 说明：Model可以作为一个入参，在代码中，将属性以”key-value”的形式存入model，最后直接返回字符串即可。 interview.html123456789101112&lt;!DOCTYPE html&gt;&lt;html xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"/&gt; &lt;title&gt;thymeleaf程序&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;!--/*@thymesVar id="templateName" type="nuc.jyg.controller.ThymeleafController"*/--&gt;&lt;p th:text="'Hello,' + $&#123;templateName&#125; + '!!!'"&gt;&lt;/p&gt;&lt;div&gt;1234567890!!!!&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 注意：src/main/resources/templates：页面存放目录src/main/resources/static：方式静态文件（css、js等）以上的目录与ssm中开发的不一样，ssm中会放在src/main/webapp下 测试：修改类 –&gt; 保存：应用会重启修改配置文件 –&gt; 保存：应用会重启修改页面 –&gt; 保存：应用不会重启，但会重新加载，页面会刷新（原理是将spring.thymeleaf.cache设为false) 补充：默认情况下: /META-INF/maven，/METAINF/resources，/resources，/static，/templates，/public 这些文件夹下的文件修改不会使应用重启，但是会重新加载（devtools内嵌了一个LiveReload server，当资源发生改变时，浏览器刷新）。 如果想改变默认的设置，可以自己设置不重启的目录： spring.devtools.restart.exclude=static/,public/ 这样的话，就只有这两个目录下的文件修改不会导致restart操作了。 如果要在保留默认设置的基础上还要添加其他的排除目录，使用：： spring.devtools.restart.additional-exclude 如果想要使得当非classpath下的文件发生变化时应用得以重启，使用： spring.devtools.restart.additional-paths 这样devtools就会将该目录列入了监听范围。]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot]]></title>
    <url>%2Fframe-springboot.html</url>
    <content type="text"><![CDATA[application.propertiesSpringboot,classpath路径下的application.properties形式的配置文件中不可以写yaml格式的配置代码。如果写上不会报错，但是无效。application.yaml形式的配置文件中也不能写properties格式的配置代码。如果写上在springboot项目启动的时候会报错。 application.properties和application.yml文件可以放在一下四个位置： 外置，在相对于应用程序运行目录的/congfig子目录里。 外置，在应用程序运行的目录里 内置，在config包内 内置，在Classpath根目录 同样，这个列表按照优先级排序，也就是说，src/main/resources/config下application.properties覆盖src/main/resources下application.properties中相同的属性，如图： 此外，如果你在相同优先级位置同时有application.properties和application.yml，那么application.yml里面的属性就会覆盖application.properties里的属性。 Profile 多环境配置在Spring Boot中多环境配置文件名需要满足application-{profile}.properties的格式，其中{profile}对应你的环境标识，比如： application-dev.properties：开发环境 # info application-prod.properties：生产环境 # warn 想要使用对应的环境，只需要在application.properties中使用spring.profiles.active属性来设置，值对应上面提到的{profile}，这里就是指dev、prod这2个。 Pom.xml如果pom.xml文件中已经继承了 spring-boot-starter-parent，而 spring-boot-starter-parent 又提供了 dependency-management 。那么我们可以忽略被选中依赖的版本(version元素)。12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.0.RELEASE&lt;/version&gt;&lt;/parent&gt; @Bean的作用1234567891011121314151617181920@Configurationpublic class JedisClusterConfig &#123; @Autowired private RedisProperties redisProperties; @Bean public JedisCluster getJedisCluster() &#123; String[] serverArray = redisProperties.getClusterNodes().split(",");//获取服务器数组(这里要相信自己的输入，所以没有考虑空指针问题) Set&lt;HostAndPort&gt; nodes = new HashSet&lt;&gt;(); for (String ipPort : serverArray) &#123; String[] ipPortPair = ipPort.split(":"); nodes.add(new HostAndPort(ipPortPair[0].trim(), Integer.valueOf(ipPortPair[1].trim()))); &#125; return new JedisCluster(nodes, redisProperties.getCommandTimeout()); &#125;&#125; 注意： 在方法上使用@Bean注解可以让方法的返回值为单例 该方法的返回值可以直接注入到其他类中去使用 @Bean注解是方法级别的 如果使用的是常用的spring注解@Component，在方法上没有注解的话，方法的返回值就会是一个多例 该方法的返回值不可以直接注入到其他类去使用 该方式的注解是类级别的 Mybatis123456789101112131415161718192021&lt;!-- 指定工作空间，要与接口名相同，源代码没有去看，猜测应该是通过"这里的namespace.下边方法的id"来定位方法的 --&gt;&lt;mapper namespace="com.xxx.firstboot.mapper.UserMapper"&gt; &lt;!-- 若不需要自动返回主键，将useGeneratedKeys="true" keyProperty="id"去掉即可(当然如果不需要自动返回主键，直接用注解即可) --&gt; &lt;insert id="insertUserWithBackId" parameterType="User" useGeneratedKeys="true" keyProperty="id" &gt; &lt;!-- useGeneratedKeys代表使用数据库自动自增的主键值填充到 作为参数插入的user对象的keyProperty属性id上 --&gt; &lt;![CDATA[ INSERT INTO tb_user ( username, password ) VALUES ( #&#123;username, jdbcType=VARCHAR&#125;, #&#123;password, jdbcType=VARCHAR&#125; ) ]]&gt; &lt;/insert&gt; &lt;/mapper&gt; Swagger @Api：用在类上，说明该类的作用 @ApiOperation：用在方法上，说明方法的作用 @ApiImplicitParams：用在方法上包含一组参数说明 @ApiImplicitParam：用在@ApiImplicitParams注解中，指定一个请求参数的各个方面 paramType：参数放在哪个地方 header–&gt;请求参数的获取：@RequestHeader query–&gt;请求参数的获取：@RequestParam path（用于restful接口）–&gt;请求参数的获取：@PathVariable body（不常用） form（不常用） name：参数名 dataType：参数类型 required：参数是否必须传 value：参数的意思 defaultValue：参数的默认值 @ApiResponses：用于表示一组响应 @ApiResponse：用在@ApiResponses中，一般用于表达一个错误的响应信息 code：数字，例如400 message：信息，例如”请求参数没填好” response：抛出异常的类 @ApiModel：描述一个Model的信息（这种一般用在post创建的时候，使用@RequestBody这样的场景，请求参数无法使用@ApiImplicitParam注解进行描述的时候） @ApiModelProperty：描述一个model的属性 maven packagemaven项目借助于1234&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&lt;/plugin&gt; 打包之后生成的项目的jar包在项目根目录下生成的target目录下。其中项目中所有配置文件及依赖的jar包(均在自动生成的lib目录下)项目的类文件编译生成的class文件。 Starts可以创建自己的Starter，但名字格式不能是 spring-boot-starter-&amp;，而是 &amp;-spring-boot-starter。类似Maven插件的规则。 cmd运行fat jar远程调试12345运行fat jar（executable jar）+ java -jar target/xxxx.jar 注意，是在项目路径下执行。开启远程调试支持：java -Xdebug -Xrunjdwp:server=y,transport=dt_socket,address=8000,suspend=n -jar target/springbootpractice-0.0.1-SNAPSHOT.jar Springdevtools一些特定的资源改变时没有必要引起重启。有一些不会引起重启，但是会重加载。如果你想自定义的设置一下，可以使用 spring.devtools.restart.exclude 属性。如下：spring.devtools.restart.exclude=static/&amp;&amp;,public/&amp;&amp; 如果想在默认的设置之外再添加新的排除选项，可以使用 spring.devtools.restart.additional-exclude 属性。 如果想在修改classpath之外的文件时也让应用重启，可以使用 spring.devtools.restart.additional-paths 属 如果想完全禁止自动重启，需要在调用 SpringApplication.run(..) 之前设置一个System属性。如下： 1234public static void main(String[] args) &#123; System.setProperty("spring.devtools.restart.enabled", "false"); SpringApplication.run(MyApp.class, args);&#125; 静态资源导入需要注意：templates 对外可见。 static 被保护，并且这样引用找不到。templates 目录下的模板与 static 目录下的 assets，css，image，js 目录同级。 1&lt;script src="../static/assets/js/ace-extra.min.js"&gt;&lt;/script&gt; 这样才可以： 1&lt;script src="/assets/js/ace-extra.min.js"&gt;&lt;/script&gt; 或者使用 thymeleaf 语法： 1&lt;script th:src="@&#123;/assets/js/ace-extra.min.js&#125;"&gt;&lt;/script&gt; BootStrap 字体目标： 如图红圈中，内容在复制引用时排除在外。只需复制icon-minus即可。 1&lt;i class="icon-user orange"&gt;&lt;/i&gt;]]></content>
      <categories>
        <category>学习</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
</search>